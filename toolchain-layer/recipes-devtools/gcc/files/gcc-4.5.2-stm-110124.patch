Index: gcc-4.5.2.orig/configure
===================================================================
--- gcc-4.5.2.orig/configure	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/configure	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -774,7 +774,8 @@
 ac_subst_files='serialization_dependencies
 host_makefile_frag
 target_makefile_frag
-alphaieee_frag
+ieee_frag
+relax_frag
 ospace_frag'
 ac_user_opts='
 enable_option_checking
@@ -5782,7 +5783,7 @@
 # Check for PPL
 ppl_major_version=0
 ppl_minor_version=10
-ppllibs=" -lppl_c -lppl -lgmpxx"
+ppllibs=" -lppl_c -lppl -lgmpxx $with_host_libstdcxx"
 pplinc=
 
 
@@ -7389,12 +7390,18 @@
     ;;
 esac
 
-alphaieee_frag=/dev/null
+ieee_frag=/dev/null
 case $target in
-  alpha*-*-*)
+  alpha*-*-* | sh*-*-*)
     # This just makes sure to use the -mieee option to build target libs.
     # This should probably be set individually by each library.
-    alphaieee_frag="config/mt-alphaieee"
+    ieee_frag="config/mt-ieee"
+    ;;
+esac
+
+relax_frag=/dev/null
+case $target in
+  sh-superh-elf)
     ;;
 esac
 
@@ -7977,7 +7984,7 @@
        # to it.  This is right: we don't want to search that directory
        # for binaries, but we want the header files in there, so add
        # them explicitly.
-       FLAGS_FOR_TARGET=$FLAGS_FOR_TARGET' -isystem $$r/$(HOST_SUBDIR)/gcc/include'
+       FLAGS_FOR_TARGET=$FLAGS_FOR_TARGET' -isystem $$r/$(HOST_SUBDIR)/gcc/include  -isystem $$r/$(HOST_SUBDIR)/gcc/include-fixed'
 
        # Someone might think of using the pre-installed headers on
        # Canadian crosses, in case the installed compiler is not fully
@@ -8064,7 +8071,7 @@
 esac
 
 # Makefile fragments.
-for frag in host_makefile_frag target_makefile_frag alphaieee_frag ospace_frag;
+for frag in host_makefile_frag target_makefile_frag ieee_frag ospace_frag relax_frag;
 do
   eval fragval=\$$frag
   if test $fragval != /dev/null; then
Index: gcc-4.5.2.orig/Makefile.in
===================================================================
--- gcc-4.5.2.orig/Makefile.in	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/Makefile.in	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -553,8 +553,9 @@
 
 #### host and target specific makefile fragments come in here.
 @target_makefile_frag@
-@alphaieee_frag@
 @ospace_frag@
+@ieee_frag@
+@relax_frag@
 @host_makefile_frag@
 ###
 
Index: gcc-4.5.2.orig/libgcc/config.host
===================================================================
--- gcc-4.5.2.orig/libgcc/config.host	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/libgcc/config.host	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,6 +1,7 @@
 # libgcc host-specific configuration file.
 # Copyright 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007,
 # 2008, 2009, 2010 Free Software Foundation, Inc.
+# Copyright (c) 2009  STMicroelectronics.
 
 #This file is part of GCC.
 
@@ -519,7 +520,8 @@
    sh64-*-netbsd* | sh64l*-*-netbsd*)
 	case ${host} in
 	sh*-*-linux*)
-		tmake_file="${tmake_file} sh/t-linux"
+		tmake_file="${tmake_file} sh/t-linux sh/t-extra"
+		extra_parts="$extra_parts libgcc-4-200.a libgcc-Os-4-200.a libgcc-4-300.a"
 		;;
 	esac
 	;;
Index: gcc-4.5.2.orig/libgcc/config/sh/t-extra
===================================================================
--- gcc-4.5.2.orig/libgcc/config/sh/t-extra	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/libgcc/config/sh/t-extra	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,18 @@
+sdivsi3_i4i-Os-4-200.o: $(gcc_srcdir)/config/sh/lib1funcs-Os-4-200.asm $(GCC_PASSES)
+	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $@ -DL_sdivsi3_i4i -x assembler-with-cpp $<
+udivsi3_i4i-Os-4-200.o: $(gcc_srcdir)/config/sh/lib1funcs-Os-4-200.asm $(GCC_PASSES)
+	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $@ -DL_udivsi3_i4i -x assembler-with-cpp $<
+OBJS_Os_4_200=sdivsi3_i4i-Os-4-200.o udivsi3_i4i-Os-4-200.o 
+libgcc-Os-4-200.a: $(OBJS_Os_4_200) $(GCC_PASSES)
+	$(AR_CREATE_FOR_TARGET) $@ $(OBJS_Os_4_200)
+
+div_table-4-200.o: $(gcc_srcdir)/config/sh/lib1funcs.asm $(GCC_PASSES)
+	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $@ -DL_div_table -x assembler-with-cpp $<
+libgcc-4-200.a: div_table-4-200.o $(GCC_PASSES)
+	$(AR_CREATE_FOR_TARGET) $@ div_table-4-200.o
+
+div_table-4-300.o: $(gcc_srcdir)/config/sh/lib1funcs-4-300.asm $(GCC_PASSES)
+	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $@ -DL_div_table -x assembler-with-cpp $<
+libgcc-4-300.a: div_table-4-300.o $(GCC_PASSES)
+	$(AR_CREATE_FOR_TARGET) $@ div_table-4-300.o
+
Index: gcc-4.5.2.orig/libgcc/ChangeLog.STM
===================================================================
--- gcc-4.5.2.orig/libgcc/ChangeLog.STM	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/libgcc/ChangeLog.STM	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,5 @@
+2009-07-27  Christian Bruel  <christian.bruel@st.com>
+
+        * config.host (extra_parts): Set for sh*-*-linux.
+	(tmake_file): Add t-extra for sh*-*-linux.
+	* config/sh/t-extra: New file to build optimized libgcc objects.
Index: gcc-4.5.2.orig/ChangeLog.STM
===================================================================
--- gcc-4.5.2.orig/ChangeLog.STM	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/ChangeLog.STM	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,41 @@
+2010-04-12  Christian Bruel  <christian.bruel@st.com>
+
+	* config/mh-mingw (LDFLAGS): Remove wrap rename.
+
+2009-12-07  Yvan Roux  <yvan.roux@st.com>
+
+	* config/mh-mingw (LDFLAGS): Wrap syscall for cygwin path support.
+
+2009-10-22  Christian Bruel  <christian.bruel@st.com>
+
+	* configure.ac: Use include-fixed header path for canadian cross build.
+	* configure: Regenerate.
+
+2009-02-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/mt-ospace: Don't overwrite CFLAGS_FOR_TARGET.
+	* config/mt-relax: Not supported for c++.
+
+2008-05-26  Christian Bruel  <christian.bruel@st.com>
+
+	* config/mt-relax: New file.
+	* Makefile.in: Add relax fragment.
+	* Makefile.tpl: Likewise
+	* configure.ac: Likewise.
+	* configure: Regenerate.
+
+2008-09-30  Christian Bruel  <christian.bruel@st.com>
+
+	* configure.in: Allow libgloss configure for sh.
+	* configure: Regenerate.
+
+2008-05-26  Christian Bruel  <christian.bruel@st.com>
+
+	* config/mt-alphaieee: Removed.
+	* config/mt-ieee: Renamed from mt-alphaieee.
+	* Makefile.in: alphaieee_frag renamed ieee_frag.
+	ieee_frag must be included after ospace_frag.
+	* Makefile.tpl: Likewise
+	* configure.ac: Likewise. Enable for sh.
+	* configure: Regenerate.
+
Index: gcc-4.5.2.orig/gcc/regrename.c
===================================================================
--- gcc-4.5.2.orig/gcc/regrename.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/regrename.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -39,6 +39,7 @@
 #include "timevar.h"
 #include "tree-pass.h"
 #include "df.h"
+#include "expr.h"
 
 #if HOST_BITS_PER_WIDE_INT <= MAX_RECOG_OPERANDS
 #error "Use a different bitmap implementation for untracked_operands."
Index: gcc-4.5.2.orig/gcc/doc/tm.texi
===================================================================
--- gcc-4.5.2.orig/gcc/doc/tm.texi	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/doc/tm.texi	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -3515,6 +3515,13 @@
 linkage is necessary.  The default is @code{0}.
 @end defmac
 
+@defmac TARGET_USES_LEB128
+A C expression that evaluates to true if the target requires leb128
+to be used for dwarf compression.  Define it to be @code{1} if leb128
+linkage is necessary.  The default is @code{1} if @code{HAVE_AS_LEB128}
+is defined.
+@end defmac
+
 @node Stack Checking
 @subsection Specifying How Stack Checking is Done
 
@@ -9478,10 +9485,10 @@
 @code{num_modes_for_mode_switching[@var{entity}] - 1}.
 @end defmac
 
-@defmac EMIT_MODE_SET (@var{entity}, @var{mode}, @var{hard_regs_live})
+@defmac EMIT_MODE_SET (@var{entity}, @var{mode}, @var{flip}, @var{hard_regs_live})
 Generate one or more insns to set @var{entity} to @var{mode}.
 @var{hard_reg_live} is the set of hard registers live at the point where
-the insn(s) are to be inserted.
+the insn(s) are to be inserted. @var{flip} is a boolean to indicate that current mode can be flipped.
 @end defmac
 
 @node Target Attributes
Index: gcc-4.5.2.orig/gcc/doc/gcc.1
===================================================================
--- gcc-4.5.2.orig/gcc/doc/gcc.1	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/doc/gcc.1	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -839,7 +839,7 @@
 \&\-m5\-compact  \-m5\-compact\-nofpu 
 \&\-mb  \-ml  \-mdalign  \-mrelax 
 \&\-mbigtable \-mfmovd \-mhitachi \-mrenesas \-mno\-renesas \-mnomacsave 
-\&\-mieee  \-mbitops  \-misize  \-minline\-ic_invalidate \-mpadstruct  \-mspace 
+\&\-mieee  \-mbitops  \-misize  \-minline\-ic_invalidate \-mpadstruct \-mdead-delay
 \&\-mprefergot  \-musermode \-multcost=\fR\fInumber\fR \fB\-mdiv=\fR\fIstrategy\fR 
 \&\fB\-mdivsi3_libfunc=\fR\fIname\fR \fB\-mfixed\-range=\fR\fIregister-range\fR 
 \&\fB\-madjust\-unroll \-mindexed\-addressing \-mgettrcost=\fR\fInumber\fR \fB\-mpt\-fixed 
@@ -15016,9 +15016,6 @@
 .IX Item "-mpadstruct"
 This option is deprecated.  It pads structures to multiple of 4 bytes,
 which is incompatible with the \s-1SH\s0 \s-1ABI\s0.
-.IP "\fB\-mspace\fR" 4
-.IX Item "-mspace"
-Optimize for space instead of speed.  Implied by \fB\-Os\fR.
 .IP "\fB\-mprefergot\fR" 4
 .IX Item "-mprefergot"
 When generating position-independent code, emit function calls using
Index: gcc-4.5.2.orig/gcc/doc/invoke.texi
===================================================================
--- gcc-4.5.2.orig/gcc/doc/invoke.texi	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/doc/invoke.texi	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,6 +1,7 @@
 @c Copyright (C) 1988, 1989, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,
 @c 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010
 @c Free Software Foundation, Inc.
+@c Copyright (c) 2009  STMicroelectronics.
 @c This is part of the GCC manual.
 @c For copying conditions, see the file gcc.texi.
 
@@ -229,6 +230,7 @@
 @xref{Warning Options,,Options to Request or Suppress Warnings}.
 @gccoptlist{-fsyntax-only  -pedantic  -pedantic-errors @gol
 -w  -Wextra  -Wall  -Waddress  -Waggregate-return  -Warray-bounds @gol
+-Wbranch-probabilities-computation
 -Wno-attributes -Wno-builtin-macro-redefined @gol
 -Wc++-compat -Wc++0x-compat -Wcast-align  -Wcast-qual  @gol
 -Wchar-subscripts -Wclobbered  -Wcomment @gol
@@ -248,7 +250,7 @@
 -Wmain  -Wmissing-braces  -Wmissing-field-initializers @gol
 -Wmissing-format-attribute  -Wmissing-include-dirs @gol
 -Wmissing-noreturn  -Wno-mudflap @gol
--Wno-multichar  -Wnonnull  -Wno-overflow @gol
+-Wno-multichar  -Wnonnull -Wnon-finite-math -Wno-overflow @gol
 -Woverlength-strings  -Wpacked  -Wpacked-bitfield-compat  -Wpadded @gol
 -Wparentheses  -Wpedantic-ms-format -Wno-pedantic-ms-format @gol
 -Wpointer-arith  -Wno-pointer-to-int-cast @gol
@@ -820,16 +822,18 @@
 -m2a-nofpu -m2a-single-only -m2a-single -m2a @gol
 -m3  -m3e @gol
 -m4-nofpu  -m4-single-only  -m4-single  -m4 @gol
+-m4-300-nofpu  -m4-300-single-only  -m4-300-single  -m4-300 @gol
 -m4a-nofpu -m4a-single-only -m4a-single -m4a -m4al @gol
 -m5-64media  -m5-64media-nofpu @gol
 -m5-32media  -m5-32media-nofpu @gol
 -m5-compact  -m5-compact-nofpu @gol
--mb  -ml  -mdalign  -mrelax @gol
+-mb  -ml  -mdalign  -mtas -mno-tas -mrelax @gol
 -mbigtable -mfmovd -mhitachi -mrenesas -mno-renesas -mnomacsave @gol
--mieee  -mbitops  -misize  -minline-ic_invalidate -mpadstruct  -mspace @gol
+-mieee  -mbitops  -misize  -minline-ic_invalidate -mpadstruct -mdead-delay @gol
 -mprefergot  -musermode -multcost=@var{number} -mdiv=@var{strategy} @gol
 -mdivsi3_libfunc=@var{name} -mfixed-range=@var{register-range} @gol
--madjust-unroll -mindexed-addressing -mgettrcost=@var{number} -mpt-fixed @gol
+-maccumulate-outgoing-args -mindexed-addressing -mgettrcost=@var{number} @gol
+-mpt-fixed -malign-small-blocks=@var{block-size} @gol
 -minvalid-symbols}
 
 @emph{SPARC Options}
@@ -2746,6 +2750,11 @@
 only in the case of very minor changes such as bug fixes to an
 existing code-base.
 
+@item -Wbranch-probabilities-computation
+@opindex Wbranch-probabilities-computation
+Warn if edge and/or basic block counts computation is not consistent
+when using the @option{-fbranch-probabilities} option.
+
 @end table
 
 @node Warning Options
@@ -2882,6 +2891,7 @@
 -Wmain @r{(only for C/ObjC and unless} @option{-ffreestanding}@r{)}  @gol
 -Wmissing-braces  @gol
 -Wnonnull  @gol
+-Wnon-finite-math @gol
 -Wparentheses  @gol
 -Wpointer-sign  @gol
 -Wreorder   @gol
@@ -3080,6 +3090,11 @@
 @option{-Wnonnull} is included in @option{-Wall} and @option{-Wformat}.  It
 can be disabled with the @option{-Wno-nonnull} option.
 
+@item -Wnon-finite-math
+@opindex Wnon-finite-math
+@opindex Wno-non-finite-math
+Warn if non-finite builtins are used with -ffinite-math-only.
+
 @item -Winit-self @r{(C, C++, Objective-C and Objective-C++ only)}
 @opindex Winit-self
 @opindex Wno-init-self
@@ -9196,6 +9211,10 @@
 designated output file of this compilation.  This puts the argument
 into the sequence of arguments that @samp{%o} will substitute later.
 
+@item %M
+If the target supports multilibs substitute the current multilib directory
+otherwise substitute @samp{.}.
+
 @item %o
 Substitutes the names of all the output files, with spaces
 automatically placed around them.  You should write spaces
@@ -9337,11 +9356,11 @@
 
 @table @code
 @item @code{getenv}
-The @code{getenv} spec function takes two arguments: an environment
-variable name and a string.  If the environment variable is not
-defined, a fatal error is issued.  Otherwise, the return value is the
-value of the environment variable concatenated with the string.  For
-example, if @env{TOPDIR} is defined as @file{/path/to/top}, then:
+The @code{getenv} spec function takes two or more arguments: an environment
+variable name and a list of strings.  If the environment variable is not
+defined, a fatal error is issued.  Otherwise, the return value is the value
+of the environment variable concatenated with the strings.  For example, if
+@env{TOPDIR} is defined as @file{/path/to/top}, then:
 
 @smallexample
 %:getenv(TOPDIR /include)
@@ -15965,6 +15984,24 @@
 @opindex m4
 Generate code for the SH4.
 
+@item -m4-300-nofpu
+@opindex m4-300-nofpu
+Generate code for the ST40-300 without a floating-point unit.
+
+@item -m4-300-single-only
+@opindex m4-300-single-only
+Generate code for the ST40-300 with a floating-point unit that only
+supports single-precision arithmetic.
+
+@item -m4-300-single
+@opindex m4-300-single
+Generate code for the ST40-300 assuming the floating-point unit is in
+single-precision mode by default.
+
+@item -m4-300
+@opindex m4-300
+Generate code for the ST40-300.
+
 @item -m4a-nofpu
 @opindex m4a-nofpu
 Generate code for the SH4al-dsp, or for a SH4a in such a way that the
@@ -16004,6 +16041,12 @@
 conventions, and thus some functions from the standard C library will
 not work unless you recompile it first with @option{-mdalign}.
 
+@item -mtas
+@itemx -mno-tas
+@opindex mtas
+@opindex mno-tas
+Allow or disallow the @code{tas.b} instruction.
+
 @item -mrelax
 @opindex mrelax
 Shorten some address references at link time, when possible; uses the
@@ -16018,6 +16061,10 @@
 @opindex mbitops
 Enable the use of bit manipulation instructions on SH2A.
 
+@item -mdead-delay
+@opindex mdead-delay
+Try to eliminate dead delay slot instructions.
+
 @item -mfmovd
 @opindex mfmovd
 Enable the use of the instruction @code{fmovd}.  Check @option{-mdalign} for
@@ -16073,10 +16120,6 @@
 This option is deprecated.  It pads structures to multiple of 4 bytes,
 which is incompatible with the SH ABI@.
 
-@item -mspace
-@opindex mspace
-Optimize for space instead of speed.  Implied by @option{-Os}.
-
 @item -mprefergot
 @opindex mprefergot
 When generating position-independent code, emit function calls using
@@ -16094,28 +16137,28 @@
 
 @item -mdiv=@var{strategy}
 @opindex mdiv=@var{strategy}
-Set the division strategy to use for SHmedia code.  @var{strategy} must be
-one of: call, call2, fp, inv, inv:minlat, inv20u, inv20l, inv:call,
-inv:call2, inv:fp .
-"fp" performs the operation in floating point.  This has a very high latency,
-but needs only a few instructions, so it might be a good choice if
+Set the division strategy to use. For SHmedia code, @var{strategy} must be
+one of: @var{call}, @var{call2}, @var{fp}, @var{inv}, @var{inv:minlat},
+@var{inv20u}, @var{inv20l}, @var{inv:call}, @var{inv:call2}, @var{inv:fp}.
+@samp{fp} performs the operation in floating point.  This has a very high
+latency, but needs only a few instructions, so it might be a good choice if
 your code has enough easily exploitable ILP to allow the compiler to
 schedule the floating point instructions together with other instructions.
 Division by zero causes a floating point exception.
-"inv" uses integer operations to calculate the inverse of the divisor,
+@samp{inv} uses integer operations to calculate the inverse of the divisor,
 and then multiplies the dividend with the inverse.  This strategy allows
 cse and hoisting of the inverse calculation.  Division by zero calculates
 an unspecified result, but does not trap.
-"inv:minlat" is a variant of "inv" where if no cse / hoisting opportunities
+@samp{inv:minlat} is a variant of "inv" where if no cse / hoisting opportunities
 have been found, or if the entire operation has been hoisted to the same
 place, the last stages of the inverse calculation are intertwined with the
 final multiply to reduce the overall latency, at the expense of using a few
 more instructions, and thus offering fewer scheduling opportunities with
 other code.
-"call" calls a library function that usually implements the inv:minlat
+@samp{call} calls a library function that usually implements the inv:minlat
 strategy.
 This gives high code density for m5-*media-nofpu compilations.
-"call2" uses a different entry point of the same library function, where it
+@samp{call2} uses a different entry point of the same library function, where it
 assumes that a pointer to a lookup table has already been set up, which
 exposes the pointer load to cse / code hoisting optimizations.
 "inv:call", "inv:call2" and "inv:fp" all use the "inv" algorithm for initial
@@ -16131,6 +16174,8 @@
 by inserting a test to skip a number of operations in this case; this test
 slows down the case of larger dividends.  inv20u assumes the case of a such
 a small dividend to be unlikely, and inv20l assumes it to be likely.
+@samp{call-pre1} optimizes return 1 cases with divisor greater than dividend
+before calling the library function.
 
 @item -mdivsi3_libfunc=@var{name}
 @opindex mdivsi3_libfunc=@var{name}
@@ -16147,11 +16192,14 @@
 two registers separated by a dash.  Multiple register ranges can be
 specified separated by a comma.
 
-@item -madjust-unroll
-@opindex madjust-unroll
-Throttle unrolling to avoid thrashing target registers.
-This option only has an effect if the gcc code base supports the
-TARGET_ADJUST_UNROLL_MAX target hook.
+@item -maccumulate-outgoing-args
+@opindex maccumulate-outgoing-args
+Reserve space for outgoing arguments in the function prologue.
+
+@item -malign-small-blocks=@var{number}
+@opindex align-small-blocks=@var{number}
+Set the size among which basic blocks are aligned on cache line boundaries.
+Default is 16 bytes. 0 means default alignment.
 
 @item -mindexed-addressing
 @opindex mindexed-addressing
Index: gcc-4.5.2.orig/gcc/doc/md.texi
===================================================================
--- gcc-4.5.2.orig/gcc/doc/md.texi	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/doc/md.texi	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -3011,6 +3011,37 @@
 
 @end table
 
+@item SH---@file{config/sh/constraints.md}
+@table @code
+@item c
+FPSCR. Floating-point status/control register
+
+@item d
+Any 64-bit Floating-point register
+
+@item f
+Any 32-bit Floating-point register
+
+@item l
+PR register
+
+@item t
+T bit from SR. Status register
+
+@item w
+FR0 floating-point register
+
+@item x
+MAC register (MACH and MACL)
+
+@item y
+FPUL register
+
+@item z
+R0 register
+
+@end table
+
 @item SPU---@file{config/spu/spu.h}
 @table @code
 @item a
Index: gcc-4.5.2.orig/gcc/doc/g++.1
===================================================================
--- gcc-4.5.2.orig/gcc/doc/g++.1	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/doc/g++.1	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -839,7 +839,7 @@
 \&\-m5\-compact  \-m5\-compact\-nofpu 
 \&\-mb  \-ml  \-mdalign  \-mrelax 
 \&\-mbigtable \-mfmovd \-mhitachi \-mrenesas \-mno\-renesas \-mnomacsave 
-\&\-mieee  \-mbitops  \-misize  \-minline\-ic_invalidate \-mpadstruct  \-mspace 
+\&\-mieee  \-mbitops  \-misize  \-minline\-ic_invalidate \-mpadstruct
 \&\-mprefergot  \-musermode \-multcost=\fR\fInumber\fR \fB\-mdiv=\fR\fIstrategy\fR 
 \&\fB\-mdivsi3_libfunc=\fR\fIname\fR \fB\-mfixed\-range=\fR\fIregister-range\fR 
 \&\fB\-madjust\-unroll \-mindexed\-addressing \-mgettrcost=\fR\fInumber\fR \fB\-mpt\-fixed 
@@ -15016,9 +15016,6 @@
 .IX Item "-mpadstruct"
 This option is deprecated.  It pads structures to multiple of 4 bytes,
 which is incompatible with the \s-1SH\s0 \s-1ABI\s0.
-.IP "\fB\-mspace\fR" 4
-.IX Item "-mspace"
-Optimize for space instead of speed.  Implied by \fB\-Os\fR.
 .IP "\fB\-mprefergot\fR" 4
 .IX Item "-mprefergot"
 When generating position-independent code, emit function calls using
Index: gcc-4.5.2.orig/gcc/doc/gcc.info
===================================================================
--- gcc-4.5.2.orig/gcc/doc/gcc.info	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/doc/gcc.info	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1058,7 +1058,8 @@
           -m5-compact  -m5-compact-nofpu
           -mb  -ml  -mdalign  -mrelax
           -mbigtable -mfmovd -mhitachi -mrenesas -mno-renesas -mnomacsave
-          -mieee  -mbitops  -misize  -minline-ic_invalidate -mpadstruct  -mspace
+          -mieee  -mbitops  -misize  -minline-ic_invalidate -mpadstruct
+	  -mdead-delay
           -mprefergot  -musermode -multcost=NUMBER -mdiv=STRATEGY
           -mdivsi3_libfunc=NAME -mfixed-range=REGISTER-RANGE
           -madjust-unroll -mindexed-addressing -mgettrcost=NUMBER -mpt-fixed
@@ -15005,6 +15006,9 @@
 `-mbitops'
      Enable the use of bit manipulation instructions on SH2A.
 
+`-mdead-delay'
+     Try to eliminate dead delay slot instructions.
+
 `-mfmovd'
      Enable the use of the instruction `fmovd'.  Check `-mdalign' for
      alignment constraints.
@@ -15050,9 +15054,6 @@
      This option is deprecated.  It pads structures to multiple of 4
      bytes, which is incompatible with the SH ABI.
 
-`-mspace'
-     Optimize for space instead of speed.  Implied by `-Os'.
-
 `-mprefergot'
      When generating position-independent code, emit function calls
      using the Global Offset Table instead of the Procedure Linkage
@@ -43644,7 +43645,6 @@
 * msoft-quad-float:                      SPARC Options.      (line   45)
 * msoft-reg-count:                       M68hc1x Options.    (line   43)
 * mspace <1>:                            V850 Options.       (line   30)
-* mspace:                                SH Options.         (line  142)
 * mspe:                                  RS/6000 and PowerPC Options.
                                                              (line  226)
 * mspecld-anomaly:                       Blackfin Options.   (line   47)
Index: gcc-4.5.2.orig/gcc/doc/gccint.info
===================================================================
--- gcc-4.5.2.orig/gcc/doc/gccint.info	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/doc/gccint.info	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -28207,6 +28207,11 @@
      info to be given comdat linkage.  Define it to be `1' if comdat
      linkage is necessary.  The default is `0'.
 
+ -- Macro:  TARGET_USES_LEB128
+     A C expression that evaluates to true if the target requires leb128
+     to be used for dwarf compression.  Define it to be @code{1} if leb128
+     linkage is necessary.  The default is `1' if `HAVE_AS_LEB128' is defined.
+
 
 File: gccint.info,  Node: Stack Checking,  Next: Frame Registers,  Prev: Exception Handling,  Up: Stack and Calling
 
Index: gcc-4.5.2.orig/gcc/dwarf2asm.c
===================================================================
--- gcc-4.5.2.orig/gcc/dwarf2asm.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/dwarf2asm.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,6 +1,7 @@
 /* Dwarf2 assembler output helper routines.
    Copyright (C) 2001, 2002, 2003, 2004, 2005, 2007, 2008, 2009, 2010
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -566,7 +567,8 @@
 
   va_start (ap, comment);
 
-#ifdef HAVE_AS_LEB128
+  if (TARGET_USES_LEB128)
+    {
   fprintf (asm_out_file, "\t.uleb128 " HOST_WIDE_INT_PRINT_HEX , value);
 
   if (flag_debug_asm && comment)
@@ -574,7 +576,8 @@
       fprintf (asm_out_file, "\t%s ", ASM_COMMENT_START);
       vfprintf (asm_out_file, comment, ap);
     }
-#else
+    }
+  else
   {
     unsigned HOST_WIDE_INT work = value;
     const char *byte_op = targetm.asm_out.byte_op;
@@ -611,7 +614,7 @@
 	}
     }
   }
-#endif
+
   fputc ('\n', asm_out_file);
 
   va_end (ap);
@@ -713,14 +716,15 @@
 
   va_start (ap, comment);
 
-#ifdef HAVE_AS_LEB128
+  if (TARGET_USES_LEB128)
+    {
   fputs ("\t.uleb128 ", asm_out_file);
   assemble_name (asm_out_file, lab1);
   fputc ('-', asm_out_file);
   assemble_name (asm_out_file, lab2);
-#else
+    }
+  else
   gcc_unreachable ();
-#endif
 
   if (flag_debug_asm && comment)
     {
@@ -743,14 +747,15 @@
 
   va_start (ap, comment);
 
-#ifdef HAVE_AS_LEB128
+  if (TARGET_USES_LEB128)
+    {
   fputs ("\t.sleb128 ", asm_out_file);
   assemble_name (asm_out_file, lab1);
   fputc ('-', asm_out_file);
   assemble_name (asm_out_file, lab2);
-#else
+    }
+  else
   gcc_unreachable ();
-#endif
 
   if (flag_debug_asm && comment)
     {
Index: gcc-4.5.2.orig/gcc/DATESTAMP
===================================================================
--- gcc-4.5.2.orig/gcc/DATESTAMP	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/DATESTAMP	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1 +1 @@
-20101216
+20110124
Index: gcc-4.5.2.orig/gcc/defaults.h
===================================================================
--- gcc-4.5.2.orig/gcc/defaults.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/defaults.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -3,6 +3,7 @@
    2005, 2007, 2008, 2009, 2010
    Free Software Foundation, Inc.
    Contributed by Ron Guilmette (rfg@monkeys.com)
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -292,6 +293,15 @@
 #define TARGET_USES_WEAK_UNWIND_INFO 0
 #endif
 
+/* Use leb128 encoding based on command line options.  */
+#ifndef TARGET_USES_LEB128
+#ifdef HAVE_AS_LEB128
+#define TARGET_USES_LEB128 1
+#else
+#define TARGET_USES_LEB128 0
+#endif
+#endif
+
 /* By default, there is no prefix on user-defined symbols.  */
 #ifndef USER_LABEL_PREFIX
 #define USER_LABEL_PREFIX ""
@@ -893,6 +903,14 @@
 #define TARGET_DEC_EVAL_METHOD 2
 #endif
 
+#ifndef HOT_TEXT_SECTION_PREFIX
+#define HOT_TEXT_SECTION_PREFIX ".hot"
+#endif
+
+#ifndef UNLIKELY_EXECUTED_TEXT_SECTION_PREFIX
+#define UNLIKELY_EXECUTED_TEXT_SECTION_PREFIX ".unlikely"
+#endif
+
 #ifndef HOT_TEXT_SECTION_NAME
 #define HOT_TEXT_SECTION_NAME ".text.hot"
 #endif
Index: gcc-4.5.2.orig/gcc/configure
===================================================================
--- gcc-4.5.2.orig/gcc/configure	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/configure	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -646,6 +646,7 @@
 extra_parts
 extra_objs
 extra_headers_list
+extra_libgcc_srcs
 extra_gcc_objs
 TM_MULTILIB_EXCEPTIONS_CONFIG
 TM_MULTILIB_CONFIG
@@ -1642,7 +1643,7 @@
                           use sysroot as the system root during the build
   --with-sysroot=DIR Search for usr/lib, usr/include, et al, within DIR.
   --with-specs=SPECS      add SPECS to driver command-line processing
-  --with-pkgversion=PKG   Use PKG in the version string in place of "GCC"
+  --with-pkgversion=PKG   Use PKG in the version string in place of "STMicroelectronics Base"
   --with-bugurl=URL       Direct users to URL to report a bug
   --with-multilib-list    Select multilibs (SH only)
   --with-gnu-ld           assume the C compiler uses GNU ld default=no
@@ -6897,7 +6898,7 @@
       *)   PKGVERSION="($withval) " ;;
      esac
 else
-  PKGVERSION="(GCC) "
+  PKGVERSION="(STMicroelectronics Base) "
 
 fi
 
@@ -6915,7 +6916,7 @@
 	   ;;
      esac
 else
-  BUGURL="http://gcc.gnu.org/bugs.html"
+  BUGURL="<file://doc/docbug.htm> on the installation CD"
 
 fi
 
@@ -10421,7 +10422,7 @@
     target_thread_file='single'
     ;;
   aix | dce | gnat | irix | posix | posix95 | rtems | \
-  single | solaris | vxworks | win32 | mipssde)
+  single | solaris | vxworks | win32 | mipssde | generic)
     target_thread_file=${enable_threads}
     ;;
   *)
@@ -10446,6 +10447,14 @@
     mv -f gthr-default.h-t gthr-default.h
   fi
   gthread_flags=-DHAVE_GTHR_DEFAULT
+  if test $thread_file != posix; then
+    if test -f $srcdir/gthr-${thread_file}.c; then
+      extra_libgcc_srcs=$srcdir/gthr-${thread_file}.c
+    fi
+    if test -f $srcdir/gthr-objc-${thread_file}.c; then
+      extra_libgcc_srcs="${extra_libgcc_srcs} $srcdir/gthr-objc-${thread_file}.c"
+    fi
+  fi
 fi
 
 
@@ -10934,6 +10943,16 @@
 	CROSS="-DCROSS_DIRECTORY_STRUCTURE"
 	ALL=all.cross
 	SYSTEM_HEADER_DIR=$build_system_header_dir
+
+	# For builds with an in-tree newlib, then the headers are not
+	# copied to build_system_header_dir, so things like limits.h
+	# won't work unless we point at the real headers.
+	if test "$with_newlib" = yes \
+		&& (test -z "$with_headers" || test "$with_headers" = yes) \
+		&& test -d $srcdir/../newlib/libc/include; then
+	  SYSTEM_HEADER_DIR="\$(abs_srcdir)/../newlib/libc/include"
+	fi
+
 	case "$host","$target" in
 	# Darwin crosses can use the host system's libraries and headers,
 	# because of the fat library support.  Of course, it must be the
Index: gcc-4.5.2.orig/gcc/final.c
===================================================================
--- gcc-4.5.2.orig/gcc/final.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/final.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1989, 1992, 1993, 1994, 1995, 1996, 1997,
    1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -372,6 +373,22 @@
     }
 }
 
+#ifdef ADJUST_INSN_LENGTH
+static void realloc_insn_lengths (int uid, char **varying_length)
+{
+  int max_uid = get_max_uid ();
+
+  gcc_assert (insn_lengths);
+
+  insn_lengths = XRESIZEVEC (int, insn_lengths, max_uid);
+  insn_lengths[uid] = 0;
+  insn_lengths_max_uid = max_uid;
+  insn_lengths[uid] = 0;
+  *varying_length = XRESIZEVEC (char, *varying_length, max_uid);
+  (*varying_length)[uid] = 0;
+}
+#endif
+
 /* Obtain the current length of an insn.  If branch shortening has been done,
    get its actual length.  Otherwise, use FALLBACK_FN to calculate the
    length.  */
@@ -969,6 +986,11 @@
     }
 #ifdef HAVE_ATTR_length
 
+  gcc_assert (insn_lengths == 0);
+
+  /* New insn might have been created by insn_length_adjustment.  */
+  max_uid = get_max_uid ();
+
   /* Allocate the rest of the arrays.  */
   insn_lengths = XNEWVEC (int, max_uid);
   insn_lengths_max_uid = max_uid;
@@ -1100,7 +1122,10 @@
 	  /* Alignment is handled by ADDR_VEC_ALIGN.  */
 	}
       else if (GET_CODE (body) == ASM_INPUT || asm_noperands (body) >= 0)
+	{
 	insn_lengths[uid] = asm_insn_count (body) * insn_default_length (insn);
+	  varying_length[uid] = 1;
+	}
       else if (GET_CODE (body) == SEQUENCE)
 	{
 	  int i;
@@ -1143,12 +1168,23 @@
       else if (GET_CODE (body) != USE && GET_CODE (body) != CLOBBER)
 	{
 	  insn_lengths[uid] = insn_default_length (insn);
+
+#ifdef VARYING_INSN_P
+	  if (VARYING_INSN_P (insn))
+	    varying_length[uid] = 1;
+	  else
+#endif
 	  varying_length[uid] = insn_variable_length_p (insn);
 	}
 
       /* If needed, do any adjustment.  */
 #ifdef ADJUST_INSN_LENGTH
       ADJUST_INSN_LENGTH (insn, insn_lengths[uid]);
+      if (max_uid != get_max_uid ())
+	{
+	  realloc_insn_lengths (max_uid, &varying_length);
+	  max_uid = get_max_uid ();
+	}
       if (insn_lengths[uid] < 0)
 	fatal_insn ("negative insn length", insn);
 #endif
@@ -1177,7 +1213,7 @@
 	  if (LABEL_P (insn))
 	    {
 	      int log = LABEL_TO_ALIGNMENT (insn);
-	      if (log > insn_current_align)
+	      if (log >= insn_current_align)
 		{
 		  int align = 1 << log;
 		  int new_address= (insn_current_address + align - 1) & -align;
@@ -1328,10 +1364,10 @@
 		}
 	      else
 		insn_current_address += insn_lengths[uid];
-
 	      continue;
 	    }
 
+	  /* Varying_length.  */
 	  if (NONJUMP_INSN_P (insn) && GET_CODE (PATTERN (insn)) == SEQUENCE)
 	    {
 	      int i;
@@ -1353,6 +1389,16 @@
 		  else
 		    inner_length = insn_current_length (inner_insn);
 
+#ifdef ADJUST_INSN_LENGTH
+		  /* If needed, do any adjustment.  */
+		  ADJUST_INSN_LENGTH (inner_insn, inner_length);
+		  if (max_uid != get_max_uid ())
+		    {
+		      realloc_insn_lengths (max_uid, &varying_length);
+		      max_uid = get_max_uid ();
+		    }
+#endif
+
 		  if (inner_length != insn_lengths[inner_uid])
 		    {
 		      insn_lengths[inner_uid] = inner_length;
@@ -1364,7 +1410,20 @@
 	    }
 	  else
 	    {
+	      rtx body = PATTERN (insn);
+
+	      if (GET_CODE (body) == ASM_INPUT || asm_noperands (body) >= 0)
+		new_length = asm_insn_count (body) * insn_default_length (insn);
+	      else  
+		{
+#ifdef VARYING_INSN_P 
+		  if (VARYING_INSN_P (insn))
+		    new_length = insn_lengths[uid];
+		  else
+#endif
 	      new_length = insn_current_length (insn);
+		}
+
 	      insn_current_address += new_length;
 	    }
 
@@ -1373,6 +1432,11 @@
 	  tmp_length = new_length;
 	  ADJUST_INSN_LENGTH (insn, new_length);
 	  insn_current_address += (new_length - tmp_length);
+	  if (max_uid != get_max_uid ())
+	    {
+	      realloc_insn_lengths (max_uid, &varying_length);
+	      max_uid = get_max_uid ();
+	    }
 #endif
 
 	  if (new_length != insn_lengths[uid])
@@ -1420,10 +1484,14 @@
   if (!*templ)
     return 0;
 
+#ifdef TARGET_ASM_COUNT
+  count = TARGET_ASM_COUNT (templ, 0);
+#else
   for (; *templ; templ++)
     if (IS_ASM_LOGICAL_LINE_SEPARATOR (*templ, templ)
 	|| *templ == '\n')
       count++;
+#endif
 
   return count;
 }
@@ -1481,6 +1549,8 @@
   const char *name;
   size_t name_len;
 
+  CYGPATH (filename);
+
   for (map = debug_prefix_maps; map; map = map->next)
     if (strncmp (filename, map->old_prefix, map->old_len) == 0)
       break;
@@ -2033,6 +2103,10 @@
 
 	  if (align && NEXT_INSN (insn))
 	    {
+#ifdef FINAL_PRESCAN_INSN
+	FINAL_PRESCAN_INSN (insn, recog_data.operand, recog_data.n_operands);
+#endif
+
 #ifdef ASM_OUTPUT_MAX_SKIP_ALIGN
 	      ASM_OUTPUT_MAX_SKIP_ALIGN (file, align, max_skip);
 #else
Index: gcc-4.5.2.orig/gcc/builtins.c
===================================================================
--- gcc-4.5.2.orig/gcc/builtins.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/builtins.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -9431,7 +9431,12 @@
     {
     case BUILT_IN_ISINF:
       if (!HONOR_INFINITIES (TYPE_MODE (TREE_TYPE (arg))))
+	{
+	  if (warn_non_finite_math)
+	    warning (OPT_Wnon_finite_math,
+		     "non-finite operation %q+F always returns 0", fndecl);
 	return omit_one_operand_loc (loc, type, integer_zero_node, arg);
+	}
 
       if (TREE_CODE (arg) == REAL_CST)
 	{
@@ -9480,7 +9485,11 @@
     case BUILT_IN_ISFINITE:
       if (!HONOR_NANS (TYPE_MODE (TREE_TYPE (arg)))
 	  && !HONOR_INFINITIES (TYPE_MODE (TREE_TYPE (arg))))
+	{
+	  warning (OPT_Wnon_finite_math, "non-finite operation %q+D not honored" ,
+		   fndecl);
 	return omit_one_operand_loc (loc, type, integer_one_node, arg);
+	}
 
       if (TREE_CODE (arg) == REAL_CST)
 	{
@@ -9492,7 +9501,11 @@
 
     case BUILT_IN_ISNAN:
       if (!HONOR_NANS (TYPE_MODE (TREE_TYPE (arg))))
+	{
+	  warning (OPT_Wnon_finite_math, "non-finite operation %q+D not honored",
+		   fndecl);
 	return omit_one_operand_loc (loc, type, integer_zero_node, arg);
+	}
 
       if (TREE_CODE (arg) == REAL_CST)
 	{
@@ -9616,7 +9629,12 @@
   if (unordered_code == UNORDERED_EXPR)
     {
       if (!HONOR_NANS (TYPE_MODE (TREE_TYPE (arg0))))
+	{
+	  if (warn_non_finite_math)
+	    warning (OPT_Wnon_finite_math,
+		     "non-finite operation %q+F always returns 0", fndecl);
 	return omit_two_operands_loc (loc, type, integer_zero_node, arg0, arg1);
+	}
       return fold_build2_loc (loc, UNORDERED_EXPR, type, arg0, arg1);
     }
 
Index: gcc-4.5.2.orig/gcc/gcc.c
===================================================================
--- gcc-4.5.2.orig/gcc/gcc.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/gcc.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -3,6 +3,7 @@
    1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,
    2010
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -480,6 +481,7 @@
  %W{...}
 	like %{...} but mark last argument supplied within
 	as a file to be deleted on failure.
+ %M	substitue the current multilib directory.
  %o	substitutes the names of all the output files, with spaces
 	automatically placed around them.  You should write spaces
 	around the %o as well or the results are undefined.
@@ -2556,15 +2558,17 @@
     {
       size_t multi_dir_len = 0;
       size_t multi_os_dir_len = 0;
-      size_t suffix_len;
-      size_t just_suffix_len;
+      size_t suffix_len = 0;
+      size_t just_suffix_len = 0;
       size_t len;
 
       if (multi_dir)
 	multi_dir_len = strlen (multi_dir);
       if (multi_os_dir)
 	multi_os_dir_len = strlen (multi_os_dir);
+      if (multi_suffix)
       suffix_len = strlen (multi_suffix);
+      if (just_multi_suffix)
       just_suffix_len = strlen (just_multi_suffix);
 
       if (path == NULL)
@@ -2583,7 +2587,7 @@
 	  memcpy (path, pl->prefix, len);
 
 	  /* Look first in MACHINE/VERSION subdirectory.  */
-	  if (!skip_multi_dir)
+	  if (!skip_multi_dir && multi_suffix)
 	    {
 	      memcpy (path + len, multi_suffix, suffix_len + 1);
 	      ret = callback (path, callback_info);
@@ -2593,7 +2597,7 @@
 
 	  /* Some paths are tried with just the machine (ie. target)
 	     subdir.  This is used for finding as, ld, etc.  */
-	  if (!skip_multi_dir
+	  if (!skip_multi_dir && just_multi_suffix
 	      && pl->require_machine_suffix == 2)
 	    {
 	      memcpy (path + len, just_multi_suffix, just_suffix_len + 1);
@@ -3606,20 +3610,7 @@
 		     CONST_CAST2 (const char *const **, const char ***,
 				  &argv));
 
-  /* Handle any -no-canonical-prefixes flag early, to assign the function
-     that builds relative prefixes.  This function creates default search
-     paths that are needed later in normal option handling.  */
-
-  for (i = 1; i < argc; i++)
-    {
-      if (! strcmp (argv[i], "-no-canonical-prefixes"))
-	{
 	  get_relative_prefix = make_relative_prefix_ignore_links;
-	  break;
-	}
-    }
-  if (! get_relative_prefix)
-    get_relative_prefix = make_relative_prefix;
 
   /* Set up the default search paths.  If there is no GCC_EXEC_PREFIX,
      see if we can create it from the pathname specified in argv[0].  */
@@ -5592,6 +5583,14 @@
 	    }
 	    break;
 
+	  case 'M':
+	    {
+	      const char *mlib = multilib_dir ? multilib_dir : ".";
+	      obstack_grow (&obstack, mlib, strlen (mlib));
+	      arg_going = 1;
+	    }
+	    break;
+
 	  case 'o':
 	    {
 	      int max = n_infiles;
@@ -8565,7 +8564,7 @@
 /* getenv built-in spec function.
 
    Returns the value of the environment variable given by its first
-   argument, concatenated with the second argument.  If the
+   argument, concatenated with the remaining arguments.  If the
    environment variable is not defined, a fatal error is issued.  */
 
 static const char *
@@ -8575,8 +8574,9 @@
   char *result;
   char *ptr;
   size_t len;
+  int i;
 
-  if (argc != 2)
+  if (argc < 2)
     return NULL;
 
   value = getenv (argv[0]);
@@ -8587,7 +8587,9 @@
      they are not interpreted as active spec characters.  A
      particularly painful case is when we are reading a variable
      holding a windows path complete with \ separators.  */
-  len = strlen (value) * 2 + strlen (argv[1]) + 1;
+  len = strlen (value) * 2 + 1;
+  for (i = 1; i < argc; i++)
+    len += strlen (argv[i]);
   result = XNEWVAR (char, len);
   for (ptr = result; *value; ptr += 2)
     {
@@ -8595,7 +8597,11 @@
       ptr[1] = *value++;
     }
 
-  strcpy (ptr, argv[1]);
+  for (i = 1; i < argc; i++)
+    {
+      strcpy (ptr, argv[i]);
+      ptr += strlen (argv[i]);
+    }
 
   return result;
 }
Index: gcc-4.5.2.orig/gcc/fold-const.c
===================================================================
--- gcc-4.5.2.orig/gcc/fold-const.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/fold-const.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -7741,7 +7741,7 @@
 			  tree arg0, tree arg1)
 {
   tree arg00, arg01, arg10, arg11;
-  tree alt0 = NULL_TREE, alt1 = NULL_TREE, same;
+  tree alt0 = NULL_TREE, alt1 = NULL_TREE, same = NULL_TREE;
 
   /* (A * C) +- (B * C) -> (A+-B) * C.
      (A * C) +- A -> A * (C+-1).
@@ -7795,7 +7795,6 @@
       arg10 = arg1;
       arg11 = build_one_cst (type);
     }
-  same = NULL_TREE;
 
   if (operand_equal_p (arg01, arg11, 0))
     same = arg01, alt0 = arg00, alt1 = arg10;
@@ -7806,10 +7805,18 @@
   else if (operand_equal_p (arg01, arg10, 0))
     same = arg01, alt0 = arg00, alt1 = arg11;
 
+  if (same)
+    {
+      /* Catch base+index gimple trees.  */
+      if (host_integerp (same, 1) && exact_log2 (TREE_INT_CST_LOW (same)) > 0)
+	return NULL_TREE;
+    }
+  else 
+
   /* No identical multiplicands; see if we can find a common
      power-of-two factor in non-power-of-two multiplies.  This
      can help in multi-dimensional array access.  */
-  else if (host_integerp (arg01, 0)
+  if (host_integerp (arg01, 0)
 	   && host_integerp (arg11, 0))
     {
       HOST_WIDE_INT int01, int11, tmp;
@@ -7847,11 +7854,16 @@
     }
 
   if (same)
+    {
+      if (! (host_integerp (alt1, 0) &&
+	     host_integerp (same, 1) &&
+	     exact_log2 (TREE_INT_CST_LOW (same)) > 0))
     return fold_build2_loc (loc, MULT_EXPR, type,
 			fold_build2_loc (loc, code, type,
 				     fold_convert_loc (loc, type, alt0),
 				     fold_convert_loc (loc, type, alt1)),
 			fold_convert_loc (loc, type, same));
+    }
 
   return NULL_TREE;
 }
Index: gcc-4.5.2.orig/gcc/cfg.c
===================================================================
--- gcc-4.5.2.orig/gcc/cfg.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/cfg.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -695,6 +695,9 @@
       fprintf (file, HOST_WIDEST_INT_PRINT_DEC, e->count);
     }
 
+  if (e->goto_locus)
+    fprintf (file, "locus = %d\n", e->goto_locus);
+
   if (e->flags)
     {
       static const char * const bitnames[] = {
Index: gcc-4.5.2.orig/gcc/DEV-PHASE
===================================================================
--- gcc-4.5.2.orig/gcc/DEV-PHASE	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/DEV-PHASE	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1 @@
+
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/execute/lrintf.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/execute/lrintf.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/gcc.c-torture/execute/lrintf.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,53 @@
+#include <math.h>
+
+extern void abort (void);
+extern void exit (int);
+
+void __attribute__ ((noinline))
+test(float a)
+{
+  int a1 = __builtin_lrintf (a);
+  int a3 = lrintf (a);
+
+  if (a1 != a3)
+    exit (1);
+}
+
+int main()
+{
+  test (__builtin_nanf(""));
+  test (__builtin_inff());
+
+  test (0);
+  test (1);
+
+  test (2.5);
+  test (3.5);
+  test (-2.5);
+  test (-3.5);
+
+  test (2.4);
+  test (3.4);
+  test (-2.4);
+  test (-3.4);
+
+  test (2.0);
+  test (3.0);
+  test (-2.0);
+  test (-3.0);
+
+  test (2.9);
+  test (3.9);
+  test (-2.9);
+  test (-3.9);
+
+  test (2.1);
+  test (3.1);
+  test (-2.1);
+  test (-3.1);
+
+  test (0.1);
+  test (-0.1);
+
+  return 0;
+}
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/execute/lrintf.x
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/execute/lrintf.x	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/gcc.c-torture/execute/lrintf.x	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,3 @@
+set additional_flags "-fno-math-errno -std=c99 -fno-builtin -fno-finite-math-only"
+
+return 0
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/execute/builtin-prefetch-6.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/execute/builtin-prefetch-6.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/gcc.c-torture/execute/builtin-prefetch-6.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,3 +1,6 @@
+/* can trap for SH with RADDERR on MMU with 31th bit set.  */
+/* { dg-do run { xfail sh*-*linux* } } */
+
 /* Test that __builtin_prefetch does no harm.
 
    Data prefetch should not fault if used with an invalid address.  */
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/execute/lroundf.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/execute/lroundf.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/gcc.c-torture/execute/lroundf.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,53 @@
+#include <math.h>
+
+extern void abort (void);
+extern void exit (int);
+
+void __attribute__ ((noinline))
+test(float a)
+{
+  int a1 = __builtin_lroundf (a);
+  int a3 = lroundf (a);
+
+  if (a1 != a3)
+    exit (1);
+}
+
+int main()
+{
+  test (__builtin_nanf(""));
+  test (__builtin_inff());
+
+  test (0);
+  test (1);
+
+  test (2.5);
+  test (3.5);
+  test (-2.5);
+  test (-3.5);
+
+  test (2.4);
+  test (3.4);
+  test (-2.4);
+  test (-3.4);
+
+  test (2.0);
+  test (3.0);
+  test (-2.0);
+  test (-3.0);
+
+  test (2.9);
+  test (3.9);
+  test (-2.9);
+  test (-3.9);
+
+  test (2.1);
+  test (3.1);
+  test (-2.1);
+  test (-3.1);
+
+  test (0.1);
+  test (-0.1);
+
+  return 0;
+}
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/execute/lroundf.x
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/execute/lroundf.x	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/gcc.c-torture/execute/lroundf.x	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,3 @@
+set additional_flags "-fno-math-errno -std=c99 -fno-builtin -fno-finite-math-only"
+
+return 0
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/compile/limits-structnest.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.c-torture/compile/limits-structnest.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/gcc.c-torture/compile/limits-structnest.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,3 +1,6 @@
+/* http://gcc.gnu.org/bugzilla/show_bug.cgi?id=35608  */
+/* { dg-xfail-if "Big stack for recursive macro" { *-*-* } { "*" } { "" } } */
+
 #define LIM1(x) x##0 {x##1 {x##2 {x##3 {x##4 {x##5 {x##6 {x##7 {x##8 {x##9 {
 #define LIM2(x) LIM1(x##0) LIM1(x##1) LIM1(x##2) LIM1(x##3) LIM1(x##4) \
 		LIM1(x##5) LIM1(x##6) LIM1(x##7) LIM1(x##8) LIM1(x##9)
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.target/sh/fpchg1.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.target/sh/fpchg1.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/gcc.target/sh/fpchg1.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,24 @@
+/* { dg-do run } */
+/* { dg-options "-O1 -m4-300" } */
+
+/* Check that the fpchg instruction is not moved in a delay slot if the
+   fallthru block uses the mode.  */
+
+__attribute__ ((weak))
+void barrier(void)
+{
+}
+
+float f;
+int i;
+double d;
+
+int main()
+{
+  i = 4;
+
+  barrier();
+
+  i = (f + (i && f && d));
+  return i;
+}
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.target/sh/fpchg2.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.target/sh/fpchg2.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/gcc.target/sh/fpchg2.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,16 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -m4-300" } */
+
+/* Make sure that fpchg is preferred over lfd.s fpscr.  */
+/* { dg-final { scan-assembler "fpchg" } } */
+/* { dg-final { scan-assembler-not "fpscr" } } */
+
+extern float c;
+
+void
+foo(int j)
+{
+  while (j--)
+    c++;
+
+}
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/nested-func-4.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/nested-func-4.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/nested-func-4.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,4 +1,3 @@
-/* { dg-do run } */
 /* { dg-options "-pg" } */
 /* { dg-options "-pg -static" { target hppa*-*-hpux* } } */
 /* { dg-require-profiling "-pg" } */
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/builtins-nan.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/builtins-nan.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/builtins-nan.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,54 @@
+/* { dg-do run } */
+/* { dg-options "-mieee" { target sh*-*-* } } */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <math.h>
+
+static int lisnan(double v)
+{
+  return (v != v);
+}
+
+static int lisnanf(float v)
+{
+  return (v != v);
+}
+
+int main(void)
+{
+  double d;
+  float f;
+
+  /* double */
+  d = __builtin_nans("");
+  if (! lisnan(d))
+    abort();
+
+  if (! __builtin_isnan(d))
+    abort();
+
+  d = __builtin_nan("");
+  if (! lisnan(d))
+    abort();
+
+  if (! __builtin_isnan(d))
+    abort();
+
+  /* float */
+  f = __builtin_nansf("");
+  if (! lisnanf(f))
+    abort();
+
+  if (! __builtin_isnanf(f))
+    abort();
+
+  f = __builtin_nanf("");
+  if (! lisnanf(f))
+    abort();
+
+  if (! __builtin_isnanf(f))
+    abort();
+
+  exit (0);
+}
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/array-index.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/array-index.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/array-index.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,15 @@
+/* PR tree-optimization/39423 */
+/* { dg-do compile } */
+/* { dg-options "-O2 -fdump-tree-original" } */
+
+int
+foo (int tab[], int index)
+{
+  return tab [index + 1];
+} 
+
+/* { dg-final { scan-tree-dump-times "\\+ 4" 1 "original" } } */
+/* { dg-final { scan-tree-dump-times "\\+ 1" 0 "original" } } */
+/* { dg-final { scan-tree-dump-times "index \\* 4" 1 "original" } } */
+/* { dg-final { cleanup-tree-dump "original" } } */
+
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/const-weak.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/const-weak.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/const-weak.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,16 @@
+/* weak constants can be replaced at link time. */
+
+/* { dg-do compile } */
+/* { dg-options "-O2 -fdump-tree-pre" } */
+
+const int wconst __attribute__((weak)) = 2;
+
+int f(void)
+{
+  return wconst;
+}
+
+/* { dg-final { scan-tree-dump-not "return 2" "pre"} } */
+/* { dg-final { cleanup-tree-dump "pre*]" } } */
+
+	
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/pr36998.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/pr36998.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/pr36998.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,6 +1,7 @@
 /* PR rtl-optimization/36998 */
 /* { dg-do compile } */
 /* { dg-options "-Os -fasynchronous-unwind-tables" } */
+/* { dg-options "-Os -fno-omit-frame-pointer -fasynchronous-unwind-tables" { target { sh-*-* } } } */
 /* { dg-options "-Os -mpreferred-stack-boundary=2 -fasynchronous-unwind-tables" { target { { i?86-*-* x86_64-*-* } && ilp32 } } } */
 /* { dg-options "-fno-omit-frame-pointer" { target { avr-*-* } } } */
 
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/cpp/trad/include.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/cpp/trad/include.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/cpp/trad/include.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -7,6 +7,5 @@
    Newlib uses ## when including stdlib.h as of 2007-09-07.  */
 /* { dg-do preprocess { target { { ! vxworks_kernel } && { ! newlib } } } } */
 
-#define __STDC__ 1		/* Stop complaints about non-ISO compilers.  */
 #define stdlib 1
 #include <stdlib.h>		/* { dg-bogus "o such file or directory" } */
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/ssp.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/ssp.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/ssp.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,13 @@
+/* { dg-do compile { target fpic } } */
+/* { dg-options "-Os -fpic -fstack-protector-all -fnon-call-exceptions " } */
+/* Causes error: unable to find a register to spill in class 'R0_REGS' on SH4 */
+
+int
+foo (int d, int rp)
+{
+  if (d == 0)
+    if (rp == 0)
+      return 1;
+
+  return 0;
+}
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/shlrtst.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/shlrtst.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/shlrtst.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,25 @@
+/* { dg-do run } */
+
+extern void abort (void);
+unsigned char test_char[2] ={0x80,0x40};
+
+void Funtion_test(unsigned char *buf, unsigned int num)
+{
+    unsigned int byte = num / 2;
+
+    if(!num)
+      buf[ byte] |= 0x80;
+    else
+      buf[ byte] |= 0x7f;      
+}
+
+main()
+{
+  Funtion_test(test_char, 0);
+
+  if (test_char[0] != 0x80)
+    abort();
+
+  return 0;
+}
+
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/pr42427.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/pr42427.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/pr42427.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2,6 +2,7 @@
 /* { dg-options "-O2 -fexceptions -fnon-call-exceptions -fpeel-loops" } */
 /* { dg-add-options c99_runtime } */
 /* { dg-require-effective-target ilp32 } */
+/* { dg-require-effective-target complex } */
 
 #include <complex.h>
 
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/torture/pr37868.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/torture/pr37868.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/torture/pr37868.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,6 +1,7 @@
 /* { dg-do run } */
 /* { dg-options "-fno-strict-aliasing" } */
 /* { dg-skip-if "unaligned access" { sparc*-*-* } "*" "" } */
+/* { dg-do run { xfail sh-superh-elf } } */ 
 
 extern void abort (void);
 #if (__SIZEOF_INT__ <= 2)
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/tree-ssa/pr42585.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/tree-ssa/pr42585.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/tree-ssa/pr42585.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -32,6 +32,8 @@
 }
 
 /* The local aggregates . */
-/* { dg-final { scan-tree-dump-times "struct _fat_ptr _ans" 0 "optimized"} } */
-/* { dg-final { scan-tree-dump-times "struct _fat_ptr _T2" 0 "optimized"} } */
+
+/* { dg-final { scan-tree-dump-times "struct _fat_ptr _ans" 0 "optimized" { xfail { sh*-*-* } } } } */
+/* { dg-final { scan-tree-dump-times "struct _fat_ptr _T2" 0 "optimized" { xfail { sh*-*-* } } } } */
+
 /* { dg-final { cleanup-tree-dump "optimized" } } */
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/fold-plusmult-2.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/fold-plusmult-2.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/fold-plusmult-2.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,20 +1,20 @@
 /* { dg-do compile } */
-/* { dg-options "-fdump-tree-original" } */
+/* { dg-options "-O2 -fdump-tree-original" } */
 
 int foo (int i)
 {
   return 2 + i * 4;
 }
 
-/* We do _not_ want the above to be canonicalized to (i * 2 + 1) * 2.  */
-
-int bar (int i)
+int
+bar (int tab[], int index)
 {
-  return 4 + i * 2;
+  return tab [index+2];
 }
 
-/* But eventually this to be canonicalized to (i + 2) * 2.  */
+
+/* The rational is that it is best not to downsize the multiplier. */
 
 /* { dg-final { scan-tree-dump "i \\\* 4 \\\+ 2" "original" } } */
-/* { dg-final { scan-tree-dump "\\\(i \\\+ 2\\\) \\\* 2" "original" } } */
+/* { dg-final { scan-tree-dump "index \\\* 4\\\) \\\+ 8" "original" } } */
 /* { dg-final { cleanup-tree-dump "original" } } */
Index: gcc-4.5.2.orig/gcc/testsuite/gcc.dg/fold-plusmult.c
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/gcc.dg/fold-plusmult.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/gcc.dg/fold-plusmult.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,5 +1,8 @@
 /* { dg-do compile } */
-/* { dg-options "-fdump-tree-original" } */
+/* moved from gimple to rtl. see
+	http://gcc.gnu.org/bugzilla/show_bug.cgi?id=39423
+*/
+/* { dg-options "-O2 -fdump-rtl-cse2" } */
 
 int test1 (int a)
 {
@@ -11,5 +14,6 @@
   return (a + a)*2;
 }
 
-/* { dg-final { scan-tree-dump-times "<a> \\\* 4" 2 "original" } } */
-/* { dg-final { cleanup-tree-dump "original" } } */
+/* { dg-final { scan-rtl-dump-times "ashift" 2 "cse2" } } */
+/* { dg-final { scan-rtl-dump-times "const_int 2" 2 "cse2" } } */
+/* { dg-final { cleanup-tree-dump "cse2" } } */
Index: gcc-4.5.2.orig/gcc/testsuite/ChangeLog.STM
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/ChangeLog.STM	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/ChangeLog.STM	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,119 @@
+2010-12-07  Christian Bruel  <christian.bruel@st.com>
+
+	* lib/lto.exp: Disable whopr.
+	* lib/gcc.exp: Likewise.
+	* lib/c-torture.exp: Likewise.
+
+2010-11-08  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=10391
+	* gcc.dg/ssp.c: New testcase. 
+
+2010-11-03  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.c-torture/execute/lroundf.c: New testcase. 
+	* gcc.c-torture/execute/lroundf.x: New.
+
+2010-10-14  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.c-torture/execute/lrintf.c: New testcase. 
+	* gcc.c-torture/execute/lrintf.x: New.
+
+2010-08-10  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.c-torture/compile/limits-structnest.c: xfail
+	* gcc.c-torture/execute/builtin-prefetch-6.c: xfail for sh-linux.
+
+2010-06-15  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=9320
+	* gcc.dg/shlrtst.c: New testcase. 
+
+2010-06-07  Christian Bruel  <christian.bruel@st.com>
+
+	* lib/target-supports.exp (check_effective_target_complex): Define.
+	* gcc.dg/pr42427.c: Check complex available.
+
+2010-06-07  Christian Bruel  <christian.bruel@st.com>
+
+	http://gcc.gnu.org/bugzilla/show_bug.cgi?id=42855
+	* gcc.dg/tree-ssa/pr42585.c: xfail for SH.
+
+2010-04-20  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl30850:
+	* gcc.dg/builtins-nan.c: New test.
+
+2010-01-26  Christian Bruel  <christian.bruel@st.com>
+
+	http://gcc.gnu.org/bugzilla/show_bug.cgi?id=39423
+	* gcc.dg/fold-plusmult.c: Check rtl instead of gimple.
+
+2010-01-26  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.target/sh/20080410-1.c: Remove -fira option.
+
+2009-11-10  Christian Bruel  <christian.bruel@st.com>
+
+	* g++.dg/eh/postreload.C: New test.
+
+2009-10-06  Antony King  <antony.king@st.com>
+
+	INSbl30052:
+	* lib/target-supports.exp (check_effective_target_sync_int_long):
+	Enable atomic builtins for sh*-superh-elf.
+	(check_effective_target_sync_char_short): Likewise.
+
+2009-09-29  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/const-weak.c: Change dump.
+
+2009-09-03  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/memcpy-1.c: xfail for SH.
+
+2009-09-03  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/const-weak.c: Update dg-final rules.
+
+2008-06-01  Richard Sandiford  <rdsandiford@googlemail.com>
+ 
+	* gcc.c-torture/execute/ieee/ieee.exp: Load c-torture.exp.
+
+2009-07-03  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/torture/pr36998.c: Add -fno-omit-frame-pointer for SH.
+
+2009-06-18  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/torture/pr37868.c: xfail for SH.
+	
+2009-06-26  Christian Bruel  <christian.bruel@st.com>
+
+	* lib/target-supports.exp: Disable profiling for SH when on the simu.
+
+2009-03-12  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/array-index.c: New optimisation test.
+
+2009-05-27  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/cpp/trad/include.c: Don't force __STDC__.
+
+2008-05-06  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/28671
+	* gcc.dg/const-weak.c: New testcase. 
+
+2008-04-17  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/28594
+	* gcc.dg/long-long-compare-1.c: New testcase. 
+	
+2008-01-28  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=3313
+	* gcc.dg/packed-array.c: New testcase. 
+
+
+
Index: gcc-4.5.2.orig/gcc/testsuite/g++.dg/other/error27.C
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/g++.dg/other/error27.C	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/g++.dg/other/error27.C	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,5 +1,4 @@
 // PR c++/35332
-// { dg-do compile }
 // { dg-options "-fno-finite-math-only" { target sh*-*-* } }
 
 void foo (double x, double y)
Index: gcc-4.5.2.orig/gcc/testsuite/g++.dg/eh/postreload.C
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/g++.dg/eh/postreload.C	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/testsuite/g++.dg/eh/postreload.C	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,35 @@
+// This testcase failed on sh, because stack offset to access i was shared
+// between handler and main.
+// { dg-do run }
+// { dg-options "-O2" }
+
+extern void abort (void);
+extern void exit (int);
+
+void
+bar (int *i, int *tab) __attribute__ ((weak,noinline)); 
+
+main()
+{
+  int i = 123;
+  int tab[47];
+
+  bar (&i, tab);
+
+  try
+    {
+      throw 1;
+    }
+  catch (...)
+    {
+      return 0;
+    }
+
+  abort ();
+}
+
+void
+bar (int *i, int *tab)
+{
+}
+
Index: gcc-4.5.2.orig/gcc/testsuite/lib/lto.exp
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/lib/lto.exp	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/lib/lto.exp	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -64,8 +64,6 @@
     # add it to site.exp directly.
     if ![info exists LTO_OPTIONS] {
 	set LTO_OPTIONS [list	\
-	    {-O0 -fwhopr}	\
-	    {-O2 -fwhopr}	\
 	    {-O0 -flto}		\
 	    {-O2 -flto}		\
 	]
Index: gcc-4.5.2.orig/gcc/testsuite/lib/gcc-dg.exp
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/lib/gcc-dg.exp	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/lib/gcc-dg.exp	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -70,8 +70,7 @@
 set LTO_TORTURE_OPTIONS ""
 if [check_effective_target_lto] {
     set LTO_TORTURE_OPTIONS [list \
-	{ -O2 -flto } \
-	{ -O2 -fwhopr }
+	{ -O2 -flto }
     ]
 }
 
Index: gcc-4.5.2.orig/gcc/testsuite/lib/c-torture.exp
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/lib/c-torture.exp	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/lib/c-torture.exp	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -53,8 +53,7 @@
 set LTO_TORTURE_OPTIONS ""
 if [check_effective_target_lto] {
     set LTO_TORTURE_OPTIONS [list \
-	{ -O2 -flto } \
-	{ -O2 -fwhopr }
+	{ -O2 -flto }
     ]
 }
 
Index: gcc-4.5.2.orig/gcc/testsuite/lib/target-supports.exp
===================================================================
--- gcc-4.5.2.orig/gcc/testsuite/lib/target-supports.exp	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/testsuite/lib/target-supports.exp	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -487,6 +487,13 @@
 	return 0
     }
 
+    # There is no profiling support on SH when running on the simu.
+    if { [istarget sh-superh-elf] } {
+	if [board_info target exists is_simulator] {
+	    return 0
+	}
+    }
+
     # uClibc does not have gcrt1.o.
     if { [check_effective_target_uclibc]
 	 && ([lindex $test_what 1] == "-p"
@@ -2845,6 +2852,7 @@
 	     || [istarget bfin*-*linux*]
 	     || [istarget s390*-*-*] 
 	     || [istarget powerpc*-*-*]
+	     || [istarget sh*-superh-elf]
 	     || [istarget sparc64-*-*]
 	     || [istarget sparcv9-*-*]
 	     || [istarget mips*-*-*] } {
@@ -2874,6 +2882,7 @@
 	     || [istarget arm*-*-linux-gnueabi] 
 	     || [istarget s390*-*-*] 
 	     || [istarget powerpc*-*-*]
+	     || [istarget sh*-superh-elf]
 	     || [istarget sparc64-*-*]
 	     || [istarget sparcv9-*-*]
 	     || [istarget mips*-*-*] } {
@@ -2926,6 +2935,15 @@
     }]
 }
 
+# Return true if this is a target supports complex.h
+
+proc check_effective_target_complex { } {
+    return [check_no_compiler_messages complex assembly {
+	#include <complex.h>
+	main() { complex double a; return 0; }
+    }]
+}
+
 # Return 1 if
 #   (a) an error of a few ULP is expected in string to floating-point
 #       conversion functions; and
Index: gcc-4.5.2.orig/gcc/cp/ChangeLog.STM
===================================================================
--- gcc-4.5.2.orig/gcc/cp/ChangeLog.STM	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/cp/ChangeLog.STM	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,4 @@
+2009-03-26  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl27506
+	* name-lookup.c: (do_nonmember_using_decl): Fixed error handling.
Index: gcc-4.5.2.orig/gcc/cp/name-lookup.c
===================================================================
--- gcc-4.5.2.orig/gcc/cp/name-lookup.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/cp/name-lookup.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2332,7 +2332,11 @@
     {
       *newtype = decls.type;
       if (oldtype && *newtype && !decls_match (oldtype, *newtype))
+	{
 	error ("%qD is already declared in this scope", name);
+	  *newtype = NULL_TREE;
+	}
+
     }
 
     /* If *newval is empty, shift any class or enumeration name down.  */
Index: gcc-4.5.2.orig/gcc/builtin-types.def
===================================================================
--- gcc-4.5.2.orig/gcc/builtin-types.def	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/builtin-types.def	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -115,11 +115,11 @@
 DEF_PRIMITIVE_TYPE (BT_VALIST_REF, va_list_ref_type_node)
 DEF_PRIMITIVE_TYPE (BT_VALIST_ARG, va_list_arg_type_node)
 
-DEF_PRIMITIVE_TYPE (BT_I1, builtin_type_for_size (BITS_PER_UNIT*1, 1))
-DEF_PRIMITIVE_TYPE (BT_I2, builtin_type_for_size (BITS_PER_UNIT*2, 1))
-DEF_PRIMITIVE_TYPE (BT_I4, builtin_type_for_size (BITS_PER_UNIT*4, 1))
-DEF_PRIMITIVE_TYPE (BT_I8, builtin_type_for_size (BITS_PER_UNIT*8, 1))
-DEF_PRIMITIVE_TYPE (BT_I16, builtin_type_for_size (BITS_PER_UNIT*16, 1))
+DEF_PRIMITIVE_TYPE (BT_I1, builtin_type_for_size (BITS_PER_UNIT*1, 0))
+DEF_PRIMITIVE_TYPE (BT_I2, builtin_type_for_size (BITS_PER_UNIT*2, 0))
+DEF_PRIMITIVE_TYPE (BT_I4, builtin_type_for_size (BITS_PER_UNIT*4, 0))
+DEF_PRIMITIVE_TYPE (BT_I8, builtin_type_for_size (BITS_PER_UNIT*8, 0))
+DEF_PRIMITIVE_TYPE (BT_I16, builtin_type_for_size (BITS_PER_UNIT*16, 0))
 
 DEF_POINTER_TYPE (BT_PTR_CONST_STRING, BT_CONST_STRING)
 DEF_POINTER_TYPE (BT_PTR_LONG, BT_LONG)
Index: gcc-4.5.2.orig/gcc/tree-ssa-ccp.c
===================================================================
--- gcc-4.5.2.orig/gcc/tree-ssa-ccp.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/tree-ssa-ccp.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -3,6 +3,7 @@
    2010 Free Software Foundation, Inc.
    Adapted from original RTL SSA-CCP by Daniel Berlin <dberlin@dberlin.org>
    Adapted to GIMPLE trees by Diego Novillo <dnovillo@redhat.com>
+   Copyright (c) 2010 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -276,7 +277,7 @@
 tree
 get_symbol_constant_value (tree sym)
 {
-  if (TREE_STATIC (sym)
+  if (TREE_STATIC (sym) && !DECL_WEAK (sym)
       && (TREE_READONLY (sym)
 	  || TREE_CODE (sym) == CONST_DECL))
     {
@@ -452,6 +453,9 @@
   if (!HONOR_NANS (mode)
       && REAL_VALUE_ISNAN (d))
     {
+      if (warn_non_finite_math)
+	warning (OPT_Wnon_finite_math,
+		 "non-finite operation %E not honored", val->value);
       val->lattice_val = UNDEFINED;
       val->value = NULL;
       return;
Index: gcc-4.5.2.orig/gcc/gthr-objc-generic.c
===================================================================
--- gcc-4.5.2.orig/gcc/gthr-objc-generic.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/gthr-objc-generic.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,221 @@
+/* Threads compatibility routines for libobjc.  */
+/* Compile this one with gcc.  */
+/* Copyright (C) 1997, 1999, 2000, 2006 Free Software Foundation, Inc.
+   Copyright (c) 2006  STMicroelectronics.
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify it under
+the terms of the GNU General Public License as published by the Free
+Software Foundation; either version 2, or (at your option) any later
+version.
+
+GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+for more details.
+
+You should have received a copy of the GNU General Public License
+along with GCC; see the file COPYING.  If not, write to the Free
+Software Foundation, 51 Franklin Street, Fifth Floor, Boston, MA
+02110-1301, USA.  */
+
+/* As a special exception, if you link this library with other files,
+   some of which are compiled with GCC, to produce an executable,
+   this library does not by itself cause the resulting executable
+   to be covered by the GNU General Public License.
+   This exception does not however invalidate any other reasons why
+   the executable file might be covered by the GNU General Public License.  */
+
+#include "tconfig.h"
+
+#define __GTHR_WEAK __attribute__ ((weak))
+#define _LIBOBJC
+
+/* ??? The objc thread types are defined in ../libobjc/objc/thr.h,
+   but we don't want the gcc core to depend on libobjc.  */
+typedef void * objc_thread_t;
+typedef struct objc_mutex *objc_mutex_t;
+typedef struct objc_condition *objc_condition_t;
+#define OBJC_THREAD_INTERACTIVE_PRIORITY        2
+
+#include "gthr.h"
+
+#define UNUSED(x) x ATTRIBUTE_UNUSED
+
+/* Just provide compatibility for mutex handling.  */
+
+/* Thread local storage for a single thread */
+static void *thread_local_storage = 0;
+
+/* Backend initialization functions */
+
+/* Initialize the threads subsystem.  */
+int
+__generic_gxx_objc_init_thread_system (void)
+{
+  /* No thread support available */
+  return -1;
+}
+
+/* Close the threads subsystem.  */
+int
+__generic_gxx_objc_close_thread_system (void)
+{
+  /* No thread support available */
+  return -1;
+}
+
+/* Backend thread functions */
+
+/* Create a new thread of execution.  The thread starts executing by calling
+   FUNC with ARG as its only argument.
+   On success, a handle for the new thread is returned.
+   On failure, zero is returned.  */
+objc_thread_t
+__generic_gxx_objc_thread_detach (void UNUSED ((* func)(void *)),
+				  void * UNUSED(arg))
+{
+  /* No thread support available */
+  return 0;
+}
+
+/* Set the current thread's priority.  */
+int
+__generic_gxx_objc_thread_set_priority (int UNUSED(priority))
+{
+  /* No thread support available */
+  return -1;
+}
+
+/* Return the current thread's priority.  */
+int
+__generic_gxx_objc_thread_get_priority (void)
+{
+  return OBJC_THREAD_INTERACTIVE_PRIORITY;
+}
+
+/* Yield our process time to another thread.  */
+void
+__generic_gxx_objc_thread_yield (void)
+{
+  return;
+}
+
+/* Terminate the current thread.  */
+int
+__generic_gxx_objc_thread_exit (void)
+{
+  /* No thread support available */
+  /* Should we really exit the program */
+  /* exit (&__objc_thread_exit_status); */
+  return -1;
+}
+
+/* Returns an integer value which uniquely describes a thread.  */
+objc_thread_t
+__generic_gxx_objc_thread_id (void)
+{
+  /* No thread support, use 1.  */
+  return (objc_thread_t) 1;
+}
+
+/* Sets the thread's objc local storage pointer.  */
+int
+__generic_gxx_objc_thread_set_data (void *value)
+{
+  thread_local_storage = value;
+  return 0;
+}
+
+/* Returns the thread's objc local storage pointer.  */
+void *
+__generic_gxx_objc_thread_get_data (void)
+{
+  return thread_local_storage;
+}
+
+/* Backend mutex functions */
+
+/* Allocate a backend-specific mutex data in MUTEX->backend.
+   Return 0 on success, -1 for failure.  */
+int
+__generic_gxx_objc_mutex_allocate (objc_mutex_t UNUSED(mutex))
+{
+  return 0;
+}
+
+/* Deallocate backend-specific mutex data in MUTEX->backend.
+   Return 0 on success, -1 for failure.  */
+int
+__generic_gxx_objc_mutex_deallocate (objc_mutex_t UNUSED(mutex))
+{
+  return 0;
+}
+
+/* Grab a lock on MUTEX.  Return 0 on success.  */
+int
+__generic_gxx_objc_mutex_lock (objc_mutex_t UNUSED(mutex))
+{
+  /* There can only be one thread, so we always get the lock */
+  return 0;
+}
+
+/* Try to grab a lock on MUTEX.  Return 0 on success.  */
+int
+__generic_gxx_objc_mutex_trylock (objc_mutex_t UNUSED(mutex))
+{
+  /* There can only be one thread, so we always get the lock */
+  return 0;
+}
+
+/* Unlock MUTEX.  Return 0 on success.  */
+int
+__generic_gxx_objc_mutex_unlock (objc_mutex_t UNUSED(mutex))
+{
+  return 0;
+}
+
+/* Backend condition mutex functions */
+
+/* Allocate backend-specific condition data in CONDITION->backend.
+   Return 0 on success, -1 for failure.  */
+int
+__generic_gxx_objc_condition_allocate (objc_condition_t UNUSED(condition))
+{
+  return 0;
+}
+
+/* Deallocate backend-specific condition data in CONDITION->backend.
+   Return 0 for success.  */
+int
+__generic_gxx_objc_condition_deallocate (objc_condition_t UNUSED(condition))
+{
+  return 0;
+}
+
+/* MUTEX is a locked mutex.  Atomically release MUTEX and wait on
+   CONDITION, i.e. so that no other thread can observe a state after
+   the release of MUTEX but before this thread has blocked.
+   Then re-acquire a lock on MUTEX.
+   Return 0 on success.  */
+int
+__generic_gxx_objc_condition_wait (objc_condition_t UNUSED(condition),
+				   objc_mutex_t UNUSED(mutex))
+{
+  return 0;
+}
+
+/* Wake up all threads waiting on CONDITION.  Return 0 on success.  */
+int
+__generic_gxx_objc_condition_broadcast (objc_condition_t UNUSED(condition))
+{
+  return 0;
+}
+
+/* Wake up one thread waiting on CONDITION.  Return 0 on success.  */
+int
+__generic_gxx_objc_condition_signal (objc_condition_t UNUSED(condition))
+{
+  return 0;
+}
Index: gcc-4.5.2.orig/gcc/mode-switching.c
===================================================================
--- gcc-4.5.2.orig/gcc/mode-switching.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/mode-switching.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,6 +1,7 @@
 /* CPU mode switching
    Copyright (C) 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2007, 2008,
    2009 Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -96,6 +97,181 @@
 static void reg_becomes_live (rtx, const_rtx, void *);
 static void make_preds_opaque (basic_block, int);
 
+/* Bitmap to compute mode flipping.  */
+
+static sbitmap *mode_in_flip;  /* flip in mode status for each basic blocks.  */
+static sbitmap *mode_out_flip; /* flip out mode status for each basic blocks.  */
+/* To support mode switching, the algorithm cannot set the modes after
+   the insert and delete bitmaps are computed by pre_edge_lcm, because
+   'avin' is computed iteratively for each possible modes for each entity.
+   The mode emission will be done after all mode are processed.
+   (see commit_mode_sets).  */
+
+static int **modes_needed;  /* modes needs to be inserted on this edge.  */
+
+/* Indicates that edge mode information is unknown. Cannot use 'no_mode'
+   because its value depends of its entity */
+#define NO_MODE -1
+
+
+/* Return true when one of the predecessor edges of BB is marked with
+   EDGE_COMPLEX. (similar to bb_has_eh_pred in basic_block.h).  */
+static bool
+bb_has_complex_pred (basic_block bb)
+{
+  edge e;
+  edge_iterator ei;
+
+  FOR_EACH_EDGE (e, ei, bb->preds)
+    {
+      if (e->flags & EDGE_COMPLEX)
+	return true;
+    }
+  return false;
+}
+
+/* Test avin modes.
+   if 'out' is 'true' we want to know if the mode out of the basic block
+   can be flipped. If 'in' is true we want to know if the mode entering the basic
+   block can be flipped.  */
+
+static int
+test_flip_status(int entity, basic_block bb, bool out)
+{
+  if (out)
+    return TEST_BIT (mode_out_flip[bb->index], entity);
+  else
+    return TEST_BIT (mode_in_flip[bb->index], entity);
+}
+
+/* Merges the avin modes.  */
+
+static void
+set_flip_status (sbitmap *avin, sbitmap *avout)
+{
+  basic_block bb;
+
+  FOR_EACH_BB (bb)
+    {
+      int i = bb->index;
+
+      /* Merge modes for each entity for each bb.
+	 If multiple avin modes are set for the same bb, they are not
+	 exclusive and a flip may not be emitted.
+	 If more that 2 modes can be defined, flip may not be emitted.  */
+      if (! bb_has_complex_pred (bb))
+	{
+	  sbitmap_a_xor_b (mode_in_flip[i], mode_in_flip[i], avin[i]);
+	  sbitmap_a_xor_b (mode_out_flip[i], mode_out_flip[i], avout[i]);
+	}
+    }
+}
+
+/* Allocates and initializes modes_infos.  */
+
+static void
+init_modes_infos (int n_entities)
+{
+  int j;
+  int num_edges = 0;
+  basic_block bb;
+
+  /* How many edges do we have ?  */
+
+  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, EXIT_BLOCK_PTR, next_bb)
+      num_edges += EDGE_COUNT (bb->succs);
+
+  modes_needed = XNEWVEC (int *, n_entities);
+
+  for (j = 0; j < n_entities; j++)
+    {
+      modes_needed[j] = XNEWVEC (int, num_edges);
+
+      /* Initial NO_MODE value is -1, because 0 is a value mode.  */
+      memset (modes_needed[j], NO_MODE, num_edges * sizeof (int));
+    }
+
+  /* Allocates bitmaps for modes.  */
+  mode_in_flip = sbitmap_vector_alloc (last_basic_block, n_entities);
+  mode_out_flip = sbitmap_vector_alloc (last_basic_block, n_entities);
+  sbitmap_vector_zero (mode_in_flip, last_basic_block);
+  sbitmap_vector_zero (mode_out_flip, last_basic_block);
+}
+
+/* frees memory used to hold the modes information.  */
+
+static void
+free_modes_infos (int n_entities)
+{
+  int j;
+
+  for (j = 0; j < n_entities; j++)
+    free (modes_needed[j]);
+
+  free (modes_needed);
+  sbitmap_vector_free (mode_in_flip);
+  sbitmap_vector_free (mode_out_flip);
+}
+
+/* records the mode associated with edge e for entity j.  */
+
+static void
+add_mode_set (int j, int e, int mode)
+{
+  modes_needed[j][e] = mode;
+}
+
+/* returns the mode needed on edge e for entity j. -1 if none.  */
+
+static int
+get_mode (int j, int e)
+{
+  return modes_needed[j][e];
+}
+
+/* Finally, after all the modes after been inserted after lcm, we can
+   process with the mode emission.  */
+
+static int
+commit_mode_sets (struct edge_list *edge_list, int j)
+{
+  int need_commit = 0;
+  int e;
+
+  for (e = 0; e < NUM_EDGES (edge_list); e++)
+    {
+      HARD_REG_SET live_at_edge;
+      edge eg = INDEX_EDGE (edge_list, e);
+      basic_block src_bb = eg->src;
+      int mode, prev_mode;
+      rtx mode_set;
+
+      if ((mode = get_mode (j, e)) == NO_MODE)
+	continue;
+
+      prev_mode = test_flip_status (j, src_bb, true);
+
+      REG_SET_TO_HARD_REG_SET (live_at_edge, df_get_live_out (src_bb));
+
+      start_sequence ();
+      EMIT_MODE_SET (entity_map[j], mode, prev_mode, live_at_edge);
+
+      mode_set = get_insns ();
+      end_sequence ();
+
+      /* Do not bother to insert empty sequence.  */
+      if (mode_set == NULL_RTX)
+	continue;
+
+      /* We should not get an abnormal edge here.  */
+      gcc_assert (! (eg->flags & EDGE_ABNORMAL));
+	
+      need_commit = 1;
+      insert_insn_on_edge (mode_set, eg);
+    }
+
+  return need_commit;
+}
 
 /* This function will allocate a new BBINFO structure, initialized
    with the MODE, INSN, and basic block BB parameters.  */
@@ -435,7 +611,6 @@
   basic_block bb;
   int need_commit = 0;
   sbitmap *kill;
-  struct edge_list *edge_list;
   static const int num_modes[] = NUM_MODES_FOR_MODE_SWITCHING;
 #define N_ENTITIES ARRAY_SIZE (num_modes)
   int entity_map[N_ENTITIES];
@@ -445,6 +620,8 @@
   int max_num_modes = 0;
   bool emited = false;
   basic_block post_entry ATTRIBUTE_UNUSED, pre_exit ATTRIBUTE_UNUSED;
+  sbitmap *avin, *avout;
+  struct edge_list *edge_list = 0;
 
   for (e = N_ENTITIES - 1, n_entities = 0; e >= 0; e--)
     if (OPTIMIZE_MODE_SWITCHING (e))
@@ -481,6 +658,8 @@
   antic = sbitmap_vector_alloc (last_basic_block, n_entities);
   transp = sbitmap_vector_alloc (last_basic_block, n_entities);
   comp = sbitmap_vector_alloc (last_basic_block, n_entities);
+  avin = sbitmap_vector_alloc (last_basic_block, n_entities);
+  avout = sbitmap_vector_alloc (last_basic_block, n_entities);
 
   sbitmap_vector_ones (transp, last_basic_block);
 
@@ -582,6 +761,9 @@
     }
 
   kill = sbitmap_vector_alloc (last_basic_block, n_entities);
+
+  init_modes_infos (n_entities);
+
   for (i = 0; i < max_num_modes; i++)
     {
       int current_mode[N_ENTITIES];
@@ -611,8 +793,11 @@
 
       FOR_EACH_BB (bb)
 	sbitmap_not (kill[bb->index], transp[bb->index]);
-      edge_list = pre_edge_lcm (n_entities, transp, comp, antic,
-				kill, &insert, &del);
+      edge_list = pre_edge_lcm_avs (n_entities, transp, comp, antic,
+				    kill, avin, avout, &insert, &del);
+
+      /* Merge modes for all entities.  */
+      set_flip_status (avin, avout);
 
       for (j = n_entities - 1; j >= 0; j--)
 	{
@@ -629,10 +814,6 @@
 	  for (e = NUM_EDGES (edge_list) - 1; e >= 0; e--)
 	    {
 	      edge eg = INDEX_EDGE (edge_list, e);
-	      int mode;
-	      basic_block src_bb;
-	      HARD_REG_SET live_at_edge;
-	      rtx mode_set;
 
 	      eg->aux = 0;
 
@@ -641,25 +822,8 @@
 
 	      eg->aux = (void *)1;
 
-	      mode = current_mode[j];
-	      src_bb = eg->src;
-
-	      REG_SET_TO_HARD_REG_SET (live_at_edge, df_get_live_out (src_bb));
-
-	      start_sequence ();
-	      EMIT_MODE_SET (entity_map[j], mode, live_at_edge);
-	      mode_set = get_insns ();
-	      end_sequence ();
-
-	      /* Do not bother to insert empty sequence.  */
-	      if (mode_set == NULL_RTX)
-		continue;
-
-	      /* We should not get an abnormal edge here.  */
-	      gcc_assert (! (eg->flags & EDGE_ABNORMAL));
-
-	      need_commit = 1;
-	      insert_insn_on_edge (mode_set, eg);
+	      /* Remember we need to emit it.  */
+	      add_mode_set(j, e, current_mode[j]);
 	    }
 
 	  FOR_EACH_BB_REVERSE (bb)
@@ -674,6 +838,9 @@
       sbitmap_vector_free (del);
       sbitmap_vector_free (insert);
       clear_aux_for_edges ();
+
+      /* Keep an edge_list for later.  */
+      if (i != max_num_modes - 1)
       free_edge_list (edge_list);
     }
 
@@ -682,9 +849,16 @@
     {
       int no_mode = num_modes[entity_map[j]];
 
+      /* In case there was no mode inserted. the mode information on the edge
+	 might not be complete.
+	 Update mode info on edges and commit pending mode sets.  */
+      need_commit |= commit_mode_sets (edge_list, j);
+
       FOR_EACH_BB_REVERSE (bb)
 	{
 	  struct seginfo *ptr, *next;
+	  int last_mode = test_flip_status (j, bb, false);
+
 	  for (ptr = bb_info[j][bb->index].seginfo; ptr; ptr = next)
 	    {
 	      next = ptr->next;
@@ -693,10 +867,14 @@
 		  rtx mode_set;
 
 		  start_sequence ();
-		  EMIT_MODE_SET (entity_map[j], ptr->mode, ptr->regs_live);
+		  EMIT_MODE_SET (entity_map[j], ptr->mode, last_mode,
+				 ptr->regs_live);
 		  mode_set = get_insns ();
 		  end_sequence ();
 
+		  /* modes are are localy set.  */
+		  last_mode = 1;
+
 		  /* Insert MODE_SET only if it is nonempty.  */
 		  if (mode_set != NULL_RTX)
 		    {
@@ -715,6 +893,9 @@
       free (bb_info[j]);
     }
 
+  free_edge_list (edge_list);
+  free_modes_infos (n_entities);
+
   /* Finished. Free up all the things we've allocated.  */
   sbitmap_vector_free (kill);
   sbitmap_vector_free (antic);
Index: gcc-4.5.2.orig/gcc/dwarf2out.c
===================================================================
--- gcc-4.5.2.orig/gcc/dwarf2out.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/dwarf2out.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -3963,13 +3963,13 @@
   if (flag_reorder_blocks_and_partition)
     {
       section *unlikelysec;
-      if (first_function_block_is_cold)
+      if (in_cold_section_p)
 	fde->in_std_section = 1;
       else
 	fde->in_std_section
 	  = (fnsec == text_section
 	     || (cold_text_section && fnsec == cold_text_section));
-      unlikelysec = unlikely_text_section ();
+      unlikelysec = unlikely_text_section (current_function_decl);
       fde->cold_in_std_section
 	= (unlikelysec == text_section
 	   || (cold_text_section && unlikelysec == cold_text_section));
@@ -20733,7 +20733,7 @@
   ASM_OUTPUT_LABEL (asm_out_file, text_section_label);
   if (flag_reorder_blocks_and_partition)
     {
-      cold_text_section = unlikely_text_section ();
+      cold_text_section = unlikely_text_section (current_function_decl);
       switch_to_section (cold_text_section);
       ASM_OUTPUT_LABEL (asm_out_file, cold_text_section_label);
     }
@@ -21467,7 +21467,7 @@
   targetm.asm_out.internal_label (asm_out_file, TEXT_END_LABEL, 0);
   if (flag_reorder_blocks_and_partition)
     {
-      switch_to_section (unlikely_text_section ());
+      switch_to_section (unlikely_text_section (current_function_decl));
       targetm.asm_out.internal_label (asm_out_file, COLD_END_LABEL, 0);
     }
 
Index: gcc-4.5.2.orig/gcc/expr.c
===================================================================
--- gcc-4.5.2.orig/gcc/expr.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/expr.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -7469,6 +7469,29 @@
 		  return REDUCE_BIT_FIELD (temp);
 		}
 	    }
+
+	  /* This used to be canonicalized by fold-const (see
+	     fold_plusminus_mult_expr), but we prefer not to do it for
+	     indirect_ref, sine this gives better code for base+imm
+	     addressing modes.
+	     INDIRECT_REF are expanded with EXPAND_SUM modifier. Is
+	     there a better way to test it ?  */
+	  if (modifier == EXPAND_NORMAL
+	      && TREE_CODE (subsubexp1) == INTEGER_CST
+	      && TREE_CODE (treeop1) == INTEGER_CST)
+	    {
+	      if (operand_equal_p (subsubexp1, treeop1, 0)
+		  && exact_log2 (TREE_INT_CST_LOW (subsubexp1)) > 0)
+		{
+		  HOST_WIDE_INT val = TREE_INT_CST_LOW (subsubexp1);
+
+		  op0 = plus_constant (expand_normal (subsubexp0), 1);
+		  temp = expand_mult (mode, op0, GEN_INT (val),
+				      target, unsignedp);
+		  gcc_assert (temp);
+		  return REDUCE_BIT_FIELD (temp);
+		}
+	    }
 	}
 
       /* If we are adding a constant, a VAR_DECL that is sp, fp, or ap, and
Index: gcc-4.5.2.orig/gcc/longlong.h
===================================================================
--- gcc-4.5.2.orig/gcc/longlong.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/longlong.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -965,6 +965,30 @@
 /* This is the same algorithm as __udiv_qrnnd_c.  */
 #define UDIV_NEEDS_NORMALIZATION 1
 
+#ifdef	DB_ST40300_BUG_WORKAROUND
+#define udiv_qrnnd(q, r, n1, n0, d) \
+  do {									\
+    extern UWtype __udiv_qrnnd_16 (UWtype, UWtype)			\
+                        __attribute__ ((visibility ("hidden")));	\
+    /* r0: rn r1: qn */ /* r0: n1 r4: n0 r5: d r6: d1 */ /* r2: __m */	\
+    __asm__ (								\
+"	.align	2\n"                                                    \
+"       mov%M4 %4,r5\n"						        \
+"	swap.w %3,r4\n"							\
+"	swap.w r5,r6\n"							\
+"       nop\n"                                                          \
+"	jsr @%5\n"							\
+"	shll16 r6\n"							\
+"	swap.w r4,r4\n"							\
+"       nop\n"                                                          \
+"	jsr @%5\n"							\
+"	swap.w r1,%0\n"							\
+"	or r1,%0"							\
+	: "=r" (q), "=&z" (r)						\
+	: "1" (n1), "r" (n0), "rm" (d), "r" (&__udiv_qrnnd_16)		\
+        : "r1", "r2", "r4", "r5", "r6", "pr", "t");			\
+  } while (0)
+#else
 #define udiv_qrnnd(q, r, n1, n0, d) \
   do {									\
     extern UWtype __udiv_qrnnd_16 (UWtype, UWtype)			\
@@ -984,6 +1008,7 @@
 	: "1" (n1), "r" (n0), "rm" (d), "r" (&__udiv_qrnnd_16)		\
 	: "r1", "r2", "r4", "r5", "r6", "pr", "t");			\
   } while (0)
+#endif
 
 #define UDIV_TIME 80
 
Index: gcc-4.5.2.orig/gcc/predict.c
===================================================================
--- gcc-4.5.2.orig/gcc/predict.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/predict.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -77,7 +77,6 @@
 static void combine_predictions_for_insn (rtx, basic_block);
 static void dump_prediction (FILE *, enum br_predictor, int, basic_block, int);
 static void predict_paths_leading_to (basic_block, enum br_predictor, enum prediction);
-static void choose_function_section (void);
 static bool can_predict_insn_p (const_rtx);
 
 /* Information we hold about each branch predictor.
@@ -2139,8 +2138,6 @@
       free_aux_for_edges ();
     }
   compute_function_frequency ();
-  if (flag_reorder_functions)
-    choose_function_section ();
 }
 
 /* Decide whether function is hot, cold or unlikely executed.  */
@@ -2172,34 +2169,6 @@
     }
 }
 
-/* Choose appropriate section for the function.  */
-static void
-choose_function_section (void)
-{
-  if (DECL_SECTION_NAME (current_function_decl)
-      || !targetm.have_named_sections
-      /* Theoretically we can split the gnu.linkonce text section too,
-	 but this requires more work as the frequency needs to match
-	 for all generated objects so we need to merge the frequency
-	 of all instances.  For now just never set frequency for these.  */
-      || DECL_ONE_ONLY (current_function_decl))
-    return;
-
-  /* If we are doing the partitioning optimization, let the optimization
-     choose the correct section into which to put things.  */
-
-  if (flag_reorder_blocks_and_partition)
-    return;
-
-  if (cfun->function_frequency == FUNCTION_FREQUENCY_HOT)
-    DECL_SECTION_NAME (current_function_decl) =
-      build_string (strlen (HOT_TEXT_SECTION_NAME), HOT_TEXT_SECTION_NAME);
-  if (cfun->function_frequency == FUNCTION_FREQUENCY_UNLIKELY_EXECUTED)
-    DECL_SECTION_NAME (current_function_decl) =
-      build_string (strlen (UNLIKELY_EXECUTED_TEXT_SECTION_NAME),
-		    UNLIKELY_EXECUTED_TEXT_SECTION_NAME);
-}
-
 static bool
 gate_estimate_probability (void)
 {
Index: gcc-4.5.2.orig/gcc/lcm.c
===================================================================
--- gcc-4.5.2.orig/gcc/lcm.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/lcm.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,6 +1,7 @@
 /* Generic partial redundancy elimination with lazy code motion support.
    Copyright (C) 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2007, 2008
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -370,17 +371,18 @@
     }
 }
 
-/* Given local properties TRANSP, ANTLOC, AVOUT, KILL return the insert and
-   delete vectors for edge based LCM.  Returns an edgelist which is used to
-   map the insert vector to what edge an expression should be inserted on.  */
+/* Given local properties TRANSP, ANTLOC, AVLOC, KILL return the insert and
+   delete vectors for edge based LCM, and return the AVIN, AVOUT bitmap.
+   Returns an edgelist which is used to map the insert vector to
+   what edge an expression should be inserted on.  */
 
 struct edge_list *
-pre_edge_lcm (int n_exprs, sbitmap *transp,
+pre_edge_lcm_avs (int n_exprs, sbitmap *transp,
 	      sbitmap *avloc, sbitmap *antloc, sbitmap *kill,
+		  sbitmap *avin, sbitmap *avout,
 	      sbitmap **insert, sbitmap **del)
 {
   sbitmap *antin, *antout, *earliest;
-  sbitmap *avin, *avout;
   sbitmap *later, *laterin;
   struct edge_list *edge_list;
   int num_edges;
@@ -402,10 +404,7 @@
 #endif
 
   /* Compute global availability.  */
-  avin = sbitmap_vector_alloc (last_basic_block, n_exprs);
-  avout = sbitmap_vector_alloc (last_basic_block, n_exprs);
   compute_available (avloc, kill, avout, avin);
-  sbitmap_vector_free (avin);
 
   /* Compute global anticipatability.  */
   antin = sbitmap_vector_alloc (last_basic_block, n_exprs);
@@ -431,7 +430,6 @@
 
   sbitmap_vector_free (antout);
   sbitmap_vector_free (antin);
-  sbitmap_vector_free (avout);
 
   later = sbitmap_vector_alloc (num_edges, n_exprs);
 
@@ -468,6 +466,28 @@
   return edge_list;
 }
 
+/* Wrapper to allocate avin/avout and call pre_edge_lcm_avs.  */
+
+struct edge_list *
+pre_edge_lcm (int n_exprs, sbitmap *transp,
+	      sbitmap *avloc, sbitmap *antloc, sbitmap *kill,
+	      sbitmap **insert, sbitmap **delete)
+{
+  struct edge_list *edge_list;
+  sbitmap *avin, *avout;
+
+  avin = sbitmap_vector_alloc (last_basic_block, n_exprs);
+  avout = sbitmap_vector_alloc (last_basic_block, n_exprs);
+
+  edge_list = pre_edge_lcm_avs (n_exprs, transp, avloc, antloc, kill,
+				 avin, avout, insert, delete);
+
+  sbitmap_vector_free (avout);
+  sbitmap_vector_free (avin);
+
+  return edge_list;
+}
+
 /* Compute the AVIN and AVOUT vectors from the AVLOC and KILL vectors.
    Return the number of passes we performed to iterate to a solution.  */
 
Index: gcc-4.5.2.orig/gcc/configure.ac
===================================================================
--- gcc-4.5.2.orig/gcc/configure.ac	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/configure.ac	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -803,8 +803,8 @@
 [onestep=""])
 AC_SUBST(onestep)
 
-ACX_PKGVERSION([GCC])
-ACX_BUGURL([http://gcc.gnu.org/bugs.html])
+ACX_PKGVERSION(STMicroelectronics Base)
+ACX_BUGURL(<file://doc/docbug.htm> on the installation CD)
 
 # Sanity check enable_languages in case someone does not run the toplevel
 # configure # script.
@@ -1373,7 +1373,7 @@
     target_thread_file='single'
     ;;
   aix | dce | gnat | irix | posix | posix95 | rtems | \
-  single | solaris | vxworks | win32 | mipssde)
+  single | solaris | vxworks | win32 | mipssde | generic)
     target_thread_file=${enable_threads}
     ;;
   *)
@@ -1398,6 +1398,14 @@
     mv -f gthr-default.h-t gthr-default.h
   fi
   gthread_flags=-DHAVE_GTHR_DEFAULT
+  if test $thread_file != posix; then
+    if test -f $srcdir/gthr-${thread_file}.c; then
+      extra_libgcc_srcs=$srcdir/gthr-${thread_file}.c
+    fi
+    if test -f $srcdir/gthr-objc-${thread_file}.c; then
+      extra_libgcc_srcs="${extra_libgcc_srcs} $srcdir/gthr-objc-${thread_file}.c"
+    fi
+  fi
 fi
 AC_SUBST(gthread_flags)
 
@@ -1753,6 +1761,16 @@
 	CROSS="-DCROSS_DIRECTORY_STRUCTURE"
 	ALL=all.cross
 	SYSTEM_HEADER_DIR=$build_system_header_dir
+
+	# For builds with an in-tree newlib, then the headers are not
+	# copied to build_system_header_dir, so things like limits.h
+	# won't work unless we point at the real headers.
+	if test "$with_newlib" = yes \
+		&& (test -z "$with_headers" || test "$with_headers" = yes) \
+		&& test -d $srcdir/../newlib/libc/include; then
+	  SYSTEM_HEADER_DIR="\$(abs_srcdir)/../newlib/libc/include"
+	fi
+
 	case "$host","$target" in
 	# Darwin crosses can use the host system's libraries and headers,
 	# because of the fat library support.  Of course, it must be the
@@ -4473,6 +4491,7 @@
 AC_SUBST(TM_MULTILIB_EXCEPTIONS_CONFIG)
 AC_SUBST(extra_gcc_objs)
 AC_SUBST(extra_headers_list)
+AC_SUBST(extra_libgcc_srcs)
 AC_SUBST(extra_objs)
 AC_SUBST(extra_parts)
 AC_SUBST(extra_passes)
Index: gcc-4.5.2.orig/gcc/cppdefault.h
===================================================================
--- gcc-4.5.2.orig/gcc/cppdefault.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/cppdefault.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -67,4 +67,11 @@
 /* Return true if the toolchain is relocated.  */
 bool cpp_relocated (void);
 
+extern const char cpp_STANDARD_EXEC_PREFIX[];
+extern const size_t cpp_STANDARD_EXEC_PREFIX_len;
+extern const char *gcc_exec_prefix;
+
+/* Return true if the toolchain is relocated.  */
+bool cpp_relocated (void);
+
 #endif /* ! GCC_CPPDEFAULT_H */
Index: gcc-4.5.2.orig/gcc/stor-layout.c
===================================================================
--- gcc-4.5.2.orig/gcc/stor-layout.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/stor-layout.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1992, 1993, 1994, 1995, 1996, 1996, 1998,
    1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -1488,14 +1489,6 @@
   rli->offset_align = BITS_PER_UNIT;
   normalize_rli (rli);
 
-  /* Determine the desired alignment.  */
-#ifdef ROUND_TYPE_ALIGN
-  TYPE_ALIGN (rli->t) = ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t),
-					  rli->record_align);
-#else
-  TYPE_ALIGN (rli->t) = MAX (TYPE_ALIGN (rli->t), rli->record_align);
-#endif
-
   /* Compute the size so far.  Be sure to allow for extra bits in the
      size in bytes.  We have guaranteed above that it will be no more
      than a single byte.  */
@@ -1505,6 +1498,17 @@
     unpadded_size_unit
       = size_binop (PLUS_EXPR, unpadded_size_unit, size_one_node);
 
+
+  /* Determine the desired alignment.  */
+#ifdef ROUND_TYPE_ALIGN
+  TYPE_SIZE (rli->t) = unpadded_size;
+  TYPE_ALIGN (rli->t) = ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t),
+					  rli->record_align);
+
+#else
+  TYPE_ALIGN (rli->t) = MAX (TYPE_ALIGN (rli->t), rli->record_align);
+#endif
+
   /* Round the size up to be a multiple of the required alignment.  */
   TYPE_SIZE (rli->t) = round_up_loc (input_location, unpadded_size,
 				 TYPE_ALIGN (rli->t));
Index: gcc-4.5.2.orig/gcc/read-rtl.c
===================================================================
--- gcc-4.5.2.orig/gcc/read-rtl.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/read-rtl.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -767,9 +767,10 @@
 void
 print_rtx_ptr_loc (const void *ptr)
 {
+#if 0
   const struct ptr_loc *loc = get_rtx_ptr_loc (ptr);
-  if (loc != 0)
     printf ("#line %d \"%s\"\n", loc->lineno, loc->filename);
+#endif
 }
 
 /* Return a condition that satisfies both COND1 and COND2.  Either string
Index: gcc-4.5.2.orig/gcc/profile.c
===================================================================
--- gcc-4.5.2.orig/gcc/profile.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/profile.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -654,8 +654,13 @@
 
       if (bb->count < 0)
 	{
-	  error ("corrupted profile info: number of iterations for basic block %d thought to be %i",
-		 bb->index, (int)bb->count);
+	  if (warn_branch_probabilities_computation)
+	    warning (OPT_Wbranch_probabilities_computation, "corrupted profile "
+		     "info: number of iterations for basic block %d thought to "
+		     "be %i", bb->index, (int)bb->count);
+	  else
+	    error ("corrupted profile info: number of iterations for basic "
+		   "block %d thought to be %i", bb->index, (int)bb->count);
 	  bb->count = 0;
 	}
       FOR_EACH_EDGE (e, ei, bb->succs)
@@ -675,8 +680,14 @@
 	    }
 	  if (e->count < 0 || e->count > bb->count)
 	    {
-	      error ("corrupted profile info: number of executions for edge %d-%d thought to be %i",
-		     e->src->index, e->dest->index,
+	      if (warn_branch_probabilities_computation)
+		warning (OPT_Wbranch_probabilities_computation, "corrupted "
+			 "profile info: number of executions for edge %d-%d "
+			 "thought to be %i", e->src->index, e->dest->index,
+			 (int)e->count);
+	      else 
+		error ("corrupted profile info: number of executions for edge "
+		       "%d-%d thought to be %i", e->src->index, e->dest->index,
 		     (int)e->count);
 	      e->count = bb->count / 2;
 	    }
Index: gcc-4.5.2.orig/gcc/c-typeck.c
===================================================================
--- gcc-4.5.2.orig/gcc/c-typeck.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/c-typeck.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998,
    1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010
    Free Software Foundation, Inc.
+   Copyright (c) 2010 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -1703,6 +1704,7 @@
       && !TREE_THIS_VOLATILE (decl)
       && TREE_READONLY (decl)
       && DECL_INITIAL (decl) != 0
+      && !DECL_WEAK (decl)
       && TREE_CODE (DECL_INITIAL (decl)) != ERROR_MARK
       /* This is invalid if initial value is not constant.
 	 If it has either a function call, a memory reference,
Index: gcc-4.5.2.orig/gcc/except.c
===================================================================
--- gcc-4.5.2.orig/gcc/except.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/except.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -197,10 +197,10 @@
 
 static void push_uleb128 (VEC (uchar, gc) **, unsigned int);
 static void push_sleb128 (VEC (uchar, gc) **, int);
-#ifndef HAVE_AS_LEB128
+
 static int dw2_size_of_call_site_table (int);
 static int sjlj_size_of_call_site_table (void);
-#endif
+
 static void dw2_output_call_site_table (int, int);
 static void sjlj_output_call_site_table (void);
 
@@ -1560,6 +1560,22 @@
     }
 }
 
+/* Invoke CALLBACK for every exception region in the current function.  */
+
+void
+for_each_eh_region (void (*callback) (struct eh_region_d *, void *), void *arg)
+{
+  eh_region region;
+  int i;
+
+  for (i = 1; VEC_iterate (eh_region, cfun->eh->region_array, i, region); ++i)
+    {
+      if (region)
+	(*callback) (region, arg);
+    }
+}
+
+
 /* Create the REG_EH_REGION note for INSN, given its ECF_FLAGS for a
    call insn.
 
@@ -2710,7 +2726,6 @@
 }
 
 
-#ifndef HAVE_AS_LEB128
 static int
 dw2_size_of_call_site_table (int section)
 {
@@ -2745,7 +2760,6 @@
 
   return size;
 }
-#endif
 
 static void
 dw2_output_call_site_table (int cs_format, int section)
@@ -2756,7 +2770,7 @@
 
   if (section == 0)
     begin = current_function_func_begin_label;
-  else if (first_function_block_is_cold)
+  else if (in_cold_section_p)
     begin = crtl->subsections.hot_section_label;
   else
     begin = crtl->subsections.cold_section_label;
@@ -2942,13 +2956,10 @@
 				     int section, rtx ARG_UNUSED (personality))
 {
   int tt_format, cs_format, lp_format, i;
-#ifdef HAVE_AS_LEB128
   char ttype_label[32];
   char cs_after_size_label[32];
   char cs_end_label[32];
-#else
   int call_site_len;
-#endif
   int have_tt_data;
   int tt_format_size = 0;
 
@@ -2977,11 +2988,12 @@
   else
     {
       tt_format = ASM_PREFERRED_EH_DATA_FORMAT (/*code=*/0, /*global=*/1);
-#ifdef HAVE_AS_LEB128
+      if (TARGET_USES_LEB128)
+	{
       ASM_GENERATE_INTERNAL_LABEL (ttype_label,
 				   section ? "LLSDATTC" : "LLSDATT",
 				   current_function_funcdef_no);
-#endif
+	}
       tt_format_size = size_of_encoded_value (tt_format);
 
       assemble_align (tt_format_size * BITS_PER_UNIT);
@@ -3007,17 +3019,19 @@
   dw2_asm_output_data (1, tt_format, "@TType format (%s)",
 		       eh_data_format_name (tt_format));
 
-#ifndef HAVE_AS_LEB128
+  if (! TARGET_USES_LEB128)
+    {
   if (USING_SJLJ_EXCEPTIONS)
     call_site_len = sjlj_size_of_call_site_table ();
   else
     call_site_len = dw2_size_of_call_site_table (section);
-#endif
+    }
 
   /* A pc-relative 4-byte displacement to the @TType data.  */
   if (have_tt_data)
     {
-#ifdef HAVE_AS_LEB128
+      if (TARGET_USES_LEB128)
+	{
       char ttype_after_disp_label[32];
       ASM_GENERATE_INTERNAL_LABEL (ttype_after_disp_label,
 				   section ? "LLSDATTDC" : "LLSDATTD",
@@ -3025,7 +3039,9 @@
       dw2_asm_output_delta_uleb128 (ttype_label, ttype_after_disp_label,
 				    "@TType base offset");
       ASM_OUTPUT_LABEL (asm_out_file, ttype_after_disp_label);
-#else
+	}
+      else
+	{
       /* Ug.  Alignment queers things.  */
       unsigned int before_disp, after_disp, last_disp, disp;
 
@@ -3053,19 +3069,20 @@
       while (disp != last_disp);
 
       dw2_asm_output_data_uleb128 (disp, "@TType base offset");
-#endif
+	}
     }
 
   /* Indicate the format of the call-site offsets.  */
-#ifdef HAVE_AS_LEB128
+  if (TARGET_USES_LEB128)
   cs_format = DW_EH_PE_uleb128;
-#else
+  else
   cs_format = DW_EH_PE_udata4;
-#endif
+
   dw2_asm_output_data (1, cs_format, "call-site format (%s)",
 		       eh_data_format_name (cs_format));
 
-#ifdef HAVE_AS_LEB128
+  if (TARGET_USES_LEB128)
+    {
   ASM_GENERATE_INTERNAL_LABEL (cs_after_size_label,
 			       section ? "LLSDACSBC" : "LLSDACSB",
 			       current_function_funcdef_no);
@@ -3080,13 +3097,15 @@
   else
     dw2_output_call_site_table (cs_format, section);
   ASM_OUTPUT_LABEL (asm_out_file, cs_end_label);
-#else
+    }
+  else
+    {
   dw2_asm_output_data_uleb128 (call_site_len, "Call-site table length");
   if (USING_SJLJ_EXCEPTIONS)
     sjlj_output_call_site_table ();
   else
     dw2_output_call_site_table (cs_format, section);
-#endif
+    }
 
   /* ??? Decode and interpret the data for flag_debug_asm.  */
   {
@@ -3105,10 +3124,8 @@
       output_ttype (type, tt_format, tt_format_size);
     }
 
-#ifdef HAVE_AS_LEB128
-  if (have_tt_data)
+  if (TARGET_USES_LEB128 && have_tt_data)
       ASM_OUTPUT_LABEL (asm_out_file, ttype_label);
-#endif
 
   /* ??? Decode and interpret the data for flag_debug_asm.  */
   if (targetm.arm_eabi_unwinder)
Index: gcc-4.5.2.orig/gcc/except.h
===================================================================
--- gcc-4.5.2.orig/gcc/except.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/except.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -228,6 +228,9 @@
    loop hackery; should not be used by new code.  */
 extern void for_each_eh_label (void (*) (rtx));
 
+/* Invokes CALLBACK for every exception region in the current function.  */
+extern void for_each_eh_region (void (*) (struct eh_region_d *, void *), void *);
+
 extern void init_eh (void);
 extern void init_eh_for_function (void);
 
Index: gcc-4.5.2.orig/gcc/emit-rtl.c
===================================================================
--- gcc-4.5.2.orig/gcc/emit-rtl.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/emit-rtl.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1992, 1993, 1994, 1995, 1996, 1997, 1998,
    1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -4344,8 +4345,17 @@
   PREV_INSN (first) = after;
   NEXT_INSN (last) = after_after;
   if (after_after)
+    {
     PREV_INSN (after_after) = last;
 
+      if (NONJUMP_INSN_P (after_after)
+	  && GET_CODE (PATTERN (after_after)) == SEQUENCE)
+	{
+	  rtx sequence = PATTERN (after_after);
+	  PREV_INSN (XVECEXP (sequence, 0, 0)) = last;
+	}
+    }
+
   if (after == last_insn)
     last_insn = last;
 
Index: gcc-4.5.2.orig/gcc/gthr-generic.c
===================================================================
--- gcc-4.5.2.orig/gcc/gthr-generic.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/gthr-generic.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,167 @@
+/* Generic threads supplementary implementation. */
+/* Compile this one with gcc.  */
+/* Copyright (C) 1997, 1999, 2000, 2002, 2006 Free Software Foundation, Inc.
+   Copyright (c) 2006  STMicroelectronics.
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify it under
+the terms of the GNU General Public License as published by the Free
+Software Foundation; either version 3, or (at your option) any later
+version.
+
+GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+for more details.
+
+Under Section 7 of GPL version 3, you are granted additional
+permissions described in the GCC Runtime Library Exception, version
+3.1, as published by the Free Software Foundation.
+
+You should have received a copy of the GNU General Public License and
+a copy of the GCC Runtime Library Exception along with this program;
+see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+<http://www.gnu.org/licenses/>.  */
+
+#define __GTHR_WEAK __attribute__ ((weak))
+
+#include "tconfig.h"
+#include "gthr.h"
+
+#ifndef __gthr_generic_h
+#error "Generic thread support package not supported"
+#endif
+
+/* These are stub functions.  When threading is available, a suitable set of definitions should be linked in.  */
+
+/* Return 1 if thread system is active, 0 if not.  */
+int
+__generic_gxx_active_p (void)
+{
+  return 0;
+}
+
+/* The following functions should return zero on success or the error
+   number.  If the operation is not supported, -1 is returned.
+
+   __generic_gxx_once
+   __generic_gxx_key_create
+   __generic_gxx_key_delete
+   __generic_gxx_setspecific
+   __generic_gxx_mutex_lock
+   __generic_gxx_mutex_trylock
+   __generic_gxx_mutex_unlock
+   __generic_gxx_recursive_mutex_lock
+   __generic_gxx_recursive_mutex_trylock
+   __generic_gxx_recursive_mutex_unlock  */
+
+/* FUNC is a function that should be called without parameters.
+   *ONCE has been initialized to __GTHREAD_ONCE_INIT and is otherwise only
+   used in calls to __generic_gxx_once with FUNC as the second parameter.
+   If __generic_gxx_once succeeds, FUNC will have been called exactly once
+   since the initialization of ONCE through any number of calls of
+   __generic_gxx_once with this pair of ONCE and FUNC values.  */
+int
+__generic_gxx_once (__gthread_once_t *once ATTRIBUTE_UNUSED,
+		    void (*func)(void) ATTRIBUTE_UNUSED)
+{
+  return -1;
+}
+
+/* Assign a key to *KEY that can be used in calls to
+   __generic_gxx_setspecific / __generic_gxx_getspecific.
+   If DTOR is nonzero, and at thread exit the value associated with the key
+   is nonzero, DTOR will be called at thread exit with the value associated
+   with the key as its only argument.  */
+int
+__generic_gxx_key_create (__gthread_key_t *key ATTRIBUTE_UNUSED,
+			  void (*dtor)(void *) ATTRIBUTE_UNUSED)
+{
+  return -1;
+}
+
+/* KEY is a key previously allocated by __generic_gxx_key_create.
+   Remove it from the set of keys known for this thread.  */
+int
+__generic_gxx_key_delete (__gthread_key_t key ATTRIBUTE_UNUSED)
+{
+  return -1;
+}
+
+/* Return thread-specific data associated with KEY.  */
+void *
+__generic_gxx_getspecific (__gthread_key_t key ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* Set thread-specific data associated with KEY to PTR.  */
+int
+__generic_gxx_setspecific (__gthread_key_t key ATTRIBUTE_UNUSED,
+		      const void *ptr ATTRIBUTE_UNUSED)
+{
+  return -1;
+}
+
+/* Initialize *MUTEX.  */
+void
+__generic_gxx_mutex_init_function (__gthread_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+}
+
+/* Acquire a lock on *MUTEX.  The behaviour is undefined if a lock on *MUTEX
+   has already been acquired by the same thread.  */
+int
+__generic_gxx_mutex_lock (__gthread_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* Try to acquire a lock on *MUTEX.  If a lock on *MUTEX already exists,
+   return an error code.  */
+int
+__generic_gxx_mutex_trylock (__gthread_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* A lock on *MUTEX has previously been acquired with __generic_gxx_mutex_lock
+   or __generic_gxx_mutex_trylock.  Release the lock.  */
+int
+__generic_gxx_mutex_unlock (__gthread_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* Initialize *MUTEX.  */
+void
+__generic_gxx_recursive_mutex_init_function (__gthread_recursive_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+}
+
+/* Acquire a lock on *MUTEX.  If a lock on *MUTEX has already been acquired by
+   the same thread, succeed.  */
+int
+__generic_gxx_recursive_mutex_lock (__gthread_recursive_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* Try to acquire a lock on *MUTEX.  If a lock on *MUTEX has already been
+   acquired by the same thread, succeed.  If any other lock on *MUTEX
+   already exists, return an error code.  */
+int
+__generic_gxx_recursive_mutex_trylock (__gthread_recursive_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* A lock on *MUTEX has previously been acquired with
+   __generic_gxx_recursive_mutex_lock or
+   __generic_gxx_recursive_mutex_trylock.  Release the lock.  */
+int
+__generic_gxx_recursive_mutex_unlock (__gthread_recursive_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
Index: gcc-4.5.2.orig/gcc/gthr-generic.h
===================================================================
--- gcc-4.5.2.orig/gcc/gthr-generic.h	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/gthr-generic.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,369 @@
+/* Generic threads compatibility routines for libgcc2 and libobjc. */
+/* Compile this one with gcc.  */
+/* Copyright (C) 1997, 1999, 2000, 2002, 2006 Free Software Foundation, Inc.
+   Copyright (c) 2006  STMicroelectronics.
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify it under
+the terms of the GNU General Public License as published by the Free
+Software Foundation; either version 3, or (at your option) any later
+version.
+
+GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+for more details.
+
+Under Section 7 of GPL version 3, you are granted additional
+permissions described in the GCC Runtime Library Exception, version
+3.1, as published by the Free Software Foundation.
+
+You should have received a copy of the GNU General Public License and
+a copy of the GCC Runtime Library Exception along with this program;
+see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+<http://www.gnu.org/licenses/>.  */
+
+#ifndef __gthr_generic_h
+#define __gthr_generic_h
+
+#define __GTHREADS 1
+
+#define __GTHREAD_ONCE_INIT 0
+#define __GTHREAD_MUTEX_INIT_FUNCTION __gthread_mutex_init_function
+#define __GTHREAD_RECURSIVE_MUTEX_INIT_FUNCTION __gthread_recursive_mutex_init_function
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Avoid depedency on specific headers.
+   The general idea is that you dynamically allocate the required data
+   structures, and a void * is used to point to this dynamically allocated
+   data.  If your implementation can put all the required information in
+   the void * itself, that's fine, too, of course.
+   libstdc++ inherits from the mutex types, whcih is why they need to be
+   wrapped up as structs.  */
+typedef void *__gthread_key_t;
+typedef void *__gthread_once_t;
+typedef struct __gthread_mutex_s { void *__p; } __gthread_mutex_t;
+typedef struct __gthread_recursive_mutex_s { void *__p; } __gthread_recursive_mutex_t;
+
+/* We should always link with at least one definition, so we want strong
+   references.  The stub definitions are weak so that they can be overriden.  */
+#ifndef __GTHR_WEAK
+#define __GTHR_WEAK
+#endif
+
+extern int __generic_gxx_active_p (void) __GTHR_WEAK;
+
+extern int __generic_gxx_once (__gthread_once_t *, void (*)(void)) __GTHR_WEAK;
+
+extern int __generic_gxx_key_create (__gthread_key_t *,
+				     void (*)(void *)) __GTHR_WEAK;
+
+extern int __generic_gxx_key_delete (__gthread_key_t key) __GTHR_WEAK;
+
+extern void *__generic_gxx_getspecific (__gthread_key_t key) __GTHR_WEAK;
+
+extern int __generic_gxx_setspecific (__gthread_key_t, const void *) __GTHR_WEAK;
+
+extern void __generic_gxx_mutex_init_function (__gthread_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_mutex_lock (__gthread_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_mutex_trylock (__gthread_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_mutex_unlock (__gthread_mutex_t *) __GTHR_WEAK;
+
+extern void __generic_gxx_recursive_mutex_init_function (__gthread_recursive_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_recursive_mutex_lock (__gthread_recursive_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_recursive_mutex_trylock (__gthread_recursive_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_recursive_mutex_unlock (__gthread_recursive_mutex_t *) __GTHR_WEAK;
+
+#ifdef __cplusplus
+}
+#endif
+
+#ifdef _LIBOBJC
+
+extern int __generic_gxx_objc_init_thread_system (void) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_close_thread_system (void) __GTHR_WEAK;
+
+extern objc_thread_t __generic_gxx_objc_thread_detach (void (*)(void *), void *) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_thread_set_priority (int priority) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_thread_get_priority (void) __GTHR_WEAK;
+
+extern void __generic_gxx_objc_thread_yield (void) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_thread_exit (void) __GTHR_WEAK;
+
+extern objc_thread_t __generic_gxx_objc_thread_id (void) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_thread_set_data (void *value) __GTHR_WEAK;
+
+extern void *__generic_gxx_objc_thread_get_data (void) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_mutex_allocate (objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_mutex_deallocate (objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_mutex_lock (objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_mutex_trylock (objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_mutex_unlock (objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_condition_allocate (objc_condition_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_condition_deallocate (objc_condition_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_condition_wait (objc_condition_t, objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_condition_broadcast (objc_condition_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_condition_signal (objc_condition_t) __GTHR_WEAK;
+
+/* Backend initialization functions */
+
+/* Initialize the threads subsystem.  */
+static inline int
+__gthread_objc_init_thread_system (void)
+{
+  return __generic_gxx_objc_init_thread_system ();
+}
+
+/* Close the threads subsystem.  */
+static inline int
+__gthread_objc_close_thread_system (void)
+{
+  return __generic_gxx_objc_close_thread_system ();
+}
+
+/* Backend thread functions */
+
+/* Create a new thread of execution.  */
+static inline objc_thread_t
+__gthread_objc_thread_detach (void (* func)(void *), void * arg)
+{
+  return __generic_gxx_objc_thread_detach (func, arg);
+}
+
+/* Set the current thread's priority.  */
+static inline int
+__gthread_objc_thread_set_priority (int priority)
+{
+  return __generic_gxx_objc_thread_set_priority (priority);
+}
+
+/* Return the current thread's priority.  */
+static inline int
+__gthread_objc_thread_get_priority (void)
+{
+  return __generic_gxx_objc_thread_get_priority ();
+}
+
+/* Yield our process time to another thread.  */
+static inline void
+__gthread_objc_thread_yield (void)
+{
+  __generic_gxx_objc_thread_yield ();
+}
+
+/* Terminate the current thread.  */
+static inline int
+__gthread_objc_thread_exit (void)
+{
+  return __generic_gxx_objc_thread_exit ();
+}
+
+/* Returns an integer value which uniquely describes a thread.  */
+static inline objc_thread_t
+__gthread_objc_thread_id (void)
+{
+  return __generic_gxx_objc_thread_id ();
+}
+
+/* Sets the thread's local storage pointer.  */
+static inline int
+__gthread_objc_thread_set_data (void *value)
+{
+  return __generic_gxx_objc_thread_set_data (value);
+}
+
+/* Returns the thread's local storage pointer.  */
+static inline void *
+__gthread_objc_thread_get_data (void)
+{
+  return __generic_gxx_objc_thread_get_data ();
+}
+
+/* Backend mutex functions */
+
+/* Allocate a mutex.  */
+static inline int
+__gthread_objc_mutex_allocate (objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_mutex_allocate (mutex);
+}
+
+/* Deallocate a mutex.  */
+static inline int
+__gthread_objc_mutex_deallocate (objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_mutex_deallocate (mutex);
+}
+
+/* Grab a lock on a mutex.  */
+static inline int
+__gthread_objc_mutex_lock (objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_mutex_lock (mutex);
+}
+
+/* Try to grab a lock on a mutex.  */
+static inline int
+__gthread_objc_mutex_trylock (objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_mutex_trylock (mutex);
+}
+
+/* Unlock the mutex */
+static inline int
+__gthread_objc_mutex_unlock (objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_mutex_unlock (mutex);
+}
+
+/* Backend condition mutex functions */
+
+/* Allocate a condition.  */
+static inline int
+__gthread_objc_condition_allocate (objc_condition_t condition)
+{
+  return __generic_gxx_objc_condition_allocate (condition);
+}
+
+/* Deallocate a condition.  */
+static inline int
+__gthread_objc_condition_deallocate (objc_condition_t condition)
+{
+  return __generic_gxx_objc_condition_deallocate (condition);
+}
+
+/* Wait on the condition */
+static inline int
+__gthread_objc_condition_wait (objc_condition_t condition, objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_condition_wait (condition, mutex);
+}
+
+/* Wake up all threads waiting on this condition.  */
+static inline int
+__gthread_objc_condition_broadcast (objc_condition_t condition)
+{
+  return __generic_gxx_objc_condition_broadcast ( condition);
+}
+
+/* Wake up one thread waiting on this condition.  */
+static inline int
+__gthread_objc_condition_signal (objc_condition_t condition)
+{
+  return __generic_gxx_objc_condition_signal (condition);
+}
+
+#else /* !_LIBOBJC */
+
+static inline int
+__gthread_active_p (void)
+{
+  return __generic_gxx_active_p ();
+}
+
+static inline int
+__gthread_once (__gthread_once_t *once, void (*func)(void))
+{
+  return __generic_gxx_once (once, func);
+}
+
+static inline int
+__gthread_key_create (__gthread_key_t *key, void (*dtor)(void *))
+{
+  return __generic_gxx_key_create (key, dtor);
+}
+
+static inline int
+__gthread_key_delete (__gthread_key_t key)
+{
+  return __generic_gxx_key_delete (key);
+}
+
+static inline void *
+__gthread_getspecific (__gthread_key_t key)
+{
+  return __generic_gxx_getspecific (key);
+}
+
+static inline int
+__gthread_setspecific (__gthread_key_t key, const void *ptr)
+{
+  return __generic_gxx_setspecific (key, ptr);
+}
+
+static inline void
+__gthread_mutex_init_function (__gthread_mutex_t *mutex)
+{
+  __generic_gxx_mutex_init_function (mutex);
+}
+
+static inline int
+__gthread_mutex_lock (__gthread_mutex_t * mutex)
+{
+  return __generic_gxx_mutex_lock (mutex);
+}
+
+static inline int
+__gthread_mutex_trylock (__gthread_mutex_t * mutex)
+{
+  return __generic_gxx_mutex_trylock (mutex);
+}
+
+static inline int
+__gthread_mutex_unlock (__gthread_mutex_t * mutex)
+{
+  return __generic_gxx_mutex_unlock (mutex);
+}
+
+static inline void
+__gthread_recursive_mutex_init_function (__gthread_recursive_mutex_t *mutex)
+{
+  __generic_gxx_recursive_mutex_init_function (mutex);
+}
+
+static inline int
+__gthread_recursive_mutex_lock (__gthread_recursive_mutex_t * mutex)
+{
+  return __generic_gxx_recursive_mutex_lock (mutex);
+}
+
+static inline int
+__gthread_recursive_mutex_trylock (__gthread_recursive_mutex_t * mutex)
+{
+  return __generic_gxx_recursive_mutex_trylock (mutex);
+}
+
+static inline int
+__gthread_recursive_mutex_unlock (__gthread_recursive_mutex_t * mutex)
+{
+  return __generic_gxx_recursive_mutex_unlock (mutex);
+}
+
+#endif /* _LIBOBJC */
+
+#endif /* __gthr_generic_h */
Index: gcc-4.5.2.orig/gcc/ChangeLog.STM
===================================================================
--- gcc-4.5.2.orig/gcc/ChangeLog.STM	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/ChangeLog.STM	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,928 @@
+2011-01-24  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/read-rtl.c (print_rtx_ptr_loc): Don't emit #line for .md files
+
+2011-01-24  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.md (movsf_ie): Adjust fp_mode for fldi instructions.
+
+2011-01-12  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.c (handler_uses_reg): Fix landing_pad scan.
+
+2011-01-11  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.c (movsf_ie): Fix fp_mode.
+
+2010-11-30  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=10586
+	* gcc/config/sh/sh.c (find_barrier): Skip notes.
+	(sh_asm_count): Conservately count aligns before reorg.
+
+2010-11-08  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=10391
+	* gcc/ira.c (update_equiv_regs): Don't propagate after blockage.
+
+2010-11-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh-protos.h (sh_expand_lround): Addto_nearest flag.
+	* gcc/config/sh/sh.c (sh_expand_lround): Use to_nearest flag.
+	* gcc/config/sh/sh.md (lroundsfsi2): Define.
+
+2010-10-13  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh-protos.h (sh_expand_lround): Declare.
+	* gcc/config/sh/sh.c (sh_expand_lround): Define.
+	* gcc/config/sh/sh.md (UNSPEC_BUILTIN_ROUND, lrintsfsi2): Define.
+
+2010-09-29  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (sh_compare_op0, sh_compare_op1): Delete.
+
+2010-09-24  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/gcc.c (process_command): -no-canonical-prefixes set by default.
+
+2010-09-23  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (TARGET_CPU_CPP_BUILTINS): Define __MOVD__.
+	(ROUND_TYPE_ALIGN, MOVE_BY_PIECES_P): Fix test.
+	* config/sh/sh.c (expand_block_move): Don't toggle sz bit.
+
+2010-09-20  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (dump_table): Fixed constants alignments for 
+	TARGET_ALIGN_DOUBLE.
+
+2010-09-02  Christian Bruel  <christian.bruel@st.com>
+
+	* final.c (remap_debug_filename): translate filename for CYGPATH.
+
+2010-08-12  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.opt (mdiv=call-pre1): New option.
+	* config/sh/sh.h (SH_DIV_CALL_PRE1): New sh_div_strategy.
+	* config/sh/sh.md (sdivsi3): Use TARGET_DIVIDE_CALL_PRE1.
+	 (ashlsi3_k): New pattern.
+	* doc/invoke.texi (mdiv=call-pre1): Document.
+
+2010-07-21  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=9620
+        * config/sh/sh.c (find_barrier): Update alignement after barrier.
+
+2010-07-07  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.opt (mtas): New Target option.
+	* config/sh/sh.h (SUBTARGET_ASM_ISA_SPEC): Pass --tas to assembler
+	(TARGET_CPU_CPP_BUILTINS): Define __HAVE_TAS__.
+	* doc/invoke.texi (mtas,mno-tas): Documents.
+
+2010-07-05  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.c (sh_dwarf_register_span): No span if TARGET_FMOVD.
+	(push_regs): Push FP_REGISTER first.
+	(pop_regs): Pop FP_REGISTER last.
+	(emit_fpu_flip): Switch size if TARGET_FMOVD.
+
+2010-07-02  Christian Bruel  <christian.bruel@st.com>
+
+	* doc/md.texi: Document SH constraints.
+
+2010-06-04  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/supervisor-atomic.asm: (sync_nand_and_fetch): Fix
+	* gcc/config/sh/linux-atomic.asm: (sync_nand_and_fetch): Fix
+	(_sync_fetch_and_): Don't use R3.
+	(__sync_bool_compare_and_swap_, __sync_val_compare_and_swap_).
+	 Reorganized.
+
+2010-06-04  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/gthr-generic.c: Change license to GPLv3.
+	* gcc/gthr-generic.h: Likewise
+	* gcc/config/sh/supervisor-atomic.asm: Likewise
+	* gcc/config/sh/ieee-754-df.S: Likewise
+	* gcc/config/sh/ieee-754-df.S: Likewise
+
+2010-06-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/crti.asm (_init, _fini): Remove underscore.
+	* config/sh/crt1.asm (_init, _fini): Likewise.
+
+2010-06-02  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/linux.h (TARGET_OS_CPP_BUILTINS): Make __GNUC_STM_RELEASE__.
+
+2010-05-27  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (movdf_i4): Refined constraints for -mfmovd
+
+2010-04-29  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh-protos.h (sh_varying_insn_p): Declare.
+	* gcc/config/sh/sh.c (sh_varying_insn_p): Define.
+	(sh_insn_length_adjustment): Use.
+	* gcc/config/sh/sh.h (VARYING_INSN_P): Define.
+	* gcc/final.c (VARYING_INSN_P): Use.
+
+2010-04-20  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl30850:
+	* config/sh/ieee-754-df.S (nedf2f): Don't check Qbit for NaNs.
+	* config/sh/ieee-754-sf.S (nesf2f): Likewise.
+	* config/sh/sh.md (cmpunsf_i1, cmpundf_i1): Likewise. Clobber R2.
+
+2010-04-09  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/sched-deps.c (sched_analyze_1): Don't extend R0 lifetime.
+	* config/sh/sh.md (movsf_ie): fix clobber constraint.
+	
+2010-03-27  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_insn_length_adjustment): Adjust instruction size
+	 for jump_compact.
+
+2010-03-26  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=8634
+	Backport from trunk:
+	2009-04-22  Paolo Bonzini  <bonzini@gnu.org>
+
+	* config/sh/sh.c (shift_insns_rtx, shiftcosts, gen_shifty_op,
+	sh_dynamicalize_shift_p, shl_and_scr_length): Truncate
+	shift counts to avoid out-of-bounds array accesses.
+
+2010-02-10  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (find_barrier): Don't emit a CP inside the GP setting.
+
+2010-01-04  Christian Bruel  <christian.bruel@st.com>
+  
+        https://bugzilla.stlinux.com/show_bug.cgi?id=8178
+	* final.c (shorten_branches): Enable asm statements to vary.
+ 	* config/sh/sh.c (asm_size): Catch multiple .long asm statements.
+	(sh_insn_length_alignment): New function.
+	(sh_asm_count): force max addr if insn_current_address unknown.
+	* config/sh/sh-protos.h (sh_insn_length_alignment): Declare.
+	* config/sh/sh.h (INSN_LENGTH_ALIGNMENT): Call sh_insn_length_alignment.
+
+2010-01-26  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-sh: Remove duplicate gt-sh.h dependencies.
+
+2010-01-20  Christian Bruel  <christian.bruel@st.com>
+
+	Backport from trunk:
+        2009-05-19  Ben Elliston  <bje@au.ibm.com>
+
+	* unwind-dw2-fde.c (fde_unencoded_compare): Replace type punning
+	assignments with memcpy calls.
+	(add_fdes): Likewise.
+	(binary_search_unencoded_fdes): Likewise.
+	(linear_search_fdes): Eliminate type puns.
+
+2010-01-20  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (OVERRIDE_OPTIONS, OPTIMIZATION_OPTIONS): Don't force
+	flag_schedule_insns for pic.
+
+2010-01-20  Christian Bruel  <christian.bruel@st.com>
+
+	Backport from trunk:
+	2009-05-12  Kaz Kojima  <kkojima@gcc.gnu.org>
+
+	PR target/39561
+	* config/sh/sh.h (OPTIMIZATION_OPTIONS): Don't set
+	TARGET_EXPAND_CBRANCHDI4.
+	* config/sh/sh.md (cbranchdi4): Don't check TARGET_EXPAND_CBRANCHDI4.
+	* config/sh/sh.opt (mexpand-cbranchdi): Remove.
+	(cmpeqdi): Fix comment.
+
+2009-10-26  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (ACCUMULATE_OUTGOING_ARGS): Define.
+	(MASK_ADJUST_UNROLL): Remove.
+        (OVERRIDE_OPTION): Check and set.
+	* config/sh/sh.opt (maccumulate-outgoing-args): New Target option.
+	(madjust-unroll): Remove.
+	* doc/invoke.texi (maccumulate-outgoing-args, madjust-unroll): Likewise.
+	* gcc/config/sh/sh.c (rounded_frame_size): Alloc outgoing args.
+
+2009-11-03  Christian Bruel  <christian.bruel@st.com>
+  
+        https://bugzilla.stlinux.com/show_bug.cgi?id=7377
+ 	* config/sh/sh.c (sh_insn_length_adjustment): Adjust jumps labels with
+	alignment.
+
+2009-10-29  Yvan Roux  <yvan.roux@st.com>
+
+	* doc/invoke.texi (-Wbranch-probabilities-computation): Document.
+	* common.opt (-Wbranch-probabilities-computation): New warning option.
+	* profile.c (compute_branch_probabilities): Ignore inconsistent bb
+	and/or edge counts computation if -Wbranch-probabilities-computation is
+	given.
+
+2009-10-28  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (SUBTARGET_ASM_ISA_SPEC): --isa=sh4-up for generic SH4s.
+
+2009-10-26  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (SUBTARGET_ASM_ISA_SPEC): Fix specs for -m4-singles.
+	* config/sh/sh.opt (SH_ASM_SPEC): Add -mnotas option.
+	* doc/invoke.texi (-mnotas): Document.
+
+2009-10-22  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/lib1funcs.asm (udiv_qrnnd_16): Fix alignment.
+
+2009-10-21  Christian Bruel  <christian.bruel@st.com>
+	    Yvan Roux  <yvan.roux@st.com>
+
+	* config/sh/sh.c (sh_reorg): Fix relax after incoming edges.
+
+2009-10-16  Christian Bruel  <christian.bruel@st.com>
+
+	* cfg.c (dump_edge_info): Print locus.
+	* cfgexpand.c (expand_gimple_basic_block): Initialize goto_locus.
+
+2009-10-14  Antony King  <antony.king@st.com>
+
+	INSbl30528:
+	* gcc.c (do_spec_1): Add support for %M specs.
+	(getenv_spec_function): Allow multiple arguments.
+	* doc/invoke.texi: Likewise.
+
+2009-10-15  Christian Bruel  <christian.bruel@st.com>
+	    Yvan Roux  <yvan.roux@st.com>
+
+	* config/sh/sh.c (handler_uses_reg): New function.
+	(sh_reorg): Call for each region.
+	* except.c (struct eh_region): Move to except.h
+	(for_each_eh_region): Accepts parameter.
+	* except.h (struct eh_region): Move here.
+	* tree-cfg.c (for_each_eh_region): Accepts parameter.
+
+2009-10-12  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_output_mi_thunk): Mark temporary dead.
+
+2009-10-08  Christian Bruel  <christian.bruel@st.com>
+
+	http://gcc.gnu.org/bugzilla/show_bug.cgi?id=41639 
+	* builtin-types.def (BT_I[1,2,4,8,16): Set signed.
+	* config/sh/linux-atomic.asm (ATOMIC_TEST_AND_SET): Keep sign.
+	(ATOMIC_COMPARE_AND_SWAP): Likewise.
+	(ATOMIC_FETCH_AND_OP, ATOMIC_FETCH_AND_COMBOP): Likewise.
+
+2009-10-06  Antony King  <antony.king@st.com>
+
+	INSbl30052:
+	* config/sh/t-superh [LIB2FUNCS_EXTRA]: Add.
+	* config/sh/supervisor-atomic.asm: New file.
+
+2009-10-09  Christian Bruel  <christian.bruel@st.com>
+
+	* doc/invoke.texi (mdead-delay): Document.
+	* doc/gcc.info (mdead-delay): Document.
+
+2009-10-05  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_reorg): Call df_analyze for notes.
+	    
+2009-10-02  Christian Bruel  <christian.bruel@st.com>
+	    Yvan Roux  <yvan.roux@st.com>
+
+	* defaults.h (HOT_TEXT_SECTION_PREFIX,
+	 UNLIKELY_EXECUTED_TEXT_SECTION_PREFIX): New macros.
+	* dwarf2out.c (dwarf2out_init, dwarf2out_finish): unlikely_text_section
+	takes param.		  
+	* predict.c (choose_function_section): Remove.
+	* varasm.c (first_function_block_is_cold): Remove.
+	(initialize_cold_section_name): Handle named unlikely sections.
+	(unlikely_text_section): Takes tree parameter.
+	(unlikely_text_section_p): Remove.
+	(function_section): Handle cold sections.
+	* output.h (first_function_block_is_cold): Remove.
+	(unlikely_text_section_p): Likewise.
+	(unlikely_text_section): Takes tree parameter.
+	* config/i386/i386.c: first_function_block_is_cold renamed 
+	in_cold_section_p.
+
+2009-08-28  Jan Beulich  <jbeulich@novell.com>
+
+	* configure.ac: For in-tree ld, do a plain version check to
+	determine whether comdat groups are supported.
+	* configure: Regenerate.
+
+2009-09-24  Christian Bruel  <christian.bruel@st.com>
+
+	http://gcc.gnu.org/bugzilla/show_bug.cgi?id=41486
+	* config/sh/sh.h (flag_tree_cselim): Unset flag_tree_cselim.
+
+2009-09-24  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_optimization_options): Set flag_omit_frame_pointer.
+
+2009-09-03  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=7000
+	* config/sh/sh.md (movdf_i4): Fix length attribute.
+	* config/sh/sh.c (sh_jump_align): Rework.
+
+2009-08-10  SUGIOKA Toshinobu  <sugioka@itonet.co.jp>
+
+	PR target/41015
+	* longlong.h [__sh__] (udiv_qrnnd): Add T register to clobber list.
+	(sub_ddmmss): Likewise.
+
+2008-05-06  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/28671
+	* tree-ssa-ccp.c (get_symbol_constant_value): Check DECL_WEAK.
+	* c-typeck.c (decl_constant_value): Likewise.
+
+2009-08-14  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-linux (LIB1ASMMFUNCS_DIVTABLE): Define.
+	* config/sh/t-sh (libgcc-4-200.a): Create.
+	(LIB1ASMMFUNCS_DIVTABLE): Use.
+	(LIB1ASMFUNCS): Remove _sdivsi3_i4 _udivsi3_i4 _div_table from built.
+	* config/sh/embed-elf.h (LIBGCC_SPEC): Fixed lgcc-X-4-200 specs.
+	* config/sh/lib1funcs.asm (ieee-754-X.S): Guard against L_div_table.
+
+2009-08-10  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh.c (OPTIMIZATION_OPTIONS): Unset fschedule_insns off.
+
+2009-08-07  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh.c (fixup_mova): Fix casesi_worker access.
+	(dump_table): Likewise.
+
+2009-07-30  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config.gcc (fix-proto): Set to no for SH.
+
+2009-07-27  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-linux (EXTRA_MULTILIB_PARTS): Set.
+	* config/sh/t-sh (unwind-dw2-Os-4-200.o): Remove.
+
+2009-07-27  Christian Bruel  <christian.bruel@st.com>
+
+        * config/sh/sh.h (OPTIMIZATION_OPTIONS): Set dead-delay if optimizing.
+	* config/sh/sh.opt (mdead-delay): don't force 0.
+
+2009-07-02  Christian Bruel  <christian.bruel@st.com>
+
+	* tree-sra.c (bitfield_overlaps_p): Fix array tree type check.
+
+2009-06-18  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (simultaneous-prefetches): Set for st40-300.
+
+2009-06-18  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=6459
+	* config/sh/sh.md (cbranchdi4_i): Don't define insn.
+
+2009-06-05  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh.c (expand_block_move): Improve 64 bit -mfmovd.
+
+2009-06-09  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (SUBTARGET_ASM_ISA_SPEC): Pass -isa=sh4-nofpu-up
+	 for m4-nofpu.
+
+2009-04-12  Christian Bruel  <christian.bruel@st.com>
+
+	* default.h (TARGET_USES_LEB128): New macro.
+	* config/sh/sh.h (TARGET_USES_LEB128): Redefine.
+	* dwarf2asm.c (TARGET_USES_LEB128): Use instead of HAVE_AS_LEB128.
+	* except.c: Likewise.
+	* doc/tm.texi (TARGET_USES_LEB128): Document.
+	* doc/gccint.info (TARGET_USES_LEB128): Likewise.
+	
+2009-05-05  Antony King  <antony.king@st.com>
+	    Christian Bruel  <christian.bruel@st.com>
+
+        INSbl30131
+	* lib1funcs.asm: Change local label naming convention.
+	* lib1funcs-Os-4-200.asm: Idem.
+
+2009-04-09  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-sh (ic_invalidate_array_4a.o): Fix st40-300 isa build.
+       (ic_invalidate_4a): Idem.
+        * config/sh/embed-elf.h (LIBGCC_SPEC): Fix ic_invalidate*.
+	* config/sh/sh.h (TARGET_CPU_DEFAULT, SUBTARGET_ASM_ISA_SPEC): Idem.
+	(ASM_ISA_SPEC_DEFAULT): Idem.
+
+2009-04-09  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (load_gbr): Fix operand constraint.
+
+2009-03-31  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (broken_move): Fixed.
+
+2009-03-31  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (OVERRIDE_OPTIONS, OPTIMIZATION_OPTIONS): Set 
+	flag_emit_frame_pointer.
+ 
+2009-03-24  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/trap-handler.c (exit): Declare noreturn.
+	* config/sh/t-sh $(CFLAGS_FOR_TARGET): passed to trap-handler build.
+
+2009-03-12  Christian Bruel  <christian.bruel@st.com>
+
+	http://gcc.gnu.org/bugzilla/show_bug.cgi?id=39423
+	* fold-const.c (fold_plusminus_mult_expr): Move canonicalization of
+	 index+cst...
+	* expr.c (expand_expr_real_1): ... here.
+
+2009-03-10  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_expand_epilogue): Don't insert blockage.
+
+2009-03-09  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl21915
+	* config/sh/sh.h (SH_LINK_SPEC): Pass -shared on -pic.
+
+2009-03-09  Christian Bruel  <christian.bruel@st.com>
+
+	* configure.ac: Change BUGURL, PKGVERSION.
+	* configure: Regenerate.
+
+2009-03-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (cbranchsi4): Enable.
+
+2009-03-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (CASE_VECTOR_MODE): Fix offset size for hwbug.
+	* config/sh/sh.c (sh_insn_length_adjustment): Fix pools for hwbug.
+
+2009-02-16  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/superh.h (SUBTARGET_ASM_RELAX_SPEC): Remove.
+	* config/sh/sh.h (SUBTARGET_ASM_RELAX_SPEC): Likewise.
+	(subtarget_asm_relax_spec). Likewise.
+
+2009-02-05  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (asm_size): Handle alignments.
+	(sh_asm_count): Likewise.
+	(sh_hw_workaround): Redesigned.
+	* config/sh/sh.h (SH_LINK_SPEC): pass --db-page-bug to the linker.
+	(INSN_LENGTH_ALIGNMENT): Fix minimum alignment.
+	* config/sh/linux-atomic.h: DB_ST40300_BUG_WORKAROUND fixes.
+	* config/sh/lib1funcs.asm: Likewise.
+
+2009-01-24  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (ivsi_inv_hitable): Fix alternative.
+	(divsi_inv_qitable): Likewise.
+
+2009-01-24  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/constraints.md (R03): New constraint.
+
+2009-01-24  Christian Bruel  <christian.bruel@st.com>
+
+	* emit-rtl.c (emit_insn_after_1): Update SEQUENCE.
+
+2009-01-20  Christian Bruel  <christian.bruel@st.com>
+
+	* final.c (TARGET_ASM_COUNT): Use.
+	* config/sh/sh-protos.h (sh_asm_count): Declared.
+	* config/sh/sh.h (TARGET_ASM_COUNT): Declared.
+	* config/sh/sh.c (sh_asm_count): Defined.
+
+2009-01-19  Christian Bruel  <christian.bruel@st.com>
+
+	* final.c (asm_insn_count): Check for empty asm.
+
+2009-01-05  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl29600
+	* config/sh/sh.c (sh_dwarf_register_span): New function.
+	(TARGET_DWARF_REGISTER_SPAN): Defined.
+	* config/sh/sh-protos.h (sh_dwarf_register_span): Declared.
+
+2008-12-08  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_insn_length_adjustment): Optimize out delay slot.
+	* config/sh/sh.md (dup_db_insn): New unspec pattern.
+	* config/sh/sh.opt (mdead-delay): New option.
+	* final.c (realloc_insn_lengths): New function.
+	* output.h (realloc_insn_lengths): Declare.
+
+2008-12-08  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (OPVERRIDE_OPTIONS): Don't force function alignment.
+
+2008-11-28  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl29605
+	* config/sh/sh.opt (mfmovd): Document.
+
+2008-11-27  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (CAN_DEBUG_WITHOUT_FP): Defined.
+
+2008-11-14  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.opt (mspace): Removed.
+	* doc/invoke.texi (mspace): Removed.
+	* config/sh/sh.h: Use optimize_size for TARGET_SMALLCODE.
+	* config/sh/sh.c: Likewise.
+	* config/sh/t-sh (TARGET_LIBGCC2_CFLAGS): Defined.
+
+2008-10-30  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_reorg): Allow relaxation within simple loops.
+	
+2008-10-24  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=4907
+	* config/sh/sh.md (casesi_worker_x): Add MEM indirect.
+	* config/sh/sh.c (sh_insn_length_adjustment): Handle casesi_worker.
+
+2008-10-12  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_forward_branch_p): Handle casesi_worker.
+
+2008-05-28  Antony King  <antony.king@st.com>
+
+	Fix INSbl27707:
+	* config/sh/superh.h (LIB_SPEC): Re-order libraries.
+
+2008-08-03  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/24528
+	* config/sh/sh.md (ashrsi2_16): make it a define_expand.
+	(ashrsi2_31): Likewise.
+
+2008-08-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (find_barrier): Update lengths for conditional branches.
+
+2008-07-09  Christian Bruel  <christian.bruel@st.com>
+
+	st40-300 hardware bug workaround	
+	* config/sh/linux.h: (SUBTARGET_LINK_SPEC): Options passed to the linker.
+	* config/sh/sh.h (TARGET_CPU_CPP_BUILTINS): Define DB_ST40300_BUG_WORKAROUND.
+	(OVERRIDE_OPTIONS): Set align_functions.
+	* config/sh/sh.c (sh_hw_workaround, sh_forward_branch_p): New function.
+	(sh_insn_length_adjustment): Add length parameter, 
+	adjust length for workaround.
+	* config/sh/sh_protos.h (sh_hw_workaround): Likewise.
+	(sh_insn_length_adjustment): Add length parameter.
+	* final.c (final_scan_insn): call FINAL_PRESCAN_INSN.
+	* config/sh/sh.md (db-page-bug): new option.
+	* config/sh/sh.opt (mdb-page-bug): New option.
+
+2008-07-02  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (consttable_end): set length.
+	* config/sh/sh.h (MD_CAN_REDIRECT_BRANCH): Disable.
+	* final.c (shorten_branches): Add assertion.
+	* config/sh/sh.c (sh_jump_align): Use get_attr_min_length.
+	(barrier_align): Likewise.
+	(find_barrier): Take into account alignments into size.
+	(sh_reorg): use init_insn_lengths instead of INSN_ADDRESSES_FREE.
+
+2008-07-02  Christian Bruel  <christian.bruel@st.com>
+
+	* final.c (get_attr_length_1): Call get_attr_length_1 with fallback_fn
+	 instead of get_attr_length.
+
+2008-06-22  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_cfun_naked_p): New function.
+	(sh_handle_fndecl_attribute): Likewise.
+	(sh_attribute_table): Add "naked".
+	(sh_expand_prologue): Check sh_cfun_naked_p.
+	(sh_expand_prologue): Likewise.
+
+2008-06-22  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_can_redirect_branch): Check simplejump_p.
+	backwark starts from PREV_INSN.
+	(expand_cbranchdi4): Shut up warning.
+
+2008-06-22  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/24993
+	* config/sh/elf.h (MAX_OFILE_ALIGNMENT): Define.
+
+2008-06-17  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (doloop_end): Disable when optimizing for size.
+
+2008-05-07  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=3891
+	* config/sh/sh.c (find_barrier): Increase size of conditional branches.
+
+2008-04-17  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/28594
+	* config/sh/sh.c (expand_cbranchdi4): Use original operands for
+	msw_skip comparison.
+
+2008-04-25  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/28502
+	* config/sh/sh.c (barrier_align): Skip notes.
+
+2007-12-12  Christian Bruel  <christian.bruel@st.com>
+
+	* store-layout.c (finalize_record_size): Fixed TYPE_ALIGN.
+	* sh.c (expand_block_move): Optimize 64 bits copies if -mfmovd.
+	* sh.h (MOVE_BY_PIECES_P): Handle -mfmov.
+	(ROUND_TYPE_ALIGN): Likewise.
+
+2007-10-23  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-sh (_addsub_sf, _mul_sf, _addsub_df,  _extendsfdf2,
+	 _truncdfsf2, _fixunssfsi, _fixsfsi, _floatunssisf, _floatsisf,
+	_fixdfsi _floatunssidf _floatsidf, _muldf3, _divsf3): Renamed.
+	* config/sh/ieee-754-df.S: Likewise.
+	* config/sh/ieee-754-sf.S: Likewise.
+
+2007-10-23  Yvan Roux  <yvan.roux@st.com>
+
+	* config/sh/lib1funcs-4-300.asm (le128_neg): Fixed.
+	
+2007-10-04  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.c (for_each_path): Check just_multi_suffix and multi_suffix.
+
+2007-10-04  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-linux (LIB1ASMFUNCS_CACHE): Cleaned up.
+
+2007-10-04  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (TARGET_HAVE_TLS): Removed.
+	* config/sh/linux.h (TARGET_HAVE_TLS): Defined.
+
+2007-10-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (cmpnedf_i1): Fix.
+
+2007-09-20  Yvan Roux  <yvan.roux@st.com>
+
+	* config/sh/t-sh: (LIB1ASMFUNCS) Add asm functions.
+	* config/sh/ieee-754-df.S: Fixed.
+	* config/sh/IEEE-754/m3/divsf3.S: Fixed.
+	* config/sh/IEEE-754/m3/divdf3.S: Fixed.
+	* config/sh/IEEE-754/m3/addsf3.S: Fixed.
+	* config/sh/IEEE-754/m3/adddf3.S: Fixed.
+	* config/sh/IEEE-754/m3/mulsf3.S: Fixed.
+	* config/sh/IEEE-754/m3muldf3.S: Fixed.
+
+2007-09-19  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/25896
+	* sh.md (movsf_y): New pattern.
+	(pop_fpul2_y): Likewise.
+
+2007-09-07  Christian Bruel  <christian.bruel@st.com>
+
+	* sh.h (SH_DBX_REGISTER_NUMBER): Added fpscr and fixed sr/gbr_regs.
+
+2007-08-16  Antony King  <antony.king@st.com>
+
+	* configure.ac: Relaxed check for .[su]leb128 support.
+	* configure: Regenerate.
+
+2007-08-14  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* configure.ac (SYSTEM_HEADER_DIR): Adjust for in-tree Newlib.
+	* configure: Regenerate.
+
+2007-07-16  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (MOVE_MAX_PIECES): Tuned for TARGET_SH1.
+
+2007-06-26  Christian Bruel  <christian.bruel@st.com>
+
+	* gthr-generic.h: Rename *p to *__p.
+
+2007-05-23  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.opt (align-small-blocks=): New Optimisation.
+	* doc/invoke.texi (align-small-blocks=): Likewise.
+	* config/sh/sh.c (sh_jump_align): Check sh_align_small_blocks.
+	(barrier_align): Check sh_align_small_blocks.
+
+2007-04-30  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh-protos.h (sh_jump_align): New Function.
+	* config/sh/sh.c (sh_jump_align): Likewise.
+	(barrier_align): compute alignment based on TARGET_CACHE32.
+	* config/sh/sh.h (JUMP_ALIGN): Define.
+
+2007-03-29  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.h (OVERRIDE_OPTIONS): Set assembler_dialect for sh1.
+2007-03-28  Christian Bruel  <christian.bruel@st.com>
+	* doc/invoke.texi: Document -m4-300.
+
+2007-03-09  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (__nesf2): Renamed.
+	(__nedf2): Likewise.
+	* config/sh/ieee-754-df.S (__nesf2): Likewise.
+	* config/sh/ieee-754-sf.S (__nedf2): Likewise.
+	* config/sh/t-sh: Likewise.
+
+2007-01-31  Christian Bruel  <christian.bruel@st.com>
+
+	* basic-block.h (pre_edge_lcm_avs): Declare.
+	* config/i386/i386.h (EMIT_MODE_SET): Add FLIP parameter.
+	* doc/tm.texi (EMIT_MODE_SET): Idem.
+	* config/sh/sh.h (EMIT_MODE_SET): Idem. Call emit_fpu_flip.
+        (CONDITIONAL_REGISTER_USAGE): Set global_regs[FPSCR_REG].
+	* config/sh/sh-protos.h	(emit_fpu_flip): Add proto.
+	* config/sh/sh.c (emit_fpu_flip): New function.
+	* config/sh/sh.md (toggle_pr): Defined for TARGET_SH4_300.
+	Defined if TARGET_FPU_SINGLE.
+	fpscr_toggle don't go in delay slot (temporary fix).
+	* lcm.c (pre_edge_lcm_avs): Renamed from pre_edge_lcm.
+	Call clear_aux_for_edges. Fix comments.
+	(pre_edge_lcm): New wrapper function to call pre_edge_lcm_avs.
+	(pre_edge_rev_lcm): Idem.
+	* mode-switching.c (init_modes_infos): New function.
+	(bb_has_complex_pred): New function.
+	(free_modes_infos): Idem.
+	(init_modes_infos): Idem
+	(add_mode_set): Idem.
+	(get_mode): Idem.
+	(commit_mode_sets): Idem.
+	(merge_modes): Idem.
+	(set_flip_status): Idem
+	(test_flip_status): Idem.
+	(optimize_mode_switching): Add support to maintain flip mode information.
+	* testsuite/gcc.target/sh/sh.exp: New file.
+	* testsuite/gcc.target/sh/fpchg1.c: New test.
+	* testsuite/gcc.target/sh/fpchg2.c: Idem.
+
+2007-01-29  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/IEEE-754/m3/adddf3.S: Fix inf mantissa.
+	* config/sh/IEEE-754/m3/addsf3.S: Likewise.
+	* config/sh/IEEE-754/m3/divsf3.S: Intialize xff000000 label.
+	* config/sh/sh.c (expand_sfunc_op): Use FIRST_FP_PARM_REG for
+	parameters.
+	* config/sh/sh.h (TARGET_OSFP): Disable.
+	* config/sh/sh.md (addsf3, subsf3, mulsf3): Use expand_sfunc_binopt
+	only when TARGET_OSFP.
+	(adddf3, subdf3, muldf3): Likewise.
+	(trunkdfsf2): Likewise.
+
+2007-01-22  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-sh (LIB1ASMFUNCS): Remove _add_sub_sf3, _mulsf3,
+	_hypotf, _muldf3, _add_sub_df3, _divsf3, _divdf3, _fixunssfsi,
+	_fixsfsi, _fixunsdfsi, _fixdfsi, _floatunssisf, _floatsisf,
+	_floatunssidf and _floatsidf.
+	(FPBIT, DPBIT, dp-bit.c, fp-bit.c): Re-instated.
+
+2007-01-12  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* config/sh/trap-handler.c: Call exit like old one used to.
+
+2006-09-02  J"orn Rennecke  <joern.rennecke@st.com>
+
+	config/sh/t-sh: ($(T)ic_invalidate_array_4-100.o): Add -I. .
+	($(T)ic_invalidate_array_4-200.o): Likewise.
+	($(T)ic_invalidate_array_4a.o): Likewise.
+
+2006-09-02  J"orn Rennecke  <joern.rennecke@st.com>
+
+	* sh.md (*movsicc_t_false, *movsicc_t_true): Add mode.
+
+2006-11-10  J"orn Rennecke  <joern.rennecke@st.com> 
+	    Aanchal Khanna   <aanchalk@noida.hcltech.com>
+	    Rakesh Kumar  <rakesh.kumar@noida.hcltech.com>
+
+	PR target/29845
+	* config/sh/sh-protos.h (sh_function_kind): New enumerator
+	SFUNC_FREQUENT.
+	(expand_sfunc_unop, expand_sfunc_binop): Declare.
+	* config/sh/lib1funcs.asm (ieee-754-sf.S, ieee-754-df.S): #include.
+	* config/sh/t-sh (LIB1ASMFUNCS): Add nesf2, _nedf2, _gtsf2t, _gtdf2t,
+	_gesf2f, _gedf2f, _extendsfdf2, , _truncdfsf2, _add_sub_sf3, _mulsf3,
+	_hypotf, _muldf3, _add_sub_df3, _divsf3, _divdf3, _fixunssfsi,
+	_fixsfsi, _fixunsdfsi, _fixdfsi, _floatunssisf, _floatsisf,
+	_floatunssidf and _floatsidf.
+	(FPBIT, DPBIT, dp-bit.c, fp-bit.c): Removed.
+	* config/sh/ieee-754-df.S, config/sh/ieee-754-sf.S: New files.
+	* config/sh/predicates.md (soft_fp_comparison_operand): New predicate.
+	(soft_fp_comparison_operator): Likewise.
+	* config/sh/sh.c (sh_soft_fp_cmp, expand_sfunc_op): New functions.
+	(expand_sfunc_unop, expand_sfunc_binop): Likewise.
+	(sh_expand_float_condop, sh_expand_float_scc): Likewise.
+	(from_compare): Add support for software floating point.
+	(function_symbol): Always look up name.  Add SFUNC_FREQUENT case.
+	* config/sh/sh.h (TARGET_SH1_SOFTFP): New macro.
+	(TARGET_SH1_SOFTFP_MODE): Likewise.
+	* config/sh/sh-modes.def (CC_FP_NE, CC_FP_GT, CC_FP_UNLT): New modes.
+	* config/sh/lib1funcs.h (SLC, SLI, SLCMP, DMULU_SAVE): New macros.
+	(DMULUL, DMULUH, DMULU_RESTORE, SHLL4, SHLR4, SHLL6, SHLR6): Likewise.
+	(SHLL12, SHLR12, SHLR19, SHLL23, SHLR24, SHLR21, SHLL21): Likewise.
+	(SHLR11, SHLR22, SHLR23, SHLR20, SHLL20, SHLD_COUNT, SHLRN): Likewise.
+	(SHLLN, DYN_SHIFT): Likewise.
+	(SUPPORT_SH3_OSFP, SUPPORT_SH3E_OSFP): Likewise.
+	(SUPPORT_SH4_NOFPU_OSFP, SUPPORT_SH4_SINGLE_ONLY_OSFP): Likewise.
+	(TARGET_OSFP): Likewise.
+	(OPTIMIZATION_OPTIONS): Always enable TARGET_CBRANCHDI4 and
+	TARGET_EXPAND_CBRANCHDI4.
+	If flag_trapping_math is set, make it 2.
+	(OVERRIDE_OPTIONS): If flag_trapping_math is 2 and non-trapping
+	software floating point is used, clear flag_trapping_math.
+	For SH1, set TARGET_EXPAND_CBRANCHDI4
+	* config/sh/ieee-754-df.S, config/sh/ieee-754-sf.S: New files.
+	* config/sh/IEEE-754/m3/divsf3.S: Likewise.
+	* config/sh/IEEE-754/m3/divdf3.S: Likewise.
+	* config/sh/IEEE-754/m3/floatunssisf.S: Likewise.
+	* config/sh/IEEE-754/m3/floatunssidf.S: Likewise.
+	* config/sh/IEEE-754/m3/fixunsdfsi.S: Likewise.
+	* config/sh/IEEE-754/m3/divdf3-rt.S: Likewise.
+	* config/sh/IEEE-754/m3/addsf3.S: Likewise.
+	* config/sh/IEEE-754/m3/adddf3.S: Likewise.
+	* config/sh/IEEE-754/m3/mulsf3.S: Likewise.
+	* config/sh/IEEE-754/m3/muldf3.S: Likewise.
+	* config/sh/IEEE-754/m3/floatsisf.S: Likewise.
+	* config/sh/IEEE-754/m3/floatsidf.S: Likewise.
+	* config/sh/IEEE-754/m3/fixdfsi.S: Likewise.
+	* config/sh/IEEE-754/divdf3.S: Likewise.
+	* config/sh/IEEE-754/floatunssisf.S: Likewise.
+	* config/sh/IEEE-754/fixunsdfsi.S: Likewise.
+	* config/sh/IEEE-754/adddf3.S: Likewise.
+	* config/sh/IEEE-754/floatsisf.S: Likewise.
+	* config/sh/IEEE-754/muldf3.S: Likewise.
+	* config/sh/IEEE-754/fixdfsi.S: Likewise.
+	* config/sh/IEEE-754/divsf3.S: Likewise.
+	* config/sh/IEEE-754/fixunssfsi.S: Likewise.
+	* config/sh/IEEE-754/floatunssidf.S: Likewise.
+	* config/sh/IEEE-754/addsf3.S: Likewise.
+	* config/sh/IEEE-754/mulsf3.S: Likewise.
+	* config/sh/IEEE-754/floatsidf.S: Likewise.
+	* config/sh/IEEE-754/fixsfsi.S: Likewise.
+	* config/sh/sh.md (SF_NAN_MASK, DF_NAN_MASK, FR4_REG): New constants.
+	(fpcmp_i1, addsf3_i3, subsf3_i3): New patterns.
+	(mulsf3_i3, cmpnesf_i1, cmpgtsf_i1, cmpunltsf_i1): Likewise.
+	(cmpeqsf_i1_finite, cmplesf_i1_finite, cmpunsf_i1): Likewise.
+	(cmpuneqsf_i1, movcc_fp_ne, movcc_fp_gtmovcc_fp_unlt): Likewise.
+	(cmpltgtsf_t, cmporderedsf_t, cmpltgtsf_t_4): Likewise.
+	(cmporderedsf_t_4, abssc2, adddf3_i3_wrap, adddf3_i3): Likewise.
+	(muldf3_i3_wrap, muldf3_i3, cmpnedf_i1, cmpgtdf_i1): Likewise.
+	(cmpunltdf_i1, cmpeqdf_i1_finite, cmpundf_i1, cmpuneqdf_i1): Likewise.
+	(cmpltgtdf_t, cmpordereddf_t_4, extendsfdf2_i1): Likewise.
+	(extendsfdf2_i2e, extendsfdf2_i2e_r0, truncdfsf2_i2e): Likewise.
+	(extendsfdf2_i1_r0, truncdfsf2_i1): Likewise.
+	(cmpun_sdf, sunle, cmpuneq_sdf, bunle, bunlt): Likewise.
+
+2006-11-03  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* config/sh/crt1.asm (_superh_trap_handler): Remove function.
+	* config/sh/trap-handler.c: New file.
+	* config/sh/t-elf (EXTRA_MULTILIB_PARTS): Add trap-handler.o.
+	* config/sh/t-superh (EXTRA_MULTILIB_PARTS): Likewise.
+	* config/sh/t-sh: Add rule for trap-handler.o.
+	* config/sh/elf.h (STARTFILE_SPEC): Add trap-handler.o.
+	* config/sh/superh.h (STARTFILE_SPEC): Likewise.
+
+2006-04-11  J"orn Rennecke <joern.rennecke@st.com>
+
+	* gthr-generic.h: Update to match
+	http://gcc.gnu.org/ml/gcc-patches/2006-04/msg00237.html .
+	* gthr-generic.c, gthr-objc-generic.c: Likewise.
+	* Makefile.in configure.ac: Likewise.
+	* configure: Regenerate.
+
+2006-01-17  Antony King <anthony.king@st.com>
+            J"orn Rennecke <joern.rennecke@st.com>
+
+	* configure.ac: Recognize 'generic' value for threads.
+	Check for existance of a *.c and gthr-objc-*.c file for thread support.
+	Substiture in extra_libgcc_srcs and extra_libgcc_static_srcs.
+	* configure: Regenerate.
+	* Makefile.in (LIB2ADD): Add @extra_libgcc_srcs@.
+	(LIB2ADD_ST): Add @extra_libgcc_static_srcs@.
+	* gthr-generic.h: New file.
+	* gthr-generic.c: New file.
+	* gthr-objc-generic.c: New file.
Index: gcc-4.5.2.orig/gcc/common.opt
===================================================================
--- gcc-4.5.2.orig/gcc/common.opt	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/common.opt	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -113,6 +113,10 @@
 Common Var(flag_fatal_errors)
 Exit on the first error occurred
 
+Wnon-finite-math
+Common Var(warn_non_finite_math) Warning
+Warn if explicit NaNs or infinities are used with -ffinite-math-only
+
 Wframe-larger-than=
 Common RejectNegative Joined UInteger
 -Wframe-larger-than=<number>	Warn if a function's stack frame requires more than <number> bytes
@@ -232,6 +236,10 @@
 Common RejectNegative Var(warn_coverage_mismatch) Warning
 Warn instead of error in case profiles in -fprofile-use do not match
 
+Wbranch-probabilities-computation
+Common Var(warn_branch_probabilities_computation) Warning
+Warn instead of error in probabilities computation in -fbranch-probabilities
+
 aux-info
 Common Separate
 -aux-info <file>	Emit declaration information into <file>
Index: gcc-4.5.2.orig/gcc/varasm.c
===================================================================
--- gcc-4.5.2.orig/gcc/varasm.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/varasm.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1989, 1992, 1993, 1994, 1995, 1996, 1997,
    1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,
    2010  Free Software Foundation, Inc.
+   Copyright (c) 2010  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -89,11 +90,6 @@
 
 tree last_assemble_variable_decl;
 
-/* The following global variable indicates if the first basic block
-   in a function belongs to the cold partition or not.  */
-
-bool first_function_block_is_cold;
-
 /* We give all constants their own alias set.  Perhaps redundant with
    MEM_READONLY_P, but pre-dates it.  */
 
@@ -650,43 +646,30 @@
 static void
 initialize_cold_section_name (void)
 {
-  const char *stripped_name;
-  char *name, *buffer;
-  tree dsn;
-
   gcc_assert (cfun && current_function_decl);
   if (crtl->subsections.unlikely_text_section_name)
     return;
 
-  dsn = DECL_SECTION_NAME (current_function_decl);
-  if (flag_function_sections && dsn)
-    {
-      name = (char *) alloca (TREE_STRING_LENGTH (dsn) + 1);
-      memcpy (name, TREE_STRING_POINTER (dsn), TREE_STRING_LENGTH (dsn) + 1);
-
-      stripped_name = targetm.strip_name_encoding (name);
-
-      buffer = ACONCAT ((stripped_name, "_unlikely", NULL));
-      crtl->subsections.unlikely_text_section_name = ggc_strdup (buffer);
-    }
-  else
-    crtl->subsections.unlikely_text_section_name =  UNLIKELY_EXECUTED_TEXT_SECTION_NAME;
+  crtl->subsections.unlikely_text_section_name 
+    = DECL_SECTION_NAME (current_function_decl)
+    ? TREE_STRING_POINTER (DECL_SECTION_NAME (current_function_decl))
+    : UNLIKELY_EXECUTED_TEXT_SECTION_NAME;
 }
 
 /* Tell assembler to switch to unlikely-to-be-executed text section.  */
 
 section *
-unlikely_text_section (void)
+unlikely_text_section (tree decl)
 {
   if (cfun)
     {
       if (!crtl->subsections.unlikely_text_section_name)
 	initialize_cold_section_name ();
 
-      return get_named_section (NULL, crtl->subsections.unlikely_text_section_name, 0);
+      return get_named_section (decl, crtl->subsections.unlikely_text_section_name, 0);
     }
   else
-    return get_named_section (NULL, UNLIKELY_EXECUTED_TEXT_SECTION_NAME, 0);
+    return get_named_section (decl, UNLIKELY_EXECUTED_TEXT_SECTION_NAME, 0);
 }
 
 /* When called within a function context, return true if the function
@@ -813,6 +796,8 @@
       && DECL_SECTION_NAME (decl) != NULL_TREE
       && targetm.have_named_sections)
     return get_named_section (decl, NULL, 0);
+  else if (cfun->function_frequency == FUNCTION_FREQUENCY_HOT)
+    return get_named_section (decl, HOT_TEXT_SECTION_NAME, 0);
   else
     return text_section;
 }
@@ -828,18 +813,21 @@
 {
   int reloc = 0;
 
-  if (first_function_block_is_cold)
+  gcc_assert (decl == current_function_decl);
+
+  if (in_cold_section_p)
     reloc = 1;
 
 #ifdef USE_SELECT_SECTION_FOR_FUNCTIONS
   if (decl != NULL_TREE
       && DECL_SECTION_NAME (decl) != NULL_TREE)
-    return reloc ? unlikely_text_section ()
+    return reloc ? unlikely_text_section (decl)
 		 : get_named_section (decl, NULL, 0);
   else
-    return targetm.asm_out.select_section (decl, reloc, DECL_ALIGN (decl));
+    return targetm.asm_out.select_section (decl, reloc,
+					   DECL_ALIGN (decl));
 #else
-  return reloc ? unlikely_text_section () : hot_function_section (decl);
+  return reloc ? unlikely_text_section (decl) : hot_function_section (decl);
 #endif
 }
 
@@ -849,7 +837,7 @@
 #ifdef USE_SELECT_SECTION_FOR_FUNCTIONS
   if (current_function_decl != NULL_TREE
       && DECL_SECTION_NAME (current_function_decl) != NULL_TREE)
-    return in_cold_section_p ? unlikely_text_section ()
+    return in_cold_section_p ? unlikely_text_section (current_function_decl)
 			     : get_named_section (current_function_decl,
 						  NULL, 0);
   else
@@ -858,7 +846,7 @@
 					   DECL_ALIGN (current_function_decl));
 #else
   return (in_cold_section_p
-	  ? unlikely_text_section ()
+	  ? unlikely_text_section (current_function_decl)
 	  : hot_function_section (current_function_decl));
 #endif
 }
@@ -1701,7 +1689,7 @@
 
   crtl->subsections.unlikely_text_section_name = NULL;
 
-  first_function_block_is_cold = false;
+  in_cold_section_p = false;
   if (flag_reorder_blocks_and_partition)
     {
       ASM_GENERATE_INTERNAL_LABEL (tmp_label, "LHOTB", const_labelno);
@@ -1738,7 +1726,7 @@
 
   if (flag_reorder_blocks_and_partition)
     {
-      switch_to_section (unlikely_text_section ());
+      switch_to_section (unlikely_text_section (decl));
       assemble_align (DECL_ALIGN (decl));
       ASM_OUTPUT_LABEL (asm_out_file, crtl->subsections.cold_section_label);
 
@@ -1752,25 +1740,21 @@
 	  assemble_align (DECL_ALIGN (decl));
 	  ASM_OUTPUT_LABEL (asm_out_file, crtl->subsections.hot_section_label);
 	  hot_label_written = true;
-	  first_function_block_is_cold = true;
+	  in_cold_section_p = true;
 	}
     }
   else if (DECL_SECTION_NAME (decl))
     {
-      /* Calls to function_section rely on first_function_block_is_cold
+      /* Calls to function_section rely on in_cold_section_p
 	 being accurate.  The first block may be cold even if we aren't
 	 doing partitioning, if the entire function was decided by
 	 choose_function_section (predict.c) to be cold.  */
 
       initialize_cold_section_name ();
-
-      if (crtl->subsections.unlikely_text_section_name
-	  && strcmp (TREE_STRING_POINTER (DECL_SECTION_NAME (decl)),
-		     crtl->subsections.unlikely_text_section_name) == 0)
-	first_function_block_is_cold = true;
     }
 
-  in_cold_section_p = first_function_block_is_cold;
+  if (cfun->function_frequency == FUNCTION_FREQUENCY_UNLIKELY_EXECUTED)
+    in_cold_section_p = true;
 
   /* Switch to the correct text section for the start of the function.  */
 
@@ -1855,9 +1839,9 @@
       section *save_text_section;
 
       save_text_section = in_section;
-      switch_to_section (unlikely_text_section ());
+      switch_to_section (unlikely_text_section (decl));
       ASM_OUTPUT_LABEL (asm_out_file, crtl->subsections.cold_section_end_label);
-      if (first_function_block_is_cold)
+      if (in_cold_section_p)
 	switch_to_section (text_section);
       else
 	switch_to_section (function_section (decl));
@@ -6394,7 +6378,10 @@
   /* We only need to use .gnu.linkonce if we don't have COMDAT groups.  */
   bool one_only = DECL_ONE_ONLY (decl) && !HAVE_COMDAT_GROUP;
   const char *prefix, *name, *linkonce;
+  size_t nlen, plen;
   char *string;
+  size_t llen = 0;
+  const char *loc_string = NULL;
 
   switch (categorize_decl_for_section (decl, reloc))
     {
@@ -6449,6 +6436,7 @@
     default:
       gcc_unreachable ();
     }
+  plen = strlen (prefix);
 
   name = IDENTIFIER_POINTER (DECL_ASSEMBLER_NAME (decl));
   name = targetm.strip_name_encoding (name);
@@ -6457,7 +6445,25 @@
      prefix to the section name.  */
   linkonce = one_only ? ".gnu.linkonce" : "";
 
-  string = ACONCAT ((linkonce, prefix, ".", name, NULL));
+  name = ACONCAT ((linkonce, prefix, ".", name, NULL));
+  nlen = strlen (name);
+
+  if (cfun)
+    {
+      if (cfun->function_frequency == FUNCTION_FREQUENCY_HOT)
+	loc_string = HOT_TEXT_SECTION_PREFIX;
+      else if (cfun->function_frequency == FUNCTION_FREQUENCY_UNLIKELY_EXECUTED)
+	loc_string = UNLIKELY_EXECUTED_TEXT_SECTION_PREFIX;
+      if (loc_string)
+	llen = strlen (loc_string);
+    }
+
+  string = (char *) alloca (nlen + plen + llen + 1);
+  memcpy (string, prefix, plen);
+  memcpy (string + plen, name, nlen + 1);
+
+  if (llen)
+    memcpy (string + plen + nlen, loc_string, llen + 1);
 
   DECL_SECTION_NAME (decl) = build_string (strlen (string), string);
 }
Index: gcc-4.5.2.orig/gcc/ira.c
===================================================================
--- gcc-4.5.2.orig/gcc/ira.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/ira.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2359,6 +2359,17 @@
 	     only mark all destinations as having no known equivalence.  */
 	  if (set == 0)
 	    {
+	      if (GET_CODE (PATTERN (insn)) == UNSPEC_VOLATILE)
+		{
+		  int i;
+		  /* UNSPEC_VOLATILE is considered to use and clobber all hard 
+		     registers and all of memory.  This blocks insns from being
+		     combined across this point.  */
+		  for (i = FIRST_PSEUDO_REGISTER; i < reg_equiv_init_size; i++)
+		    reg_equiv[i].replace = 0;
+		}
+
+
 	      note_stores (PATTERN (insn), no_equiv, NULL);
 	      continue;
 	    }
Index: gcc-4.5.2.orig/gcc/sched-deps.c
===================================================================
--- gcc-4.5.2.orig/gcc/sched-deps.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/sched-deps.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2260,6 +2260,20 @@
       int regno = REGNO (dest);
       enum machine_mode mode = GET_MODE (dest);
 
+      /* Don't extend the lifetime of CLASS_LIKELY_SPILLED registers before RA
+	 since the clobbers due to reload are not yet computed.  */
+      if (!reload_completed && regno < FIRST_PSEUDO_REGISTER)
+	{
+	  int i = hard_regno_nregs[regno][mode];
+	  
+	  while (--i >= 0)
+	    if (CLASS_LIKELY_SPILLED_P (REGNO_REG_CLASS (regno + i)))
+	      {
+		flush_pending_lists (deps, insn, false, true);
+		break;
+	      }
+	}
+
       sched_analyze_reg (deps, regno, mode, code, insn);
 
 #ifdef STACK_REGS
Index: gcc-4.5.2.orig/gcc/output.h
===================================================================
--- gcc-4.5.2.orig/gcc/output.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/output.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2,6 +2,7 @@
    final.c, and varasm.c.
    Copyright (C) 1987, 1991, 1994, 1997, 1998, 1999, 2000, 2001, 2002,
    2003, 2004, 2005, 2006, 2007, 2008, 2009 Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -53,6 +54,9 @@
    any branches of variable length if possible.  */
 extern void shorten_branches (rtx);
 
+/* Returns the actual insn length without adjustment.  */
+int get_insn_current_length (rtx insn);
+
 /* Output assembler code for the start of a function,
    and initialize some of the variables in this file
    for the new function.  The label for the function and associated
@@ -386,8 +390,6 @@
 extern int size_directive_output;
 extern tree last_assemble_variable_decl;
 
-extern bool first_function_block_is_cold;
-
 /* Decide whether DECL needs to be in a writable section.
    RELOC is the same as for SELECT_SECTION.  */
 extern bool decl_readonly_section (const_tree, int);
@@ -577,7 +579,7 @@
 					    unsigned HOST_WIDE_INT,
 					    unsigned int);
 extern section *function_section (tree);
-extern section *unlikely_text_section (void);
+extern section *unlikely_text_section (tree);
 extern section *current_function_section (void);
 
 /* Return the numbered .ctors.N (if CONSTRUCTOR_P) or .dtors.N (if
Index: gcc-4.5.2.orig/gcc/Makefile.in
===================================================================
--- gcc-4.5.2.orig/gcc/Makefile.in	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/Makefile.in	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -843,7 +843,7 @@
 # comma in the $(if ...) constructs is significant - do not remove it.
 BASEVER_s   := "\"$(BASEVER_c)\""
 DEVPHASE_s  := "\"$(if $(DEVPHASE_c), ($(DEVPHASE_c)))\""
-DATESTAMP_s := "\"$(if $(DEVPHASE_c), $(DATESTAMP_c))\""
+DATESTAMP_s := "\"$(if $(DATESTAMP_c), $(DATESTAMP_c))\""
 PKGVERSION_s:= "\"@PKGVERSION@\""
 BUGURL_s    := "\"@REPORT_BUGS_TO@\""
 
@@ -1805,7 +1805,7 @@
 #
 # Build libgcc.a.
 
-LIB2ADD = $(LIB2FUNCS_EXTRA)
+LIB2ADD = $(LIB2FUNCS_EXTRA) @extra_libgcc_srcs@
 LIB2ADD_ST = $(LIB2FUNCS_STATIC_EXTRA)
 
 # All source files for libgcc are either in the source directory (in
Index: gcc-4.5.2.orig/gcc/basic-block.h
===================================================================
--- gcc-4.5.2.orig/gcc/basic-block.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/basic-block.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,6 +1,7 @@
 /* Define control and data flow tables, and regsets.
    Copyright (C) 1987, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004,
    2005, 2006, 2007, 2008, 2009, 2010 Free Software Foundation, Inc.
+   Copyright (c) 2009 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -823,6 +824,9 @@
 extern struct edge_list *pre_edge_lcm (int, sbitmap *, sbitmap *,
 				       sbitmap *, sbitmap *, sbitmap **,
 				       sbitmap **);
+extern struct edge_list *pre_edge_lcm_avs (int, sbitmap *, sbitmap *,
+					   sbitmap *, sbitmap *, sbitmap *,
+					   sbitmap *, sbitmap **, sbitmap **);
 extern struct edge_list *pre_edge_rev_lcm (int, sbitmap *,
 					   sbitmap *, sbitmap *,
 					   sbitmap *, sbitmap **,
Index: gcc-4.5.2.orig/gcc/config/i386/i386.h
===================================================================
--- gcc-4.5.2.orig/gcc/config/i386/i386.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/i386/i386.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2,6 +2,7 @@
    Copyright (C) 1988, 1992, 1994, 1995, 1996, 1997, 1998, 1999, 2000,
    2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -2328,7 +2329,7 @@
    is the set of hard registers live at the point where the insn(s)
    are to be inserted.  */
 
-#define EMIT_MODE_SET(ENTITY, MODE, HARD_REGS_LIVE) 			\
+#define EMIT_MODE_SET(ENTITY, MODE, FLIP, HARD_REGS_LIVE)		\
   ((MODE) != I387_CW_ANY && (MODE) != I387_CW_UNINITIALIZED		\
    ? emit_i387_cw_initialization (MODE), 0				\
    : 0)
Index: gcc-4.5.2.orig/gcc/config/i386/i386.c
===================================================================
--- gcc-4.5.2.orig/gcc/config/i386/i386.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/i386/i386.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -7667,7 +7667,7 @@
       DECL_INITIAL (decl) = make_node (BLOCK);
       current_function_decl = decl;
       init_function_start (decl);
-      first_function_block_is_cold = false;
+      in_cold_section_p = false;
       /* Make sure unwind info is emitted for the thunk if needed.  */
       final_start_function (emit_barrier (), asm_out_file, 1);
 
Index: gcc-4.5.2.orig/gcc/config/sh/t-mlib-sh4-300
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/t-mlib-sh4-300	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/t-mlib-sh4-300	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1 @@
+ML_sh4_300=m4-300/
Index: gcc-4.5.2.orig/gcc/config/sh/sh-protos.h
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/sh-protos.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/sh-protos.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -4,6 +4,7 @@
    Free Software Foundation, Inc.
    Contributed by Steve Chamberlain (sac@cygnus.com).
    Improved by Jim Wilson (wilson@cygnus.com).
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -25,8 +26,13 @@
 #define GCC_SH_PROTOS_H
 
 enum sh_function_kind {
-  /* A function with normal C ABI  */
+  /* A function with normal C ABI, or an SH1..SH4 sfunc that may resolved via
+     a PLT.  */
   FUNCTION_ORDINARY,
+  /* A function that is a bit large to put it in every calling dso, but that's
+     typically used often enough so that calling via GOT makes sense for
+     speed.  */
+  SFUNC_FREQUENT,
   /* A special function that guarantees that some otherwise call-clobbered
      registers are not clobbered.  These can't go through the SH5 resolver,
      because it only saves argument passing registers.  */
@@ -52,6 +58,7 @@
 extern const char *output_far_jump (rtx, rtx);
 
 extern struct rtx_def *sfunc_uses_reg (rtx);
+extern int sh_jump_align (rtx);
 extern int barrier_align (rtx);
 extern int sh_loop_align (rtx);
 extern int fp_zero_operand (rtx);
@@ -116,10 +123,16 @@
 extern void expand_df_unop (rtx (*)(rtx, rtx, rtx), rtx *);
 extern void expand_df_binop (rtx (*)(rtx, rtx, rtx, rtx), rtx *);
 extern void expand_fp_branch (rtx (*)(void), rtx (*)(void));
-extern int sh_insn_length_adjustment (rtx);
+extern void expand_sfunc_unop (enum machine_mode, rtx (*) (rtx, rtx),
+			       const char *, enum rtx_code code, rtx *);
+extern void expand_sfunc_binop (enum machine_mode, rtx (*) (rtx, rtx),
+				const char *, enum rtx_code code, rtx *);
+extern int sh_insn_length_adjustment (rtx, const int);
+extern int sh_insn_length_alignment (rtx);
 extern int sh_can_redirect_branch (rtx, rtx);
 extern void sh_expand_unop_v2sf (enum rtx_code, rtx, rtx);
 extern void sh_expand_binop_v2sf (enum rtx_code, rtx, rtx, rtx);
+extern void sh_expand_lround (rtx, rtx, bool);
 extern int sh_expand_t_scc (rtx *);
 extern rtx sh_gen_truncate (enum machine_mode, rtx, int);
 extern bool sh_vector_mode_supported_p (enum machine_mode);
@@ -133,6 +146,7 @@
 extern int sh_media_register_for_return (void);
 extern void sh_expand_prologue (void);
 extern void sh_expand_epilogue (bool);
+extern void sh_expand_float_scc (rtx operands[4]);
 extern int sh_need_epilogue (void);
 extern void sh_set_return_address (rtx, rtx);
 extern int initial_elimination_offset (int, int);
@@ -147,11 +161,14 @@
 extern void sh_mark_label (rtx, int);
 extern int sh_register_move_cost
   (enum machine_mode mode, enum reg_class, enum reg_class);
+extern rtx sh_dwarf_register_span (rtx);
 extern int check_use_sfunc_addr (rtx, rtx);
+extern bool sh_varying_insn_p (rtx);
 
 #ifdef HARD_CONST
 extern void fpscr_set_from_mem (int, HARD_REG_SET);
 #endif
+extern void emit_fpu_flip (void);
 
 extern void sh_pr_interrupt (struct cpp_reader *);
 extern void sh_pr_trapa (struct cpp_reader *);
@@ -176,10 +193,14 @@
 extern enum reg_class sh_secondary_reload (bool, rtx, enum reg_class,
 					   enum machine_mode,
 					   struct secondary_reload_info *);
+
 extern int sh2a_get_function_vector_number (rtx);
 extern int sh2a_is_function_vector_call (rtx);
 extern void sh_fix_range (const char *);
 extern bool sh_hard_regno_mode_ok (unsigned int, enum machine_mode);
+
+extern int sh_asm_count (const char *, int *);
+
 #endif /* ! GCC_SH_PROTOS_H */
 
 #ifdef SYMBIAN
Index: gcc-4.5.2.orig/gcc/config/sh/linux.h
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/linux.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/linux.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -33,9 +33,17 @@
    %{pthread:-D_REENTRANT -D_PTHREADS} \
 "
 
+/* Enable tls support if the assembler supports it. */
+#ifdef HAVE_AS_TLS
+#undef TARGET_HAVE_TLS
+#define TARGET_HAVE_TLS true
+#endif
+
 #define TARGET_OS_CPP_BUILTINS() \
   do						\
     {						\
+      extern const char version_string[];       \
+      builtin_define_with_value ("__GNUC_STM_RELEASE__", version_string, 1); \
       LINUX_TARGET_OS_CPP_BUILTINS();		\
     }						\
   while (0)
Index: gcc-4.5.2.orig/gcc/config/sh/linux-atomic.asm
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/linux-atomic.asm	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/linux-atomic.asm	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,4 +1,5 @@
 /* Copyright (C) 2006, 2008, 2009 Free Software Foundation, Inc.
+   Copyright (c) 2009, 2010 STMicroelectronics.
 
    This file is part of GCC.
 
@@ -33,7 +34,7 @@
 
 #if ! __SH5__
 
-#define ATOMIC_TEST_AND_SET(N,T,EXT) \
+#define ATOMIC_TEST_AND_SET(N,T) \
 	.global	__sync_lock_test_and_set_##N; \
 	HIDDEN_FUNC(__sync_lock_test_and_set_##N); \
 	.align	2; \
@@ -46,42 +47,20 @@
 	mov.##T	r5, @r4; \
 1:	mov	r1, r15; \
 	rts; \
-	 EXT	r2, r0; \
+	mov	r2, r0; \
 	ENDFUNC(__sync_lock_test_and_set_##N)
 
-ATOMIC_TEST_AND_SET (1,b,extu.b)
-ATOMIC_TEST_AND_SET (2,w,extu.w)
-ATOMIC_TEST_AND_SET (4,l,mov)
-
-#define ATOMIC_COMPARE_AND_SWAP(N,T,EXTS,EXT) \
-	.global	__sync_val_compare_and_swap_##N; \
-	HIDDEN_FUNC(__sync_val_compare_and_swap_##N); \
-	.align	2; \
-__sync_val_compare_and_swap_##N:; \
-	mova	1f, r0; \
-	EXTS	r5, r5; \
-	mov	r15, r1; \
-	mov	#(0f-1f), r15; \
-0:	mov.##T	@r4, r2; \
-	cmp/eq	r2, r5; \
-	bf	1f; \
-	mov.##T	r6, @r4; \
-1:	mov	r1, r15; \
-	rts; \
-	 EXT	r2, r0; \
-	ENDFUNC(__sync_val_compare_and_swap_##N)
-
-ATOMIC_COMPARE_AND_SWAP (1,b,exts.b,extu.b)
-ATOMIC_COMPARE_AND_SWAP (2,w,exts.w,extu.w)
-ATOMIC_COMPARE_AND_SWAP (4,l,mov,mov)
-
-#define ATOMIC_BOOL_COMPARE_AND_SWAP(N,T,EXTS) \
-	.global	__sync_bool_compare_and_swap_##N; \
-	HIDDEN_FUNC(__sync_bool_compare_and_swap_##N); \
+ATOMIC_TEST_AND_SET (1,b)
+ATOMIC_TEST_AND_SET (2,w)
+ATOMIC_TEST_AND_SET (4,l)
+
+#define ATOMIC_COMPARE_AND_SWAP(OP,N,T) \
+	.global	__sync_##OP##_compare_and_swap_##N; \
+	HIDDEN_FUNC(__sync_##OP##_compare_and_swap_##N); \
 	.align	2; \
-__sync_bool_compare_and_swap_##N:; \
+__sync_##OP##_compare_and_swap_##N:; \
 	mova	1f, r0; \
-	EXTS	r5, r5; \
+	nop; \
 	mov	r15, r1; \
 	mov	#(0f-1f), r15; \
 0:	mov.##T	@r4, r2; \
@@ -90,134 +69,135 @@
 	mov.##T	r6, @r4; \
 1:	mov	r1, r15; \
 	rts; \
+	.ifc OP, bool; \
 	 movt	r0; \
-	ENDFUNC(__sync_bool_compare_and_swap_##N)
+	.else; \
+	 mov r2, r0; \
+	.endif; \
+	ENDFUNC(__sync_##OP##_compare_and_swap_##N)
+	
+ATOMIC_COMPARE_AND_SWAP (bool,1,b)
+ATOMIC_COMPARE_AND_SWAP (bool,2,w)
+ATOMIC_COMPARE_AND_SWAP (bool,4,l)
+
+ATOMIC_COMPARE_AND_SWAP (val,1,b)
+ATOMIC_COMPARE_AND_SWAP (val,2,w)
+ATOMIC_COMPARE_AND_SWAP (val,4,l)
 
-ATOMIC_BOOL_COMPARE_AND_SWAP (1,b,exts.b)
-ATOMIC_BOOL_COMPARE_AND_SWAP (2,w,exts.w)
-ATOMIC_BOOL_COMPARE_AND_SWAP (4,l,mov)
-
-#define ATOMIC_FETCH_AND_OP(OP,N,T,EXT) \
+#define ATOMIC_FETCH_AND_OP(OP,N,T) \
 	.global	__sync_fetch_and_##OP##_##N; \
 	HIDDEN_FUNC(__sync_fetch_and_##OP##_##N); \
 	.align	2; \
 __sync_fetch_and_##OP##_##N:; \
 	mova	1f, r0; \
-	nop; \
 	mov	r15, r1; \
 	mov	#(0f-1f), r15; \
 0:	mov.##T	@r4, r2; \
-	mov	r5, r3; \
-	OP	r2, r3; \
-	mov.##T	r3, @r4; \
+	OP	r2, r5; \
+	mov.##T	r5, @r4; \
 1:	mov	r1, r15; \
 	rts; \
-	 EXT	r2, r0; \
+	mov	r2, r0; \
 	ENDFUNC(__sync_fetch_and_##OP##_##N)
 
-ATOMIC_FETCH_AND_OP(add,1,b,extu.b)
-ATOMIC_FETCH_AND_OP(add,2,w,extu.w)
-ATOMIC_FETCH_AND_OP(add,4,l,mov)
-
-ATOMIC_FETCH_AND_OP(or,1,b,extu.b)
-ATOMIC_FETCH_AND_OP(or,2,w,extu.w)
-ATOMIC_FETCH_AND_OP(or,4,l,mov)
-
-ATOMIC_FETCH_AND_OP(and,1,b,extu.b)
-ATOMIC_FETCH_AND_OP(and,2,w,extu.w)
-ATOMIC_FETCH_AND_OP(and,4,l,mov)
-
-ATOMIC_FETCH_AND_OP(xor,1,b,extu.b)
-ATOMIC_FETCH_AND_OP(xor,2,w,extu.w)
-ATOMIC_FETCH_AND_OP(xor,4,l,mov)
+ATOMIC_FETCH_AND_OP(add,1,b)
+ATOMIC_FETCH_AND_OP(add,2,w)
+ATOMIC_FETCH_AND_OP(add,4,l)
+
+ATOMIC_FETCH_AND_OP(or,1,b)
+ATOMIC_FETCH_AND_OP(or,2,w)
+ATOMIC_FETCH_AND_OP(or,4,l)
+
+ATOMIC_FETCH_AND_OP(and,1,b)
+ATOMIC_FETCH_AND_OP(and,2,w)
+ATOMIC_FETCH_AND_OP(and,4,l)
+
+ATOMIC_FETCH_AND_OP(xor,1,b)
+ATOMIC_FETCH_AND_OP(xor,2,w)
+ATOMIC_FETCH_AND_OP(xor,4,l)
 
-#define ATOMIC_FETCH_AND_COMBOP(OP,OP0,OP1,N,T,EXT) \
+#define ATOMIC_FETCH_AND_COMBOP(OP,OP0,OP1,N,T) \
 	.global	__sync_fetch_and_##OP##_##N; \
 	HIDDEN_FUNC(__sync_fetch_and_##OP##_##N); \
 	.align	2; \
 __sync_fetch_and_##OP##_##N:; \
 	mova	1f, r0; \
+	nop; \
 	mov	r15, r1; \
 	mov	#(0f-1f), r15; \
 0:	mov.##T	@r4, r2; \
-	mov	r5, r3; \
-	OP0	r2, r3; \
-	OP1	r3, r3; \
-	mov.##T	r3, @r4; \
+	OP0	r2, r5; \
+	OP1	r5, r5; \
+	mov.##T	r5, @r4; \
 1:	mov	r1, r15; \
 	rts; \
-	 EXT	r2, r0; \
+	mov	r2, r0; \
 	ENDFUNC(__sync_fetch_and_##OP##_##N)
 
-ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,1,b,extu.b)
-ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,2,w,extu.w)
-ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,4,l,mov)
-
-ATOMIC_FETCH_AND_COMBOP(nand,and,not,1,b,extu.b)
-ATOMIC_FETCH_AND_COMBOP(nand,and,not,2,w,extu.w)
-ATOMIC_FETCH_AND_COMBOP(nand,and,not,4,l,mov)
+ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,1,b)
+ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,2,w)
+ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,4,l)
+	
+ATOMIC_FETCH_AND_COMBOP(nand,and,not,1,b)
+ATOMIC_FETCH_AND_COMBOP(nand,and,not,2,w)
+ATOMIC_FETCH_AND_COMBOP(nand,and,not,4,l)
 
-#define ATOMIC_OP_AND_FETCH(OP,N,T,EXT) \
+#define ATOMIC_OP_AND_FETCH(OP,N,T) \
 	.global	__sync_##OP##_and_fetch_##N; \
 	HIDDEN_FUNC(__sync_##OP##_and_fetch_##N); \
 	.align	2; \
 __sync_##OP##_and_fetch_##N:; \
 	mova	1f, r0; \
-	nop; \
 	mov	r15, r1; \
 	mov	#(0f-1f), r15; \
 0:	mov.##T	@r4, r2; \
-	mov	r5, r3; \
-	OP	r2, r3; \
-	mov.##T	r3, @r4; \
+	OP	r5, r2; \
+	mov.##T	r2, @r4; \
 1:	mov	r1, r15; \
 	rts; \
-	 EXT	r3, r0; \
+	mov	r2, r0; \
 	ENDFUNC(__sync_##OP##_and_fetch_##N)
 
-ATOMIC_OP_AND_FETCH(add,1,b,extu.b)
-ATOMIC_OP_AND_FETCH(add,2,w,extu.w)
-ATOMIC_OP_AND_FETCH(add,4,l,mov)
-
-ATOMIC_OP_AND_FETCH(or,1,b,extu.b)
-ATOMIC_OP_AND_FETCH(or,2,w,extu.w)
-ATOMIC_OP_AND_FETCH(or,4,l,mov)
-
-ATOMIC_OP_AND_FETCH(and,1,b,extu.b)
-ATOMIC_OP_AND_FETCH(and,2,w,extu.w)
-ATOMIC_OP_AND_FETCH(and,4,l,mov)
-
-ATOMIC_OP_AND_FETCH(xor,1,b,extu.b)
-ATOMIC_OP_AND_FETCH(xor,2,w,extu.w)
-ATOMIC_OP_AND_FETCH(xor,4,l,mov)
+ATOMIC_OP_AND_FETCH(add,1,b)
+ATOMIC_OP_AND_FETCH(add,2,w)
+ATOMIC_OP_AND_FETCH(add,4,l)
+
+ATOMIC_OP_AND_FETCH(or,1,b)
+ATOMIC_OP_AND_FETCH(or,2,w)
+ATOMIC_OP_AND_FETCH(or,4,l)
+
+ATOMIC_OP_AND_FETCH(and,1,b)
+ATOMIC_OP_AND_FETCH(and,2,w)
+ATOMIC_OP_AND_FETCH(and,4,l)
+
+ATOMIC_OP_AND_FETCH(xor,1,b)
+ATOMIC_OP_AND_FETCH(xor,2,w)
+ATOMIC_OP_AND_FETCH(xor,4,l)
 
-#define ATOMIC_COMBOP_AND_FETCH(OP,OP0,OP1,N,T,EXT) \
+#define ATOMIC_COMBOP_AND_FETCH(OP,OP0,OP1,N,T) \
 	.global	__sync_##OP##_and_fetch_##N; \
 	HIDDEN_FUNC(__sync_##OP##_and_fetch_##N); \
 	.align	2; \
 __sync_##OP##_and_fetch_##N:; \
 	mova	1f, r0; \
+	nop; \
 	mov	r15, r1; \
 	mov	#(0f-1f), r15; \
 0:	mov.##T	@r4, r2; \
-	mov	r5, r3; \
-	OP0	r2, r3; \
-	OP1	r3, r3; \
-	mov.##T	r3, @r4; \
+	OP0	r2, r5; \
+	OP1	r5, r2; \
+	mov.##T	r2, @r4; \
 1:	mov	r1, r15; \
 	rts; \
-	 EXT	r3, r0; \
+	mov	r2, r0; \
 	ENDFUNC(__sync_##OP##_and_fetch_##N)
 
-ATOMIC_COMBOP_AND_FETCH(sub,sub,neg,1,b,extu.b)
-ATOMIC_COMBOP_AND_FETCH(sub,sub,neg,2,w,extu.w)
-ATOMIC_COMBOP_AND_FETCH(sub,sub,neg,4,l,mov)
-
-ATOMIC_COMBOP_AND_FETCH(nand,and,not,1,b,extu.b)
-ATOMIC_COMBOP_AND_FETCH(nand,and,not,2,w,extu.w)
-ATOMIC_COMBOP_AND_FETCH(nand,and,not,4,l,mov)
-
-.section .note.GNU-stack,"",%progbits
-.previous
+ATOMIC_COMBOP_AND_FETCH(sub,sub,neg,1,b)
+ATOMIC_COMBOP_AND_FETCH(sub,sub,neg,2,w)
+ATOMIC_COMBOP_AND_FETCH(sub,sub,neg,4,l)
+	
+ATOMIC_COMBOP_AND_FETCH(nand,and,not,1,b)
+ATOMIC_COMBOP_AND_FETCH(nand,and,not,2,w)
+ATOMIC_COMBOP_AND_FETCH(nand,and,not,4,l)
 
 #endif /* ! __SH5__ */
Index: gcc-4.5.2.orig/gcc/config/sh/elf.h
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/elf.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/elf.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -79,7 +79,7 @@
 
 #undef STARTFILE_SPEC
 #define STARTFILE_SPEC \
-  "%{!shared: crt1.o%s} crti.o%s \
+  "%{!shared: crt1.o%s trap-handler.o%s} crti.o%s \
    %{!shared:crtbegin.o%s} %{shared:crtbeginS.o%s}"
 
 #undef ENDFILE_SPEC
@@ -89,3 +89,8 @@
 /* ASM_OUTPUT_CASE_LABEL is defined in elfos.h.  With it,
    a redundant .align was generated.  */
 #undef  ASM_OUTPUT_CASE_LABEL
+
+#undef MAX_OFILE_ALIGNMENT
+#define MAX_OFILE_ALIGNMENT (((unsigned int) 1 << 20) * 8)
+
+
Index: gcc-4.5.2.orig/gcc/config/sh/superh.h
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/superh.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/superh.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,5 +1,6 @@
 /* Definitions of target machine for gcc for Super-H using sh-superh-elf.
    Copyright (C) 2001, 2006, 2007 Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GNU CC.
 
@@ -81,11 +82,6 @@
 #undef SUBTARGET_ASM_SPEC
 #define SUBTARGET_ASM_SPEC "%{m4-100*|m4-200*:-isa=sh4} %{m4-400|m4-340:-isa=sh4-nommu-nofpu} %{m4-500:-isa=sh4-nofpu} %(asruntime)"
 
-/* Override the SUBTARGET_ASM_RELAX_SPEC so it doesn't interfere with the
-   runtime support by adding -isa=sh4 in the wrong place.  */
-#undef SUBTARGET_ASM_RELAX_SPEC
-#define SUBTARGET_ASM_RELAX_SPEC "%{!m4-100*:%{!m4-200*:%{!m4-300*:%{!m4-340:%{!m4-400:%{!m4-500:-isa=sh4}}}}}}"
-
 /* Create the CC1_SPEC to add the runtime support */
 #undef CC1_SPEC
 #define CC1_SPEC "%(cc1runtime)"
@@ -96,7 +92,7 @@
 
 /* Override the LIB_SPEC to add the runtime support */
 #undef LIB_SPEC
-#define LIB_SPEC "%{!shared:%{!symbolic:%(libruntime) -lc}} %{pg:-lprofile -lc}"
+#define LIB_SPEC "%{!shared:%{!symbolic:%{pg:-lprofile} %(libruntime) -lc}}"
 
 /* Override STARTFILE_SPEC to add profiling and MMU support.  */
 #undef STARTFILE_SPEC
@@ -104,4 +100,4 @@
   "%{!shared: %{!m4-400*:%{!m4-340*: %{pg:gcrt1-mmu.o%s}%{!pg:crt1-mmu.o%s}}}} \
    %{!shared: %{m4-340*|m4-400*: %{pg:gcrt1.o%s}%{!pg:crt1.o%s}}} \
    crti.o%s \
-   %{!shared:crtbegin.o%s} %{shared:crtbeginS.o%s}"
+   %{!shared:crtbegin.o%s trap-handler.o%s} %{shared:crtbeginS.o%s}"
Index: gcc-4.5.2.orig/gcc/config/sh/lib1funcs.asm
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/lib1funcs.asm	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/lib1funcs.asm	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,6 +1,7 @@
 /* Copyright (C) 1994, 1995, 1997, 1998, 1999, 2000, 2001, 2002, 2003,
    2004, 2005, 2006, 2009
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is free software; you can redistribute it and/or modify it
 under the terms of the GNU General Public License as published by the
@@ -876,7 +877,7 @@
 	HIDDEN_ALIAS(movstrSI12_i4,movmemSI12_i4)
 
 	.p2align	5
-L_movmem_2mod4_end:
+LOCAL(movmem_2mod4_end):
 	mov.l	r0,@(16,r4)
 	rts
 	mov.l	r1,@(20,r4)
@@ -885,7 +886,7 @@
 
 GLOBAL(movmem_i4_even):
 	mov.l	@r5+,r0
-	bra	L_movmem_start_even
+	bra	LOCAL(movmem_start_even)
 	mov.l	@r5+,r1
 
 GLOBAL(movmem_i4_odd):
@@ -896,20 +897,20 @@
 	mov.l	r1,@(4,r4)
 	mov.l	r2,@(8,r4)
 
-L_movmem_loop:
+LOCAL(movmem_loop):
 	mov.l	r3,@(12,r4)
 	dt	r6
 	mov.l	@r5+,r0
-	bt/s	L_movmem_2mod4_end
+	bt/s	LOCAL(movmem_2mod4_end)
 	mov.l	@r5+,r1
 	add	#16,r4
-L_movmem_start_even:
+LOCAL(movmem_start_even):
 	mov.l	@r5+,r2
 	mov.l	@r5+,r3
 	mov.l	r0,@r4
 	dt	r6
 	mov.l	r1,@(4,r4)
-	bf/s	L_movmem_loop
+	bf/s	LOCAL(movmem_loop)
 	mov.l	r2,@(8,r4)
 	rts
 	mov.l	r3,@(12,r4)
@@ -947,17 +948,23 @@
 ! aa = bb*dd + (aa*dd*65536) + (cc*bb*65536)
 !
 
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif
 GLOBAL(mulsi3):
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif	
 	mulu.w  r4,r5		! multiply the lsws  macl=bb*dd
 	mov     r5,r3		! r3 = ccdd
 	swap.w  r4,r2		! r2 = bbaa
 	xtrct   r2,r3		! r3 = aacc
 	tst  	r3,r3		! msws zero ?
-	bf      hiset
+	bf      LOCAL(hiset)
 	rts			! yes - then we have the answer
 	sts     macl,r0
 
-hiset:	sts	macl,r0		! r0 = bb*dd
+LOCAL(hiset):	sts	macl,r0		! r0 = bb*dd
 	mulu.w	r2,r5		! brewing macl = aa*dd
 	sts	macl,r1
 	mulu.w	r3,r4		! brewing macl = cc*bb
@@ -978,6 +985,9 @@
 
 	.global	GLOBAL(sdivsi3_i4)
 	HIDDEN_FUNC(GLOBAL(sdivsi3_i4))
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	5
+#endif	
 GLOBAL(sdivsi3_i4):
 	lds r4,fpul
 	float fpul,dr0
@@ -1249,13 +1259,18 @@
 	blink tr2,r63
 	ENDFUNC(GLOBAL(sdivsi3))
 #else /* ! __SHMEDIA__ */
+	
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif
+	
 	FUNC(GLOBAL(sdivsi3))
 GLOBAL(sdivsi3):
 	mov	r4,r1
 	mov	r5,r0
 
 	tst	r0,r0
-	bt	div0
+	bt	LOCAL(div0)
 	mov	#0,r2
 	div0s	r2,r1
 	subc	r3,r3
@@ -1330,8 +1345,10 @@
 	rts
 	mov	r1,r0
 
-
-div0:	rts
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif		
+LOCAL(div0):	rts
 	mov	#0,r0
 
 	ENDFUNC(GLOBAL(sdivsi3))
@@ -1346,16 +1363,19 @@
 !! args in r4 and r5, result in fpul, clobber r0, r1, r4, r5, dr0, dr2, dr4,
 !! and t bit
 
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif
 	.global	GLOBAL(udivsi3_i4)
 	HIDDEN_FUNC(GLOBAL(udivsi3_i4))
 GLOBAL(udivsi3_i4):
 	mov #1,r1
 	cmp/hi r1,r5
-	bf trivial
+	bf LOCAL(trivial)
 	rotr r1
 	xor r1,r4
 	lds r4,fpul
-	mova L1,r0
+	mova 1f,r0
 #ifdef FMOVD_WORKS
 	fmov.d @r0+,dr4
 #else
@@ -1372,7 +1392,7 @@
 	rts
 	ftrc dr0,fpul
 
-trivial:
+LOCAL(trivial):
 	rts
 	lds r4,fpul
 
@@ -1380,7 +1400,7 @@
 #ifdef FMOVD_WORKS
 	.align 3	! make double below 8 byte aligned.
 #endif
-L1:
+1:
 	.double 2147483648
 
 	ENDFUNC(GLOBAL(udivsi3_i4))
@@ -1407,15 +1427,14 @@
 #endif /* ! __SH5__ || __SH5__ == 32 */
 #elif defined(__SH4_SINGLE__) || defined(__SH4_SINGLE_ONLY__)
 !! args in r4 and r5, result in fpul, clobber r0, r1, r4, r5, dr0, dr2, dr4
-
 	.global	GLOBAL(udivsi3_i4)
 	HIDDEN_FUNC(GLOBAL(udivsi3_i4))
 GLOBAL(udivsi3_i4):
 	mov #1,r1
 	cmp/hi r1,r5
-	bf trivial
+	bf LOCAL(trivial)
 	sts.l fpscr,@-r15
-	mova L1,r0
+	mova 1f,r0
 	lds.l @r0+,fpscr
 	rotr r1
 	xor r1,r4
@@ -1440,12 +1459,12 @@
 #ifdef FMOVD_WORKS
 	.align 3	! make double below 8 byte aligned.
 #endif
-trivial:
+LOCAL(trivial):
 	rts
 	lds r4,fpul
 
 	.align 2
-L1:
+1:
 #ifndef FMOVD_WORKS
 	.long 0x80000
 #else
@@ -1461,7 +1480,6 @@
 /* __SH4_SINGLE_ONLY__ keeps this part for link compatibility with
    sh2e/sh3e code.  */
 #if (! defined(__SH4__) && ! defined (__SH4_SINGLE__)) || defined (__linux__)
-
 !! args in r4 and r5, result in r0, clobbers r4, pr, and t bit
 	.global	GLOBAL(udivsi3)
 	HIDDEN_FUNC(GLOBAL(udivsi3))
@@ -1603,7 +1621,15 @@
  div1 r5,r4; rotcl r0
  div1 r5,r4; rotcl r0
  div1 r5,r4; rotcl r0
- rts; div1 r5,r4
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif		
+ rts
+ div1 r5,r4
+
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif
 
 GLOBAL(udivsi3):
  sts.l pr,@-r15
@@ -1617,6 +1643,9 @@
  div0u
  swap.w r4,r0
  shlr16 r4
+#ifdef	DB_ST40300_BUG_WORKAROUND
+ nop
+#endif			
  bsr LOCAL(div8)
  shll16 r5
  bsr LOCAL(div7)
@@ -1641,6 +1670,9 @@
  mov #0,r0
  xtrct r4,r0
  xtrct r0,r4
+#ifdef	DB_ST40300_BUG_WORKAROUND
+ nop
+#endif		
  bsr LOCAL(divx4)
  rotcl r0
  bsr LOCAL(divx4)
@@ -1969,6 +2001,10 @@
 #ifdef __SH5__
 	.mode	SHcompact
 #endif
+	
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif	
 	.global GLOBAL(set_fpscr)
 	HIDDEN_FUNC(GLOBAL(set_fpscr))
 GLOBAL(set_fpscr):
@@ -2010,6 +2046,9 @@
 #endif
 #if defined(__SH4__) || defined (__SH2A_DOUBLE__)
 	swap.w r0,r2
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif		
 	rts
 	mov.l r2,@r1
 #else /* defined(__SH2E__) || defined(__SH3E__) || defined(__SH4_SINGLE*__) */
@@ -2079,7 +2118,7 @@
 	synci
 	blink	tr0, r63
 	ENDFUNC(GLOBAL(ic_invalidate))
-#elif defined(__SH4A__)
+#elif defined(__SH4A__) || defined(__FORCE_SH4A__)
 	.global GLOBAL(ic_invalidate)
 	HIDDEN_FUNC(GLOBAL(ic_invalidate))
 GLOBAL(ic_invalidate):
@@ -2102,6 +2141,9 @@
 	   repetitive.  */
 	.global GLOBAL(ic_invalidate)
 	HIDDEN_FUNC(GLOBAL(ic_invalidate))
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif	
 GLOBAL(ic_invalidate):
 #ifdef __pic__
 #ifdef __vxworks
@@ -2146,7 +2188,6 @@
 
 #ifdef L_ic_invalidate_array
 #if defined(__SH4A__) || (defined (__FORCE_SH4A__) && (defined(__SH4_SINGLE__) || defined(__SH4__) || defined(__SH4_SINGLE_ONLY__) || (defined(__SH4_NOFPU__) && !defined(__SH5__))))
-	.global GLOBAL(ic_invalidate_array)
 	/* This is needed when an SH4 dso with trampolines is used on SH4A.  */
 	.global GLOBAL(ic_invalidate_array)
 	FUNC(GLOBAL(ic_invalidate_array))
@@ -3049,7 +3090,7 @@
  .global GLOBAL(sdivsi3)
 GLOBAL(sdivsi3):
 #ifdef TEXT_DATA_BUG
- ptb datalabel Local_div_table,tr0
+ ptb datalabel LOCAL(Ldiv_table),tr0
 #else
  ptb GLOBAL(div_table_internal),tr0
 #endif
@@ -3103,8 +3144,8 @@
 #endif /* __pic__ */
 #if defined(TEXT_DATA_BUG) && defined(__pic__) && defined(__SHMEDIA__)
 	.balign 2
-	.type	Local_div_table,@object
-	.size	Local_div_table,128
+	.type	LOCAL(Ldiv_table),@object
+	.size	LOCAL(Ldiv_table),128
 /* negative division constants */
 	.word	-16638
 	.word	-17135
@@ -3140,7 +3181,7 @@
 	.byte	214
 	.byte	241
 	.skip 16
-Local_div_table:
+LOCAL(Ldiv_table):
 	.skip 16
 /* positive division factors */
 	.byte	241
@@ -3272,11 +3313,19 @@
 #define L_MSWLSB 1
 #endif
 
+	
 	.balign 4
 	.global	GLOBAL(udivsi3_i4i)
 	FUNC(GLOBAL(udivsi3_i4i))
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	5
+#endif			
 GLOBAL(udivsi3_i4i):
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	mov.w LOCAL(c128_lw), r1
+#else
 	mov.w LOCAL(c128_w), r1
+#endif
 	div0u
 	mov r4,r0
 	shlr8 r0
@@ -3324,8 +3373,14 @@
 	rts
 	shld r1,r0
 
+#ifdef	DB_ST40300_BUG_WORKAROUND	
+LOCAL(c128_lw):
+	.word 128
+#else
 LOCAL(div_by_1_neg):
 	neg r4,r0
+#endif
+	
 LOCAL(div_by_1):
 	mov.l @r15+,r5
 	rts
@@ -3395,6 +3450,17 @@
 	FUNC(GLOBAL(sdivsi3_i4i))
 	/* This is link-compatible with a GLOBAL(sdivsi3) call,
 	   but we effectively clobber only r1.  */
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	5
+	
+LOCAL(div_by_1_neg):
+	neg r4,r0
+LOCAL(div_by_12):
+	mov.l @r15+,r5
+	rts
+	mov.l @r15+,r4
+#endif			
+	
 GLOBAL(sdivsi3_i4i):
 	mov.l r4,@-r15
 	cmp/pz r5
@@ -3891,6 +3957,9 @@
 	/* n1 < d, but n1 might be larger than d1.  */
 	.global GLOBAL(udiv_qrnnd_16)
 	.balign 8
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	5
+#endif		
 GLOBAL(udiv_qrnnd_16):
 	div0u
 	cmp/hi r6,r0
@@ -3931,3 +4000,8 @@
 	ENDFUNC(GLOBAL(udiv_qrnnd_16))
 #endif /* !__SHMEDIA__ */
 #endif /* L_udiv_qrnnd_16 */
+
+#ifndef L_div_table
+#include "ieee-754-sf.S"
+#include "ieee-754-df.S"
+#endif
Index: gcc-4.5.2.orig/gcc/config/sh/embed-elf.h
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/embed-elf.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/embed-elf.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2,6 +2,7 @@
    non-Linux embedded targets.
    Copyright (C) 2002, 2003, 2007 Free Software Foundation, Inc.
    Contributed by J"orn Rennecke <joern.rennecke@superh.com>
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -29,10 +30,14 @@
    libgcc-Os-4-200 are.  Thus, when not optimizing for space, link
    libgcc-Os-4-200 after libgcc, so that -mdiv=call-table works for -m2.  */
 #define LIBGCC_SPEC "%{!shared: \
-  %{m4-100*:-lic_invalidate_array_4-100} \
-  %{m4-200*:-lic_invalidate_array_4-200} \
-  %{m4-300*|-m4-340:-lic_invalidate_array_4a %{!Os: -lgcc-4-300}} \
-  %{m4a*:-lic_invalidate_array_4a}} \
-  %{Os: -lgcc-Os-4-200} \
+  %{!m4-100*:%{!m4-200*:%{!m4-300*:%{!m4a*:-lic_invalidate}}}}	\
+  %{m4-100*:-lic_invalidate_4-100}				\
+  %{m4-200*:-lic_invalidate_4-200}				\
+  %{m4-300*|-m4-340:-lic_invalidate_4a}			        \
+  %{m4a*:-lic_invalidate_4a}}					\
   -lgcc \
-  %{!Os: -lgcc-Os-4-200}"
+  %{Os: -lgcc-Os-4-200}					        \
+  %{!Os: %{m4-300*|-m4-340: -lgcc-4-300} %{!m4-300*:%{!m4-340: -lgcc-4-200}}}"
+
+
+
Index: gcc-4.5.2.orig/gcc/config/sh/t-sh
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/t-sh	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/t-sh	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,5 +1,6 @@
 # Copyright (C) 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002,
 # 2003, 2004, 2006, 2008, 2009 Free Software Foundation, Inc.
+# Copyright (c) 2010 STMicroelectronics.
 #
 # This file is part of GCC.
 #
@@ -22,20 +23,50 @@
 	$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) \
 		$(srcdir)/config/sh/sh-c.c
 
+# _nesf2f _nedf2f _gtsf2t _gtdf2t _gesf2f _gedf2f: no-finite-math-only optimized
+# versions of _ne_sf _ne_df _gt_sf _gt_df _ge_sf _ge_df from fp-bit.c (built with
+# -ffinite-math-only. (see TARGET_LIBGCC2_CFLAGS).
+# _div_table 
+
 LIB1ASMSRC = sh/lib1funcs.asm
 LIB1ASMFUNCS = _ashiftrt _ashiftrt_n _ashiftlt _lshiftrt _movmem \
   _movmem_i4 _mulsi3 _sdivsi3 _sdivsi3_i4 _udivsi3 _udivsi3_i4 _set_fpscr \
-  _div_table _udiv_qrnnd_16 \
+  _udiv_qrnnd_16 \
+  _nesf2f _nedf2f _gtsf2t _gtdf2t _gesf2f _gedf2f \
+  _addsub_sf _mul_sf _addsub_df _mul_df \
+  _hypotf \
+  _sf_to_df _df_to_sf \
+  _fixunssfsi _sf_to_si _usi_to_sf _si_to_sf \
+  _usi_to_df _si_to_df \
+  _div_sf \
+  $(LIB1ASMFUNCS_DIVTABLE) \
   $(LIB1ASMFUNCS_CACHE)
 LIB1ASMFUNCS_CACHE = _ic_invalidate _ic_invalidate_array
 
-TARGET_LIBGCC2_CFLAGS = -mieee
+# notyet. move above and remove bellow!
+# unord_sf/unord_df
+# _div_df \
+# _df_to_usi \
+# _df_to_si \
 
 # We want fine grained libraries, so use the new code to build the
 # floating point emulation libraries.
 FPBIT = fp-bit.c
 DPBIT = dp-bit.c
 
+FPBIT_FUNCS = _pack_sf _unpack_sf \
+    _fpcmp_parts_sf _compare_sf _eq_sf _ne_sf _gt_sf _ge_sf \
+    _lt_sf _le_sf _unord_sf _negate_sf _make_sf \
+    _sf_to_tf _thenan_sf
+
+DPBIT_FUNCS = _pack_df _unpack_df _div_df \
+    _fpcmp_parts_df _compare_df _eq_df _ne_df _gt_df _ge_df \
+    _lt_df _le_df _unord_df _negate_df _make_df \
+    _df_to_tf _thenan_df _df_to_usi _df_to_si
+
+# Make sure they are compiled in optimized mode.
+TARGET_LIBGCC2_CFLAGS = -ffinite-math-only
+
 dp-bit.c: $(srcdir)/config/fp-bit.c
 	echo '#ifdef __LITTLE_ENDIAN__' > dp-bit.c
 	echo '#define FLOAT_BIT_ORDER_MISMATCH' >>dp-bit.c
@@ -118,48 +149,65 @@
 	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $(T)crti.o -x assembler-with-cpp $(srcdir)/config/sh/crti.asm
 $(T)crtn.o: $(srcdir)/config/sh/crtn.asm $(GCC_PASSES)
 	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $(T)crtn.o -x assembler-with-cpp $(srcdir)/config/sh/crtn.asm
+$(T)trap-handler.o : $(srcdir)/config/sh/trap-handler.c
+	$(GCC_FOR_TARGET) $(CFLAGS_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $(T)trap-handler.o -g $(srcdir)/config/sh/trap-handler.c
 
 $(out_object_file): gt-sh.h
-gt-sh.h : s-gtype ; @true
 
 # These are not suitable for COFF.
-# EXTRA_MULTILIB_PARTS= crt1.o crti.o crtn.o crtbegin.o crtend.o
+# EXTRA_MULTILIB_PARTS= crt1.o crti.o crtn.o crtbegin.o crtend.o trap-handler.o
 
-IC_EXTRA_PARTS= libic_invalidate_array_4-100.a libic_invalidate_array_4-200.a \
-libic_invalidate_array_4a.a
-OPT_EXTRA_PARTS= libgcc-Os-4-200.a libgcc-4-300.a
+IC_EXTRA_PARTS= libic_invalidate.a libic_invalidate_4-100.a \
+	libic_invalidate_4-200.a libic_invalidate_4a.a
+
+OPT_EXTRA_PARTS= libgcc-4-200.a libgcc-Os-4-200.a libgcc-4-300.a
 EXTRA_MULTILIB_PARTS= $(IC_EXTRA_PARTS) $(OPT_EXTRA_PARTS)
 
+$(T)ic_invalidate.o: $(srcdir)/config/sh/lib1funcs.asm $(GCC_PASSES)
+	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -I. -c -o $(T)ic_invalidate.o -DL_ic_invalidate -x assembler-with-cpp $(srcdir)/config/sh/lib1funcs.asm
+
+$(T)ic_invalidate_4a.o: $(srcdir)/config/sh/lib1funcs.asm $(GCC_PASSES)
+	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -I. -c -o $(T)ic_invalidate_4a.o -DL_ic_invalidate -D__FORCE_SH4A__ -Wa,-isa=st40-300 -x assembler-with-cpp $(srcdir)/config/sh/lib1funcs.asm
+
+$(T)ic_invalidate_array.o: $(srcdir)/config/sh/lib1funcs.asm $(GCC_PASSES)
+	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -I. -c -o $(T)ic_invalidate_array.o -DL_ic_invalidate_array  -x assembler-with-cpp $(srcdir)/config/sh/lib1funcs.asm
+$(T)libic_invalidate.a: $(T)ic_invalidate_array.o $(T)ic_invalidate.o $(GCC_PASSES)
+	$(AR_CREATE_FOR_TARGET) $(T)libic_invalidate.a $(T)ic_invalidate_array.o $(T)ic_invalidate.o 
+
 $(T)ic_invalidate_array_4-100.o: $(srcdir)/config/sh/lib1funcs.asm $(GCC_PASSES)
-	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $(T)ic_invalidate_array_4-100.o -DL_ic_invalidate_array -DWAYS=1 -DWAY_SIZE=0x2000 -x assembler-with-cpp $(srcdir)/config/sh/lib1funcs.asm
-$(T)libic_invalidate_array_4-100.a: $(T)ic_invalidate_array_4-100.o $(GCC_PASSES)
-	$(AR_CREATE_FOR_TARGET) $(T)libic_invalidate_array_4-100.a $(T)ic_invalidate_array_4-100.o
+	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -I. -c -o $(T)ic_invalidate_array_4-100.o -DL_ic_invalidate_array -DWAYS=1 -DWAY_SIZE=0x2000 -x assembler-with-cpp $(srcdir)/config/sh/lib1funcs.asm
+$(T)libic_invalidate_4-100.a: $(T)ic_invalidate_array_4-100.o $(T)ic_invalidate.o $(GCC_PASSES)
+	$(AR_CREATE_FOR_TARGET) $(T)libic_invalidate_4-100.a $(T)ic_invalidate_array_4-100.o $(T)ic_invalidate.o 
 
 $(T)ic_invalidate_array_4-200.o: $(srcdir)/config/sh/lib1funcs.asm $(GCC_PASSES)
-	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $(T)ic_invalidate_array_4-200.o -DL_ic_invalidate_array -DWAYS=2 -DWAY_SIZE=0x2000 -x assembler-with-cpp $(srcdir)/config/sh/lib1funcs.asm
-$(T)libic_invalidate_array_4-200.a: $(T)ic_invalidate_array_4-200.o $(GCC_PASSES)
-	$(AR_CREATE_FOR_TARGET) $(T)libic_invalidate_array_4-200.a $(T)ic_invalidate_array_4-200.o
+	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -I. -c -o $(T)ic_invalidate_array_4-200.o -DL_ic_invalidate_array -DWAYS=2 -DWAY_SIZE=0x2000 -x assembler-with-cpp $(srcdir)/config/sh/lib1funcs.asm
+$(T)libic_invalidate_4-200.a: $(T)ic_invalidate_array_4-200.o $(T)ic_invalidate.o $(GCC_PASSES)
+	$(AR_CREATE_FOR_TARGET) $(T)libic_invalidate_4-200.a $(T)ic_invalidate_array_4-200.o $(T)ic_invalidate.o 
 
 $(T)ic_invalidate_array_4a.o: $(srcdir)/config/sh/lib1funcs.asm $(GCC_PASSES)
-	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $(T)ic_invalidate_array_4a.o -DL_ic_invalidate_array -D__FORCE_SH4A__ -x assembler-with-cpp $(srcdir)/config/sh/lib1funcs.asm
-$(T)libic_invalidate_array_4a.a: $(T)ic_invalidate_array_4a.o $(GCC_PASSES)
-	$(AR_CREATE_FOR_TARGET) $(T)libic_invalidate_array_4a.a $(T)ic_invalidate_array_4a.o
+	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -I. -c -o $(T)ic_invalidate_array_4a.o -DL_ic_invalidate_array -D__FORCE_SH4A__ -Wa,-isa=st40-300 -x assembler-with-cpp $(srcdir)/config/sh/lib1funcs.asm
+$(T)libic_invalidate_4a.a: $(T)ic_invalidate_array_4a.o $(T)ic_invalidate_4a.o $(GCC_PASSES)
+	$(AR_CREATE_FOR_TARGET) $(T)libic_invalidate_4a.a $(T)ic_invalidate_array_4a.o $(T)ic_invalidate_4a.o 
 
+OBJS_Os_4_200=$(T)sdivsi3_i4i-Os-4-200.o $(T)udivsi3_i4i-Os-4-200.o 
+$(T)libgcc-Os-4-200.a: $(OBJS_Os_4_200) $(GCC_PASSES)
+	$(AR_CREATE_FOR_TARGET) $@ $(OBJS_Os_4_200)
 $(T)sdivsi3_i4i-Os-4-200.o: $(srcdir)/config/sh/lib1funcs-Os-4-200.asm $(GCC_PASSES)
 	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $@ -DL_sdivsi3_i4i -x assembler-with-cpp $<
 $(T)udivsi3_i4i-Os-4-200.o: $(srcdir)/config/sh/lib1funcs-Os-4-200.asm $(GCC_PASSES)
 	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $@ -DL_udivsi3_i4i -x assembler-with-cpp $<
-$(T)unwind-dw2-Os-4-200.o: $(srcdir)/unwind-dw2.c $(srcdir)/unwind-generic.h unwind-pe.h unwind.inc unwind-dw2-fde.h unwind-dw2.h $(CONFIG_H) coretypes.h $(TM_H) $(MACHMODE_H) longlong.h config.status stmp-int-hdrs tsystem.h $(GCC_PASSES)
-	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) $(LIBGCC2_CFLAGS) $(INCLUDES) $(vis_hide) -fexceptions -Os -c -o $@ $<
-OBJS_Os_4_200=$(T)sdivsi3_i4i-Os-4-200.o $(T)udivsi3_i4i-Os-4-200.o $(T)unwind-dw2-Os-4-200.o
-$(T)libgcc-Os-4-200.a: $(OBJS_Os_4_200) $(GCC_PASSES)
-	$(AR_CREATE_FOR_TARGET) $@ $(OBJS_Os_4_200)
 
-$(T)div_table-4-300.o: $(srcdir)/config/sh/lib1funcs-4-300.asm $(GCC_PASSES)
+OBJS_4_200=$(T)div_table-4-200.o 
+$(T)libgcc-4-200.a: $(OBJS_4_200) $(GCC_PASSES)
+	$(AR_CREATE_FOR_TARGET) $@ $(OBJS_4_200)
+$(OBJS_4_200): $(srcdir)/config/sh/lib1funcs.asm $(GCC_PASSES)
 	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $@ -DL_div_table -x assembler-with-cpp $<
 
-$(T)libgcc-4-300.a: $(T)div_table-4-300.o $(GCC_PASSES)
-	$(AR_CREATE_FOR_TARGET) $@ $(T)div_table-4-300.o
+OBJS_4_300=$(T)div_table-4-300.o 
+$(T)libgcc-4-300.a: $(OBJS_4_300) $(GCC_PASSES)
+	$(AR_CREATE_FOR_TARGET) $@ $(OBJS_4_300) 
+$(OBJS_4_300): $(srcdir)/config/sh/lib1funcs-4-300.asm $(GCC_PASSES)
+	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $@ -DL_div_table -x assembler-with-cpp $<
 
 # Local Variables:
 # mode: Makefile
Index: gcc-4.5.2.orig/gcc/config/sh/crti.asm
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/crti.asm	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/crti.asm	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -44,8 +44,8 @@
 #else
 	.p2align 1
 #endif
-	.global	 _init
-_init:
+	.global	 __init
+__init:
 #if __SHMEDIA__
 	addi	r15, -16, r15
 	st.q	r15, 8, r14
@@ -89,8 +89,8 @@
 #else
 	.p2align 1
 #endif
-	.global  _fini
-_fini:	
+	.global  __fini
+__fini:	
 #if __SHMEDIA__
 	addi	r15, -16, r15
 	st.q	r15, 8, r14
Index: gcc-4.5.2.orig/gcc/config/sh/crtn.asm
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/crtn.asm	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/crtn.asm	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -39,9 +39,15 @@
 	rts
 	add	#8,r15
 #else
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif	
 	mov	r14,r15
 	lds.l	@r15+,pr
 	mov.l	@r15+,r14
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif		
 	rts
 #ifdef __ELF__
 	mov.l	@r15+,r12
@@ -65,9 +71,15 @@
 	rts
 	add	#8,r15
 #else
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif		
 	mov	r14,r15
 	lds.l	@r15+,pr
 	mov.l	@r15+,r14
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif			
 	rts
 #ifdef __ELF__
 	mov.l	@r15+,r12
Index: gcc-4.5.2.orig/gcc/config/sh/lib1funcs-4-300.asm
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/lib1funcs-4-300.asm	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/lib1funcs-4-300.asm	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -403,7 +403,7 @@
 	addc r6,r0
 	rotcr r0
 	mov.l @r15+,r6
-	shad r1,r0
+	shld r1,r0	
 	rts
 	neg r0,r0
 	ENDFUNC(GLOBAL(udivsi3_i4i))
Index: gcc-4.5.2.orig/gcc/config/sh/constraints.md
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/constraints.md	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/constraints.md	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -87,6 +87,9 @@
 (define_register_constraint "z" "R0_REGS"
   "R0 register.")
 
+(define_register_constraint "R03" "R0R3_REGS"
+  "R0/R3 registers.")
+
 ;; Integer constraints
 (define_constraint "I06"
   "A signed 6-bit constant, as used in SHmedia beqi, bnei and xori."
Index: gcc-4.5.2.orig/gcc/config/sh/sh.opt
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/sh.opt	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/sh.opt	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,6 +1,7 @@
 ; Options for the SH port of the compiler.
 
 ; Copyright (C) 2005, 2006, 2007, 2008, 2009 Free Software Foundation, Inc.
+; Copyright (c) 2009  STMicroelectronics.
 ;
 ; This file is part of GCC.
 ;
@@ -21,7 +22,7 @@
 ;; Used for various architecture options.
 Mask(SH_E)
 
-;; Set if the default precision of th FPU is single.
+;; Set if the default precision of the FPU is single.
 Mask(FPU_SINGLE)
 
 ;; Set if we should generate code using type 2A insns.
@@ -200,9 +201,13 @@
 Target RejectNegative Condition(SUPPORT_SH5_32MEDIA_NOFPU)
 Generate FPU-less SHcompact code
 
-madjust-unroll
-Target Report Mask(ADJUST_UNROLL) Condition(SUPPORT_ANY_SH5)
-Throttle unrolling to avoid thrashing target registers unless the unroll benefit outweighs this
+maccumulate-outgoing-args
+Target Report Mask(ACCUMULATE_OUTGOING_ARGS)
+Reserve space for outgoing arguments in the function prologue
+
+malign-small-blocks=
+Target RejectNegative Joined UInteger Var(sh_align_small_blocks) Init(16)
+Honor align-jump-loops for basic block bigger than number of instructions.
 
 mb
 Target Report RejectNegative InverseMask(LITTLE_ENDIAN)
@@ -236,9 +241,13 @@
 Target Report RejectNegative Mask(ALIGN_DOUBLE)
 Align doubles at 64-bit boundaries
 
+mdb-page-bug
+Target Report RejectNegative Mask(DBHWBUG)
+Undocumented
+
 mdiv=
 Target RejectNegative Joined Var(sh_div_str) Init("")
-Division strategy, one of: call, call2, fp, inv, inv:minlat, inv20u, inv20l, inv:call, inv:call2, inv:fp, call-div1, call-fp, call-table
+Division strategy, one of: call, call2, fp, inv, inv:minlat, inv20u, inv20l, inv:call, inv:call2, inv:fp, call-div1, call-fp, call-table, call-pre1
 
 mdivsi3_libfunc=
 Target RejectNegative Joined Var(sh_divsi3_libfunc) Init("")
@@ -288,6 +297,14 @@
 Target Report RejectNegative Mask(LITTLE_ENDIAN)
 Generate code in little endian mode
 
+mlate-r0r3-to-reg-mul
+Target RejectNegative Var(TARGET_R0R3_TO_REG_MUL, 1) VarExists
+Assume availability of integer multiply instruction (src only opd in r0-r3), but only try to use this instruction after register allocation.
+
+mdead-delay
+Target Report Mask(DEAD_DELAY)
+Try to eliminate a dead delay slot instruction.
+
 mnomacsave
 Target Report RejectNegative Mask(NOMACSAVE)
 Mark MAC register as call-clobbered
@@ -306,6 +323,10 @@
 Target Report Mask(PT_FIXED) Condition(SUPPORT_ANY_SH5)
 Assume pt* instructions won't trap
 
+mr0r3-to-reg-mul
+Target Var(TARGET_R0R3_TO_REG_MUL, 2) Init(-1)
+Assume availability of integer multiply instruction (src only opd in r0-r3)
+
 mrelax
 Target Report RejectNegative Mask(RELAX)
 Shorten address references during linking
@@ -314,9 +335,9 @@
 Target Mask(HITACHI) MaskExists
 Follow Renesas (formerly Hitachi) / SuperH calling conventions
 
-mspace
-Target Report RejectNegative Mask(SMALLCODE)
-Deprecated.  Use -Os instead
+mtas
+Target Var(TARGET_TAS) 
+Allow TAS.B instruction.
 
 multcost=
 Target RejectNegative Joined UInteger Var(sh_multcost) Init(-1)
Index: gcc-4.5.2.orig/gcc/config/sh/ieee-754-df.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/ieee-754-df.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/ieee-754-df.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,794 @@
+/* Copyright (C) 2006, 2008, 2009 Free Software Foundation, Inc.
+   Copyright (c) 2010 STMicroelectronics.
+	
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   Under Section 7 of GPL version 3, you are granted additional
+   permissions described in the GCC Runtime Library Exception, version
+   3.1, as published by the Free Software Foundation.
+
+   You should have received a copy of the GNU General Public License and
+   a copy of the GCC Runtime Library Exception along with this program;
+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+   <http://www.gnu.org/licenses/>.  */
+
+!! libgcc software floating-point routines for Renesas SH /
+!! STMicroelectronics ST40 CPUs
+!! Contributed by J"orn Rennecke joern.rennecke@st.com
+
+#ifndef __SH_FPU_DOUBLE__
+
+#include "lib1funcs.h"
+#include "insn-constants.h"
+
+/* Double-precision floating-point emulation.
+   We handle NANs, +-infinity, and +-zero.
+   However, we assume that for NANs, the topmost bit of the fraction is set.  */
+
+#ifdef __LITTLE_ENDIAN__
+#define DBL0L r4
+#define DBL0H r5
+#define DBL1L r6
+#define DBL1H r7
+#define DBLRL r0
+#define DBLRH r1
+#else
+#define DBL0L r5
+#define DBL0H r4
+#define DBL1L r7
+#define DBL1H r6
+#define DBLRL r1
+#define DBLRH r0
+#endif
+
+#ifdef __SH_FPU_ANY__
+#define RETURN_R0_MAIN
+#define RETURN_R0 bra LOCAL(return_r0)
+#define RETURN_FR0 \
+LOCAL(return_r0): \
+ lds r0,fpul; \
+ rts; \
+ fsts fpul,fr0
+#define ARG_TO_R4 \
+ flds fr4,fpul; \
+ sts fpul,r4
+#else /* ! __SH_FPU_ANY__ */
+#define RETURN_R0_MAIN rts
+#define RETURN_R0 rts
+#define RETURN_FR0
+#define ARG_TO_R4
+#endif /* ! __SH_FPU_ANY__ */
+
+#ifdef L_nedf2f
+/* -fno-finite-math-only -mb inline version, T := r4:DF == r6:DF
+	cmp/eq	r5,r7
+	mov	r4,r0
+	bf	0f
+	cmp/eq	r4,r6
+	bt	0f
+	or	r6,r0
+	add	r0,r0
+	or	r5,r0
+	tst	r0,r0
+	0:			*/
+	.balign 4
+	.global GLOBAL(nedf2f)
+	HIDDEN_FUNC(GLOBAL(nedf2f))
+GLOBAL(nedf2f):
+	cmp/eq	DBL0L,DBL1L
+	bf.s 	LOCAL(ne)
+	mov     #1,r0
+	cmp/eq	DBL0H,DBL1H
+	mov.l   LOCAL(c_DF_NAN_MASK),r1
+	bt.s	LOCAL(check_nan)
+	not	DBL0H,r0	
+	mov	DBL0H,r0
+	or	DBL1H,r0
+	add	r0,r0
+	rts
+	or	DBL0L,r0
+LOCAL(check_nan):
+	tst	r1,r0
+	bt.s 	LOCAL(nan)
+	mov	#12,r2
+	shll16  r2
+	xor 	r2,r1
+	tst 	r1,r0
+LOCAL(nan):	
+	movt	r0
+LOCAL(ne):
+	rts
+	nop
+	
+	.balign 4
+LOCAL(c_DF_NAN_MASK):
+	.long DF_NAN_MASK
+	ENDFUNC(GLOBAL(nedf2f))
+#endif /* L_nedf2f */
+
+#ifdef L_unord_df
+	.balign 4
+	.global GLOBAL(unorddf2)
+	HIDDEN_FUNC(GLOBAL(unorddf2))
+GLOBAL(unorddf2):
+	mov.l	LOCAL(c_DF_NAN_MASK),r1
+	not	DBL0H,r0
+	tst	r1,r0
+	not	r6,r0
+	bt	LOCAL(unord)
+	tst	r1,r0
+LOCAL(unord):
+	rts
+	movt	r0
+	.balign	4
+LOCAL(c_DF_NAN_MASK):
+	.long DF_NAN_MASK
+	ENDFUNC(GLOBAL(unorddf2))
+#endif /* L_unord_df */
+
+#if defined(L_gtdf2t) || defined(L_gtdf2t_trap)
+/* -fno-finite-math-only version of _gt_df */
+#ifdef L_gtdf2t
+#define fun_label GLOBAL(gtdf2t)
+#else
+#define fun_label GLOBAL(gtdf2t_trap)
+#endif
+	.balign 4
+	.global fun_label
+	HIDDEN_FUNC(fun_label)
+fun_label:
+	/* If the raw values compare greater, the result true, unless
+	   any of them is a nan (but infinity is fine), or both values are
+	   +- zero.  Otherwise, the result false.  */
+	mov.l	LOCAL(c_DF_NAN_MASK),r1
+	cmp/pz	DBL0H
+	not	DBL1H,r0
+	SLC(bf,	LOCAL(neg),
+	 tst	r1,r0)
+	mov	DBL0H,r0
+	bt	LOCAL(nan) /* return zero if DBL1 is NAN.  */
+	cmp/eq	DBL1H,DBL0H
+	bt	LOCAL(cmp_low)
+	cmp/gt	DBL1H,DBL0H
+	or	DBL1H,r0
+	SLC(bf,	LOCAL(check_nan),
+	 cmp/gt	DBL0H,r1)
+	add	r0,r0
+	bf	LOCAL(nan) /* return zero if DBL0 is NAN.  */
+	or	DBL0L,r0
+	rts
+	or	DBL1L,r0 /* non-zero unless both DBL0 and DBL1 are +-zero.  */
+LOCAL(cmp_low):
+	cmp/hi	DBL1L,DBL0L
+	rts
+	movt	r0
+LOCAL(neg):
+	SLI(tst	r1,r0)
+	bt	LOCAL(nan) /* return zero if DBL1 is NAN.  */
+	cmp/eq	DBL1H,DBL0H
+	SLC(bt,	LOCAL(neg_cmp_low),
+	 cmp/hi	DBL0L,DBL1L)
+	not	DBL0H,r0
+	tst	r1,r0
+	bt	LOCAL(nan) /* return zero if DBL0 is NAN.  */
+	cmp/hi	DBL0H,DBL1H
+	SLI(rts	!,)
+	SLI(movt r0 !,)
+LOCAL(neg_cmp_low):
+	SLI(cmp/hi	DBL0L,DBL1L)
+	rts
+	movt	r0
+LOCAL(check_nan):
+#ifdef L_gtdf2t
+LOCAL(nan):
+	rts
+	mov	#0,r0
+#else
+	SLI(cmp/gt DBL0H,r1)
+	bf	LOCAL(nan) /* return zero if DBL0 is NAN.  */
+	rts
+	mov	#0,r0
+LOCAL(nan):
+	mov	#0,r0
+	trapa	#0
+#endif
+	.balign	4
+LOCAL(c_DF_NAN_MASK):
+	.long DF_NAN_MASK
+	ENDFUNC(fun_label)
+#endif /* defined(L_gtdf2t) || defined(L_gtdf2t_trap) */
+
+#ifdef L_gedf2f
+	.balign 4
+	.global GLOBAL(gedf2f)
+	HIDDEN_FUNC(GLOBAL(gedf2f))
+GLOBAL(gedf2f):
+	/* -fno-finite-math-only version of _ge_df */
+	/* If the raw values compare greater or equal, the result is
+	   true, unless any of them is a nan, or both are the
+	   same infinity.  If both are -+zero, the result is true;
+	   otherwise, it is false.
+	   We use 0 as true and nonzero as false for this function.  */
+	mov.l	LOCAL(c_DF_NAN_MASK),r1
+	cmp/pz	DBL1H
+	not	DBL0H,r0
+	SLC(bf,	LOCAL(neg),
+	 tst	r1,r0)
+	mov	DBL0H,r0
+	bt	LOCAL(nan)
+	cmp/eq	DBL0H,DBL1H
+	bt	LOCAL(cmp_low)
+	cmp/gt	DBL0H,DBL1H
+	or	DBL1H,r0
+	SLC(bf,	LOCAL(check_nan),
+	 cmp/ge	r1,DBL1H)
+	add	r0,r0
+	bt	LOCAL(nan)
+	or	DBL0L,r0
+	rts
+	or	DBL1L,r0
+LOCAL(cmp_low):
+	cmp/hi	DBL0L,DBL1L
+#if defined(L_gedf2f) && defined(DELAYED_BRANCHES)
+LOCAL(nan): LOCAL(check_nan):
+#endif
+	rts
+	movt	r0
+#if defined(L_gedf2f) && ! defined(DELAYED_BRANCHES)
+LOCAL(check_nan):
+	SLI(cmp/ge	r1,DBL1H)
+LOCAL(nan):
+	rts
+	movt	r0
+#elif defined(L_gedf2f_trap)
+LOCAL(check_nan):
+	SLI(cmp/ge	r1,DBL1H)
+	bt	LOCAL(nan)
+	rts
+LOCAL(nan):
+	movt	r0
+	trapa	#0
+#endif /* L_gedf2f_trap */
+LOCAL(neg):
+	SLI(tst	r1,r0)
+	bt	LOCAL(nan)
+	cmp/eq	DBL0H,DBL1H
+	not	DBL1H,r0
+	SLC(bt,	LOCAL(neg_cmp_low),
+	 cmp/hi	DBL1L,DBL0L)
+	tst	r1,r0
+	bt	LOCAL(nan)
+	cmp/hi	DBL1H,DBL0H
+	SLI(rts !,)
+	SLI(movt	r0 !,)
+LOCAL(neg_cmp_low):
+	SLI(cmp/hi	DBL1L,DBL0L)
+	rts
+	movt	r0
+	.balign	4
+LOCAL(c_DF_NAN_MASK):
+	.long DF_NAN_MASK
+	ENDFUNC(GLOBAL(gedf2f))
+#endif /* L_gedf2f */
+
+#ifndef DYN_SHIFT /* SH1 / SH2 code */
+#ifdef L_sf_to_df
+	.balign 4
+	.global GLOBAL(extendsfdf2)
+	FUNC(GLOBAL(extendsfdf2))
+GLOBAL(extendsfdf2):
+	ARG_TO_R4
+	mov.l	LOCAL(x7f800000),r3
+	mov	r4,DBLRL
+	tst	r3,r4
+	bt	LOCAL(zero_denorm)
+	mov.l	LOCAL(xe0000000),r2
+	rotr	DBLRL
+	rotr	DBLRL
+	rotr	DBLRL
+	and	r2,DBLRL
+	mov	r4,DBLRH
+	not	r4,r2
+	tst	r3,r2
+	mov.l	LOCAL(x38000000),r2
+	bf	0f
+	add	r2,r2	! infinity / NaN adjustment
+0:	shll	DBLRH
+	shlr2	DBLRH
+	shlr2	DBLRH
+	add	DBLRH,DBLRH
+	rotcr	DBLRH
+	rts
+	add	r2,DBLRH
+LOCAL(zero_denorm):
+	mov.l	r4,@-r15
+	add	r4,r4
+	tst	r4,r4
+	bt	LOCAL(zero)
+	shlr8	r3	/* 0x007f8000 */
+	mov.w	LOCAL(x389),r2
+LOCAL(shift_byte):
+	tst	r3,r4
+	shll8	r4
+	SL(bt,	LOCAL(shift_byte),
+	 add	#-8,r2)
+LOCAL(shift_bit):
+	shll	r4
+	SL(bf,	LOCAL(shift_bit),
+	 add	#-1,r2)
+	mov	#0,DBLRL
+	mov	r4,DBLRH
+	mov.l	@r15+,r4
+	shlr8	DBLRH
+	shlr2	DBLRH
+	shlr	DBLRH
+	rotcr	DBLRL
+	cmp/gt	r4,DBLRH	! get sign
+	rotcr	DBLRH
+	rotcr	DBLRL
+	shll16	r2
+	shll8	r2
+	rts
+	add	r2,DBLRH
+LOCAL(zero):
+	mov.l	@r15+,DBLRH
+	rts
+	mov	#0,DBLRL
+LOCAL(x389):	.word 0x389
+	.balign	4
+LOCAL(x7f800000):
+	.long	0x7f800000
+LOCAL(x38000000):
+	.long	0x38000000
+LOCAL(xe0000000):
+	.long	0xe0000000
+	ENDFUNC(GLOBAL(extendsfdf2))
+#endif /* L_sf_to_df */
+
+#ifdef L_df_to_sf
+	.balign 4
+	.global GLOBAL(truncdfsf2)
+	FUNC(GLOBAL(truncdfsf2))
+GLOBAL(truncdfsf2):
+	mov.l	LOCAL(x38000000),r3	! exponent adjustment DF -> SF
+	mov	DBL0H,r1
+	mov.l	LOCAL(x70000000),r2	! mask for out-of-range exponent bits
+	mov	DBL0H,r0
+	mov.l	DBL0L,@-r15
+	sub	r3,r1
+	tst	r2,r1
+	shll8	r0			!
+	shll2	r0			! Isolate highpart fraction.
+	shll2	r0			!
+	bf	LOCAL(ill_exp)
+	shll2	r1
+	mov.l	LOCAL(x2fffffff),r2 /* Fraction lsb | lower guard bits.  */
+	shll2	r1
+	mov.l	LOCAL(xff000000),r3
+	shlr8	r0
+	tst	r2,DBL0L /* Check if msb guard bit wants rounding up.  */
+	shlr16	DBL0L
+	shlr8	DBL0L
+	shlr2	DBL0L
+	SL1(bt,	LOCAL(add_frac),
+	 shlr2	DBL0L)
+	add	#1,DBL0L
+LOCAL(add_frac):
+	add	DBL0L,r0
+	mov.l	LOCAL(x01000000),r2
+	and	r3,r1
+	mov.l	@r15+,DBL0L
+	add	r1,r0
+	tst	r3,r0
+	bt	LOCAL(inf_denorm0)
+	cmp/hs	r3,r0
+LOCAL(denorm_noup_sh1):
+	bt	LOCAL(inf)
+	div0s	DBL0H,r2	/* copy orig. sign into T.  */
+RETURN_R0_MAIN
+	rotcr	r0
+RETURN_FR0
+LOCAL(inf_denorm0):	!  We might need to undo previous rounding.
+	mov.l	LOCAL(x2fffffff),r3 /* Old fraction lsb | lower guard bits.  */
+	tst	r1,r1
+	bf	LOCAL(inf)
+	add	#-1,r0
+	tst	r3,DBL0L /* Check if msb guard bit was rounded up.  */
+	mov.l	LOCAL(x5fffffff),r3 /* Fraction lsb | lower guard bits.  */
+	addc	r2,r0
+	shlr	r0
+	tst	r3,DBL0L /* Check if msb guard bit wants rounding up.  */
+#ifdef DELAYED_BRANCHES
+	bt/s	LOCAL(denorm_noup)
+#else
+	bt	LOCAL(denorm_noup_sh1)
+#endif
+	div0s	DBL0H,r2	/* copy orig. sign into T.  */
+	add	#1,r0
+LOCAL(denorm_noup):
+	RETURN_R0
+	rotcr	r0
+LOCAL(ill_exp):
+	div0s	DBL0H,r1
+	mov.l	LOCAL(x7ff80000),r2
+	add	r1,r1
+	bf	LOCAL(inf_nan)
+	mov.w	LOCAL(m32),r3 /* Handle denormal or zero.  */
+	shlr16	r1
+	exts.w	r1,r1
+	shll2	r1
+	add	r1,r1
+	shlr8	r1
+	exts.w	r1,r1
+	add	#-8,r1	/* Go from 9 to 1 guard bit in MSW.  */
+	cmp/gt	r3,r1
+	mov.l	@r15+,r3 /* DBL0L */
+	bf	LOCAL(zero)
+	mov.l	DBL0L, @-r15
+	shll8	DBL0L
+	rotcr	r0	/* Insert leading 1.  */
+	shlr16	r3
+	shll2	r3
+	add	r3,r3
+	shlr8	r3
+	cmp/pl	DBL0L	/* Check lower 23 guard bits if guard bit 23 is 0.  */
+	addc	r3,r0	/* Assemble fraction with compressed guard bits.  */
+	mov.l	@r15+,DBL0L
+	mov	#0,r2
+	neg	r1,r1
+LOCAL(denorm_loop):
+	shlr	r0
+	rotcl	r2
+	dt	r1
+	bf	LOCAL(denorm_loop)
+	tst	#2,r0
+	rotcl	r0
+	tst	r2,r2
+	rotcl	r0
+	xor	#3,r0
+	add	#3,r0	/* Even overflow gives the correct result.  */
+	shlr2	r0
+	div0s	r0,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(zero):
+	mov	#0,r0
+	div0s	r0,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(inf_nan):
+	not	DBL0H,r0
+	tst	r2,r0
+	mov.l	@r15+,DBL0L
+	bf	LOCAL(inf)
+	RETURN_R0
+	mov	#-1,r0	/* NAN */
+LOCAL(inf):	/* r2 must be positive here.  */
+	mov.l	LOCAL(xff000000),r0
+	div0s	r2,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(m32):
+	.word	-32
+	.balign	4
+LOCAL(x38000000):
+	.long	0x38000000
+LOCAL(x70000000):
+	.long	0x70000000
+LOCAL(x2fffffff):
+	.long	0x2fffffff
+LOCAL(x01000000):
+	.long	0x01000000
+LOCAL(xff000000):
+	.long	0xff000000
+LOCAL(x5fffffff):
+	.long	0x5fffffff
+LOCAL(x7ff80000):
+	.long	0x7ff80000
+	ENDFUNC(GLOBAL(truncdfsf2))
+#endif /*  L_df_to_sf */
+#ifdef L_addsub_df
+#include "IEEE-754/adddf3.S"
+#endif /* _addsub_df */
+
+#ifdef L_mul_df
+#include "IEEE-754/muldf3.S"
+#endif /* L_mul_df */
+
+#ifdef L_df_to_usi
+#include "IEEE-754/fixunsdfsi.S"
+#endif /* L_df_to_usi */
+
+#ifdef L_df_to_si
+#include "IEEE-754/fixdfsi.S"
+#endif /* L_df_to_si */
+
+#ifdef L_usi_to_df
+#include "IEEE-754/floatunssidf.S"
+#endif /* L_usi_to_df */
+
+#ifdef L_si_to_df
+#include "IEEE-754/floatsidf.S"
+#endif /* L_si_df */
+
+#ifdef L_div_df
+#include "IEEE-754/divdf3.S"
+#endif /* L_div_df */
+#endif /* ! DYN_SHIFT */
+
+/* The actual arithmetic uses dynamic shift.  Supporting SH1 / SH2 here would
+   make this code too hard to maintain, so if you want to add SH1 / SH2
+   support, do it in a separate copy.  */
+#ifdef DYN_SHIFT
+#ifdef L_sf_to_df
+	.balign 4
+	.global GLOBAL(extendsfdf2)
+	FUNC(GLOBAL(extendsfdf2))
+GLOBAL(extendsfdf2):
+	ARG_TO_R4
+	mov.l	LOCAL(x7f800000),r2
+	mov	#29,r3
+	mov	r4,DBLRL
+	not	r4,DBLRH
+	tst	r2,r4
+	shld	r3,DBLRL
+	bt	LOCAL(zero_denorm)
+	mov	#-3,r3
+	tst	r2,DBLRH
+	mov	r4,DBLRH
+	mov.l	LOCAL(x38000000),r2
+	bt/s	LOCAL(inf_nan)
+	 shll	DBLRH
+	shld	r3,DBLRH
+	rotcr	DBLRH
+	rts
+	add	r2,DBLRH
+	.balign	4
+LOCAL(inf_nan):
+	shld	r3,DBLRH
+	add	r2,r2
+	rotcr	DBLRH
+	rts
+	add	r2,DBLRH
+LOCAL(zero_denorm):
+	mov.l	r4,@-r15
+	add	r4,r4
+	tst	r4,r4
+	extu.w	r4,r2
+	bt	LOCAL(zero)
+	cmp/eq	r4,r2
+	extu.b	r4,r1
+	mov.l	LOCAL(c__clz_tab),r0
+	bf	LOCAL(three_bytes)
+	nop
+	cmp/eq	r4,r1
+	mov	#22,DBLRH
+	bt	LOCAL(one_byte)
+	shlr8	r2
+	mov	#14,DBLRH
+LOCAL(one_byte):
+#ifdef __pic__
+	add	r0,r2
+	mova  LOCAL(c__clz_tab),r0
+#endif
+	mov.b	@(r0,r2),r2
+	mov	#21,r3
+	mov.w	LOCAL(x0),DBLRL
+	sub	r2,DBLRH
+LOCAL(norm_shift):
+	shld	DBLRH,r4
+	neg	DBLRH,DBLRH
+	mov.l	@r15+,r2
+	shld	r3,DBLRH
+	mov.l	LOCAL(x6fa00000),r3
+	add	r4,DBLRH
+	mov r2,r4
+	add	r3,DBLRH
+
+	div0s	r3,r4
+	rts
+	rotcr	DBLRH
+LOCAL(three_bytes):
+	mov	r4,r2
+	shlr16	r2
+#ifdef __pic__
+	add	r0,r2
+	mova  LOCAL(c__clz_tab),r0
+#endif
+	mov.b	@(r0,r2),r2
+	mov	#21,r3
+	mov	#6+10,DBLRH
+	sub	r2,DBLRH
+	mov	r4,DBLRL
+	shld	r3,DBLRL
+	shld	DBLRH,DBLRL
+	bra	LOCAL(norm_shift)
+	add	#-10,DBLRH
+LOCAL(zero):
+	rts	/* DBLRL has already been zeroed above.  */
+	mov.l @r15+,DBLRH
+LOCAL(x0):
+	.word 0
+	.balign	4
+LOCAL(x7f800000):
+	.long	0x7f800000
+LOCAL(x38000000):
+	.long	0x38000000
+LOCAL(x6fa00000):
+	/* Flip sign back, do exponent adjustment, and remove leading one.  */
+	.long 0x6fa00000 
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+	ENDFUNC(GLOBAL(extendsfdf2))
+#endif /* L_sf_to_df */
+
+#ifdef L_df_to_sf
+	.balign 4
+	.global GLOBAL(truncdfsf2)
+	FUNC(GLOBAL(truncdfsf2))
+GLOBAL(truncdfsf2):
+	mov.l	LOCAL(x38000000),r3
+	mov	DBL0H,r1
+	mov.l	LOCAL(x70000000),r2
+	mov	DBL0H,r0
+	sub	r3,r1
+	mov.l	DBL0L,@-r15
+	tst	r2,r1
+	mov	#12,r3
+	shld	r3,r0			! Isolate highpart fraction.
+	bf	LOCAL(ill_exp)
+	shll2	r1
+	mov.l	LOCAL(x2fffffff),r2 /* Fraction lsb | lower guard bits.  */
+	shll2	r1
+	mov.l	LOCAL(xff000000),r3
+	shlr8	r0
+	tst	r2,DBL0L /* Check if msb guard bit wants rounding up.  */
+	mov	#-28,r2
+	bt/s	LOCAL(add_frac)
+	 shld	r2,DBL0L
+	add	#1,DBL0L
+LOCAL(add_frac):
+	add	DBL0L,r0
+	mov.l	LOCAL(x01000000),r2
+	and	r3,r1
+	mov.l	@r15+,DBL0L
+	add	r1,r0
+	tst	r3,r0
+	bt	LOCAL(inf_denorm0)
+	cmp/hs	r3,r0
+	bt	LOCAL(inf)
+	div0s	DBL0H,r2	/* copy orig. sign into T.  */
+	RETURN_R0_MAIN
+	rotcr	r0
+RETURN_FR0
+LOCAL(inf_denorm0):	! We might need to undo previous rounding.
+	mov.l	LOCAL(x2fffffff),r3 /* Old fraction lsb | lower guard bits.  */
+	tst	r1,r1
+	bf	LOCAL(inf)
+	add	#-1,r0
+	tst	r3,DBL0L /* Check if msb guard bit was rounded up.  */
+	mov.l	LOCAL(x5fffffff),r3 /* Fraction lsb | lower guard bits.  */
+	addc	r2,r0
+	shlr	r0
+	tst	r3,DBL0L /* Check if msb guard bit wants rounding up.  */
+	bt/s	LOCAL(denorm_noup)
+	 div0s	DBL0H,r2	/* copy orig. sign into T.  */
+	add	#1,r0
+LOCAL(denorm_noup):
+	RETURN_R0
+	rotcr	r0
+LOCAL(ill_exp):
+	div0s	DBL0H,r1
+	mov.l	LOCAL(x7ff80000),r2
+	add	r1,r1
+	bf	LOCAL(inf_nan)
+	mov.w	LOCAL(m32),r3 /* Handle denormal or zero.  */
+	mov	#-21,r2
+	shad	r2,r1
+	add	#-8,r1	/* Go from 9 to 1 guard bit in MSW.  */
+	cmp/gt	r3,r1
+	mov.l	@r15+,r3 /* DBL0L */
+	bf	LOCAL(zero)
+	mov.l	DBL0L, @-r15
+	shll8	DBL0L
+	rotcr	r0	/* Insert leading 1.  */
+	shld	r2,r3
+	cmp/pl	DBL0L	/* Check lower 23 guard bits if guard bit 23 is 0.  */
+	addc	r3,r0	/* Assemble fraction with compressed guard bits.  */
+	mov	r0,r2
+	shld	r1,r0
+	mov.l	@r15+,DBL0L
+	add	#32,r1
+	shld	r1,r2
+	tst	#2,r0
+	rotcl	r0
+	tst	r2,r2
+	rotcl	r0
+	xor	#3,r0
+	add	#3,r0	/* Even overflow gives the correct result.  */
+	shlr2	r0
+	div0s	r0,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(zero):
+	mov	#0,r0
+	div0s	r0,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(inf_nan):
+	not	DBL0H,r0
+	tst	r2,r0
+	mov.l	@r15+,DBL0L
+	bf	LOCAL(inf)
+	RETURN_R0
+	mov	#-1,r0	/* NAN */
+LOCAL(inf):	/* r2 must be positive here.  */
+	mov.l	LOCAL(xff000000),r0
+	div0s	r2,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(m32):
+	.word	-32
+	.balign	4
+LOCAL(x38000000):
+	.long	0x38000000
+LOCAL(x70000000):
+	.long	0x70000000
+LOCAL(x2fffffff):
+	.long	0x2fffffff
+LOCAL(x01000000):
+	.long	0x01000000
+LOCAL(xff000000):
+	.long	0xff000000
+LOCAL(x5fffffff):
+	.long	0x5fffffff
+LOCAL(x7ff80000):
+	.long	0x7ff80000
+	ENDFUNC(GLOBAL(truncdfsf2))
+#endif /* L_df_to_sf */
+
+
+#ifdef L_addsub_df
+#include "IEEE-754/m3/adddf3.S"
+#endif /* _addsub_df */
+
+#ifdef L_mul_df
+#include "IEEE-754/m3/muldf3.S"
+#endif /* L_mul_df */
+
+#ifdef L_df_to_usi
+#include "IEEE-754/m3/fixunsdfsi.S"
+#endif /* L_df_to_usi */
+
+#ifdef L_df_to_si
+#include "IEEE-754/m3/fixdfsi.S"
+#endif /* L_df_to_si */
+
+#ifdef L_usi_to_df
+#include "IEEE-754/m3/floatunssidf.S"
+#endif /* L_usi_to_df */
+
+#ifdef L_si_to_df
+#include "IEEE-754/m3/floatsidf.S"
+#endif /* L_si_to_df */
+
+#ifdef L_div_df
+#include "IEEE-754/m3/divdf3.S"
+#endif /* L_div_df */
+#endif /* DYN_SHIFT */
+
+#endif /* __SH_FPU_DOUBLE__ */
Index: gcc-4.5.2.orig/gcc/config/sh/predicates.md
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/predicates.md	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/predicates.md	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,5 +1,6 @@
 ;; Predicate definitions for Renesas / SuperH SH.
 ;; Copyright (C) 2005, 2006, 2007, 2008, 2009 Free Software Foundation, Inc.
+;; Copyright (c) 2006  STMicroelectronics.
 ;;
 ;; This file is part of GCC.
 ;;
@@ -699,6 +700,33 @@
 (define_predicate "symbol_ref_operand"
   (match_code "symbol_ref"))
 
+(define_special_predicate "soft_fp_comparison_operand"
+  (match_code "subreg,reg")
+{
+  switch (GET_MODE (op))
+    {
+    default:
+      return 0;
+    case CC_FP_NEmode: case CC_FP_GTmode: case CC_FP_UNLTmode:
+      break;
+    }
+  return register_operand (op, mode);
+})
+
+(define_predicate "soft_fp_comparison_operator"
+  (match_code "eq, unle, ge")
+{
+  switch (GET_CODE (op))
+    {
+    default:
+      return 0;
+    case EQ:  mode = CC_FP_NEmode;    break;
+    case UNLE:        mode = CC_FP_GTmode;    break;
+    case GE:  mode = CC_FP_UNLTmode;  break;
+    }
+  return register_operand (XEXP (op, 0), mode);
+})
+
 ;; Same as target_reg_operand, except that label_refs and symbol_refs
 ;; are accepted before reload.
 
Index: gcc-4.5.2.orig/gcc/config/sh/sh.c
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/sh.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/sh.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -4,6 +4,7 @@
    Free Software Foundation, Inc.
    Contributed by Steve Chamberlain (sac@cygnus.com).
    Improved by Jim Wilson (wilson@cygnus.com).
+   Copyright (c) 2010 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -56,7 +57,7 @@
 #include "cfgloop.h"
 #include "alloc-pool.h"
 #include "tm-constrs.h"
-
+#include "except.h"
 
 int code_for_indirect_jump_scratch = CODE_FOR_indirect_jump_scratch;
 
@@ -189,11 +190,13 @@
 static int calc_live_regs (HARD_REG_SET *);
 static HOST_WIDE_INT rounded_frame_size (int);
 static rtx mark_constant_pool_use (rtx);
+static int sh_cfun_naked_p (void);
 static tree sh_handle_interrupt_handler_attribute (tree *, tree, tree, int, bool *);
 static tree sh_handle_resbank_handler_attribute (tree *, tree,
 						 tree, int, bool *);
 static tree sh2a_handle_function_vector_handler_attribute (tree *, tree,
 							   tree, int, bool *);
+static tree  sh_handle_fndecl_attribute (tree *, tree, tree, int, bool *);
 static tree sh_handle_sp_switch_attribute (tree *, tree, tree, int, bool *);
 static tree sh_handle_trap_exit_attribute (tree *, tree, tree, int, bool *);
 static tree sh_handle_renesas_attribute (tree *, tree, tree, int, bool *);
@@ -284,6 +287,7 @@
 static void sh_trampoline_init (rtx, tree, rtx);
 static rtx sh_trampoline_adjust_address (rtx);
 
+
 static const struct attribute_spec sh_attribute_table[] =
 {
   /* { name, min_len, max_len, decl_req, type_req, fn_type_req, handler } */
@@ -306,6 +310,8 @@
   { "dllimport",         0, 0, true,  false, false, sh_symbian_handle_dll_attribute },
   { "dllexport",         0, 0, true,  false, false, sh_symbian_handle_dll_attribute },
 #endif
+  /* don't generate function prologue/epilogue and `ret' command.  */
+  { "naked",             0, 0, true,  false, false, sh_handle_fndecl_attribute },
   { NULL,                0, 0, false, false, false, NULL }
 };
 
@@ -663,19 +669,20 @@
 void
 sh_optimization_options (int level ATTRIBUTE_UNUSED, int size ATTRIBUTE_UNUSED)
 {
+  TARGET_CBRANCHDI4 = 1;
+
   if (level)
     {
-      flag_omit_frame_pointer = 2;
       if (!size)
 	sh_div_str = "inv:minlat";
     }
   if (size)
     {
-      target_flags |= MASK_SMALLCODE;
       sh_div_str = SH_DIV_STR_FOR_SIZE ;
     }
-  else
-    TARGET_CBRANCHDI4 = 1;
+
+  flag_omit_frame_pointer = (PREFERRED_DEBUGGING_TYPE == DWARF2_DEBUG);	
+
   /* We can't meaningfully test TARGET_SHMEDIA here, because -m options
      haven't been parsed yet, hence we'd read only the default.
      sh_target_reg_class will return NO_REGS if this is not SHMEDIA, so
@@ -685,18 +692,22 @@
       flag_branch_target_load_optimize = 1;
       if (!size)
 	target_flags |= MASK_SAVE_ALL_TARGET_REGS;
+
+      target_flags |= MASK_DEAD_DELAY;            
     }
   /* Likewise, we can't meaningfully test TARGET_SH2E / TARGET_IEEE
      here, so leave it to OVERRIDE_OPTIONS to set
     flag_finite_math_only.  We set it to 2 here so we know if the user
     explicitly requested this to be on or off.  */
   flag_finite_math_only = 2;
-  /* If flag_schedule_insns is 1, we set it to 2 here so we know if
-     the user explicitly requested this to be on or off.  */
-  if (flag_schedule_insns > 0)
-    flag_schedule_insns = 2;
 
-  set_param_value ("simultaneous-prefetches", 2);
+  /* If flag_tree_cselim is 1, we set it to 2 here so we know if	
+     the user explicitly requested this to be on or off. XXX check */		
+  if (flag_tree_cselim > 0)				  
+    flag_tree_cselim = 2;                                               
+
+  if (!PARAM_SET_P (PARAM_SIMULTANEOUS_PREFETCHES))                     
+    set_param_value ("simultaneous-prefetches", (TARGET_SH4_300 ? 6 : 2)); 
 }
 
 /* Implement OVERRIDE_OPTIONS macro.  Validate and override various
@@ -710,6 +721,8 @@
   if (flag_finite_math_only == 2)
     flag_finite_math_only
       = !flag_signaling_nans && TARGET_SH2E && ! TARGET_IEEE;
+  if (flag_trapping_math == 2)				
+    flag_trapping_math = (!TARGET_SH2E && TARGET_OSFP);	
   if (TARGET_SH2E && !flag_finite_math_only)
     target_flags |= MASK_IEEE;
   sh_cpu = PROCESSOR_SH1;
@@ -808,6 +821,8 @@
 	sh_div_strategy = SH_DIV_CALL_FP;
       else if (! strcmp (sh_div_str, "call-table") && TARGET_SH2)
 	sh_div_strategy = SH_DIV_CALL_TABLE;
+      else if (! strcmp (sh_div_str, "call-pre1"))	     
+ 	sh_div_strategy = SH_DIV_CALL_PRE1;
       else
 	/* Pick one that makes most sense for the target in general.
 	   It is not much good to use different functions depending
@@ -855,21 +870,13 @@
     if (! VALID_REGISTER_P (ADDREGNAMES_REGNO (regno)))
       sh_additional_register_names[regno][0] = '\0';
 
-  if (flag_omit_frame_pointer == 2)
-   {
-     /* The debugging information is sufficient,
-        but gdb doesn't implement this yet */
-     if (0)
-      flag_omit_frame_pointer
-        = (PREFERRED_DEBUGGING_TYPE == DWARF2_DEBUG);
-     else
-      flag_omit_frame_pointer = 0;
-   }
-
   if ((flag_pic && ! TARGET_PREFERGOT)
       || (TARGET_SHMEDIA && !TARGET_PT_FIXED))
     flag_no_function_cse = 1;
 
+  if (flag_tree_cselim == 2)
+    flag_tree_cselim = 0;   
+									\
   if (SMALL_REGISTER_CLASSES)
     {
       /* Never run scheduling before reload, since that can
@@ -887,15 +894,30 @@
 	 on gcc-patches
          <http://gcc.gnu.org/ml/gcc-patches/2005-10/msg00816.html>.  */
       else if (flag_exceptions)
-	{
-	  if (flag_schedule_insns == 1)
-	    warning (0, "ignoring -fschedule-insns because of exception handling bug");
 	  flag_schedule_insns = 0;
 	}
-      else if (flag_schedule_insns == 2)
-	flag_schedule_insns = 0;
+
+    if ((target_flags_explicit & MASK_ACCUMULATE_OUTGOING_ARGS) == 0)	
+      target_flags |= MASK_ACCUMULATE_OUTGOING_ARGS;			
+    
+  /* ??? Unwind info is not correct around the CFG unless either a frame 
+     pointer is present or M_A_O_A is set.  Fixing this requires rewriting
+     unwind info generation to be aware of the CFG and propagating states
+     around edges.  */                                                  
+  if ((flag_unwind_tables || flag_asynchronous_unwind_tables            
+       || flag_exceptions || flag_non_call_exceptions)                  
+      && flag_omit_frame_pointer                                        
+      && !(target_flags & MASK_ACCUMULATE_OUTGOING_ARGS))               
+    {                                                                   
+      if (target_flags_explicit & MASK_ACCUMULATE_OUTGOING_ARGS)        
+	warning (0, "unwind tables currently require either a frame pointer " 
+		 "or -maccumulate-outgoing-args for correctness");     
+      target_flags |= MASK_ACCUMULATE_OUTGOING_ARGS;                   
     }
 
+  if (TARGET_DBHWBUG)
+       align_functions = 32;
+
   /* Unwinding with -freorder-blocks-and-partition does not work on this
      architecture, because it requires far jumps to label crossing between
      hot/cold sections which are rejected on this architecture.  */
@@ -932,21 +954,7 @@
      SH2 .. SH5 : align to cache line start.  */
   if (align_functions == 0)
     align_functions
-      = TARGET_SMALLCODE ? FUNCTION_BOUNDARY/8 : (1 << CACHE_LOG);
-  /* The linker relaxation code breaks when a function contains
-     alignments that are larger than that at the start of a
-     compilation unit.  */
-  if (TARGET_RELAX)
-    {
-      int min_align
-	= align_loops > align_jumps ? align_loops : align_jumps;
-
-      /* Also take possible .long constants / mova tables int account.	*/
-      if (min_align < 4)
-	min_align = 4;
-      if (align_functions < min_align)
-	align_functions = min_align;
-    }
+      = optimize_size ? FUNCTION_BOUNDARY/8 : (1 << CACHE_LOG);
 
   if (sh_fixed_range_str)
     sh_fix_range (sh_fixed_range_str);
@@ -1008,6 +1016,12 @@
     }
 }
 
+static int deleted_delay_slot_p (rtx insn)
+{
+  return (GET_CODE (PATTERN (insn)) == UNSPEC_VOLATILE
+	  && XINT (PATTERN (insn), 1) == UNSPECV_DB_INSN);
+}
+
 /* Print operand x (an rtx) in assembler syntax to file stream
    according to modifier code.
 
@@ -1046,7 +1060,8 @@
     case '.':
       if (final_sequence
 	  && ! INSN_ANNULLED_BRANCH_P (XVECEXP (final_sequence, 0, 0))
-	  && get_attr_length (XVECEXP (final_sequence, 0, 1)))
+	  && (get_attr_length (XVECEXP (final_sequence, 0, 1))
+	      || deleted_delay_slot_p (XVECEXP (final_sequence, 0, 1))))
 	fprintf (stream, ASSEMBLER_DIALECT ? "/s" : ".s");
       break;
     case ',':
@@ -1426,6 +1441,91 @@
   if (! constp)
     return 0;
 
+  if ((TARGET_SH4 || TARGET_SH2A_DOUBLE)
+      && TARGET_FMOVD
+      && !optimize_size && align == 8 && bytes > 4)
+  {
+      rtx dest = copy_rtx (operands[0]);
+      rtx src = copy_rtx (operands[1]);
+      rtx temp = gen_reg_rtx (DFmode);
+      rtx temp1 = gen_reg_rtx (DFmode);
+      rtx temp2 = gen_reg_rtx (DFmode);
+      rtx src_addr = copy_addr_to_reg (XEXP (src, 0));
+      int copied = 0;
+
+      while (copied + 24 <= bytes)
+	{
+	  rtx to = adjust_address (dest, DFmode, copied);
+
+	  rtx from = adjust_automodify_address (src, DFmode, src_addr, copied);
+	  rtx from1 = adjust_automodify_address (src, DFmode, src_addr, copied + 8);
+	  rtx from2 = adjust_automodify_address (src, DFmode, src_addr, copied + 16);
+
+	  emit_move_insn (temp, from);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+
+	  emit_move_insn (temp1, from1);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+
+	  emit_move_insn (temp2, from2);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+
+	  emit_move_insn (to, temp);
+	  copied += 8;
+
+	  to = adjust_address (dest, DFmode, copied);
+	  emit_move_insn (to, temp1);
+	  copied += 8;
+
+	  to = adjust_address (dest, DFmode, copied);
+	  emit_move_insn (to, temp2);
+	  copied += 8;
+	}
+
+      while (copied + 16 <= bytes)
+	{
+	  rtx to = adjust_address (dest, DFmode, copied);
+
+	  rtx from = adjust_automodify_address (src, DFmode, src_addr, copied);
+	  rtx from1 = adjust_automodify_address (src, DFmode, src_addr, copied + 8);
+
+	  emit_move_insn (temp, from);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+
+	  emit_move_insn (temp1, from1);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+
+	  emit_move_insn (to, temp);
+	  copied += 8;
+
+	  to = adjust_address (dest, DFmode, copied);
+	  emit_move_insn (to, temp1);
+	  copied += 8;
+	}
+
+      while (copied + 8 <= bytes)
+	{
+	  rtx to = adjust_address (dest, DFmode, copied);
+	  rtx from = adjust_automodify_address (src, DFmode, src_addr, copied);
+
+	  emit_move_insn (temp, from);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+	  emit_move_insn (to, temp);
+	  copied += 8;
+	}
+
+      if (copied < bytes)
+	move_by_pieces (adjust_address (dest, BLKmode, copied),
+			adjust_automodify_address (src, BLKmode,
+						   src_addr, copied),
+			bytes - copied, align, 0);
+
+
+
+      return 1;
+  }
+
+
   /* If we could use mov.l to move words and dest is word-aligned, we
      can use movua.l for loads and still generate a relatively short
      and efficient sequence.  */
@@ -1485,7 +1585,7 @@
 	  emit_insn (gen_block_move_real_i4 (func_addr_rtx));
 	  return 1;
 	}
-      else if (! TARGET_SMALLCODE)
+      else if (! optimize_size)
 	{
 	  const char *entry_name;
 	  rtx func_addr_rtx = gen_reg_rtx (Pmode);
@@ -1524,7 +1624,7 @@
 
   /* This is the same number of bytes as a memcpy call, but to a different
      less common function name, so this will occasionally use more space.  */
-  if (! TARGET_SMALLCODE)
+  if (! optimize_size)
     {
       rtx func_addr_rtx = gen_reg_rtx (Pmode);
       int final_switch, while_loop;
@@ -2173,7 +2273,6 @@
 	    op1 = force_reg (mode, op1);
         }
     }
-
   if (GET_MODE_CLASS (mode) == MODE_FLOAT)
     {
       if (code == LT
@@ -2402,7 +2501,7 @@
       && offset - get_attr_length (insn) <= 32766)
     {
       far = 0;
-      jump = "mov.w	%O0,%1; braf	%1";
+      jump = "mov.w	%O0,%1\n\tbraf	%1";
     }
   else
     {
@@ -2410,12 +2509,12 @@
       if (flag_pic)
 	{
 	  if (TARGET_SH2)
-	    jump = "mov.l	%O0,%1; braf	%1";
+	    jump = "mov.l	%O0,%1\n\tbraf	%1";
 	  else
-	    jump = "mov.l	r0,@-r15; mova	%O0,r0; mov.l	@r0,%1; add	r0,%1; mov.l	@r15+,r0; jmp	@%1";
+	    jump = "mov.l	r0,@-r15\n\tmova	%O0,r0\n\t mov.l	@r0,%1\n\tadd	r0,%1\n\t mov.l	@r15+,r0\n\tjmp	@%1";
 	}
       else
-	jump = "mov.l	%O0,%1; jmp	@%1";
+	jump = "mov.l	%O0,%1\n\tjmp	@%1";
     }
   /* If we have a scratch register available, use it.  */
   if (NONJUMP_INSN_P ((prev = prev_nonnote_insn (insn)))
@@ -2423,7 +2522,7 @@
     {
       this_jmp.reg = SET_DEST (XVECEXP (PATTERN (prev), 0, 0));
       if (REGNO (this_jmp.reg) == R0_REG && flag_pic && ! TARGET_SH2)
-	jump = "mov.l	r1,@-r15; mova	%O0,r0; mov.l	@r0,r1; add	r1,r0; mov.l	@r15+,r1; jmp	@%1";
+	jump = "mov.l	r1,@-r15\n\t mova	%O0,r0\n\t mov.l	@r0,r1\n\t add	r1,r0\n\t mov.l	@r15+,r1\n\tjmp	@%1";
       output_asm_insn (jump, &this_jmp.lab);
       if (dbr_sequence_length ())
 	print_slot (final_sequence);
@@ -2507,8 +2606,12 @@
 	      && ! INSN_ANNULLED_BRANCH_P (XVECEXP (final_sequence, 0, 0))
 	      && get_attr_length (XVECEXP (final_sequence, 0, 1)))
 	    {
-	      asm_fprintf (asm_out_file, "\tb%s%ss\t%LLF%d\n", logic ? "f" : "t",
+	      asm_fprintf (asm_out_file, "\tb%s%ss\t%LLF%d", logic ? "f" : "t",
 	                   ASSEMBLER_DIALECT ? "/" : ".", label);
+
+	      asm_fprintf (asm_out_file, "\t%s %d\t[length = %d]\n",
+			   ASM_COMMENT_START, INSN_UID (insn),
+			   get_attr_length (insn));
 	      print_slot (final_sequence);
 	    }
 	  else
@@ -2612,6 +2715,12 @@
   return templ;
 }
 
+/* Output a code sequence for INSN using TEMPLATE with OPERANDS; but before,
+   fill in operands 9 as a label to the successor insn.
+   We try to use jump threading where possible.
+   IF CODE matches the comparison in the IF_THEN_ELSE of a following jump,
+   we assume the jump is taken.  I.e. EQ means follow jmp and bf, NE means
+   follow jmp and bt, if the address is in range.  */
 const char *
 output_ieee_ccmpeq (rtx insn, rtx *operands)
 {
@@ -2905,21 +3014,21 @@
        Using a multiply first and splitting it later if it's a loss
        doesn't work because of different sign / zero extension semantics
        of multiplies vs. shifts.  */
-    return TARGET_SMALLCODE ? 2 : 3;
+    return optimize_size ? 2 : 3;
 
   if (TARGET_SH2)
     {
       /* We have a mul insn, so we can never take more than the mul and the
 	 read of the mac reg, but count more because of the latency and extra
 	 reg usage.  */
-      if (TARGET_SMALLCODE)
+      if (optimize_size)
 	return 2;
       return 3;
     }
 
   /* If we're aiming at small code, then just count the number of
      insns in a multiply call sequence.  */
-  if (TARGET_SMALLCODE)
+  if (optimize_size)
     return 5;
 
   /* Otherwise count all the insns in the routine we'd be calling too.  */
@@ -2963,7 +3072,7 @@
 	       && CONST_OK_FOR_K08 (INTVAL (x)))
         *total = 1;
       /* prepare_cmp_insn will force costly constants int registers before
-	 the cbranch[sd]i4 patterns can see them, so preserve potentially
+	 the cbrach[sd]i4 pattterns can see them, so preserve potentially
 	 interesting ones not covered by I08 above.  */
       else if (outer_code == COMPARE
 	       && ((unsigned HOST_WIDE_INT) INTVAL (x)
@@ -4036,6 +4145,7 @@
   rtx scan = barrier;
   int i;
   int need_align = 1;
+  int need_align_d = 1;
   rtx lab;
   label_ref_list_t ref;
   int have_df = 0;
@@ -4068,6 +4178,7 @@
     }
 
   need_align = 1;
+  need_align_d = 1;
 
   if (start)
     {
@@ -4078,83 +4189,13 @@
 	    && recog_memoized (start) == CODE_FOR_casesi_worker_2)
 	  {
 	    rtx src = SET_SRC (XVECEXP (PATTERN (start), 0, 0));
-	    rtx lab = XEXP (XVECEXP (src, 0, 3), 0);
-
-	    scan = emit_label_after (lab, scan);
-	  }
-    }
-  if (TARGET_FMOVD && TARGET_ALIGN_DOUBLE && have_df)
-    {
-      rtx align_insn = NULL_RTX;
-
-      scan = emit_label_after (gen_label_rtx (), scan);
-      scan = emit_insn_after (gen_align_log (GEN_INT (3)), scan);
-      need_align = 0;
-
-      for (i = 0; i < pool_size; i++)
-	{
-	  pool_node *p = &pool_vector[i];
+	    rtx lab;
 
-	  switch (p->mode)
-	    {
-	    case HImode:
-	      break;
-	    case SImode:
-	    case SFmode:
-	      if (align_insn && !p->part_of_sequence_p)
-		{
-		  for (lab = p->label; lab; lab = LABEL_REFS (lab))
-		    emit_label_before (lab, align_insn);
-		  emit_insn_before (gen_consttable_4 (p->value, const0_rtx),
-				    align_insn);
-		  for (ref = p->wend; ref; ref = ref->next)
-		    {
-		      lab = ref->label;
-		      emit_insn_before (gen_consttable_window_end (lab),
-					align_insn);
-		    }
-		  delete_insn (align_insn);
-		  align_insn = NULL_RTX;
-		  continue;
-		}
-	      else
-		{
-		  for (lab = p->label; lab; lab = LABEL_REFS (lab))
-		    scan = emit_label_after (lab, scan);
-		  scan = emit_insn_after (gen_consttable_4 (p->value,
-							    const0_rtx), scan);
-		  need_align = ! need_align;
-		}
-	      break;
-	    case DFmode:
-	      if (need_align)
-		{
-		  scan = emit_insn_after (gen_align_log (GEN_INT (3)), scan);
-		  align_insn = scan;
-		  need_align = 0;
-		}
-	    case DImode:
-	      for (lab = p->label; lab; lab = LABEL_REFS (lab))
+	    gcc_assert (MEM_P (src));
+	    src = XEXP (src, 0);
+	    lab = XEXP (XVECEXP (src, 0, 3), 0);
 		scan = emit_label_after (lab, scan);
-	      scan = emit_insn_after (gen_consttable_8 (p->value, const0_rtx),
-				      scan);
-	      break;
-	    default:
-	      gcc_unreachable ();
-	    }
-
-	  if (p->mode != HImode)
-	    {
-	      for (ref = p->wend; ref; ref = ref->next)
-		{
-		  lab = ref->label;
-		  scan = emit_insn_after (gen_consttable_window_end (lab),
-					  scan);
-		}
-	    }
 	}
-
-      pool_size = 0;
     }
 
   for (i = 0; i < pool_size; i++)
@@ -4177,8 +4218,17 @@
 	    scan = emit_label_after (lab, scan);
 	  scan = emit_insn_after (gen_consttable_4 (p->value, const0_rtx),
 				  scan);
+
+	  need_align_d = 1;
 	  break;
+
 	case DFmode:
+	  if (TARGET_ALIGN_DOUBLE && need_align_d)
+	    {
+	      need_align = 0;
+	      need_align_d = 0;
+	      scan = emit_insn_after (gen_align_log (GEN_INT (3)), scan);
+	    }
 	case DImode:
 	  if (need_align)
 	    {
@@ -4313,6 +4363,10 @@
       wpat0 = XVECEXP (wpat, 0, 0);
       wpat1 = XVECEXP (wpat, 0, 1);
       wsrc = SET_SRC (wpat0);
+
+      gcc_assert (MEM_P (wsrc));
+      wsrc = XEXP (wsrc, 0);
+
       PATTERN (worker) = (gen_casesi_worker_2
 			  (SET_DEST (wpat0), XVECEXP (wsrc, 0, 1),
 			   XEXP (XVECEXP (wsrc, 0, 2), 0), lab,
@@ -4418,11 +4472,23 @@
   si_limit = 1018;
   hi_limit = 510;
 
+  if (TARGET_DBHWBUG)
+    {
+      hi_limit -= 2;
+      si_limit -= 2;
+    }
+
   while (from && count_si < si_limit && count_hi < hi_limit)
     {
       int inc = get_attr_length (from);
       int new_align = 1;
 
+      if (NOTE_P (from)) 
+	{
+	  from = NEXT_INSN (from);
+	  continue;
+	}
+
       /* If this is a label that existed at the time of the compute_alignments
 	 call, determine the alignment.  N.B.  When find_barrier recurses for
 	 an out-of-reach mova, we might see labels at the start of previously
@@ -4458,14 +4524,17 @@
       if (BARRIER_P (from))
 	{
 	  rtx next;
-
+	  int bar_align = barrier_align (from);
 	  found_barrier = from;
 
 	  /* If we are at the end of the function, or in front of an alignment
 	     instruction, we need not insert an extra alignment.  We prefer
 	     this kind of barrier.  */
-	  if (barrier_align (from) > 2)
+	  if (bar_align > 2)
+	    {
+	      new_align = 1 << bar_align;
 	    good_barrier = from;
+	    }
 
 	  /* If we are at the end of a hot/cold block, dump the constants
 	     here.  */
@@ -4590,9 +4659,27 @@
       /* For the SH1, we generate alignments even after jumps-around-jumps.  */
       else if (JUMP_P (from)
 	       && ! TARGET_SH2
-	       && ! TARGET_SMALLCODE)
+	       && ! optimize_size)
+	new_align = 4;
+
+      /* long jumps will change the alignment for the .long label.  */
+      else if (GET_CODE (from) == JUMP_INSN
+	       && GET_CODE (PATTERN (from)) == SET
+	       && recog_memoized (from) == CODE_FOR_jump_compact
+	       && inc == 10)
 	new_align = 4;
 
+      if (TARGET_DBHWBUG
+	  && ((GET_CODE (from) == INSN
+	       && GET_CODE (PATTERN (from)) != USE
+	       && GET_CODE (PATTERN (from)) != CLOBBER)
+	      || GET_CODE (from) == CALL_INSN
+	      || (GET_CODE (from) == JUMP_INSN
+		  && GET_CODE (PATTERN (from)) != ADDR_DIFF_VEC
+		  && GET_CODE (PATTERN (from)) != ADDR_VEC))
+	  && get_attr_needs_delay_slot (from) == NEEDS_DELAY_SLOT_YES)
+	inc += 2;
+
       /* There is a possibility that a bf is transformed into a bf/s by the
 	 delay slot scheduler.  */
       if (JUMP_P (from) && !JUMP_TABLE_DATA_P (from) 
@@ -4609,6 +4696,9 @@
 	      si_align = new_align;
 	    }
 	  count_si = (count_si + new_align - 1) & -new_align;
+
+	  if (new_align < si_align)
+	    si_align = new_align;	    
 	}
       if (found_hi)
 	{
@@ -4619,6 +4709,9 @@
 	      hi_align = new_align;
 	    }
 	  count_hi = (count_hi + new_align - 1) & -new_align;
+
+	  if (new_align < hi_align)
+	    hi_align = new_align;	    
 	}
       from = NEXT_INSN (from);
     }
@@ -4674,13 +4767,6 @@
       if (last_got)
         from = PREV_INSN (last_got);
 
-      /* Don't insert the constant pool table at the position which
-	 may be the landing pad.  */
-      if (flag_exceptions
-	  && CALL_P (from)
-	  && find_reg_note (from, REG_EH_REGION, NULL_RTX))
-	from = PREV_INSN (from);
-
       /* Walk back to be just before any jump or label.
 	 Putting it before a label reduces the number of times the branch
 	 around the constant pool table will be hit.  Putting it before
@@ -5162,6 +5248,29 @@
     }
 }
 
+int
+sh_jump_align (rtx label)
+{
+  rtx insn;
+  int size = 0;
+
+  gcc_assert (label && GET_CODE (label) == CODE_LABEL);
+
+  for (insn = NEXT_INSN (label);
+       insn && GET_CODE (insn) != BARRIER &&
+	 GET_CODE (insn) != CODE_LABEL;
+       insn = NEXT_INSN (insn))
+    {
+      if (INSN_P (insn))
+	size += get_attr_min_length (insn);
+
+      if (size > sh_align_small_blocks)
+	return align_jumps_log;
+    }
+
+  return 0;
+}
+
 /* BARRIER_OR_LABEL is either a BARRIER or a CODE_LABEL immediately following
    a barrier.  Return the base 2 logarithm of the desired alignment.  */
 int
@@ -5188,13 +5297,13 @@
       pat = PATTERN (prev);
       /* If this is a very small table, we want to keep the alignment after
 	 the table to the minimum for proper code alignment.  */
-      return ((TARGET_SMALLCODE
+      return ((optimize_size
 	       || ((unsigned) XVECLEN (pat, 1) * GET_MODE_SIZE (GET_MODE (pat))
 		   <= (unsigned) 1 << (CACHE_LOG - 2)))
 	      ? 1 << TARGET_SHMEDIA : align_jumps_log);
     }
 
-  if (TARGET_SMALLCODE)
+  if (optimize_size)
     return 0;
 
   if (! TARGET_SH2 || ! optimize)
@@ -5275,7 +5384,21 @@
 	}
     }
 
-  return align_jumps_log;
+  while (BARRIER_P (barrier_or_label))
+    barrier_or_label = next_nonnote_insn (barrier_or_label);
+
+  return sh_jump_align (barrier_or_label);
+}
+
+static bool
+in_between(rtx start, rtx end, rtx r)
+{
+  rtx scan;
+  for (scan = NEXT_INSN (start); scan && scan != end; scan = NEXT_INSN (scan))
+    if (scan == r)
+      return 1;
+
+  return 0;
 }
 
 /* If we are inside a phony loop, almost any kind of label can turn up as the
@@ -5302,6 +5425,50 @@
   return align_loops_log;
 }
 
+static int fixup_addr;
+
+/* Check if a register function load is not alive in an exception handler
+   and can be safely removed when relaxing.  */
+
+typedef struct 
+{
+  bool ret;
+  rtx reg;
+} rdata;
+
+static void
+handler_uses_reg (eh_region region, void *arg)
+{
+  rdata *rarg = (rdata*)arg;
+  eh_landing_pad lp;
+
+  if (rarg->ret)
+    return;
+
+  for (lp = region->landing_pads; lp ; lp = lp->next_lp)
+    {
+      rtx scan = lp->landing_pad;
+      
+      if (scan && LABEL_P (scan))
+	for (; scan; scan = NEXT_INSN (scan))  
+	  {
+	    if (! reg_mentioned_p (rarg->reg, scan))
+	      continue;
+	      
+	    if (reg_set_p (rarg->reg, scan))
+	      {
+		rarg->ret = false;
+		return;
+	      }
+	    if (reg_referenced_p (rarg->reg, PATTERN (scan)))
+	      {
+		rarg->ret = true;
+		return;
+	      }
+	  }
+    }
+}
+
 /* Do a final pass over the function, just before delayed branch
    scheduling.  */
 
@@ -5352,10 +5519,17 @@
 	    }
 	}
 
+      if (df && optimize)
+	{
+	  df_note_add_problem ();
+	  df_analyze ();
+	}
+
       for (insn = first; insn; insn = NEXT_INSN (insn))
 	{
 	  rtx pattern, reg, link, set, scan, dies, label;
-	  int rescan = 0, foundinsn = 0;
+	  bool rescan = false, foundinsn = false;
+	  rdata region_arg;
 
 	  if (CALL_P (insn))
 	    {
@@ -5437,7 +5611,7 @@
 		 the call, and can result in situations where a single call
 		 insn may have two targets depending on where we came from.  */
 
-	      if (LABEL_P (scan) && ! foundinsn)
+	      if (LABEL_P (scan) && (LABEL_NUSES (scan) > 0))
 		break;
 
 	      if (! INSN_P (scan))
@@ -5448,7 +5622,13 @@
                  instructions at the jump destination did not use REG.  */
 
 	      if (JUMP_P (scan))
+		{
+		  rtx next = next_active_insn (JUMP_LABEL (scan));
+
+		  if (next && in_between (link, scan, next))
+		    continue;
 		break;
+		}
 
 	      if (! reg_mentioned_p (reg, scan))
 		continue;
@@ -5465,7 +5645,7 @@
 		  /* There is a function call to this register other
                      than the one we are checking.  If we optimize
                      this call, we need to rescan again below.  */
-		  rescan = 1;
+		  rescan = true;
 		}
 
 	      /* ??? We shouldn't have to worry about SCANSET here.
@@ -5498,6 +5678,15 @@
 	      continue;
 	    }
 
+	  /* If the register is in use in one of the exception handler,
+	     can't relax it.  */
+
+	  region_arg.reg = reg;
+	  region_arg.ret = false;
+	  for_each_eh_region (handler_uses_reg, (void *)&region_arg);
+	  if (region_arg.ret)
+	    continue;
+
 	  /* Create a code label, and put it in a REG_LABEL_OPERAND note
              on the insn which sets the register, and on each call insn
              which uses the register.  In final_prescan_insn we look for
@@ -5507,6 +5696,7 @@
 	  label = gen_label_rtx ();
 	  add_reg_note (link, REG_LABEL_OPERAND, label);
 	  add_reg_note (insn, REG_LABEL_OPERAND, label);
+
 	  if (rescan)
 	    {
 	      scan = link;
@@ -5728,7 +5918,7 @@
     PUT_MODE (insn, VOIDmode);
 
   mdep_reorg_phase = SH_SHORTEN_BRANCHES1;
-  INSN_ADDRESSES_FREE ();
+  init_insn_lengths ();
   split_branches (first);
 
   /* The INSN_REFERENCES_ARE_DELAYED in sh.h is problematic because it
@@ -5755,6 +5945,8 @@
     REG_USERVAR_P (get_fpscr_rtx ()) = 0;
 #endif
   mdep_reorg_phase = SH_AFTER_MDEP_REORG;
+
+   fixup_addr = 0;
 }
 
 int
@@ -6011,10 +6203,15 @@
    variable length.  This is because the second pass of shorten_branches
    does not bother to update them.  */
 
+static void sh_hw_workaround (rtx insn);
+
 void
 final_prescan_insn (rtx insn, rtx *opvec ATTRIBUTE_UNUSED,
 		    int noperands ATTRIBUTE_UNUSED)
 {
+  if (TARGET_DBHWBUG)
+    sh_hw_workaround (insn);
+
   if (TARGET_DUMPISIZE)
     fprintf (asm_out_file, "\n! at %04x\n", INSN_ADDRESSES (INSN_UID (insn)));
 
@@ -6123,6 +6320,7 @@
 
       if (CONST_OK_FOR_ADD (size))
 	emit_fn (GEN_ADD3 (reg, reg, GEN_INT (size)));
+
       /* Try to do it with two partial adjustments; however, we must make
 	 sure that the stack is properly aligned at all times, in case
 	 an interrupt occurs between the two partial adjustments.  */
@@ -6335,14 +6533,24 @@
 static void
 push_regs (HARD_REG_SET *mask, int interrupt_handler)
 {
-  int i = interrupt_handler ? LAST_BANKED_REG + 1 : 0;
+  int i;
   int skip_fpscr = 0;
 
+  /* Push double first. Keep the strictness alignment in case of -mdalign.  */
+  for (i = FIRST_FP_REG; i <= LAST_FP_REG; i++)
+    if (TEST_HARD_REG_BIT (*mask, i))
+      push (i);
+
+  i = interrupt_handler ? LAST_BANKED_REG + 1 : 0;
+
   /* Push PR last; this gives better latencies after the prologue, and
      candidates for the return delay slot when there are no general
      registers pushed.  */
   for (; i < FIRST_PSEUDO_REGISTER; i++)
     {
+      if (FP_REGISTER_P(i))
+	continue;
+
       /* If this is an interrupt handler, and the SZ bit varies,
 	 and we have to push any floating point register, we need
 	 to switch to the correct precision first.  */
@@ -6599,6 +6807,9 @@
   HOST_WIDE_INT size = get_frame_size ();
   HOST_WIDE_INT align = STACK_BOUNDARY / BITS_PER_UNIT;
 
+  if (ACCUMULATE_OUTGOING_ARGS)
+    size += crtl->outgoing_args_size;
+
   return ((size + pushed + align - 1) & -align) - pushed;
 }
 
@@ -6763,6 +6974,9 @@
   tree sp_switch_attr
     = lookup_attribute ("sp_switch", DECL_ATTRIBUTES (current_function_decl));
 
+  if (sh_cfun_naked_p ())
+    return;
+
   current_function_interrupt = sh_cfun_interrupt_handler_p ();
 
   /* We have pretend args if we had an object sent partially in registers
@@ -7109,6 +7323,9 @@
   int fpscr_deferred = 0;
   int e = sibcall_p ? -1 : 1;
 
+  if (sh_cfun_naked_p ())
+    return;
+
   d = calc_live_regs (&live_regs_mask);
 
   save_size = d;
@@ -7301,11 +7518,7 @@
 	   register.  */
       if (TEST_HARD_REG_BIT (live_regs_mask, PR_REG)
 	  && !sh_cfun_resbank_handler_p ())	
-	{
-	  if (!frame_pointer_needed)
-	    emit_insn (gen_blockage ());
 	  pop (PR_REG);
-	}
 
       /* Banked registers are popped first to avoid being scheduled in the
 	 delay slot. RTE switches banks before the ds instruction.  */
@@ -7324,6 +7537,9 @@
 	{
 	  int j = (FIRST_PSEUDO_REGISTER - 1) - i;
 
+	  if (FP_REGISTER_P(j))
+	    continue;
+
 	  if (j == FPSCR_REG && current_function_interrupt && TARGET_FMOVD
 	      && hard_reg_set_intersect_p (live_regs_mask,
 					  reg_class_contents[DF_REGS]))
@@ -7343,6 +7559,12 @@
 	    pop (FPSCR_REG);
 	}
     }
+
+  /* Pop double last. */
+  for (i = LAST_FP_REG; i >= FIRST_FP_REG; i--)
+    if (TEST_HARD_REG_BIT (live_regs_mask, i))
+      pop (i);
+
   if (target_flags != save_flags && ! current_function_interrupt)
     emit_insn (gen_toggle_sz ());
   target_flags = save_flags;
@@ -7447,7 +7669,7 @@
     pr_offset = rounded_frame_size (d);
 
   emit_insn (GEN_MOV (tmp, GEN_INT (pr_offset)));
-  emit_insn (GEN_ADD3 (tmp, tmp, hard_frame_pointer_rtx));
+  emit_insn (GEN_ADD3 (tmp, tmp, stack_pointer_rtx));
 
   tmp = gen_frame_mem (Pmode, tmp);
   emit_insn (GEN_MOV (tmp, ra));
@@ -7984,7 +8206,7 @@
 {
   unsigned regno = REGNO (reg);
 
-  if (WORDS_BIG_ENDIAN || GET_MODE (reg) != DFmode)
+  if (WORDS_BIG_ENDIAN || GET_MODE (reg) != DFmode || TARGET_FMOVD)
     return NULL_RTX;
 
   return
@@ -8738,6 +8960,22 @@
   return NULL_TREE;
 }
 
+/* Handle an attribute requiring a FUNCTION_DECL;
+   arguments as in struct attribute_spec.handler.  */
+static tree
+sh_handle_fndecl_attribute (tree *node, tree name, tree args ATTRIBUTE_UNUSED,
+			     int flags ATTRIBUTE_UNUSED, bool *no_add_attrs)
+{
+  if (TREE_CODE (*node) != FUNCTION_DECL)
+    {
+      warning (OPT_Wattributes, "%qs attribute only applies to functions",
+	       IDENTIFIER_POINTER (name));
+      *no_add_attrs = true;
+    }
+
+  return NULL_TREE;
+}
+
 /* Handle an "interrupt_handler" attribute; arguments as in
    struct attribute_spec.handler.  */
 static tree
@@ -8974,6 +9212,15 @@
               != NULL_TREE) && TARGET_SH2A);
 }
 
+/* Return nonzero if the current function has attribute naked .  */
+static int
+sh_cfun_naked_p (void)
+{
+  return (lookup_attribute ("naked",
+			    DECL_ATTRIBUTES (current_function_decl))
+	  != NULL_TREE);
+}
+
 /* Implement TARGET_CHECK_PCH_TARGET_FLAGS.  */
 
 static const char *
@@ -9065,6 +9312,65 @@
   return SYMBOL_REF_TLS_MODEL (op);
 }
 
+/* Expand an sfunc operation taking NARGS MODE arguments, using generator
+   function FUN, which needs symbol NAME loaded int a register first.
+   Add a REG_EQUAL note using EQUIV.  */
+static void
+expand_sfunc_op (int nargs, enum machine_mode mode, rtx (*fun) (rtx, rtx),
+		 const char *name, rtx equiv, rtx *operands)
+{
+  int i;
+  rtx addr, first = NULL_RTX, last, insn;
+  /* For now keep all variants ABI compatibilities.
+     Check for TARGET_OSFP: ARG_TO_R4 (see ieee-754-df.S) and _SH_FPU_ANY_.  */
+  int next_reg = FIRST_PARM_REG;
+
+  addr = gen_reg_rtx (Pmode);
+  function_symbol (addr, name, SFUNC_FREQUENT);
+
+  for (i = 1; i <= nargs; i++)
+    {
+      insn = emit_move_insn (gen_rtx_REG (mode, next_reg), operands[i]);
+      if (!first)
+	first = insn;
+      next_reg += GET_MODE_SIZE (mode) / UNITS_PER_WORD;
+    }
+  last = emit_insn ((*fun) (operands[0], addr));
+  REG_NOTES (last) = gen_rtx_EXPR_LIST (REG_EQUAL, equiv, REG_NOTES (last));
+
+  /* If flag_non_call_exceptions is in effect, it will stipulate BB boundaries
+     where we don't want them; we must not have a LIBCALL block spanning
+     multiple basic blocks.  */
+  if (flag_non_call_exceptions)
+    {
+      for (insn = first; insn != last; insn = NEXT_INSN (insn))
+	if (may_trap_p (insn))
+	  return;
+    }
+}
+
+/* Expand an sfunc unary operation taking an MODE argument, using generator
+   function FUN, which needs symbol NAME loaded int a register first.
+   Add a REG_EQUAL note using CODE.  */
+void
+expand_sfunc_unop (enum machine_mode mode, rtx (*fun) (rtx, rtx),
+		   const char *name, enum rtx_code code, rtx *operands)
+{
+  rtx equiv = gen_rtx_fmt_e (code, GET_MODE (operands[0]), operands[1]);
+  expand_sfunc_op (1, mode, fun, name, equiv, operands);
+}
+
+/* Expand an sfunc binary operation in MODE, using generator function FUN,
+   which needs symbol NAME loaded int a register first.
+   Add a REG_EQUAL note using CODE.  */
+void
+expand_sfunc_binop (enum machine_mode mode, rtx (*fun) (rtx, rtx),
+		    const char *name, enum rtx_code code, rtx *operands)
+{
+  rtx equiv = gen_rtx_fmt_ee (code, mode, operands[1], operands[2]);
+  expand_sfunc_op (2, mode, fun, name, equiv, operands);
+}
+
 /* Return the destination address of a branch.  */
 
 static int
@@ -9297,6 +9603,15 @@
   return gen_rtx_REG (Pmode, 7);
 }
 
+/* This function switches the fpscr.  */
+void
+emit_fpu_flip (void)
+{
+  emit_insn (gen_toggle_pr ());
+  if (TARGET_FMOVD)
+    emit_insn (gen_toggle_sz ());    
+}
+
 /* This function will set the fpscr from memory.
    MODE is the mode we are setting it to.  */
 void
@@ -9315,9 +9630,291 @@
 #define IS_ASM_LOGICAL_LINE_SEPARATOR(C, STR) ((C) == ';')
 #endif
 
+static int
+sh_forward_branch_p(rtx first, int n)
+{
+  int new_align;
+  rtx insn;
+  rtx lab = JUMP_LABEL (first);
+  int njumps = 0;
+
+  for (insn = NEXT_INSN (first); insn; insn = NEXT_INSN (insn))
+    {
+      if (((GET_CODE (insn) == CALL_INSN
+	    || (GET_CODE (insn) == JUMP_INSN
+		&& GET_CODE (PATTERN (insn)) != ADDR_DIFF_VEC
+		&& GET_CODE (PATTERN (insn)) != ADDR_VEC))
+	   && num_delay_slots (insn))
+	  || (GET_CODE (insn) == INSN && GET_CODE (PATTERN (insn)) == SEQUENCE))
+	njumps += get_attr_length (insn) + 2;
+
+      else if (GET_CODE (insn) == INSN
+	       && GET_CODE (PATTERN (insn)) == UNSPEC_VOLATILE
+	       && XINT (PATTERN (insn), 1) == UNSPECV_ALIGN)
+	{
+	  new_align = 1 << INTVAL (XVECEXP (PATTERN (insn), 0, 0));
+	  njumps += new_align;
+	}
+
+      else if (GET_CODE (insn) == CODE_LABEL)
+	{
+	  new_align = label_to_alignment (insn);
+	  if (new_align)
+	    new_align = 1 << new_align;
+	  njumps += new_align;
+	}
+
+      else
+	njumps += get_attr_length (insn);
+
+      if (insn == lab)
+	  return njumps > (n * 2);
+    }
+
+  njumps = 0;
+
+  for (insn = PREV_INSN (first); insn; insn = PREV_INSN (insn))
+    {
+      if (((GET_CODE (insn) == CALL_INSN
+	    || ((GET_CODE (insn) == JUMP_INSN)
+		&& GET_CODE (PATTERN (insn)) != ADDR_DIFF_VEC
+		&& GET_CODE (PATTERN (insn)) != ADDR_VEC))
+	   && num_delay_slots (insn))
+	  || (GET_CODE (insn) == INSN && GET_CODE (PATTERN (insn)) == SEQUENCE))
+	njumps += get_attr_length (insn) + 2;
+
+      else if (GET_CODE (insn) == INSN
+	       && GET_CODE (PATTERN (insn)) == UNSPEC_VOLATILE
+	       && XINT (PATTERN (insn), 1) == UNSPECV_ALIGN)
+	{
+	  new_align = 1 << INTVAL (XVECEXP (PATTERN (insn), 0, 0));
+	  njumps += new_align;
+	}
+
+      else if (GET_CODE (insn) == CODE_LABEL)
+	{
+	  new_align = label_to_alignment (insn);
+	  if (new_align)
+	    new_align = 1 << new_align;
+	  njumps += new_align;
+	}
+
+      else
+	njumps += get_attr_length (insn);
+
+      if (insn == lab)
+	return njumps > (n * 2);
+    }
+
+  return 0;
+}
+
+int
+sh_insn_length_alignment (rtx insn)
+{
+  int align = 1;
+
+  if (INSN_P (insn))
+    {
+      rtx body = PATTERN (insn);
+
+      if (GET_CODE (body) == ASM_INPUT || asm_noperands (body) >= 0)
+	{
+	  const char *templ;
+
+	  if (GET_CODE (body) == ASM_INPUT)
+	    templ = XSTR (body, 0);
+	  else
+	    templ = decode_asm_operands (body, NULL, NULL, NULL, NULL, NULL);
+
+	  (void) sh_asm_count (templ, &align);
+	  return align;
+	}
+
+      return 1 << TARGET_SHMEDIA;
+    }
+
+#if 0
+  (NONJUMP_INSN_P (A_INSN)						\
+   ? 1 << TARGET_SHMEDIA						\
+   : JUMP_P (A_INSN) || CALL_P (A_INSN)					\
+   ? 1 << TARGET_SHMEDIA						\
+   : CACHE_LOG)
+#endif
+
+  align = GET_CODE (insn) == JUMP_INSN
+    && GET_CODE (PATTERN (insn)) == ADDR_DIFF_VEC                   
+    && GET_MODE (PATTERN (insn)) == HImode                   
+    ? 0
+    : GET_CODE (insn) == BARRIER
+    ? 0                         
+    : GET_CODE (insn) == JUMP_INSN || GET_CODE (insn) == CALL_INSN
+    ? 1 << TARGET_SHMEDIA
+    : 1;
+
+  return align;
+}
+
+bool
+sh_varying_insn_p (rtx insn) 
+{
+  return (mdep_reorg_phase == SH_AFTER_MDEP_REORG
+	  && GET_CODE (insn) == INSN
+	  && recog_memoized (insn) == CODE_FOR_casesi_worker_1);
+}
+
 int
-sh_insn_length_adjustment (rtx insn)
+sh_insn_length_adjustment (rtx insn, const int cur_length)
 {
+  int addlen = 0;
+
+  if (sh_varying_insn_p (insn))
+    {
+      if (recog_memoized (insn) == CODE_FOR_casesi_worker_1) 
+	{
+	  rtx src = SET_SRC (XVECEXP (PATTERN (insn), 0, 0));
+	  rtx lab, diff_vec;
+	  int u;
+
+	  if (MEM_P (src))
+	    src = XEXP (src, 0);
+
+	  lab = XEXP (XVECEXP (src, 0, 2), 0);
+	  diff_vec = PATTERN (next_real_insn (lab));
+      
+	  u = ADDR_DIFF_VEC_FLAGS (diff_vec).offset_unsigned;
+
+	  if (GET_MODE (diff_vec) == QImode)
+	    {
+	      if (!u && cur_length == 4)
+		return -2;
+	      else if (u && cur_length == 2)
+		return 2;
+	    }
+	}
+
+      return 0;
+    }
+
+  /* optimize DC introduced by reorg.  */
+  if (TARGET_DEAD_DELAY && mdep_reorg_phase == SH_AFTER_MDEP_REORG)
+    {
+      if (deleted_delay_slot_p (insn))
+	return 0;
+
+      if (NONJUMP_INSN_P (insn) && GET_CODE (PATTERN (insn)) == SEQUENCE
+	  && cur_length == 4 && INSN_ADDRESSES_SET_P ())
+	{
+	  rtx body = PATTERN (insn);
+	  rtx delay_insn = XVECEXP (body, 0, 1);
+	  rtx dpat = PATTERN (delay_insn);
+	  rtx nexti = next_real_insn (delay_insn);
+	  rtx label = NEXT_INSN (delay_insn);
+	  int log = 0;
+
+	  if (label && BARRIER_P (label))
+	    {
+	      for (; label && ! INSN_P (label);
+		   label = NEXT_INSN (label))
+		if (LABEL_P (label))
+		  {
+		    log = label_to_alignment (label);
+		    if (log) break;
+		  }
+	    }
+
+	  if (nexti && GET_CODE (dpat) == SET)
+	    {
+	      rtx jump_insn = XVECEXP (body, 0, 0);
+	      enum attr_type jump_type = get_attr_type (jump_insn);
+
+	      if ((jump_type != TYPE_SFUNC && jump_type != TYPE_CALL)
+		  && GET_CODE (jump_insn) == JUMP_INSN
+		  && rtx_equal_p (PATTERN (nexti), dpat)
+		  && ! reg_overlap_mentioned_p (SET_DEST (dpat), dpat))
+		{
+		  rtx lab = JUMP_LABEL (jump_insn);
+		  rtx prev = prev_real_insn (lab);
+
+		  /* bug 50754 optimize 2 instructions :
+		     br .l
+		     mov r1,r3
+		     .l: mov r1,r3  */
+		  if (nexti == prev)
+		    {
+		      delete_insn (insn);
+		      return -4;
+		    }
+		  /* bug 58105: optimize 1 instruction :
+		     bf/s .l
+		     mov r1,r3
+		     mov r1,r3  */
+		  else if (!log)
+		    {
+		      rtx old_delay = delay_insn;
+		      delay_insn = make_insn_raw (gen_dup_db_insn ());
+
+		      NEXT_INSN (delay_insn) = NEXT_INSN (old_delay);
+		      PREV_INSN (delay_insn) = jump_insn;
+		      NEXT_INSN (jump_insn) = delay_insn;
+		      XVECEXP (body, 0, 1) = delay_insn;		
+
+		      INSN_ADDRESSES_NEW (delay_insn, -1);
+		      return -2;
+		    }
+		}
+	    }
+	}
+    }
+
+  if (TARGET_DBHWBUG
+      && mdep_reorg_phase == SH_AFTER_MDEP_REORG && INSN_ADDRESSES_SET_P ())
+    {
+      if (recog_memoized (insn) == CODE_FOR_tls_global_dynamic
+	  || recog_memoized (insn) == CODE_FOR_tls_local_dynamic
+	  || recog_memoized (insn) == CODE_FOR_tls_initial_exec)
+	return -2;
+
+      if (recog_memoized (insn) == CODE_FOR_jump_compact)
+	{
+	  if (cur_length == 2)
+	    {
+	      int long_b = sh_forward_branch_p (insn, 0x7ff);
+
+	      if (long_b)
+		{
+		  rtx prev;
+		  int xlen = 0;
+		
+		  /* will need a scratch register.  */
+		  if (GET_CODE ((prev = prev_nonnote_insn (insn))) != INSN
+		      || INSN_CODE (prev) != CODE_FOR_indirect_jump_scratch)
+		    xlen = 4;
+
+		  if (!xlen)
+		    {
+		      /* a nop will be inserted. count it.  */
+		      /* mov r0 lab; braf r0; nop.  */
+		      if (GET_CODE (PATTERN (NEXT_INSN (PREV_INSN (insn))))
+			  != SEQUENCE)
+			xlen += 2;
+		    }
+		  addlen = 4 + xlen;
+		  return addlen;
+		}
+	    }
+	}
+
+      if ((recog_memoized (insn) == CODE_FOR_branch_true
+	   || recog_memoized (insn) == CODE_FOR_branch_false)
+	  && cur_length == 2)
+	{
+	  int long_b = sh_forward_branch_p (insn, 0x7f);
+	  if (long_b)
+	    return 4;
+	}
+    }
+
   /* Instructions with unfilled delay slots take up an extra two bytes for
      the nop in the delay slot.  */
   if (((NONJUMP_INSN_P (insn)
@@ -9327,7 +9924,118 @@
        || (JUMP_P (insn) && !JUMP_TABLE_DATA_P (insn)))
       && GET_CODE (PATTERN (NEXT_INSN (PREV_INSN (insn)))) != SEQUENCE
       && get_attr_needs_delay_slot (insn) == NEEDS_DELAY_SLOT_YES)
+    {
+      int xnop = 0;
+      if (TARGET_DBHWBUG
+	  && mdep_reorg_phase < SH_AFTER_MDEP_REORG && INSN_ADDRESSES_SET_P ())
+	xnop = 2;
+
+      /*
+	(2) mov.l	.L,r4		[length = 10]
+	(2) jmp	@r4
+	(2) nop
+	(4) .L: .long	.L5
+      */
+      if (cur_length == 10)
+	{
+	  /* Ideally that should be in final.c but we don't have computed the
+	     insns lengths at that time.
+	     Make sure here that .align padding is taken into account when 
+	     computing distances.  */
+	  int uid_address = INSN_ADDRESSES (INSN_UID (insn));
+	  int long_address = uid_address + 6;
+	  int aligned_long_address = (long_address + 3) & -4;
+
+	  int offset = branch_dest (insn) - INSN_ADDRESSES (INSN_UID (insn));
+	  int far;
+
+	  far = ! (offset >= -32764 && offset - get_attr_length (insn) <= 32766);
+
+	  return far ? aligned_long_address - long_address : 0;
+	}
+	
+      if (cur_length == 14)
+	{
+	  int uid_address = INSN_ADDRESSES (INSN_UID (insn));
+	  int offset = branch_dest (insn) - INSN_ADDRESSES (INSN_UID (insn));
+
+	  /*
+	    mov.l	r13,@-r15	[length = 12]
+	    mov.l	.L,r13
+	    jmp	@r13
+	    mov.l	@r15+,r13
+	    .L:	.long	.L5
+	  */
+	  if (! (offset >= -32764 && offset - get_attr_length (insn) <= 32766))
+	    {
+	      int long_address = uid_address + 8;
+	      int aligned_long_address = (long_address + 3) & -4;
+	      int adj;
+
+	      adj = aligned_long_address - long_address;
+
+	      return -2 + adj + xnop;
+	      
+	    }
+	    
+	  /*
+	    mov.l	r13,@-r15	[length = 10]
+	    mov.w	.L4460,r13
+	    braf	r13
+	    mov.l	@r15+,r13
+	    .word .L24-.L4460
+	  */
+	  return -4 + xnop;
+	}
+
+      return 2 + xnop;
+    }
+
+  /* Filled delay slot. */
+  if (TARGET_DBHWBUG  && INSN_ADDRESSES_SET_P ())
+    {
+      if (mdep_reorg_phase == SH_AFTER_MDEP_REORG)
+	{
+	  if (recog_memoized (insn) == CODE_FOR_jump_compact)
+	    {
+	      rtx prev;
+	
+	      if (cur_length == 10)
+		{
+		  /*
+		    (0) delay slot	        [length = 2]
+		    (2) mov.l	r13,@-r15	[length = 10]
+		    (2) mov.w	.L,r13
+		    (2) braf	r13
+		    (2) mov.l	@r15+,r13
+		    (2) .L: .word
+		  */
+		  if (GET_CODE ((prev = prev_nonnote_insn (insn))) != INSN
+		      || INSN_CODE (prev) != CODE_FOR_indirect_jump_scratch)
+		    return 0;
+	
+		  /*
+		    (2) mov.l	.L,r4	 [length = 10]
+		    (2) jmp	@r4
+		    (0) delay slot       [length = 2]
+		    (4) .L: .long	
+		  */
+		  return -2;
+		}
+	    }
+	  return 0;
+	}
+      else if (mdep_reorg_phase < SH_AFTER_MDEP_REORG)
+	if (((GET_CODE (insn) == INSN
+	      && GET_CODE (PATTERN (insn)) != USE
+	      && GET_CODE (PATTERN (insn)) != CLOBBER)
+	     || GET_CODE (insn) == CALL_INSN
+	     || (GET_CODE (insn) == JUMP_INSN
+		 && GET_CODE (PATTERN (insn)) != ADDR_DIFF_VEC
+		 && GET_CODE (PATTERN (insn)) != ADDR_VEC))
+	    && get_attr_needs_delay_slot (insn) == NEEDS_DELAY_SLOT_YES)
     return 2;
+    }
 
   /* SH2e has a bug that prevents the use of annulled branches, so if
      the delay slot is not filled, we'll have to put a NOP in it.  */
@@ -9390,6 +10098,7 @@
       while (c);
       return sum;
     }
+
   return 0;
 }
 
@@ -9707,6 +10416,7 @@
   return lab;
 }
 
+
 /* Return true if it's possible to redirect BRANCH1 to the destination
    of an unconditional jump BRANCH2.  We only want to do this if the
    resulting branch will have a short displacement.  */
@@ -9719,7 +10429,7 @@
       rtx insn;
       int distance;
 
-      for (distance = 0, insn = NEXT_INSN (branch1);
+      for (distance = 0, insn = PREV_INSN (branch1);
 	   insn && distance < 256;
 	   insn = PREV_INSN (insn))
 	{
@@ -9738,6 +10448,7 @@
 	    distance += get_attr_length (insn);
 	}
     }
+
   return 0;
 }
 
@@ -10408,9 +11119,6 @@
 sh_optimize_target_register_callee_saved (bool after_prologue_epilogue_gen)
 {
   HARD_REG_SET dummy;
-#if 0
-  rtx insn;
-#endif
 
   if (! shmedia_space_reserved_for_target_registers)
     return 0;
@@ -11000,6 +11708,61 @@
 }
 
 void
+sh_expand_lround (rtx op0, rtx op1, bool to_nearest)
+{
+  rtx tmp3;
+  rtx tmp2 = gen_reg_rtx (SImode);
+  rtx tmp1 = gen_reg_rtx (SImode);
+  rtx ftmp1 = gen_reg_rtx (SFmode);
+  rtx ftmp0 = gen_reg_rtx (SFmode);
+  rtx fpul = gen_rtx_REG (SImode, FPUL_REG);
+
+  emit_insn (gen_movsi_i (tmp2, GEN_INT (1 << 31)));
+
+  emit_move_insn (ftmp0, op1);
+
+  emit_move_insn (fpul, gen_lowpart (SImode, ftmp0));
+  emit_move_insn (tmp1, fpul);
+  emit_insn (gen_andsi3 (tmp2, tmp2, tmp1));
+
+  tmp3 = gen_lowpart (SImode, 
+		      force_reg (SFmode,
+				 CONST_DOUBLE_ATOF ("0.5", SFmode)));
+
+  emit_insn (gen_iorsi3 (tmp3, tmp3, tmp2));
+
+  emit_insn (gen_addsf3 (ftmp0, ftmp0, gen_lowpart (SFmode, tmp3)));
+
+  emit_sf_insn (gen_fix_truncsfsi2_i4 (fpul, ftmp0, get_fpscr_rtx ()));
+
+  emit_move_insn (op0, fpul);
+
+  if (to_nearest)
+    {
+      rtx lab = gen_label_rtx ();
+
+      emit_sf_insn (gen_floatsisf2_i4 (ftmp1, fpul, get_fpscr_rtx ()));
+
+      emit_sf_insn (gen_cmpeqsf_t_i4 (ftmp1, ftmp0, get_fpscr_rtx ()));
+
+      emit_jump_insn (gen_branch_false (lab));
+
+      emit_move_insn (tmp3, const1_rtx);
+      emit_insn (gen_andsi3 (tmp3, tmp3, op0));
+      emit_insn (gen_cmpeqsi_t (tmp3, const0_rtx));
+      emit_jump_insn (gen_branch_true (lab));
+
+      emit_insn (gen_cmpeqsi_t (tmp2, const0_rtx));
+      emit_insn (gen_movt (tmp2));
+      emit_insn (gen_ashlsi_c (tmp2, tmp2));
+      emit_insn (gen_addsi3 (tmp2, tmp2, GEN_INT (-1)));
+      emit_insn (gen_subsi3 (op0, op0, tmp2));
+
+      emit_label (lab);
+    }
+}
+
+void
 sh_expand_binop_v2sf (enum rtx_code code, rtx op0, rtx op1, rtx op2)
 {
   rtx op = gen_rtx_fmt_ee (code, SFmode, op1, op2);
@@ -11407,10 +12170,13 @@
       emit_move_insn (scratch2, funexp);
       funexp = gen_rtx_MEM (FUNCTION_MODE, scratch2);
       sibcall = gen_sibcall (funexp, const0_rtx, NULL_RTX);
+      REG_NOTES (sibcall) = gen_rtx_INSN_LIST (REG_DEAD, scratch2,
+					REG_NOTES (sibcall));
     }
   sibcall = emit_call_insn (sibcall);
   SIBLING_CALL_P (sibcall) = 1;
   use_reg (&CALL_INSN_FUNCTION_USAGE (sibcall), this_rtx);
+
   emit_barrier ();
 
   /* Run just enough of rest_of_compilation to do scheduling and get
@@ -11446,10 +12212,9 @@
 {
   rtx sym;
 
-  /* If this is not an ordinary function, the name usually comes from a
-     string literal or an sprintf buffer.  Make sure we use the same
+  /* The name usually comes from a string literal or an sprintf buffer.
+     Make sure we use the same
      string consistently, so that cse will be able to unify address loads.  */
-  if (kind != FUNCTION_ORDINARY)
     name = IDENTIFIER_POINTER (get_identifier (name));
   sym = gen_rtx_SYMBOL_REF (Pmode, name);
   SYMBOL_REF_FLAGS (sym) = SYMBOL_FLAG_FUNCTION;
@@ -11458,6 +12223,10 @@
       {
       case FUNCTION_ORDINARY:
 	break;
+      case SFUNC_FREQUENT:
+	if (!optimize || optimize_size)
+	  break;
+	/* Fall through.  */
       case SFUNC_GOT:
 	{
 	  rtx reg = target ? target : gen_reg_rtx (Pmode);
@@ -11568,6 +12337,133 @@
   return 1;
 }
 
+/* The first element of USER is for positive logic, the second one for
+   negative logic.  */
+static void
+sh_expand_float_condop (rtx operands[4], rtx (*user[2]) (rtx))
+{
+  enum machine_mode mode = GET_MODE (operands[1]);
+  enum rtx_code comparison = GET_CODE (operands[0]);
+  int swap_operands = 0;
+
+  if (TARGET_SH1_SOFTFP_MODE (mode))
+    {
+      switch (comparison)
+	{
+	case NE:
+	  comparison = EQ;
+	  user++;
+	  break;
+	case LT:
+	  swap_operands = 1;	/* Fall through.  */
+	case GT:
+	  comparison = UNLE;
+	  user++;
+	  break;
+	case UNGT:
+	  swap_operands = 1;	/* Fall through.  */
+	case UNLT:
+	  comparison = GE;
+	  user++;
+	  break;
+	case UNGE:
+	  swap_operands = 1;
+	  comparison = UNLE;
+	  break;
+	case LE:
+	  swap_operands = 1;
+	  comparison = GE;	/* Fall through.  */
+	case EQ:
+	case UNEQ:
+	case GE:
+	case UNLE:
+	case UNORDERED:
+	  break;
+	case LTGT:
+	  comparison = UNEQ;
+	  user++;
+	  break;
+	case ORDERED:
+	  comparison = UNORDERED;
+	  user++;
+	  break;
+	
+	default: gcc_unreachable ();
+	}
+    }
+  else /* SH2E .. SH4 Hardware floating point */
+    {
+      switch (comparison)
+	{
+	case NE:
+	  comparison = EQ;
+	  user++;
+	  break;
+	case LT:
+	  swap_operands = 1;	/* Fall through.  */
+	  comparison = GT;
+	case GT:
+	case EQ:
+	case LTGT:
+	case ORDERED:
+	  break;
+	case LE:
+	  if (flag_finite_math_only)
+	    {
+	      comparison = GT;
+	      user++;
+	      break;
+	    }
+	  swap_operands = 1;
+	  comparison = GE;	/* Fall through.  */
+	case GE:
+	  if (flag_finite_math_only)
+	    {
+	      swap_operands = 1;
+	      comparison = GT;
+	      user++;
+	      break;
+	    }
+	  break;
+	case UNGE:
+	  swap_operands = 1;	/* Fall through.  */
+	case UNLE:
+	  comparison = GT;
+	  user++;
+	  break;
+	case UNGT:
+	  swap_operands = 1;	/* Fall through.  */
+	case UNLT:
+	  comparison = GE;
+	  user++;
+	  break;
+	case UNEQ:
+	  comparison = LTGT;
+	  user++;
+	  break;
+	case UNORDERED:
+	  comparison = ORDERED;
+	  user++;
+	  break;
+
+	default: gcc_unreachable ();
+	}
+    }
+
+  sh_emit_compare_and_branch (operands, mode);
+  emit_jump_insn ((*user) (operands[3]));
+}
+
+/* For cstroresf4. use sh_emit_compare_and_branch instead.  */
+void
+sh_expand_float_scc (rtx operands[4])
+{
+  static rtx (*movts[]) (rtx) = { gen_movt, gen_movnegt };
+
+  operands[3] = NULL_RTX;
+  sh_expand_float_condop (operands, movts);
+}
+
 /* INSN is an sfunc; return the rtx that describes the address used.  */
 static rtx
 extract_sfunc_addr (rtx insn)
@@ -12119,4 +13015,418 @@
 
 enum sh_divide_strategy_e sh_div_strategy = SH_DIV_STRATEGY_DEFAULT;
 
+static int asm_size (char *s, int addr, int *seen_align)
+{
+  char *pt;
+
+  if (*s == ';' || *s == '\n' || *s == '\0')
+    return 0;
+
+  else if (strstr (s, ".long"))
+    {
+      int n = 1;
+      /* parse .long	1, 3 syntax.  */
+      while (*s != '\n' && *s != '\0')
+	{
+	  s++;
+	  if (*s == ',')  n++;
+	}
+      return 2 * n;
+    }
+
+  else if (strstr (s, ".short") || strstr (s, ".word"))
+    {
+      int n = 1;
+      /* parse .short	1, 3 syntax.  */
+      while (*s != '\n' && *s != '\0')
+	{
+	  s++;
+	  if (*s == ',')  n++;
+	}
+      return n;
+    }
+
+  else if (insn_current_address != -1 && strstr (s, ".balign"))
+    {
+      long int align;
+      int new_address;
+
+      while (*s != '\t' && *s != ' ') s++;
+      align = strtol (s, NULL, 10);
+      if (errno == ERANGE || errno == EINVAL)
+	{
+	  warning (OPT_mdb_page_bug, "unsupported %s asm for w/a.", s);
+	  return 0;
+	}
+
+      /* return log.  */
+      if (seen_align) 
+	*seen_align = exact_log2 (align);
+      new_address = (addr + align - 1) & -align;
+      /* return size / insn_default_length().  */
+      return (new_address - addr) / 2;
+    }
+
+  else if (insn_current_address != -1 && strstr (s, ".align"))
+    {
+      long int align;
+      int new_address;
+
+      while (*s != '\t' && *s != ' ') s++;
+      align = strtol (s, NULL, 10);
+      if (errno == ERANGE || errno == EINVAL)
+	{
+	  warning (OPT_mdb_page_bug, "unsupported %s asm for w/a.", s);
+	  return 0;
+	}
+
+      /* return log.  */
+      if (seen_align)
+	*seen_align = align;
+
+      align = 1 << align;
+      new_address = (addr + align - 1) & -align;
+      /* return size / insn_default_length().  */
+      return (new_address - addr) / 2;
+    }
+
+  else if (strstr (s, ".space") || strstr (s, ".skip"))
+    {
+      long int align;
+      errno = 0;
+      while (*s != '\t' && *s != ' ') s++;
+      align = strtol (s, NULL, 10);
+      if (errno == ERANGE || errno == EINVAL)
+	{
+	  warning (OPT_mdb_page_bug, "unsupported %s asm for w/a.", s);
+	  return 0;
+	}
+      return align / 2;
+    }
+
+  else if ((pt = strrchr (s, ':')) != NULL)
+    {
+      while (*pt == '\t' || *pt == ' ' || *pt == ':') pt++;
+      return asm_size (pt, addr, seen_align);
+    }
+
+  if (*s == '.' && mdep_reorg_phase == SH_AFTER_MDEP_REORG)
+    warning (OPT_mdb_page_bug, "unsupported %s asm for w/a.", s);
+
+  return 1;
+}
+
+int
+sh_asm_count (const char *templ, int *seen_align)
+{
+  int count = 0;
+  char *s, *lt;
+  char delim[] = ";\n";
+  int in_sub = 0;
+  int addr;
+
+  addr = mdep_reorg_phase == SH_AFTER_MDEP_REORG && INSN_ADDRESSES_SET_P () ?
+    insn_current_address : 2;
+
+  lt = (char *) alloca (strlen (templ) + 1);
+  strcpy (lt, templ);
+
+  s = strtok(lt, delim);
+
+  while (s != NULL)
+    {
+      while (*s == '\t' || *s == ' ') s++;
+
+      if (strstr (s, ".pushsection") || strstr (s, ".section"))
+	in_sub++;
+
+      if (! in_sub)
+	count += asm_size (s, addr + (count * 2), seen_align);
+
+      if (strstr (s, ".popsection") || strstr (s, ".previous"))
+	in_sub--;
+
+      s = strtok(NULL, delim);
+    }
+
+  return count;
+}
+
+static int align_next_insn;
+
+static void
+sh_hw_workaround (rtx insn)
+{
+  int uid_address = INSN_ADDRESSES (INSN_UID (insn));
+  int real_address = uid_address + fixup_addr;
+
+  if (GET_CODE (insn) == CODE_LABEL)
+    {
+      rtx barrier = prev_nonnote_insn (insn);
+      if (barrier && BARRIER_P (barrier))
+	{
+	  int log = label_to_alignment (insn);
+	  int align = 1 << log;
+
+	  int aligned_real_address;
+	  int last_unaligned_uid_address = INSN_ADDRESSES (INSN_UID (barrier));
+	
+	  real_address -= (uid_address - last_unaligned_uid_address);
+	  aligned_real_address = (real_address + align - 1) & -align;
+
+	  fixup_addr = aligned_real_address - uid_address;
+	  return;
+	}
+    }
+
+  if (INSN_P (insn))
+    {
+      rtx body = PATTERN (insn);
+
+      if (GET_CODE (body) == UNSPEC_VOLATILE && XINT (body, 1) == UNSPECV_ALIGN)
+	{
+	  int log = INTVAL (XVECEXP (body, 0, 0));
+	  int align = 1 << log;
+	  int aligned_real_address = (real_address + align - 1) & -align;
+	  int aligned_current_address = (uid_address + align - 1) & -align;
+
+	  fixup_addr = aligned_real_address - aligned_current_address;
+	  return;
+	}
+
+      if (align_next_insn)
+	{
+	  align_next_insn = 0;
+	  fixup_addr = -uid_address;
+	  fprintf (asm_out_file, ".align 5\t\t! for hw workaround \n");
+	}
+
+      if (GET_CODE (body) == ASM_INPUT || asm_noperands (body) >= 0)
+	{
+	  int align = 0;
+	  const char *templ;
+
+	  if (GET_CODE (body) == ASM_INPUT)
+	    templ = XSTR (body, 0);
+	  else
+	    templ = decode_asm_operands (body, NULL, NULL, NULL, NULL, NULL);
+
+	  (void) sh_asm_count (templ, &align);
+	  if (align)
+	    {
+	      align_next_insn = 1;
+	      return;
+	    }
+	}
+
+      gcc_assert (! (real_address % 2));
+
+      /* +2 because we check that the ds is not aligned on 32.  */
+      real_address += 2;
+
+      if (recog_memoized (insn) == CODE_FOR_cmpgtudi_t
+	  || recog_memoized (insn) == CODE_FOR_cmpgeudi_t
+	  || recog_memoized (insn) == CODE_FOR_cmpgtdi_t
+	  || recog_memoized (insn) == CODE_FOR_cmpgedi_t)
+	if (!((real_address + 2) % 32))
+	  {
+	    fprintf (asm_out_file,
+		     "\tnop\t\t! for hw workaround @%d\n", real_address);
+	    fixup_addr += 2;
+	    return;
+	  }
+
+      if (recog_memoized (insn) == CODE_FOR_tls_global_dynamic
+	  || recog_memoized (insn) == CODE_FOR_tls_local_dynamic)
+	{
+	  int aligned_real_address;
+	  int align = 4;
+
+	  if (!((real_address + 8) % 32) || !((real_address + 12) % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	      real_address += get_attr_length (insn);
+	    }
+	  else
+	    real_address += get_attr_length (insn) - 2;
+
+	  aligned_real_address = (real_address + align - 1) & -align;
+	  fixup_addr += aligned_real_address - real_address;	
+	  return;
+	}
+
+      if (recog_memoized (insn) == CODE_FOR_tls_initial_exec)
+	{
+	  int aligned_real_address;
+	  int align = 4;
+
+	  if (!((real_address + 6) % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	      real_address += get_attr_length (insn);
+	    }
+	  else
+	    real_address += get_attr_length (insn) - 2;
+
+	  aligned_real_address = (real_address + align - 1) & -align;
+	  fixup_addr += aligned_real_address - real_address;	
+	  return;
+	}
+
+      if (recog_memoized (insn) == CODE_FOR_jump_compact)
+	{
+	  int offset = branch_dest (insn) - INSN_ADDRESSES (INSN_UID (insn));
+	  int far;
+
+	  far = ! (offset >= -32764 && offset - get_attr_length (insn) <= 32766);
+
+	  /* length = 6
+	     mov.w	.L8588,r1
+	     braf	r1
+	     mov	#81,r4	         [length = 2]
+	     .L8588: .word .L12-.L8588
+
+	     length = 8
+	     mov.w	.L8588,r1	
+	     braf	r1
+	     nop
+	     .L8588: .word .L12-.L8588
+
+	     length = 10
+	     mov	#81,r4	         [length = 2]
+	     mov.l	r13,@-r15	
+	     mov.w	.L,r13
+	     braf	r13
+	     mov.l	@r15+,r13
+	     .L: .word
+	  */
+	  if (!far)
+	    {
+	      if (get_attr_length (insn) == 6 || get_attr_length (insn) == 8)
+		real_address += 2;
+	      if (get_attr_length (insn) == 10)
+		{
+		  if (dbr_sequence_length ())
+		    real_address += 6;
+		  else
+		    real_address += 4;
+		}
+	    }
+
+	  /* length = 8
+	     mov.l	.L8586,r4	
+	     jmp	@r4
+	     mov	#81,r4         [length = 2]
+	     .align	2
+	     .L8586:  .long	.L5
+
+	     length = 10
+	     mov.l	.L8589,r3
+	     jmp	@r3
+	     nop
+	     .align	2
+	     .L8589:  .long	.L2242
+	  */
+	  else if (far
+		   && (get_attr_length (insn) == 8 || get_attr_length (insn) == 10))
+	    {
+	      int aligned_real_address;
+	      int next_uid_address = uid_address + 10;
+	      int align = 4;
+
+	      if (!((real_address + 2) % 32))
+		{
+		  fprintf (asm_out_file,
+			   "\tnop\t\t! for hw workaround @%d\n", real_address);
+		  real_address += 10;
+		  aligned_real_address = (real_address + align - 1) & -align;
+		  fixup_addr = aligned_real_address - next_uid_address;
+		}
+	      else
+		{
+		  real_address += 8;
+		  aligned_real_address = (real_address + align - 1) & -align;
+		  fixup_addr = aligned_real_address - next_uid_address;
+		}
+	      return;
+	    }
+
+	  if (!(real_address % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround 1 @%d\n", real_address);
+	      fixup_addr += 2;
+	      return;
+	    }
+	}
+
+      /* we have bt; (aligned)bra; nop; avoid nop ; (aligned)bt; bra; nop.  */
+      /* or bt; delayed instruction; (aligned)bra.  */
+      if ((recog_memoized (insn) == CODE_FOR_branch_true
+	   || recog_memoized (insn) == CODE_FOR_branch_false)
+	  && get_attr_length (insn) == 6)
+	{
+	  if (!((real_address + 2) % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address-2);
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 4;
+	    }
+	  else if (!(real_address % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	    }
+	  else if (!((real_address + 4) % 32)
+		   && (dbr_sequence_length ()
+		       && ! INSN_ANNULLED_BRANCH_P (XVECEXP (final_sequence, 0, 0))
+		       && get_attr_length (XVECEXP (final_sequence, 0, 1))))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	    }
+	}
+
+      if ((GET_CODE (insn) == JUMP_INSN
+	   && GET_CODE (PATTERN (insn)) != ADDR_DIFF_VEC
+	   && GET_CODE (PATTERN (insn)) != ADDR_VEC))
+	{
+	  if (!(real_address % 32)
+	      && (dbr_sequence_length ()
+		  && ! INSN_ANNULLED_BRANCH_P (XVECEXP (final_sequence, 0, 0))
+		  && get_attr_length (XVECEXP (final_sequence, 0, 1))))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	    }
+	  else if (GET_CODE (insn) == CALL_INSN
+		   && !(real_address % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	    }
+	}
+
+	if ((GET_CODE (insn) == CALL_INSN || INSN_P (insn))
+	    && !(real_address % 32)
+	    && get_attr_needs_delay_slot (insn) == NEEDS_DELAY_SLOT_YES)
+	{
+	  fprintf (asm_out_file,
+		   "\tnop\t\t! for hw workaround @%d\n", real_address);
+	  fixup_addr += 2;
+	}
+    }
+}
+
 #include "gt-sh.h"
+
Index: gcc-4.5.2.orig/gcc/config/sh/sh.h
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/sh.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/sh.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -3,6 +3,7 @@
    2003, 2004, 2005, 2006, 2007, 2008, 2009 Free Software Foundation, Inc.
    Contributed by Steve Chamberlain (sac@cygnus.com).
    Improved by Jim Wilson (wilson@cygnus.com).
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -35,6 +36,12 @@
 
 #define TARGET_CPU_CPP_BUILTINS() \
 do { \
+  if (TARGET_DBHWBUG) \
+      builtin_define_with_value ("DB_ST40300_BUG_WORKAROUND", "32", 0); \
+  if (TARGET_TAS) \
+      builtin_define ("__HAVE_TAS__"); \
+  if (TARGET_FMOVD) \
+      builtin_define ("__MOVD__"); \
   builtin_define ("__sh__"); \
   builtin_assert ("cpu=sh"); \
   builtin_assert ("machine=sh"); \
@@ -98,7 +105,7 @@
 } while (0)
 
 /* We can not debug without a frame pointer.  */
-/* #define CAN_DEBUG_WITHOUT_FP */
+#define CAN_DEBUG_WITHOUT_FP
 
 #define CONDITIONAL_REGISTER_USAGE do					\
 {									\
@@ -107,6 +114,10 @@
     if (! VALID_REGISTER_P (regno))					\
       fixed_regs[regno] = call_used_regs[regno] = 1;			\
   /* R8 and R9 are call-clobbered on SH5, but not on earlier SH ABIs.  */ \
+  if (TARGET_SH4A_FP || TARGET_SH4_300)					\
+    {                                                                   \
+      global_regs[FPSCR_REG] = 1;                                       \
+    }									\
   if (TARGET_SH5)							\
     {									\
       call_used_regs[FIRST_GENERAL_REG + 8]				\
@@ -120,6 +131,10 @@
       CLEAR_HARD_REG_SET (reg_class_contents[FP0_REGS]);		\
       regno_reg_class[FIRST_FP_REG] = FP_REGS;				\
     }									\
+  if (TARGET_R0R3_TO_REG_MUL < 2)					\
+    regno_reg_class[R1_REG] = regno_reg_class[R2_REG]			\
+      = regno_reg_class[R3_REG] = GENERAL_REGS;				\
+    /* The peephole2s needs reg_class_contents[R0R3_REGS].  */		\
   if (flag_pic)								\
     {									\
       fixed_regs[PIC_OFFSET_TABLE_REGNUM] = 1;				\
@@ -175,6 +190,11 @@
 #define TARGET_FPU_DOUBLE \
   ((target_flags & MASK_SH4) != 0 || TARGET_SH2A_DOUBLE)
 
+#define TARGET_SH1_SOFTFP (TARGET_SH1 && !TARGET_FPU_DOUBLE)
+
+#define TARGET_SH1_SOFTFP_MODE(MODE) \
+  (TARGET_SH1_SOFTFP && (!TARGET_SH2E || (MODE) == DFmode))
+
 /* Nonzero if an FPU is available.  */
 #define TARGET_FPU_ANY (TARGET_SH2E || TARGET_FPU_DOUBLE)
 
@@ -215,7 +235,7 @@
    && ! (TARGET_HITACHI || sh_attr_renesas_p (FUN_DECL)))
 
 #ifndef TARGET_CPU_DEFAULT
-#define TARGET_CPU_DEFAULT SELECT_SH1
+#define TARGET_CPU_DEFAULT SELECT_SH4
 #define SUPPORT_SH1 1
 #define SUPPORT_SH2E 1
 #define SUPPORT_SH4 1
@@ -239,7 +259,9 @@
 #define TARGET_DIVIDE_INV_CALL2 (sh_div_strategy == SH_DIV_INV_CALL2)
 #define TARGET_DIVIDE_CALL_DIV1 (sh_div_strategy == SH_DIV_CALL_DIV1)
 #define TARGET_DIVIDE_CALL_FP (sh_div_strategy == SH_DIV_CALL_FP)
-#define TARGET_DIVIDE_CALL_TABLE (sh_div_strategy == SH_DIV_CALL_TABLE)
+#define TARGET_DIVIDE_CALL_PRE1 (sh_div_strategy == SH_DIV_CALL_PRE1)
+#define TARGET_DIVIDE_CALL_TABLE (sh_div_strategy == SH_DIV_CALL_TABLE \
+   || TARGET_DIVIDE_CALL_PRE1)
 
 #define SELECT_SH1               (MASK_SH1)
 #define SELECT_SH2               (MASK_SH2 | SELECT_SH1)
@@ -272,6 +294,42 @@
 #define SELECT_SH5_COMPACT       (MASK_SH5 | MASK_SH4 | SELECT_SH3E)
 #define SELECT_SH5_COMPACT_NOFPU (MASK_SH5 | SELECT_SH3)
 
+/* Check if we have support for optimized software floating point using
+   dynamic shifts - then some function calls clobber fewer registers.  */
+#ifdef SUPPORT_SH3
+#define SUPPORT_SH3_OSFP 1
+#else
+#define SUPPORT_SH3_OSFP 0
+#endif
+
+#ifdef SUPPORT_SH3E
+#define SUPPORT_SH3E_OSFP 1
+#else
+#define SUPPORT_SH3E_OSFP 0
+#endif
+
+#if defined(SUPPORT_SH4_NOFPU) || defined(SUPPORT_SH3_OSFP)
+#define SUPPORT_SH4_NOFPU_OSFP 1
+#else
+#define SUPPORT_SH4_NOFPU_OSFP 0
+#endif
+
+#if defined(SUPPORT_SH4_SINGLE_ONLY) || defined (SUPPORT_SH3E_OSFP)
+#define SUPPORT_SH4_SINGLE_ONLY_OSFP 1
+#else
+#define SUPPORT_SH4_SINGLE_ONLY_OSFP 0
+#endif
+
+#ifdef notyet
+#define TARGET_OSFP (0 \
+ || (TARGET_SH3 && !TARGET_SH2E && SUPPORT_SH3_OSFP) \
+ || (TARGET_SH3E && SUPPORT_SH3E_OSFP) \
+ || (TARGET_HARD_SH4 && !TARGET_SH2E && SUPPORT_SH4_NOFPU_OSFP) \
+ || (TARGET_HARD_SH4 && TARGET_SH2E && SUPPORT_SH4_SINGLE_ONLY_OSFP))
+#else
+#define TARGET_OSFP (0)
+#endif
+
 #if SUPPORT_SH1
 #define SUPPORT_SH2 1
 #endif
@@ -332,7 +390,7 @@
 #endif
 
 #ifndef TARGET_OPT_DEFAULT
-#define TARGET_OPT_DEFAULT  MASK_ADJUST_UNROLL
+#define TARGET_OPT_DEFAULT 0
 #endif
 
 #define TARGET_DEFAULT \
@@ -365,20 +423,13 @@
   { "subtarget_link_emul_suffix", SUBTARGET_LINK_EMUL_SUFFIX },	\
   { "subtarget_link_spec", SUBTARGET_LINK_SPEC },		\
   { "subtarget_asm_endian_spec", SUBTARGET_ASM_ENDIAN_SPEC },	\
-  { "subtarget_asm_relax_spec", SUBTARGET_ASM_RELAX_SPEC },	\
   { "subtarget_asm_isa_spec", SUBTARGET_ASM_ISA_SPEC },		\
   { "subtarget_asm_spec", SUBTARGET_ASM_SPEC },			\
   SUBTARGET_EXTRA_SPECS
 
-#if TARGET_CPU_DEFAULT & MASK_HARD_SH4
-#define SUBTARGET_ASM_RELAX_SPEC "%{!m1:%{!m2:%{!m3*:%{!m5*:-isa=sh4-up}}}}"
-#else
-#define SUBTARGET_ASM_RELAX_SPEC "%{m4*:-isa=sh4-up}"
-#endif
-
 #define SH_ASM_SPEC \
- "%(subtarget_asm_endian_spec) %{mrelax:-relax %(subtarget_asm_relax_spec)}\
-%(subtarget_asm_isa_spec) %(subtarget_asm_spec)\
+"%(subtarget_asm_endian_spec) %{mrelax:-relax} \
+%(subtarget_asm_isa_spec) %(subtarget_asm_spec) \
 %{m2a:--isa=sh2a} \
 %{m2a-single:--isa=sh2a} \
 %{m2a-single-only:--isa=sh2a} \
@@ -386,7 +437,8 @@
 %{m5-compact*:--isa=SHcompact} \
 %{m5-32media*:--isa=SHmedia --abi=32} \
 %{m5-64media*:--isa=SHmedia --abi=64} \
-%{m4al:-dsp} %{mcut2-workaround:-cut2-workaround}"
+%{m4al:-dsp} %{mcut2-workaround:-cut2-workaround} \
+%{mtas:--tas}"
 
 #define ASM_SPEC SH_ASM_SPEC
 
@@ -402,14 +454,18 @@
 /* Strict nofpu means that the compiler should tell the assembler
    to reject FPU instructions. E.g. from ASM inserts.  */
 #if TARGET_CPU_DEFAULT & MASK_HARD_SH4 && !(TARGET_CPU_DEFAULT & MASK_SH_E)
-#define SUBTARGET_ASM_ISA_SPEC "%{!m1:%{!m2:%{!m3*:%{m4-nofpu|!m4*:%{!m5:-isa=sh4-nofpu}}}}}"
+#define SUBTARGET_ASM_ISA_SPEC "%{!m1:%{!m2:%{!m3*:%{m4-nofpu|!m4*:%{!m5:--isa=sh4-nofpu}}}}}"
 #else
 /* If there were an -isa option for sh5-nofpu then it would also go here. */
 #define SUBTARGET_ASM_ISA_SPEC \
- "%{m4-nofpu:-isa=sh4-nofpu} " ASM_ISA_DEFAULT_SPEC
+ "%{m4-nofpu:--isa=sh4-nofpu} " ASM_ISA_DEFAULT_SPEC
 #endif
 #else /* ! STRICT_NOFPU */
-#define SUBTARGET_ASM_ISA_SPEC ASM_ISA_DEFAULT_SPEC
+#define SUBTARGET_ASM_ISA_SPEC "%{m4-nofpu:--isa=sh4-nofpu-up} \
+ %{m4|m4-single*:--isa=sh4-up} \
+ %{m4-300-nofpu:--isa=st40-300-nofpu} \
+ %{m4-300|m4-300-single|m4-300-single-only:--isa=st40-300}" \
+ ASM_ISA_DEFAULT_SPEC
 #endif
 
 #ifndef SUBTARGET_ASM_SPEC
@@ -437,8 +493,14 @@
 #define ASM_ISA_DEFAULT_SPEC \
 " %{!m1:%{!m2*:%{!m3*:%{!m4*:%{!m5*:" ASM_ISA_SPEC_DEFAULT "}}}}}"
 #else /* !MASK_SH5 */
-#define LINK_DEFAULT_CPU_EMUL ""
+#if TARGET_CPU_DEFAULT & MASK_SH4
+#define ASM_ISA_SPEC_DEFAULT "--isa=sh4-up"
+#define ASM_ISA_DEFAULT_SPEC \
+" %{!m1:%{!m2*:%{!m3*:%{!m4*:%{!m5*:" ASM_ISA_SPEC_DEFAULT "}}}}}"
+#else /* !MASK_SH4 */
 #define ASM_ISA_DEFAULT_SPEC ""
+#endif
+#define LINK_DEFAULT_CPU_EMUL ""
 #endif /* MASK_SH5 */
 
 #define SUBTARGET_LINK_EMUL_SUFFIX ""
@@ -454,6 +516,8 @@
 %{m5-64media*:64}\
 %{!m1:%{!m2:%{!m3*:%{!m4*:%{!m5*:%(link_default_cpu_emul)}}}}}\
 %(subtarget_link_emul_suffix) \
+%{mdb-page-bug:--db-page-bug} \
+%{shared:-shared} \
 %{mrelax:-relax} %(subtarget_link_spec)"
 
 #ifndef SH_DIV_STR_FOR_SIZE
@@ -486,6 +550,7 @@
   SH_DIV_CALL_DIV1, /* No FPU, medium size, highest latency.  */
   SH_DIV_CALL_FP,     /* FPU needed, small size, high latency.  */
   SH_DIV_CALL_TABLE,  /* No FPU, large size, medium latency. */
+  SH_DIV_CALL_PRE1,  /* Preheader to optimize return 1 cases. */
   SH_DIV_INTRINSIC
 };
 
@@ -612,6 +677,18 @@
    multiple of this.  */
 #define STRUCTURE_SIZE_BOUNDARY (TARGET_PADSTRUCT ? 32 : 8)
 
+/* Define this macro as an expression for the alignment of a structure
+   (given by STRUCT as a tree node) if the alignment computed in the
+   usual way is COMPUTED and the alignment explicitly specified was
+   SPECIFIED.
+*/
+#define ROUND_TYPE_ALIGN(STRUCT, COMPUTED, SPECIFIED)	\
+    ((TARGET_ALIGN_DOUBLE &&						       \
+      TREE_CODE (STRUCT) == RECORD_TYPE && TYPE_FIELDS (STRUCT) != 0 && \
+      TREE_INT_CST_LOW (TYPE_SIZE (STRUCT)) > 64)	\
+     ? MAX (MAX ((COMPUTED), (SPECIFIED)), 64)		\
+     : MAX ((COMPUTED), (SPECIFIED)))
+
 /* Set this nonzero if move instructions will actually fail to work
    when given unaligned data.  */
 #define STRICT_ALIGNMENT 1
@@ -620,8 +697,11 @@
 #define LABEL_ALIGN_AFTER_BARRIER(LABEL_AFTER_BARRIER) \
   barrier_align (LABEL_AFTER_BARRIER)
 
+#define JUMP_ALIGN(LABEL) \
+   sh_jump_align (LABEL)
+
 #define LOOP_ALIGN(A_LABEL) \
-  ((! optimize || TARGET_HARD_SH4 || TARGET_SMALLCODE) \
+  ((! optimize || TARGET_HARD_SH4 || optimize_size) \
    ? 0 : sh_loop_align (A_LABEL))
 
 #define LABEL_ALIGN(A_LABEL) \
@@ -638,12 +718,10 @@
 #define ADDR_VEC_ALIGN(ADDR_VEC) 2
 
 /* The base two logarithm of the known minimum alignment of an insn length.  */
-#define INSN_LENGTH_ALIGNMENT(A_INSN)					\
-  (NONJUMP_INSN_P (A_INSN)						\
-   ? 1 << TARGET_SHMEDIA						\
-   : JUMP_P (A_INSN) || CALL_P (A_INSN)					\
-   ? 1 << TARGET_SHMEDIA						\
-   : CACHE_LOG)
+/* After a addr_diff_vec:HI the log align is 1.  Update it so the  next
+   insn_current_address can correctly be computed in final.  */
+#define INSN_LENGTH_ALIGNMENT(X) sh_insn_length_alignment (X)
+
 
 /* Standard register usage.  */
 
@@ -1095,6 +1173,7 @@
 {
   NO_REGS,
   R0_REGS,
+  R0R3_REGS,
   PR_REGS,
   T_REGS,
   MAC_REGS,
@@ -1120,6 +1199,7 @@
 {			\
   "NO_REGS",		\
   "R0_REGS",		\
+  "R0R3_REGS",		\
   "PR_REGS",		\
   "T_REGS",		\
   "MAC_REGS",		\
@@ -1147,6 +1227,8 @@
   { 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 },	\
 /* R0_REGS:  */								\
   { 0x00000001, 0x00000000, 0x00000000, 0x00000000, 0x00000000 },	\
+/* R0R3_REGS:  */							\
+  { 0x0000000f, 0x00000000, 0x00000000, 0x00000000, 0x00000000 },	\
 /* PR_REGS:  */								\
   { 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00040000 },	\
 /* T_REGS:  */								\
@@ -1796,7 +1878,7 @@
 
 /* Alignment required for a trampoline in bits .  */
 #define TRAMPOLINE_ALIGNMENT \
-  ((CACHE_LOG < 3 || (TARGET_SMALLCODE && ! TARGET_HARVARD)) ? 32 \
+  ((CACHE_LOG < 3 || (optimize_size && ! TARGET_HARVARD)) ? 32 \
    : TARGET_SHMEDIA ? 256 : 64)
 
 /* A C expression whose value is RTL representing the value of the return
@@ -1827,12 +1909,13 @@
                                            ? 0 : TARGET_SH1)
 
 #define MOVE_BY_PIECES_P(SIZE, ALIGN) \
-  (move_by_pieces_ninsns (SIZE, ALIGN, MOVE_MAX_PIECES + 1) \
-   < (TARGET_SMALLCODE ? 2 : ((ALIGN >= 32) ? 16 : 2)))
+  ((TARGET_ALIGN_DOUBLE) ? ((SIZE)*8 <= 64 || ALIGN != 64) \
+   : (move_by_pieces_ninsns ((SIZE), ALIGN, MOVE_MAX_PIECES + 1) \
+      < (optimize_size ? 2 : ((ALIGN >= 32) ? 16 : 2))))
 
 #define STORE_BY_PIECES_P(SIZE, ALIGN) \
   (move_by_pieces_ninsns (SIZE, ALIGN, STORE_MAX_PIECES + 1) \
-   < (TARGET_SMALLCODE ? 2 : ((ALIGN >= 32) ? 16 : 2)))
+   < (optimize_size ? 2 : ((ALIGN >= 32) ? 16 : 2)))
 
 #define SET_BY_PIECES_P(SIZE, ALIGN) STORE_BY_PIECES_P(SIZE, ALIGN)
 
@@ -2094,13 +2177,16 @@
 #define CASE_VECTOR_MODE ((! optimize || TARGET_BIGTABLE) ? SImode : HImode)
 
 #define CASE_VECTOR_SHORTEN_MODE(MIN_OFFSET, MAX_OFFSET, BODY) \
-((MIN_OFFSET) >= 0 && (MAX_OFFSET) <= 127 \
+(TARGET_DBHWBUG ? SImode                                    \
+ : (MIN_OFFSET) >= 0 && (MAX_OFFSET) <= 127		    \
  ? (ADDR_DIFF_VEC_FLAGS (BODY).offset_unsigned = 0, QImode) \
  : (MIN_OFFSET) >= 0 && (MAX_OFFSET) <= 255 \
  ? (ADDR_DIFF_VEC_FLAGS (BODY).offset_unsigned = 1, QImode) \
  : (MIN_OFFSET) >= -32768 && (MAX_OFFSET) <= 32767 ? HImode \
  : SImode)
 
+#define VARYING_INSN_P(INSN) sh_varying_insn_p(INSN) 
+
 /* Define as C expression which evaluates to nonzero if the tablejump
    instruction expects the table to contain offsets from the address of the
    table.
@@ -2144,7 +2230,7 @@
 
 /* Max number of bytes we want move_by_pieces to be able to copy
    efficiently.  */
-#define MOVE_MAX_PIECES (TARGET_SH4 || TARGET_SHMEDIA ? 8 : 4)
+#define MOVE_MAX_PIECES (TARGET_SH1 || TARGET_SH5 ? 8 : 4)
 
 /* Define if operations between registers always perform the operation
    on the full register even if a narrower mode is specified.  */
@@ -2442,6 +2528,8 @@
 /* Globalizing directive for a label.  */
 #define GLOBAL_ASM_OP "\t.global\t"
 
+#define TARGET_ASM_COUNT(TEMP, ALIGNP) sh_asm_count (TEMP, ALIGNP)
+
 /* #define ASM_OUTPUT_CASE_END(STREAM,NUM,TABLE)	    */
 
 /* Output a relative address table.  */
@@ -2626,8 +2714,6 @@
   while (0)
 
 
-extern struct rtx_def *sh_compare_op0;
-extern struct rtx_def *sh_compare_op1;
 
 /* Which processor to schedule for.  The elements of the enumeration must
    match exactly the cpu attribute in the sh.md file.  */
@@ -2681,7 +2767,8 @@
    sh-dsp parallel processing insns are four bytes long.  */
 
 #define ADJUST_INSN_LENGTH(X, LENGTH)				\
-  (LENGTH) += sh_insn_length_adjustment (X);
+  (LENGTH) += sh_insn_length_adjustment (X, LENGTH);
+
 
 /* Define this macro if it is advisable to hold scalars in registers
    in a wider mode than that declared by the program.  In such cases,
@@ -2703,14 +2790,16 @@
 
 #define SIDI_OFF (TARGET_LITTLE_ENDIAN ? 0 : 4)
 
-/* ??? Define ACCUMULATE_OUTGOING_ARGS?  This is more efficient than pushing
-   and popping arguments.  However, we do have push/pop instructions, and
+/* This is more efficient than pushing and popping arguments.
+   However, we do have push/pop instructions, and
    rather limited offsets (4 bits) in load/store instructions, so it isn't
    clear if this would give better code.  If implemented, should check for
    compatibility problems.  */
 
+#define ACCUMULATE_OUTGOING_ARGS TARGET_ACCUMULATE_OUTGOING_ARGS
+
 #define SH_DYNAMIC_SHIFT_COST \
-  (TARGET_HARD_SH4 ? 1 : TARGET_SH3 ? (TARGET_SMALLCODE ? 1 : 2) : 20)
+  (TARGET_HARD_SH4 ? 1 : TARGET_SH3 ? (optimize_size ? 1 : 2) : 20)
 
 
 #define NUM_MODES_FOR_MODE_SWITCHING { FP_MODE_NONE }
@@ -2748,11 +2837,16 @@
 #define MODE_PRIORITY_TO_MODE(ENTITY, N) \
   ((TARGET_FPU_SINGLE != 0) ^ (N) ? FP_MODE_SINGLE : FP_MODE_DOUBLE)
 
-#define EMIT_MODE_SET(ENTITY, MODE, HARD_REGS_LIVE) \
-  fpscr_set_from_mem ((MODE), (HARD_REGS_LIVE))
+#define EMIT_MODE_SET(ENTITY, MODE, FLIP, HARD_REGS_LIVE) \
+  ((TARGET_SH4A_FP || TARGET_SH4_300)                     \
+   && (FLIP) ? emit_fpu_flip ()                           \
+   : fpscr_set_from_mem ((MODE), (HARD_REGS_LIVE)))
 
+/* Too conservative, if distances are not computed get_attr_length is too
+   much conservative. better let it go and split_branches afterwards.
 #define MD_CAN_REDIRECT_BRANCH(INSN, SEQ) \
   sh_can_redirect_branch ((INSN), (SEQ))
+ */
 
 #define DWARF_FRAME_RETURN_COLUMN \
   (TARGET_SH5 ? DWARF_FRAME_REGNUM (PR_MEDIA_REG) : DWARF_FRAME_REGNUM (PR_REG))
@@ -2800,4 +2894,7 @@
 /* FIXME: middle-end support for highpart optimizations is missing.  */
 #define high_life_started reload_in_progress
 
+#define TARGET_USES_LEB128 \
+  (! TARGET_RELAX || (!flag_unwind_tables && !flag_exceptions))
+
 #endif /* ! GCC_SH_H */
Index: gcc-4.5.2.orig/gcc/config/sh/trap-handler.c
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/trap-handler.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/trap-handler.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,10 @@
+extern void exit(int) __attribute__ ((noreturn));
+
+void
+_superh_trap_handler (unsigned int trap_reason)
+{
+  exit(*(int*)0xff000024);  /* return EXPEVT */
+
+  /* in case exit returns ... */
+  while(1);
+}
Index: gcc-4.5.2.orig/gcc/config/sh/t-superh
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/t-superh	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/t-superh	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,4 +1,5 @@
 # Copyright (C) 2005, 2006 Free Software Foundation, Inc.
+# Copyright (c) 2010 STMicroelectronics.
 #
 # This file is part of GCC.
 #
@@ -16,9 +17,12 @@
 # along with GCC; see the file COPYING3.  If not see
 # <http://www.gnu.org/licenses/>.
 
+LIB2FUNCS_EXTRA= $(srcdir)/config/sh/supervisor-atomic.asm
+
 EXTRA_MULTILIB_PARTS= crt1.o crti.o crtn.o \
 	crtbegin.o crtend.o crtbeginS.o crtendS.o \
-	crt1-mmu.o gcrt1-mmu.o gcrt1.o $(IC_EXTRA_PARTS) $(OPT_EXTRA_PARTS)
+	crt1-mmu.o gcrt1-mmu.o gcrt1.o $(IC_EXTRA_PARTS) $(OPT_EXTRA_PARTS) \
+	trap-handler.o
 
 # Compile crt1-mmu.o as crt1.o with -DMMU_SUPPORT
 $(T)crt1-mmu.o: $(srcdir)/config/sh/crt1.asm $(GCC_PASSES)
@@ -31,3 +35,4 @@
 # For sh4-400: Compile gcrt1.o as crt1.o with -DPROFILE
 $(T)gcrt1.o: $(srcdir)/config/sh/crt1.asm $(GCC_PASSES)
 	$(GCC_FOR_TARGET) $(MULTILIB_CFLAGS) -c -o $(T)gcrt1.o -DPROFILE -x assembler-with-cpp $(srcdir)/config/sh/crt1.asm
+
Index: gcc-4.5.2.orig/gcc/config/sh/supervisor-atomic.asm
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/supervisor-atomic.asm	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/supervisor-atomic.asm	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,208 @@
+/* Copyright (C) 2006, 2008, 2009 Free Software Foundation, Inc.
+   Copyright (c) 2010 STMicroelectronics.
+	
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   Under Section 7 of GPL version 3, you are granted additional
+   permissions described in the GCC Runtime Library Exception, version
+   3.1, as published by the Free Software Foundation.
+
+   You should have received a copy of the GNU General Public License and
+   a copy of the GCC Runtime Library Exception along with this program;
+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+   <http://www.gnu.org/licenses/>.  */
+
+!! Atomic routines for the Renesas / SuperH SH CPUs for applications
+!! executing in supervisor mode.
+
+#include "lib1funcs.h"
+
+#if ! __SH5__
+
+#define ATOMIC_TEST_AND_SET(N,T) \
+	.global	GLOBAL(sync_lock_test_and_set_##N); \
+	.align	1; \
+GLOBAL(sync_lock_test_and_set_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov.##T	r5, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	mov	r2, r0; \
+	ENDFUNC(GLOBAL(sync_lock_test_and_set_##N))
+
+ATOMIC_TEST_AND_SET(1,b)
+ATOMIC_TEST_AND_SET(2,w)
+ATOMIC_TEST_AND_SET(4,l)
+
+#define ATOMIC_VAL_COMPARE_AND_SWAP(N,T) \
+	.global	GLOBAL(sync_val_compare_and_swap_##N); \
+	.align	1; \
+GLOBAL(sync_val_compare_and_swap_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	cmp/eq	r2, r5; \
+	bf	0f; \
+	mov.##T	r6, @r4; \
+0:	ldc	r1, sr; \
+	rts; \
+	mov	r2, r0; \
+	ENDFUNC(GLOBAL(sync_val_compare_and_swap_##N))
+
+ATOMIC_VAL_COMPARE_AND_SWAP(1,b)
+ATOMIC_VAL_COMPARE_AND_SWAP(2,w)
+ATOMIC_VAL_COMPARE_AND_SWAP(4,l)
+
+#define ATOMIC_BOOL_COMPARE_AND_SWAP(N,T) \
+	.global	GLOBAL(sync_bool_compare_and_swap_##N); \
+	.align	1; \
+GLOBAL(sync_bool_compare_and_swap_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	cmp/eq	r2, r5; \
+	bf/s	0f; \
+	movt	r0; \
+	mov.##T	r6, @r4; \
+0:	ldc	r1, sr; \
+	rts; \
+	nop; \
+	ENDFUNC(GLOBAL(sync_bool_compare_and_swap_##N))
+
+ATOMIC_BOOL_COMPARE_AND_SWAP(1,b)
+ATOMIC_BOOL_COMPARE_AND_SWAP(2,w)
+ATOMIC_BOOL_COMPARE_AND_SWAP(4,l)
+
+#define ATOMIC_FETCH_AND_OP(OP,N,T) \
+	.global	GLOBAL(sync_fetch_and_##OP##_##N); \
+	.align	1; \
+GLOBAL(sync_fetch_and_##OP##_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	OP	r2, r5; \
+	mov.##T	r5, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	mov	r2, r0; \
+	ENDFUNC(GLOBAL(sync_fetch_and_##OP##_##N))
+
+ATOMIC_FETCH_AND_OP(add,1,b)
+ATOMIC_FETCH_AND_OP(add,2,w)
+ATOMIC_FETCH_AND_OP(add,4,l)
+
+ATOMIC_FETCH_AND_OP(or,1,b)
+ATOMIC_FETCH_AND_OP(or,2,w)
+ATOMIC_FETCH_AND_OP(or,4,l)
+
+ATOMIC_FETCH_AND_OP(and,1,b)
+ATOMIC_FETCH_AND_OP(and,2,w)
+ATOMIC_FETCH_AND_OP(and,4,l)
+
+ATOMIC_FETCH_AND_OP(xor,1,b)
+ATOMIC_FETCH_AND_OP(xor,2,w)
+ATOMIC_FETCH_AND_OP(xor,4,l)
+
+#define ATOMIC_FETCH_AND_COMBOP(OP,OP0,OP1,N,T) \
+	.global	GLOBAL(sync_fetch_and_##OP##_##N); \
+	.align	1; \
+GLOBAL(sync_fetch_and_##OP##_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	OP0	r2, r5; \
+	OP1	r5, r5; \
+	mov.##T	r5, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	mov	r2, r0; \
+	ENDFUNC(GLOBAL(sync_fetch_and_##OP##_##N))
+
+ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,1,b)
+ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,2,w)
+ATOMIC_FETCH_AND_COMBOP(sub,sub,neg,4,l)
+
+ATOMIC_FETCH_AND_COMBOP(nand,and,not,1,b)
+ATOMIC_FETCH_AND_COMBOP(nand,and,not,2,w)
+ATOMIC_FETCH_AND_COMBOP(nand,and,not,4,l)
+
+#define ATOMIC_OP_AND_FETCH(OP,N,T) \
+	.global	GLOBAL(sync_##OP##_and_fetch_##N); \
+	.align	1; \
+GLOBAL(sync_##OP##_and_fetch_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	OP	r5, r2; \
+	mov.##T	r2, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	mov	r2, r0; \
+	ENDFUNC(GLOBAL(sync_##OP##_and_fetch_##N))
+
+ATOMIC_OP_AND_FETCH(add,1,b)
+ATOMIC_OP_AND_FETCH(add,2,w)
+ATOMIC_OP_AND_FETCH(add,4,l)
+
+ATOMIC_OP_AND_FETCH(sub,1,b)
+ATOMIC_OP_AND_FETCH(sub,2,w)
+ATOMIC_OP_AND_FETCH(sub,4,l)
+
+ATOMIC_OP_AND_FETCH(or,1,b)
+ATOMIC_OP_AND_FETCH(or,2,w)
+ATOMIC_OP_AND_FETCH(or,4,l)
+
+ATOMIC_OP_AND_FETCH(and,1,b)
+ATOMIC_OP_AND_FETCH(and,2,w)
+ATOMIC_OP_AND_FETCH(and,4,l)
+
+ATOMIC_OP_AND_FETCH(xor,1,b)
+ATOMIC_OP_AND_FETCH(xor,2,w)
+ATOMIC_OP_AND_FETCH(xor,4,l)
+
+#define ATOMIC_COMBOP_AND_FETCH(OP,OP0,OP1,N,T) \
+	.global	GLOBAL(sync_##OP##_and_fetch_##N); \
+	.align	1; \
+GLOBAL(sync_##OP##_and_fetch_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	OP0	r2, r5; \
+	OP1	r5, r2; \
+	mov.##T	r2, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	mov	r2, r0; \
+	ENDFUNC(GLOBAL(sync_##OP##_and_fetch_##N))
+
+ATOMIC_COMBOP_AND_FETCH(nand,and,not,1,b)
+ATOMIC_COMBOP_AND_FETCH(nand,and,not,2,w)
+ATOMIC_COMBOP_AND_FETCH(nand,and,not,4,l)
+	
+#endif /* ! __SH5__ */
Index: gcc-4.5.2.orig/gcc/config/sh/sh-modes.def
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/sh-modes.def	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/sh-modes.def	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -22,6 +22,11 @@
 /* PDI mode is used to represent a function address in a target register.  */
 PARTIAL_INT_MODE (DI);
 
+/* For software floating point comparisons.  */
+CC_MODE (CC_FP_NE);
+CC_MODE (CC_FP_GT);
+CC_MODE (CC_FP_UNLT);
+
 /* Vector modes.  */
 VECTOR_MODE  (INT, QI, 2);    /*                 V2QI */
 VECTOR_MODES (INT, 4);        /*            V4QI V2HI */
Index: gcc-4.5.2.orig/gcc/config/sh/lib1funcs.h
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/lib1funcs.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/lib1funcs.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,6 +1,7 @@
 /* Copyright (C) 1994, 1995, 1997, 1998, 1999, 2000, 2001, 2002, 2003,
    2004, 2005, 2006, 2009
    Free Software Foundation, Inc.
+   Copyright (c) 2006  STMicroelectronics.
 
 This file is free software; you can redistribute it and/or modify it
 under the terms of the GNU General Public License as published by the
@@ -64,13 +65,152 @@
 #endif /* !__LITTLE_ENDIAN__ */
 
 #ifdef __sh1__
+/* branch with two-argument delay slot insn */
 #define SL(branch, dest, in_slot, in_slot_arg2) \
 	in_slot, in_slot_arg2; branch dest
+/* branch with one-argument delay slot insn */
 #define SL1(branch, dest, in_slot) \
 	in_slot; branch dest
+/* branch with comparison in delay slot */
+#define SLC(branch, dest, in_slot, in_slot_arg2) \
+        branch dest; in_slot, in_slot_arg2
+/* comparison in a delay slot, at branch destination */
+#define SLI(in_slot, in_slot_arg2) in_slot, in_slot_arg2
+#define SLCMP(branch, cmp1, cmp1arg2, cmp2, cmp2arg2) \
+	branch .+6; bra .+6; cmp2, cmp2arg2; cmp1, cmp1arg2
+#define DMULU_SAVE \
+ mov.l r10,@-r15; \
+ mov.l r11,@-r15; \
+ mov.l r12,@-r15; \
+ mov.l r13,@-r15
+#define DMULUL(m1, m2, rl) \
+ swap.w m1,r12; \
+ mulu.w r12,m2; \
+ swap.w m2,r13; \
+ sts macl,r10; \
+ mulu.w r13,m1; \
+ clrt; \
+ sts macl,r11; \
+ mulu.w r12,r13; \
+ addc r11,r10; \
+ sts macl,r12; \
+ mulu.w m1,m2; \
+ movt r11; \
+ sts macl,rl; \
+ mov r10,r13; \
+ shll16 r13; \
+ addc r13,rl; \
+ xtrct r11,r10; \
+ addc r10,r12 \
+/* N.B. the carry is cleared here.  */
+#define DMULUH(rh) mov r12,rh
+#define DMULU_RESTORE \
+ mov.l @r15+,r13; \
+ mov.l @r15+,r12; \
+ mov.l @r15+,r11; \
+ mov.l @r15+,r10
 #else /* ! __sh1__ */
+/* branch with two-argument delay slot insn */
 #define SL(branch, dest, in_slot, in_slot_arg2) \
-	branch##.s dest; in_slot, in_slot_arg2
+	branch##/s dest; in_slot, in_slot_arg2
+/* branch with one-argument delay slot insn */
 #define SL1(branch, dest, in_slot) \
 	branch##/s dest; in_slot
+/* branch with comparison in delay slot */
+#define SLC(branch, dest, in_slot, in_slot_arg2) \
+        branch##/s dest; in_slot, in_slot_arg2
+/* comparison in a delay slot, at branch destination */
+#define SLI(in_slot, in_slot_arg)
+#define SLCMP(branch, cmp1, cmp1arg2, cmp2, cmp2arg2) \
+	branch##/s .+6; cmp1, cmp1arg2; cmp2, cmp2arg2
+#define DMULU_SAVE
+#define DMULUL(m1, m2, rl) dmulu.l m1,m2; sts macl,rl
+#define DMULUH(rh) sts mach,rh
+#define DMULU_RESTORE
 #endif /* !__sh1__ */
+
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+/* don't #define DYN_SHIFT */
+  #define SHLL4(REG)	\
+	shll2	REG;	\
+	shll2	REG
+
+  #define SHLR4(REG)	\
+	shlr2	REG;	\
+	shlr2	REG
+
+  #define SHLL6(REG)	\
+	shll2	REG;	\
+	shll2	REG;	\
+	shll2	REG
+
+  #define SHLR6(REG)	\
+	shlr2	REG;	\
+	shlr2	REG;	\
+	shlr2	REG
+
+  #define SHLL12(REG)	\
+	shll8	REG;	\
+	SHLL4 (REG)
+
+  #define SHLR12(REG)	\
+	shlr8	REG;	\
+	SHLR4 (REG)
+
+  #define SHLR19(REG)	\
+	shlr16	REG;	\
+	shlr2	REG;	\
+	shlr	REG
+
+  #define SHLL23(REG)	\
+	shll16	REG;	\
+	shlr	REG;	\
+	shll8	REG
+
+  #define SHLR24(REG)	\
+	shlr16	REG;	\
+	shlr8	REG
+
+  #define SHLR21(REG)	\
+	shlr16	REG;	\
+	shll2	REG;	\
+	add	REG,REG;\
+	shlr8	REG
+
+  #define SHLL21(REG)	\
+	shll16	REG;	\
+	SHLL4 (REG);	\
+	add	REG,REG
+
+  #define SHLR11(REG)	\
+	shlr8	REG;	\
+	shlr2	REG;	\
+	shlr	REG
+
+  #define SHLR22(REG)	\
+	shlr16	REG;	\
+	shll2	REG;	\
+	shlr8	REG
+
+  #define SHLR23(REG)	\
+	shlr16	REG;	\
+	add	REG,REG;\
+	shlr8	REG
+
+  #define SHLR20(REG)	\
+	shlr16	REG;	\
+	SHLR4 (REG)
+
+  #define SHLL20(REG)	\
+	shll16	REG;	\
+	SHLL4 (REG)
+#define SHLD_COUNT(N,COUNT)
+#define SHLRN(N,COUNT,REG) SHLR##N(REG)
+#define SHLLN(N,COUNT,REG) SHLL##N(REG)
+#else
+#define SHLD_COUNT(N,COUNT) mov #N,COUNT
+#define SHLRN(N,COUNT,REG) shld COUNT,REG
+#define SHLLN(N,COUNT,REG) shld COUNT,REG
+#define DYN_SHIFT 1
+#endif
+
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/divsf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/divsf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/divsf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,404 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!divides two single precision floating point 
+
+! Author: Aanchal Khanna
+
+! Arguments: Dividend is in r4, divisor in r5
+! Result: r0
+
+! r4 and r5 are referred as op1 and op2 resp.
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align	5
+	.global	GLOBAL (divsf3)
+	FUNC (GLOBAL (divsf3))
+
+GLOBAL (divsf3):
+	mov.l	.L_mask_sign,r1
+	mov	r4,r3
+
+	xor	r5,r3
+	shll	r4
+
+	shlr	r4
+	mov.l	.L_inf,r2
+
+	and	r3,r1		!r1=resultant sign
+	mov	r4,r6
+
+	shll	r5
+	mov	#0,r0		
+
+	shlr	r5
+	and	r2,r6
+
+	cmp/eq	r2,r6
+	mov	r5,r7
+
+	and     r2,r7
+	bt	.L_op1_inv
+
+	cmp/eq	r2,r7
+	mov	#-23,r3
+
+	bt	.L_op2_inv
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLR23 (r6)
+	SHLR23 (r7)
+#else
+	shld	r3,r6
+	shld	r3,r7
+#endif
+
+	cmp/eq	r0,r4
+
+	bt	.L_op1_zero		!dividend=0
+	cmp/eq	r0,r6
+
+	mov.l   .L_imp_bit,r3
+	bt	.L_norm_op1		!normalize dividend
+.L_chk_op2:
+	cmp/eq	r0,r5
+	bt	.L_op2_zero		!divisor=0
+
+	cmp/eq	r0,r7
+	bt	.L_norm_op2		!normalize divisor
+
+.L_div1:
+	sub	r7,r6
+	add	#127,r6			!r6=resultant exponent
+
+	mov     r3,r7
+	mov.l	.L_mask_mant,r3
+
+	and	r3,r4
+	!chk exponent for overflow
+        mov.l   .L_255,r2
+
+	and     r3,r5
+	or	r7,r4
+
+	cmp/ge  r2,r6
+	or	r7,r5
+
+	bt	.L_return_inf
+	mov	r0,r2
+
+	cmp/eq  r4,r5
+	bf      .L_den_one
+
+	cmp/ge	r6,r0
+	!numerator=denominator, quotient=1, remainder=0
+	mov	r7,r2			
+
+	mov     r0,r4
+	!chk exponent for underflow
+	bt	.L_underflow
+        bra     .L_pack
+        nop
+
+.L_den_one:
+	!denominator=1, result=numerator
+
+	cmp/eq  r7,r5
+        bf      .L_divide
+
+	!chk exponent for underflow
+	cmp/ge  r6,r0
+        mov    r4,r2           
+
+        SL(bt,    .L_underflow,
+	 mov	r0,r4)
+	bra     .L_pack
+	nop
+
+.L_divide:
+	!dividing the mantissas r4<-dividend, r5<-divisor
+
+	cmp/hi	r4,r5
+	bf	.L_loop
+
+	shll	r4		! if mantissa(op1)< mantissa(op2)
+	add     #-1,r6		! shift left the numerator and decrease the exponent.
+
+.L_loop:
+	!division loop
+
+	cmp/ge	r5,r4
+	bf	.L_skip
+
+	or	r7,r2
+	sub	r5,r4
+
+.L_skip:
+	shlr	r7
+	shll	r4
+
+	cmp/eq	r0,r7
+	bf	.L_loop
+
+	!chk the exponent for underflow
+	cmp/ge  r6,r0
+	bt      .L_underflow
+	
+	!apply rounding
+	cmp/gt	r5,r4
+	bt	.L_round1
+
+	cmp/eq	r4,r5
+	bt	.L_round2
+
+.L_pack:
+	!pack the result, r1=sign, r2=quotient, r6=exponent
+
+	mov    #23,r4
+	and     r3,r2
+
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLL23 (r6)
+#else
+	shld	r4,r6
+#endif
+	or	r2,r1
+
+	or	r6,r1
+	mov	r1,r0	
+	
+	rts
+	nop
+
+.L_round1:
+	!Apply proper rounding
+
+        bra     .L_pack
+        add     #1,r2
+
+.L_round2:
+	!Apply proper rounding
+
+        mov.l   .L_comp_1,r5
+        bra     .L_pack
+        and     r5,r2
+
+.L_op1_inv:
+	!chk if op1 is Inf or NaN
+
+	mov.l	.L_mask_mant,r3
+	mov	r4,r6
+
+	and	r3,r6
+	cmp/hi	r0,r6
+
+	bt	.L_ret_op1
+	cmp/eq	r2,r7
+
+	SL(bf,	.L_ret_op1,
+	 mov	r1,r0)
+
+	rts
+	mov	#-1,r0	! 0/0, return NaN
+	
+.L_op2_inv:
+	!chk if op2 is Inf or NaN
+
+	mov.l	.L_mask_mant,r3
+	mov	r5,r7
+	
+	and	r3,r7
+	cmp/hi	r0,r7
+
+	bt	.L_ret_op2
+	mov	r1,r0
+	
+	rts
+	nop
+
+.L_op1_zero:
+	!op1 is zero. If op2 is zero, return NaN, else return zero
+
+	cmp/eq	r0,r5
+
+	bf	.L_ret_op1	
+
+	rts
+	mov	#-1,r0
+
+.L_op2_zero:
+	!B is zero,return Inf
+
+	rts
+	or	r2,r0
+
+.L_return_inf:
+	mov.l	.L_inf,r0
+	
+	rts
+	or	r1,r0
+
+.L_norm_op1:
+	!normalize dividend
+
+	shll	r4
+	tst	r2,r4
+	
+	add     #-1,r6
+	bt	.L_norm_op1
+
+	bra	.L_chk_op2
+	add	#1,r6
+
+.L_norm_op2:
+	!normalize divisor
+
+	shll	r5
+	tst	r2,r5
+	
+	add	#-1,r7
+	bt	.L_norm_op2
+
+	bra	.L_div1
+	add	#1,r7
+
+.L_underflow:
+	!denormalize the result
+
+	add	#1,r6
+	mov	#-24,r7
+
+	cmp/gt	r6,r7
+	mov	r2,r5
+
+	bt	.L_return_zero
+	add     #-1,r6
+
+	mov	#32,r3
+	neg	r6,r7
+
+	add	#1,r7
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r6,r2
+#else
+	cmp/ge	r0,r6
+	bf	.L_mov_right
+
+.L_mov_left:
+	cmp/eq	r0,r6
+	bt	.L_out
+
+	shll	r2
+	bra	.L_mov_left
+	add	#-1,r6
+
+.L_mov_right:
+	cmp/eq	r0,r6
+	bt	.L_out
+
+	add	#1,r6
+	bra	.L_mov_right
+	shlr	r2
+	
+.L_out:
+#endif
+	sub	r7,r3
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r3,r5
+#else
+	cmp/ge	r0,r3
+	bf	.L_mov_right_1
+
+.L_mov_left_1:
+	shll	r5
+	add	#-1,r3
+
+	cmp/eq	r0,r3
+	bf	.L_mov_left_1
+
+	bt	.L_out_1
+
+.L_mov_right_1:
+	cmp/eq	r0,r3
+	bt	.L_out_1
+
+	add	#1,r3
+	bra	.L_mov_right_1
+	shlr	r5
+
+.L_out_1:
+#endif
+	shlr	r2
+	addc	r0,r2
+
+	cmp/eq	r4,r0		!r4 contains the remainder
+	mov      r2,r0
+
+	mov.l	.L_mask_sign,r7
+	bf	.L_return
+
+	mov.l   .L_comp_1,r2
+	cmp/eq	r7,r5
+
+	bf	.L_return
+	and	r2,r0
+
+.L_return:
+	rts
+	or     r1,r0
+	
+.L_ret_op1:
+	rts
+	or	r4,r0
+
+.L_ret_op2:
+	rts
+	or	r5,r0
+
+.L_return_zero:
+	rts
+	or	r1,r0
+
+
+
+	.align	2
+.L_inf:
+	.long	0x7f800000
+.L_mask_sign:
+	.long	0x80000000
+.L_mask_mant:
+	.long	0x007fffff
+.L_imp_bit:
+	.long	0x00800000
+.L_comp_1:
+	.long	0xfffffffe
+.L_255:
+	.long	255
+
+ENDFUNC (GLOBAL (divsf3))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/divsf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/divsf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/divsf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,375 @@
+/* Copyright (C) 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! divsf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+
+! long 0th..3rd significant byte
+#ifdef __LITTLE_ENDIAN__
+#define L0SB	3
+#define L1SB	2
+#define L2SB	1
+#define L3SB	0
+#else
+#define L0SB	0
+#define L1SB	1
+#define L2SB	2
+#define L3SB	3
+#endif
+
+! clobbered: r0,r1,r2,r3,r6,r7,T (and for sh.md's purposes PR)
+!
+! Note: When the divisor is larger than the divident, we have to adjust the
+! exponent down by one.  We do this automatically when subtracting the entire
+! exponent/fraction bitstring as an integer, by means of the borrow from
+! bit 23 to bit 24.
+! Note: non-denormal rounding of a division result cannot cause fraction
+! overflow / exponent change. (r4 > r5 : fraction must stay in (2..1] interval;
+! r4 < r5: having an extra bit of precision available, even the smallest
+! possible difference of the result from one is rounded in all rounding modes
+! to a fraction smaller than one.)
+! sh4-200: 59 cycles
+! sh4-300: 44 cycles
+! tab indent: exponent / sign computations
+! tab+space indent: fraction computation
+FUNC(GLOBAL(divsf3))
+	.global GLOBAL(divsf3)
+	.balign	4
+GLOBAL(divsf3):
+	mov.l	LOCAL(x7f800000),r3
+	mov	#1,r2
+	mov	r4,r6
+	 shll8	 r6
+	mov	r5,r7
+	 shll8	 r7
+	rotr	r2
+	tst	r3,r4
+	or	r2,r6
+	bt/s	LOCAL(denorm_arg0)
+	or	r2,r7
+	tst	r3,r5
+	bt	LOCAL(denorm_arg1)
+	mov.l	LOCAL(x3f000000),r3	! bias minus explict leading 1
+	 div0u
+LOCAL(denorm_done):
+!	mov.l	LOCAL(x3f000000),r3	! bias minus explict leading 1
+	cmp/hs	r7,r6
+	mov.l	r8,@-r15
+	mov.l	LOCAL(xff800000),r8
+	bt		LOCAL(no_norm)
+	add  	r8,r3
+LOCAL(no_norm):
+	shlr	 r6
+	 div1	 r7,r6
+	 bt	 0f
+	 div1	r7,r6
+0:	mov.l	r9,@-r15
+	 div1	 r7,r6
+	mov	r4,r1
+	and	r8,r1
+	add	r1,r3
+	 div1	 r7,r6
+	and	r5,r8
+	sub	r8,r3	! result sign/exponent minus 1 if no overflow/underflow
+	 div1	 r7,r6
+	or	r3,r2
+	 div1	 r7,r6
+	mov.w	LOCAL(xff00),r9
+	 div1	 r7,r6
+	mov.l	r2,@-r15 ! L0SB is 0xff iff denorm / infinity exp is computed
+	 div1	 r7,r6
+	mov.w	LOCAL(m23),r2
+	 div1	 r7,r6
+	mov	r4,r0
+	 div1	 r7,r6
+	 extu.b	 r6,r1
+	 and	 r9,r6
+	 swap.w	 r1,r1	! first 8 bits of result fraction in bit 23..16
+	 div1	 r7,r6
+	shld	r2,r0
+	 div1	 r7,r6
+	mov.b	r0,@(L3SB,r15)	! 0xff iff divident was infinity / nan
+	 div1	 r7,r6
+	mov	r5,r0
+	 div1	 r7,r6
+	shld	r2,r0
+	 div1	 r7,r6
+	mov.b	r0,@(L2SB,r15)	! 0xff iff divisor was infinity / nan
+	 div1	 r7,r6
+	mov	r4,r0
+	 div1	 r7,r6
+	mov.w	LOCAL(m31),r2
+	 div1	 r7,r6
+	 extu.b	 r6,r8	! second 8 bits of result fraction in bit 7..0
+	 and	 r9,r6
+	mov.l	LOCAL(xff800000),r9
+	 div1	 r7,r6
+	xor	r5,r0	! msb := correct result sign
+	 div1	 r7,r6
+	xor	r3,r0	! xor with sign of result sign/exponent word
+	 div1	 r7,r6
+	shad	r2,r0
+	 div1	 r7,r6
+	mov.b	r0,@(L1SB,r15)	! 0xff	iff exponent over/underflows
+	and	r9,r3	! isolate sign / exponent
+	 div1	 r7,r6
+	 swap.b	r8,r0	! second 8 bits of result fraction in bit 15..8
+	 div1	 r7,r6
+	 or	r1,r0	! first 16 bits of result fraction in bit 23..8
+	 div1	 r7,r6
+	mov.w	LOCAL(m1),r9
+	 div1	 r7,r6
+	mov.l	@r15+,r8 ! load encoding of unusal exponent conditions
+	 extu.b	 r6,r1
+	 or	 r1,r0	! 24 bit result fraction with explicit leading 1
+	addc	r3,r0	! add in exponent / sign
+	cmp/str	r9,r8
+	! (no stall *here* for SH4-100 / SH4-200)
+	bt/s	LOCAL(inf_nan_denorm_zero)
+	mov.l	@r15+,r9
+	rts
+	mov.l	@r15+,r8
+
+/* The exponennt adjustment for denormal numbers is done by leaving an
+   adjusted value in r3; r4/r5 are not changed.  */
+	.balign	4
+LOCAL(denorm_arg0):
+	mov.w	LOCAL(xff00),r1
+	sub	r2,r6	! 0x800000000 : remove implict 1
+	tst	r6,r6
+	bt	LOCAL(div_zero)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	mov	r6,r0
+	shld	r0,r6
+	tst	r3,r5
+	mov.l	LOCAL(x3f800000),r3	! bias - 1 + 1
+	mov	#23,r1
+	shld	r1,r0
+	bt/s	LOCAL(denorm_arg1_2)
+	sub	r0,r3
+	bra	LOCAL(denorm_done)
+	 div0u
+
+LOCAL(denorm_arg1):
+	mov.l	LOCAL(x3f000000),r3	! bias - 1
+LOCAL(denorm_arg1_2):
+	sub	r2,r7	! 0x800000000 : remove implict 1
+	mov.w	LOCAL(xff00),r1
+	tst	r7,r7
+	bt	LOCAL(div_by_zero)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	mov	r7,r0
+	shld	r0,r7
+	add	#-1,r0
+	mov	#23,r1
+	shld	r1,r0
+	add	r0,r3
+	bra	LOCAL(denorm_done)
+	 div0u
+
+	.balign	4
+LOCAL(inf_nan_denorm_zero):
+! r0 has the rounded result, r6 has the non-rounded lowest bits & rest.
+! the bit just below the LSB of r6 is available as ~Q
+
+! Alternative way to get at ~Q:
+! if rounding took place, ~Q must be set.
+! if the rest appears to be zero, ~Q must be set.
+! if the rest appears to be nonzero, but rounding didn't take place,
+! ~Q must be clear;  the apparent rest will then require adjusting to test if 
+! the actual rest is nonzero.
+	mov	r0,r2
+	not	r8,r0
+	tst	#0xff,r0
+	shlr8	r0
+	mov.l	@r15+,r8
+	bt/s	LOCAL(div_inf_or_nan)
+	tst	#0xff,r0
+	mov	r4,r0
+	bt	LOCAL(div_by_inf_or_nan)
+	add	r0,r0
+	mov	r5,r1
+	add	r1,r1
+	cmp/hi	r1,r0
+	mov	r6,r0
+	bt	LOCAL(overflow)
+	sub	r2,r0
+	exts.b	r0,r0	! -1 if rounding took place
+	shlr8	r6	! isolate div1-mangled rest
+	addc	r2,r0	! generate carry if rounding took place
+	shlr8	r7
+	mov.l	LOCAL(xffffff),r1
+	sub	r3,r0	! pre-rounding fraction
+	bt	0f ! going directly to denorm_sticky would cause mispredicts
+	tst	r6,r6	! rest can only be zero if lost bit was set
+0:	add	r7,r6	! (T ? corrupt : reconstruct) actual rest
+	bt	0f
+	and r1,r6
+	cmp/pl	r6
+0:	mov.w	LOCAL(m24),r1
+	addc	r0,r0	! put in sticky bit
+	add	#-1,r3
+	mov.l	LOCAL(x80000000),r6
+	add	r3,r3
+	mov	r0,r2
+	shad	r1,r3	! exponent ; s32.0
+	!
+	cmp/pl	r3
+	bt/s	LOCAL(zero_nan)	! return zero
+	clrt
+	shld	r3,r0
+	add	#31,r3
+	cmp/pl	r3
+	shld	r3,r2
+	bf	LOCAL(zero_nan)	! return zero
+	rotl	r2
+	cmp/hi	r6,r2
+	mov	#0,r7
+	addc	r7,r0
+	shll	r0
+	div0s	r4,r5
+	rts
+	rotcr	r0
+	
+! ????
+! undo normal rounding (lowest bits still in r6). then do denormal rounding.
+	
+LOCAL(overflow):
+	mov.l	LOCAL(xff000000),r0
+	div0s	r4,r5
+	rts
+	rotcr	r0
+	
+LOCAL(div_inf_or_nan):
+	mov	r4,r0
+	bra	LOCAL(nan_if_t)
+	add	r0,r0
+	
+LOCAL(div_by_inf_or_nan):
+	mov.l	LOCAL(xff000000),r1
+	mov	#0,r0
+	mov	r5,r2
+	add	r2,r2
+	bra	LOCAL(nan_if_t)
+	cmp/hi	r1,r2
+
+
+
+! still need to check for divide by zero or divide by nan
+! r3: 0x7f800000
+	.balign	4
+LOCAL(div_zero):
+	mov	r5,r1
+	add	r1,r1
+	tst	r1,r1	! 0 / 0 -> nan
+	bt	LOCAL(nan)
+	add	r3,r3
+	cmp/hi	r3,r1	! 0 / nan -> nan (but 0 / inf -> 0)
+LOCAL(zero_nan):
+	mov	#0,r0
+LOCAL(nan_if_t):
+	bf	0f:
+LOCAL(nan):
+	mov	#-1,r0
+0:	div0s	r4,r5	! compute sign
+	rts
+	rotcr	r0	! insert sign
+
+LOCAL(div_by_zero):
+	mov.l	LOCAL(xff000000),r0
+	mov	r4,r2
+	add	r2,r2
+	bra	LOCAL(nan_if_t)
+	cmp/hi	r0,r2
+	
+	.balign	4
+LOCAL(clz):
+	mov.l	r8,@-r15
+	extu.w	r0,r8
+	mov.l	r9,@-r15
+	cmp/eq	r0,r8
+	bt/s	0f
+	mov	#32,r9
+	shlr16	r0
+	extu.w	r0,r8
+	add	#-16,r9
+0:	tst	r1,r8	! 0xff00
+	mov.l	LOCAL(c_clz_tab),r0
+	bt	0f
+	shlr8	r8
+0:	bt	0f
+	add	#-8,r9
+0:
+#ifdef	__PIC__
+	add	r0,r8
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r8),r8
+	mov	r9,r0
+	mov.l	@r15+,r9
+	!
+	!
+	!
+	sub	r8,r0
+	mov.l	@r15+,r8
+	rts
+	lds.l	@r15+,pr
+
+!	We encode even some words as pc-relative that would fit as immediate
+!	in the instruction in order to avoid some pipeline stalls on
+!	SH4-100 / SH4-200.
+LOCAL(m23):	.word -23
+LOCAL(m24):	.word -24
+LOCAL(m31):	.word -31
+LOCAL(xff01):	.word 0xff01
+	.balign	4
+LOCAL(xff000000): .long 0xff000000
+#ifdef __LITTLE_ENDIAN__
+LOCAL(xff00):	.word 0xff00
+LOCAL(m1):	.word -1
+#else
+LOCAL(m1):	.word -1
+LOCAL(xff00):	.word 0xff00
+#endif
+LOCAL(xffffff): .long 0xffffff
+LOCAL(x7f800000): .long 0x7f800000
+LOCAL(x3f000000): .long 0x3f000000
+LOCAL(x3f800000): .long 0x3f800000
+LOCAL(xff800000): .long 0xff800000
+LOCAL(x40000000): .long 0x40000000
+LOCAL(x80000000): .long 0x80000000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(divsf3))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/divdf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/divdf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/divdf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,668 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! divdf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke joern.rennecke@st.com
+
+/* y = 1/x  ; x (- [1,2)
+   y0 = 1.5 - x/2 - tab[(1-x)*64] = y + d ; abs(d)/y <= 0x1.0c/256
+
+   y1 = y0 - ((y0) * x - 1) * y0  =  y-x*d^2
+   y2 = y1 - ((y1) * x - 1) * y1 =~= y-x^3*d^4
+
+   z0 = y2*a ;  a1 = a - z0*x /# 32 * 64 -> 64 bit #/
+   z1 = y2*a1 (round to nearest odd 0.5 ulp);
+   a2 = a1 - z1*x /# 32 * 64 -> 64 bit #/
+
+   z = a/x = z0 + z1 - 0.5 ulp + (a2 > 0) * ulp
+
+   Unless stated otherwise, multiplies can be done in 32 * 32 bit or less
+   with suitable scaling and/or top truncation.
+   We use a slightly modified algorithm here that checks if the lower
+   bits in z1 are sufficient to determine the outcome of rounding - in that
+   case a2 is not computed.
+   -z1 is computed in units of 1/128 ulp, with an error in the range
+   -0x3.e/128 .. +0 ulp.
+   Thus, after adding three, the result can be safely rounded for normal
+   numbers if any of the bits 5..2 is set, or if the highest guard bit
+   (bit 6 if y <1, otherwise bit 7) is set.
+   (Because of the way truncation works, we would be fine for an open
+    error interval of (-4/128..+1/128) ulp )
+   For denormal numbers, the rounding point lies higher, but it would be
+   quite cumbersome to calculate where exactly; it is sufficient if any
+   of the bits 7..3 is set.
+   x truncated to 20 bits is sufficient to calculate y0 or even y1.
+   Table entries are adjusted by about +128 to use full signed byte range.
+   This adjustment has been perturbed slightly to allow cse with the
+   shift count constant -26.
+   The threshold point for the shift adjust before rounding is found by
+   comparing the fractions, which is exact, unlike the top bit of y2.
+   Therefore, the top bit of y2 becomes slightly random after the adjustment
+   shift, but that's OK because this can happen only at the boundaries of
+   the interval, and the biasing of the error means that it can in fact happen
+   only at the bottom end.  And there, the carry propagation will make sure
+   that in the end we will have in effect an implicit 1 (or two whem rounding
+   up...)  */
+/* If an exact result exists, it can have no more bits than the divident.
+   Hence, we don't need to bother with the round-to-even tie breaker
+   unless the result is denormalized.  */
+/* 64 cycles through main path for sh4-300 (about 93.7% of normalized numbers),
+   82 for the path for rounding tie-breaking for normalized numbers
+   (including one branch mispredict).
+   Some cycles might be saved by more careful register allocation.  */
+
+#define x_h r12
+#define yn  r3
+
+FUNC(GLOBAL(divdf3))
+ .global GLOBAL(divdf3)
+
+/* Adjust arg0 now, too.  We still have to come back to denorm_arg1_done,
+   since we heven't done any of the work yet that we do till the denorm_arg0
+   entry point.  We know that neither of the arguments is inf/nan, but
+   arg0 might be zero.  Check for that first to avoid having to establish an
+   rts return address.  */
+LOCAL(both_denorm):
+	mov.l	r9,@-r15
+	mov	DBL0H,r1
+	mov.l	r0,@-r15
+	shll2	r1
+	mov.w LOCAL(both_denorm_cleanup_off),r9
+	or	DBL0L,r1
+	tst	r1,r1
+	mov	DBL0H,r0
+	bf/s	LOCAL(zero_denorm_arg0_1)
+	shll2	r0
+	mov.l	@(4,r15),r9
+	add	#8,r15
+	bra	LOCAL(ret_inf_nan_0)
+	mov	r1,DBLRH
+
+LOCAL(both_denorm_cleanup):
+	mov.l	@r15+,r0
+	!
+	mov.l	@r15+,r9
+ mov	#12,r3
+ mov.l	LOCAL(xfffe2006),r1	! yn := (-1. << 17) + (0x80 << 6) ; shift #-26
+	bra	LOCAL(denorm_arg1_done)
+	!
+	add	r0,DBL0H
+
+/* Denorm handling leaves the incoming denorm argument with an exponent of +1
+   (implicit 1).  To leave the result exponent unaltered, the other
+   argument's exponent is adjusted by the the shift count.  */
+
+	.balign 4
+LOCAL(arg0_tiny):
+	bsr	LOCAL(clz)
+	mov	DBL0L,r0
+	shll	DBL0H
+	add	#1,r0
+	mov	DBL0L,DBL0H
+	shld	r0,DBL0H
+	rotcr	DBL0H
+	
+	cmp/pl r0
+	bf/s	LOCAL(a0t_dpt_neg)
+	tst	DBL0L,DBL0L	/* Check for divide of zero.  */
+	add	#-32,r0
+	shld	r0,DBL0L
+	bf/s	LOCAL(adjust_arg1_exp)
+	add	#63,r0
+	bra 	LOCAL(return_0)
+	nop
+
+LOCAL(a0t_dpt_neg):
+	add 	#31,r0
+	bf/s	LOCAL(adjust_arg1_exp)
+	shld	r0,DBL0L
+		  
+LOCAL(return_0): /* Return 0 with appropriate sign.  */
+	mov.l	@r15+,r10
+	mov	#0,DBLRH
+	mov.l	@r15+,r9
+	bra	LOCAL(ret_inf_nan_0)
+	mov.l	@r15+,r8
+
+	.balign 4
+LOCAL(arg1_tiny):
+	bsr	LOCAL(clz)
+	mov	DBL1L,r0
+	shll	DBL1H
+	add	#1,r0
+	mov	DBL1L,DBL1H
+	shld	r0,DBL1H
+	rotcr	DBL1H
+
+	cmp/pl r0
+	bf/s	LOCAL(a1t_dpt_neg)
+	tst	DBL1L,DBL1L	/* Check for divide by zero.  */
+	add	#-32,r0
+	shld	r0,DBL1L
+	bf/s	LOCAL(adjust_arg0_exp)
+	add	#63,r0
+	bra 	LOCAL(a1t_end)
+	nop
+
+LOCAL(a1t_dpt_neg):
+	add 	#31,r0
+	bf/s	LOCAL(adjust_arg0_exp)
+	shld	r0,DBL1L
+	
+LOCAL(a1t_end):		  		  
+	mov	DBL0H,r0
+	add	r0,r0
+	tst	r0,r0	! 0 / 0 ?
+	mov	#-1,DBLRH
+	bf	LOCAL(return_inf)
+	!
+	tst   DBL0L,DBL0L
+	bf	LOCAL(return_inf)
+	bt	LOCAL(ret_inf_nan_0)
+	!
+
+	.balign 4
+LOCAL(zero_denorm_arg1):
+	not	DBL0H,r3
+	mov	DBL1H,r0
+	tst	r2,r3
+	shll2	r0
+	bt	LOCAL(early_inf_nan_arg0)
+	tst	r0,r0
+	mov.w	LOCAL(xff00),r12
+	bt/s	LOCAL(arg1_tiny)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	shlr2	r0
+	!
+	shll	DBL1H
+	mov	DBL1L,r3
+	shld	r0,DBL1H
+	shld	r0,DBL1L
+	rotcr	DBL1H
+	add	#-32,r0
+	shld	r0,r3
+	add	#32,r0
+	or	r3,DBL1H
+LOCAL(adjust_arg0_exp):
+	tst	r2,DBL0H
+	mov	#20,r3
+	shld	r3,r0
+	bt	LOCAL(both_denorm)
+	add	DBL0H,r0
+	div0s	r0,DBL0H	! Check for obvious overflow.  */
+	not	r0,r3		! Check for more subtle overflow - lest
+	bt	LOCAL(return_inf)
+	mov	r0,DBL0H
+	tst	r2,r3		! we mistake it for NaN later
+	mov	#12,r3
+	bf	LOCAL(denorm_arg1_done)
+LOCAL(return_inf): /* Return infinity with appropriate sign.  */
+	mov	#20,r3
+	mov	#-2,DBLRH
+	bra	LOCAL(ret_inf_nan_0)
+	shad	r3,DBLRH
+
+/* inf/n -> inf; inf/0 -> inf; inf/inf -> nan; inf/nan->nan  nan/x -> nan */
+LOCAL(inf_nan_arg0):
+	mov.l	@r15+,r10
+	mov.l	@r15+,r9
+	mov.l	@r15+,r8
+LOCAL(early_inf_nan_arg0):
+	not	DBL1H,r3
+	mov	DBL0H,DBLRH
+	tst	r2,r3	! both inf/nan?
+	add	DBLRH,DBLRH
+	bf	LOCAL(ret_inf_nan_0)
+	mov	#-1,DBLRH
+LOCAL(ret_inf_nan_0):
+	mov	#0,DBLRL
+	mov.l	@r15+,r12
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+	
+/* Already handled: inf/x, nan/x .  Thus: x/inf -> 0; x/nan -> nan */
+	.balign	4
+LOCAL(inf_nan_arg1):
+	mov	DBL1H,r2
+	mov	#12,r1
+	shld	r1,r2
+	mov.l	@r15+,r10
+	mov	#0,DBLRL
+	mov.l	@r15+,r9
+	or	DBL1L,r2
+	mov.l	@r15+,r8
+	cmp/hi	DBLRL,r2
+	mov.l	@r15+,r12
+	subc	DBLRH,DBLRH
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+	
+	.balign 4
+LOCAL(zero_denorm_arg0):
+	mov.w	LOCAL(denorm_arg0_done_off),r9
+	not	DBL1H,r1
+	mov	DBL0H,r0
+	tst	r2,r1
+	shll2	r0
+	bt	LOCAL(inf_nan_arg1)
+LOCAL(zero_denorm_arg0_1):
+	tst	r0,r0
+	mov.w	LOCAL(xff00),r12
+	bt/s	LOCAL(arg0_tiny)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	shlr2	r0
+	shll	DBL0H
+	mov	DBL0L,r12
+	shld	r0,DBL0H
+	shld	r0,DBL0L
+	rotcr	DBL0H
+	add	#-32,r0
+	shld	r0,r12
+	add	#32,r0
+	or	r12,DBL0H
+LOCAL(adjust_arg1_exp):
+	mov	#20,r12
+	shld	r12,r0
+	add	DBL1H,r0
+	div0s	r0,DBL1H	! Check for obvious underflow.  */
+	not	r0,r12		! Check for more subtle underflow - lest
+	bt	LOCAL(return_0)
+	mov	r0,DBL1H
+	tst	r2,r12		! we mistake it for NaN later
+	bt	LOCAL(return_0)
+	!
+	braf	r9
+	mov	#13,r0
+LOCAL(zero_denorm_arg1_dispatch):
+
+LOCAL(xff00):	.word 0xff00
+LOCAL(denorm_arg0_done_off):
+	.word LOCAL(denorm_arg0_done)-LOCAL(zero_denorm_arg1_dispatch)
+LOCAL(both_denorm_cleanup_off):
+	.word LOCAL(both_denorm_cleanup)-LOCAL(zero_denorm_arg1_dispatch)
+
+ .balign	8
+GLOBAL(divdf3):
+ mov.l	LOCAL(x7ff00000),r2
+ mov	#12,r3
+ mov.l	LOCAL(xfffe2006),r1	! yn := (-1. << 17) + (0x80 << 6) ; shift #-26
+ tst	r2,DBL1H
+ mov.l	r12,@-r15
+ bt	LOCAL(zero_denorm_arg1)
+
+LOCAL(denorm_arg1_done):
+ mov	DBL1H,x_h	! x_h live in r12
+ shld	r3,x_h	! x - 1 ; u0.20
+ mov	x_h,yn
+ mova	LOCAL(ytab),r0
+ mov.l	r8,@-r15
+ shld	r1,yn	! x-1 ; u26.6
+ mov.b	@(r0,yn),yn
+ mov	#6,r0
+ mov.l	r9,@-r15
+ mov	x_h,r8
+ mov.l	r10,@-r15
+ shlr16	x_h	! x - 1; u16.16	! x/2 - 0.5 ; u15.17
+ add	x_h,r1	! SH4-200 single-issues this insn
+ shld	r0,yn
+ sub	r1,yn	! yn := y0 ; u15.17
+ mov	DBL1L,r1
+ mov	#-20,r10
+ mul.l	yn,x_h	! r12 dead
+ swap.w	yn,r9
+ shld	r10,r1
+ sts	macl,r0	! y0 * (x-1) - n ; u-1.32
+ add	r9,r0	! y0 * x - 1     ; s-1.32
+ tst	r2,DBL0H
+ dmuls.l r0,yn
+ mov.w	LOCAL(d13),r0
+ or	r1,r8	! x  - 1; u0.32
+ add	yn,yn	! yn = y0 ; u14.18
+ bt	LOCAL(zero_denorm_arg0)
+
+LOCAL(denorm_arg0_done):
+ sts	mach,r1	!      d0 ; s14.18
+ sub	r1,yn	! yn = y1 ; u14.18 ; <= 0x3fffc
+ mov	DBL0L,r12
+ shld	r0,yn	! yn = y1 ; u1.31 ; <= 0x7fff8000
+ mov.w	LOCAL(d12),r9
+ dmulu.l yn,r8
+ shld	r10,r12
+ mov	yn,r0
+ mov	DBL0H,r8
+ add	yn,yn	! yn = y1 ; u0.32 ; <= 0xffff0000
+ sts	mach,r1	! y1 * (x-1); u1.31
+ add	r0,r1	! y1 * x    ; u1.31
+ dmulu.l yn,r1
+ not	DBL0H,r10
+ shld	r9,r8
+ tst	r2,r10
+ or	r8,r12	! a - 1; u0.32
+ bt	LOCAL(inf_nan_arg0)
+ sts	mach,r1	! d1+yn; u1.31
+ sett		! adjust y2 so that it can be interpreted as s1.31
+ not	DBL1H,r10
+ subc	r1,yn	! yn := y2 ; u1.31 ; can be 0x7fffffff
+ mov.l	LOCAL(x001fffff),r9
+ dmulu.l yn,r12
+ tst	r2,r10
+ or	DBL1H,r2
+ bt	LOCAL(inf_nan_arg1)
+ mov.l	r11,@-r15
+ sts	mach,r12	! y2*(a-1) ; u1.31
+ add	yn,r12		! z0       ; u1.31
+ dmulu.l r12,DBL1L
+ mov.l	LOCAL(x40000000),DBLRH ! bias + 1
+ and	r9,r2		! x ; u12.20
+ cmp/hi	DBL0L,DBL1L
+ sts	macl,r8
+ mov	#-24,r11
+ sts	mach,r9 	! r9:r8 := z0 * DBL1L; u-19.64
+ 
+ subc	DBL1H,DBLRH
+ mul.l	r12,r2  	! (r9+macl):r8 == z0*x; u-19.64
+ shll	r8
+ add	DBL0H,DBLRH	! result sign/exponent + 1
+ mov	r8,r10
+ sts	macl,DBLRL
+ add	DBLRL,r9
+ rotcl	r9		! r9:r8 := z*x; u-20.63
+ shld	r11,r10
+
+! mov.l	LOCAL(xfff00000),DBLRL
+! mov DBL1H,r11
+! and DBLRL,r11
+! subc r11,DBLRH
+! add DBL0H,DBLRH
+		  
+ mov.l	LOCAL(x7fe00000),DBLRL
+ sub	DBL0L,r9	! r9:r8 := -a ; u-20.63
+ cmp/pz	r9		! In corner cases this shift can loose ..
+ shll8	r9		!  .. the sign, so check it first.
+ mov.l	LOCAL(x00200000),r11
+ !mov.l	LOCAL(x00100000),r11
+ or	r10,r9	! -a1 ; s-28.32
+ mov.l	LOCAL(x00100000),r10
+ dmulu.l r9,yn	! sign for r9 is in T
+ xor	DBL0H,DBL1H	! calculate expected sign & bit20
+ mov.w	LOCAL(d120),DBL0H ! to test bits 6..4
+ xor	DBLRH,DBL1H
+ !
+ sts	mach,DBL0L	! -z1 ; s-27.32
+ bt 0f
+ sub	yn,DBL0L	! multiply adjust for -a1 negative; r3 dies here
+0:tst	r10,DBL1H		! set T if a >= x
+ mov.l LOCAL(xfff00000),r3
+ bt	0f
+ add	DBL0L,DBL0L	! z1 ; s-27.32 / s-28.32
+0:bt 0f
+ add	r12,r12	! z0 ; u1.31 / u0.31
+0:add	#6-64,DBL0L
+ and	r3,DBLRH	! isolate sign / exponent
+ tst	DBL0H,DBL0L
+ bf/s	LOCAL(exact)	! make the hot path taken for best branch prediction
+ cmp/pz	DBL1H
+
+! Unless we follow the next branch, we need to test which way the rounding
+! should go.
+! For normal numbers, we know that the result is not exact, so the sign
+! of the rest will be conclusive.
+! We generate a number that looks safely rounded so that denorm handling
+! can safely test the number twice.
+! r10:r8 == 0 will indicate if the number was exact, which can happen
+! when we come here for denormals to check a number that is close or
+! equal to a result in whole ulps.
+ bf	LOCAL(ret_denorm_inf)	! denorm or infinity, DBLRH has inverted sign
+ add	#64,DBL0L
+LOCAL(find_adjust): tst	r10,DBL1H ! set T if a >= x
+ mov	#-2,r10
+ addc	r10,r10
+ mov	DBL0L,DBLRL	! z1 ; s-27.32 / s-28.32 ; lower 4 bits unsafe.
+ shad	r10,DBLRL	! tentatively rounded z1 ; s-24.32
+ shll8	r8		! r9:r8 := -a1 ; s-28.64
+ clrt
+ dmuls.l DBLRL,DBL1L	! DBLRL signed, DBL1L unsigned
+ mov	r8,r10
+ shll16	r8		! r8  := lowpart  of -a1 ; s-44.48
+ xtrct	r9,r10		! r10 := highpart of -a1 ; s-44.48
+ !
+ sts	macl,r3
+ subc	r3,r8
+ sts	mach,r3
+ subc	r3,r10
+ cmp/pz	DBL1L
+ mul.l	DBLRL,r2
+ bt	0f
+ sub	DBLRL,r10	! adjust for signed/unsigned multiply
+0: mov.l	LOCAL(x7fe00000),DBLRL
+ mov	#-26,r2
+ sts	macl,r9
+ sub	r9,r10		! r10:r8 := -a2
+ add	#-64+16,DBL0L	! the denorm code negates this adj. for exact results
+ shld	r2,r10		! convert sign into adjustment in the range 32..63
+ sub	r10,DBL0L
+ cmp/pz	DBL1H
+
+ .balign 4
+LOCAL(exact):
+ bf	LOCAL(ret_denorm_inf)	! denorm or infinity, DBLRH has inverted sign
+ tst	DBLRL,DBLRH
+ bt	LOCAL(ret_denorm_inf)	! denorm, DBLRH has correct sign
+ mov	#-7,DBL1H
+ cmp/pz	DBL0L		! T is sign extension of z1
+ not	DBL0L,DBLRL
+ subc	r11,DBLRH	! calculate sign / exponent minus implicit 1 minus T
+ mov.l	@r15+,r11
+ mov.l	@r15+,r10
+ shad	DBL1H,DBLRL
+ mov.l	@r15+,r9
+ mov	#-11,DBL1H
+ mov	r12,r8		! z0 contributes to DBLRH and DBLRL
+ shld	DBL1H,r12
+ mov	#21,DBL1H
+ clrt
+ shld	DBL1H,r8
+ addc	r8,DBLRL
+ mov.l	@r15+,r8
+ addc	r12,DBLRH
+ rts
+ mov.l	@r15+,r12
+
+!	sign in DBLRH ^ DBL1H
+! If the last 7 bits are in the range 64..64+7, we might have an exact
+! value in the preceding bits - or we might not. For denorms, we need to
+! find out.
+! if r10:r8 is zero, we just have found out that there is an exact value.
+	.balign	4
+LOCAL(ret_denorm_inf):
+	mov	DBLRH,r3
+	add	r3,r3
+	div0s	DBL1H,r3
+!	mov	#248,DBLRL
+	mov	#120,DBLRL
+	bt	LOCAL(ret_inf_late)
+	add	#64,DBL0L
+	tst	DBLRL,DBL0L
+	mov	#-21,DBLRL
+	bt	LOCAL(find_adjust)
+	or	r10,r8
+!	add	#-64,DBL0L
+	tst	r8,r8		! check if find_adjust found an exact value.
+	shad	DBLRL,r3
+	bf	0f
+	add	#-16,DBL0L	! if yes, cancel adjustment
+0:	mov	#-8,DBLRL	! remove the three lowest (inexact) bits
+	and	DBLRL,DBL0L
+	add	#-2-11,r3	! shift count for denorm generation
+	neg 	DBL0L,DBL0L
+	mov	#-28,r2
+	mov	DBL0L,DBLRL
+	mov.l	@r15+,r11
+	mov.l	@r15+,r10
+	shll2	DBLRL
+	mov.l	@r15+,r9
+	shad	r2,DBL0L
+	mov.l	@r15+,r8
+	mov	#-31,r2
+	cmp/ge	r2,r3
+	shll2	DBLRL
+	bt/s	0f
+	add	DBL0L,r12	! fraction in r12:DBLRL ; u1.63
+	mov	#0,r2
+	cmp/hi r2,DBLRL
+	mov	#-33,r2
+	add	#31,r3
+	mov	r12,DBLRL
+	rotcl	DBLRL		! put in sticky bit
+	movt	r12
+	cmp/ge	r3,r2
+	bt	LOCAL(test1)
+0:	div0s	DBL1H,DBLRH	! calculate sign
+	mov	r12,DBLRH
+	shld	r3,DBLRH
+	mov	DBLRL,r2
+	shld	r3,DBLRL
+	add	#32,r3
+	add	DBLRH,DBLRH
+	mov.l	LOCAL(x80000000),DBL1H
+	shld	r3,r12
+	rotcr	DBLRH		! combine sign with highpart
+	add	#-1,r3
+	shld	r3,r2
+	mov	#0,r3
+	rotl	r2
+	cmp/hi	DBL1H,r2
+	addc	r12,DBLRL
+	mov.l	@r15+,r12
+	rts
+	addc	r3,DBLRH
+
+LOCAL(test1):
+	cmp/ge	r2,r3
+	bf/s	LOCAL(return_0_late)
+	div0s	DBL1H,DBLRH
+	mov #0,DBLRH
+	mov	DBLRL,r2
+	mov #0,DBLRL
+	rotcr	DBLRH		! combine sign with highpart
+	mov	#0,r3
+	rotl	r2
+	cmp/hi	r3,r2
+	addc	r3,DBLRL
+	mov.l	@r15+,r12
+	rts
+	addc	r3,DBLRH
+		  
+		  
+LOCAL(ret_inf_late):
+	mov.l	@r15+,r11
+	mov.l	@r15+,r10
+	mov	DBLRH,DBL0H
+	mov.l	@r15+,r9
+	bra	LOCAL(return_inf)
+	mov.l	@r15+,r8
+
+LOCAL(return_0_late):
+	div0s	DBLRH,DBL1H
+	mov.l	@r15+,r12
+	mov	#0,DBLRH
+	mov	#0,DBLRL
+	rts
+	rotcr	DBLRH
+
+	
+	
+	.balign	4
+LOCAL(clz):
+	mov.l	r8,@-r15
+	extu.w	r0,r8
+	mov.l	r9,@-r15
+	cmp/eq	r0,r8
+	bt/s	0f
+	mov	#21,r9
+	shlr16	r0
+	extu.w	r0,r8
+	add	#-16,r9
+0:	tst	r12,r8	! 0xff00
+	mov.l	LOCAL(c_clz_tab),r0
+	bt	0f
+	shlr8	r8
+0:	bt	0f
+	add	#-8,r9
+0:
+#ifdef	__PIC__
+	add	r0,r8
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r8),r8
+	mov	r9,r0
+	mov.l	@r15+,r9
+	!
+	!
+	!
+	sub	r8,r0
+	mov.l	@r15+,r8
+	rts
+	lds.l	@r15+,pr
+
+!	We encode even some words as pc-relative that would fit as immediate
+!	in the instruction in order to avoid some pipeline stalls on
+!	SH4-100 / SH4-200.
+LOCAL(d1):	.word 1
+LOCAL(d12):	.word 12
+LOCAL(d13):	.word 13
+LOCAL(d120):	.word 120
+
+	.balign 4
+LOCAL(x7ff00000): .long 0x7ff00000
+LOCAL(xfffe2006): .long 0xfffe2006
+LOCAL(x001fffff): .long 0x001fffff
+LOCAL(x40000000): .long 0x40000000
+LOCAL(x7fe00000): .long 0x7fe00000
+LOCAL(x00100000): .long 0x00100000
+LOCAL(x00200000): .long 0x00200000
+LOCAL(xfff00000): .long 0xfff00000
+LOCAL(x80000000): .long 0x80000000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+LOCAL(ytab):
+        .byte   120, 105,  91,  78,  66,  54,  43,  33
+        .byte    24,  15,   8,   0,  -5, -12, -17, -22
+        .byte   -27, -31, -34, -37, -40, -42, -44, -45
+        .byte   -46, -46, -47, -46, -46, -45, -44, -42
+        .byte   -41, -39, -36, -34, -31, -28, -24, -20
+        .byte   -17, -12,  -8,  -4,   0,   5,  10,  16
+        .byte    21,  27,  33,  39,  45,  52,  58,  65
+        .byte    72,  79,  86,  93, 101, 109, 116, 124
+ENDFUNC(GLOBAL(divdf3))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/floatunssisf.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/floatunssisf.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/floatunssisf.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,94 @@
+/* Copyright (C) 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! floatsisf for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+
+FUNC(GLOBAL(floatunsisf))
+	.global GLOBAL(floatunsisf)
+	.balign	4
+GLOBAL(floatunsisf):
+	mov.l	LOCAL(c_clz_tab),r0
+	extu.w	r4,r1
+	mov.w	LOCAL(xff00),r3
+	cmp/eq	r4,r1
+	mov	#24,r2
+	bt	0f
+	mov	r4,r1
+	shlr16	r1
+	add	#-16,r2
+0:	tst	r3,r1	! 0xff00
+	bt	0f
+	shlr8	r1
+0:	bt	0f
+	add	#-8,r2
+0:
+#ifdef	__PIC__
+	add	r0,r1
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r1),r1
+	mov	r4,r0
+	mov.l	LOCAL(x4a800000),r3	! bias + 23 - implicit 1
+	tst	r4,r4
+	bt	LOCAL(ret0)
+	!
+	sub	r1,r2
+	mov.l	LOCAL(x80000000),r1
+	shld	r2,r0
+	cmp/pz	r2
+	add	r3,r0
+	bt	LOCAL(noround)
+	add	#31,r2
+	shld	r2,r4
+	rotl	r4
+	add	#-31,r2
+	cmp/hi	r1,r4
+	mov	#0,r3
+	addc	r3,r0
+LOCAL(noround):
+	mov	#23,r1
+	shld	r1,r2
+	rts
+	sub	r2,r0
+LOCAL(ret0):
+	rts
+	nop
+
+LOCAL(xff00):	.word 0xff00
+	.balign	4
+LOCAL(x4a800000): .long 0x4a800000
+LOCAL(x80000000): .long 0x80000000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(floatunsisf))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/floatunssidf.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/floatunssidf.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/floatunssidf.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,96 @@
+/* Copyright (C) 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! floatunssidf for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+
+FUNC(GLOBAL(floatunsidf))
+	.global GLOBAL(floatunsidf)
+	.balign	4
+GLOBAL(floatunsidf):
+	mov.l	LOCAL(c_clz_tab),r0
+	extu.w	r4,r1
+	mov.w	LOCAL(0xff00),r3
+	cmp/eq	r4,r1
+	mov	#21,r2
+	bt	0f
+	mov	r4,r1
+	shlr16	r1
+	add	#-16,r2
+0:	tst	r3,r1	! 0xff00
+	bt	0f
+	shlr8	r1
+0:	bt	0f
+	add	#-8,r2
+0:
+#ifdef	__PIC__
+	add	r0,r1
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r1),r5
+	mov	r4,DBLRL
+	mov.l	LOCAL(x41200000),r3	! bias + 20 - implicit 1
+	tst	r4,r4
+	mov	r4,DBLRH
+	bt	LOCAL(ret0)
+	sub	r5,r2
+	mov	r2,r5
+	shld	r2,DBLRH
+	cmp/pz	r2
+	add	r3,DBLRH
+	add	#32,r2
+	shld	r2,DBLRL
+	bf	0f
+	mov.w	LOCAL(d0),DBLRL
+0:	mov	#20,r2
+	shld	r2,r5
+	rts
+	sub	r5,DBLRH
+LOCAL(ret0):
+	mov	r4,DBLRL
+	rts
+	mov	r4,DBLRH
+
+LOCAL(0xff00):	.word  0xff00
+	.balign	4
+LOCAL(x41200000):
+#ifdef __LITTLE_ENDIAN__
+LOCAL(d0):	  .word 0
+		  .word 0x4120
+#else
+		  .word 0x4120
+LOCAL(d0):	  .word 0
+#endif
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(floatunsidf))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/divdf3-rt.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/divdf3-rt.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/divdf3-rt.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,519 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! divdf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke joern.rennecke@st.com
+
+/* This version is not quite finshed, since I've found that I can
+   get better average performance with a slightly altered algorithm.
+   Still, if you want a version for hard real time, this version here might
+   be a good starting point, since it has effectively no conditional
+   branches in the path that deals with normal numbers
+   (branches with zero offset are effectively conditional execution),
+   and thus it has a uniform execution time in this path.  */
+
+/* y = 1/x  ; x (- [1,2)
+   y0 = 1.5 - x/2 - tab[(1-x)*64] = y + d ; abs(d)/y <= 0x1.0c/256
+
+   y1 = y0 - ((y0) * x - 1) * y0  =  y-x*d^2
+   y2 = y1 - ((y1) * x - 1) * y1 =~= y-x^3*d^4
+
+   z0 = y2*a ;  a1 = a - z0*x /# 32 * 64 -> 64 bit #/
+   z1 = y2*a1 (round to nearest odd 0.5 ulp);
+   a2 = a1 - z1*x /# 32 * 64 -> 64 bit #/
+
+   z = a/x = z0 + z1 - 0.5 ulp + (a2 > 0) * ulp
+
+   Unless stated otherwise, multiplies can be done in 32 * 32 bit or less
+   with suitable scaling and/or top truncation.
+   x truncated to 20 bits is sufficient to calculate y0 or even y1.
+   Table entries are adjusted by about +128 to use full signed byte range.
+   This adjustment has been perturbed slightly to allow cse with the
+   shift count constant -26.
+   The threshold point for the shift adjust before rounding is found by
+   comparing the fractions, which is exact, unlike the top bit of y2.
+   Therefore, the top bit of y2 becomes slightly random after the adjustment
+   shift, but that's OK because this can happen only at the boundaries of
+   the interval, and the baising of the error means that it can in fact happen
+   only at the bottom end.  And there, the carry propagation will make sure
+   that in the end we will have in effect an implicit 1 (or two whem rounding
+   up...)  */
+/* If an exact result exists, it can have no more bits than the divident.
+   Hence, we don't need to bother with the round-to-even tie breaker
+   unless the result is denormalized.  */
+/* 70 cycles through main path for sh4-300 .  Some cycles might be
+   saved by more careful register allocation.
+   122 cycles for sh4-200.  If execution time for sh4-200 is of concern,
+   a specially scheduled version makes sense.  */
+
+#define x_h r12
+#define yn  r3
+
+FUNC(GLOBAL(divdf3))
+ .global GLOBAL(divdf3)
+
+/* Adjust arg0 now, too.  We still have to come back to denorm_arg1_done,
+   since we heven't done any of the work yet that we do till the denorm_arg0
+   entry point.  We know that neither of the arguments is inf/nan, but
+   arg0 might be zero.  Check for that first to avoid having to establish an
+   rts return address.  */
+LOCAL(both_denorm):
+	mov.l	r9,@-r15
+	mov	DBL0H,r1
+	mov.l	r0,@-r15
+	shll2	r1
+	mov.w LOCAL(both_denorm_cleanup_off),r9
+	or	DBL0L,r1
+	tst	r1,r1
+	mov	DBL0H,r0
+	bf/s	LOCAL(zero_denorm_arg0_1)
+	shll2	r0
+	mov.l	@(4,r15),r9
+	add	#8,r15
+	bra	LOCAL(ret_inf_nan_0)
+	mov	r1,DBLRH
+
+LOCAL(both_denorm_cleanup):
+	mov.l	@r15+,r0
+	!
+	mov.l	@r15+,r9
+ mov	#12,r3
+ mov.l	LOCAL(xfffe2006),r1	! yn := (-1. << 17) + (0x80 << 6) ; shift #-26
+	bra	LOCAL(denorm_arg1_done)
+	!
+	add	r0,DBL0H
+
+/* Denorm handling leaves the incoming denorm argument with an exponent of +1
+   (implicit 1).  To leave the result exponent unaltered, the other
+   argument's exponent is adjusted by the the shift count.  */
+
+	.balign 4
+LOCAL(arg0_tiny):
+	bsr	LOCAL(clz)
+	mov	DBL0L,r0
+	shll	DBL0H
+	add	#1,r0
+	mov	DBL0L,DBL0H
+	shld	r0,DBL0H
+	rotcr	DBL0H
+	tst	DBL0L,DBL0L	/* Check for divide of zero.  */
+	add	#-33,r0
+	shld	r0,DBL0L
+	bf/s	LOCAL(adjust_arg1_exp)
+	add	#64,r0
+LOCAL(return_0): /* Return 0 with appropriate sign.  */
+	mov.l	@r15+,r10
+	mov	#0,DBLRH
+	mov.l	@r15+,r9
+	bra	LOCAL(ret_inf_nan_0)
+	mov.l	@r15+,r8
+
+	.balign 4
+LOCAL(arg1_tiny):
+	bsr	LOCAL(clz)
+	mov	DBL1L,r0
+	shll	DBL1H
+	add	#1,r0
+	mov	DBL1L,DBL1H
+	shld	r0,DBL1H
+	rotcr	DBL1H
+	tst	DBL1L,DBL1L	/* Check for divide by zero.  */
+	add	#-33,r0
+	shld	r0,DBL1L
+	bf/s	LOCAL(adjust_arg0_exp)
+	add	#64,r0
+	mov	DBL0H,r0
+	add	r0,r0
+	tst	r0,r0	! 0 / 0 ?
+	mov	#-1,DBLRH
+	bf	LOCAL(return_inf)
+	!
+	bt	LOCAL(ret_inf_nan_0)
+	!
+
+	.balign 4
+LOCAL(zero_denorm_arg1):
+	not	DBL0H,r3
+	mov	DBL1H,r0
+	tst	r2,r3
+	shll2	r0
+	bt	LOCAL(early_inf_nan_arg0)
+	tst	r0,r0
+	mov.w	LOCAL(xff00),r12
+	bt/s	LOCAL(arg1_tiny)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	shlr2	r0
+	!
+	shll	DBL1H
+	mov	DBL1L,r3
+	shld	r0,DBL1H
+	shld	r0,DBL1L
+	rotcr	DBL1H
+	add	#-32,r0
+	shld	r0,r3
+	add	#32,r0
+	or	r3,DBL1H
+LOCAL(adjust_arg0_exp):
+	tst	r2,DBL0H
+	mov	#20,r3
+	shld	r3,r0
+	bt	LOCAL(both_denorm)
+	add	DBL0H,r0
+	div0s	r0,DBL0H	! Check for obvious overflow.  */
+	not	r0,r3		! Check for more subtle overflow - lest
+	bt	LOCAL(return_inf)
+	mov	r0,DBL0H
+	tst	r2,r3		! we mistake it for NaN later
+	mov	#12,r3
+	bf	LOCAL(denorm_arg1_done)
+LOCAL(return_inf): /* Return infinity with appropriate sign.  */
+	mov	#20,r3
+	mov	#-2,DBLRH
+	bra	LOCAL(ret_inf_nan_0)
+	shad	r3,DBLRH
+
+/* inf/n -> inf; inf/0 -> inf; inf/inf -> nan; inf/nan->nan  nan/x -> nan */
+LOCAL(inf_nan_arg0):
+	mov.l	@r15+,r10
+	mov.l	@r15+,r9
+	mov.l	@r15+,r8
+LOCAL(early_inf_nan_arg0):
+	not	DBL1H,r3
+	mov	DBL0H,DBLRH
+	tst	r2,r3	! both inf/nan?
+	add	DBLRH,DBLRH
+	bf	LOCAL(ret_inf_nan_0)
+	mov	#-1,DBLRH
+LOCAL(ret_inf_nan_0):
+	mov	#0,DBLRL
+	mov.l	@r15+,r12
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+	
+/* Already handled: inf/x, nan/x .  Thus: x/inf -> 0; x/nan -> nan */
+	.balign	4
+LOCAL(inf_nan_arg1):
+	mov	DBL1H,r2
+	mov	#12,r1
+	shld	r1,r2
+	mov.l	@r15+,r10
+	mov	#0,DBLRL
+	mov.l	@r15+,r9
+	or	DBL1L,r2
+	mov.l	@r15+,r8
+	cmp/hi	DBLRL,r2
+	mov.l	@r15+,r12
+	subc	DBLRH,DBLRH
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+	
+	.balign 4
+LOCAL(zero_denorm_arg0):
+	mov.w	LOCAL(denorm_arg0_done_off),r9
+	not	DBL1H,r1
+	mov	DBL0H,r0
+	tst	r2,r1
+	shll2	r0
+	bt	LOCAL(inf_nan_arg1)
+LOCAL(zero_denorm_arg0_1):
+	tst	r0,r0
+	mov.w	LOCAL(xff00),r12
+	bt/s	LOCAL(arg0_tiny)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	shlr2	r0
+	shll	DBL0H
+	mov	DBL0L,r12
+	shld	r0,DBL0H
+	shld	r0,DBL0L
+	rotcr	DBL0H
+	add	#-32,r0
+	shld	r0,r12
+	add	#32,r0
+	or	r12,DBL0H
+LOCAL(adjust_arg1_exp):
+	mov	#20,r12
+	shld	r12,r0
+	add	DBL1H,r0
+	div0s	r0,DBL1H	! Check for obvious underflow.  */
+	not	r0,r12		! Check for more subtle underflow - lest
+	bt	LOCAL(return_0)
+	mov	r0,DBL1H
+	tst	r2,r12		! we mistake it for NaN later
+	bt	LOCAL(return_0)
+	!
+	braf	r9
+	mov	#13,r0
+LOCAL(zero_denorm_arg1_dispatch):
+
+LOCAL(xff00):	.word 0xff00
+LOCAL(denorm_arg0_done_off):
+	.word LOCAL(denorm_arg0_done)-LOCAL(zero_denorm_arg1_dispatch)
+LOCAL(both_denorm_cleanup_off):
+	.word LOCAL(both_denorm_cleanup)-LOCAL(zero_denorm_arg1_dispatch)
+
+ .balign	8
+GLOBAL(divdf3):
+ mov.l	LOCAL(x7ff00000),r2
+ mov	#12,r3
+ mov.l	LOCAL(xfffe2006),r1	! yn := (-1. << 17) + (0x80 << 6) ; shift #-26
+ tst	r2,DBL1H
+ mov.l	r12,@-r15
+ bt	LOCAL(zero_denorm_arg1)
+
+LOCAL(denorm_arg1_done):
+ mov	DBL1H,x_h	! x_h live in r12
+ shld	r3,x_h	! x - 1 ; u0.20
+ mov	x_h,yn
+ mova	LOCAL(ytab),r0
+ mov.l	r8,@-r15
+ shld	r1,yn	! x-1 ; u26.6
+ mov.b	@(r0,yn),yn
+ mov	#6,r0
+ mov.l	r9,@-r15
+ mov	x_h,r8
+ mov.l	r10,@-r15
+ shlr16	x_h	! x - 1; u16.16	! x/2 - 0.5 ; u15.17
+ add	x_h,r1	! SH4-200 single-issues this insn
+ shld	r0,yn
+ sub	r1,yn	! yn := y0 ; u15.17
+ mov	DBL1L,r1
+ mov	#-20,r10
+ mul.l	yn,x_h	! r12 dead
+ swap.w	yn,r9
+ shld	r10,r1
+ sts	macl,r0	! y0 * (x-1) - n ; u-1.32
+ add	r9,r0	! y0 * x - 1     ; s-1.32
+ tst	r2,DBL0H
+ dmuls.l r0,yn
+ mov.w	LOCAL(d13),r0
+ or	r1,r8	! x  - 1; u0.32
+ add	yn,yn	! yn = y0 ; u14.18
+ bt	LOCAL(zero_denorm_arg0)
+
+LOCAL(denorm_arg0_done):	! This label must stay aligned.
+ sts	mach,r1	!      d0 ; s14.18
+ sub	r1,yn	! yn = y1 ; u14.18 ; <= 0x3fffc
+ mov	DBL0L,r12
+ shld	r0,yn	! yn = y1 ; u1.31 ; <= 0x7fff8000
+ mov.w	LOCAL(d12),r9
+ dmulu.l yn,r8
+ shld	r10,r12
+ mov	yn,r0
+ mov	DBL0H,r8
+ add	yn,yn	! yn = y1 ; u0.32 ; <= 0xffff0000
+ sts	mach,r1	! y1 * (x-1); u1.31
+ add	r0,r1	! y1 * x    ; u1.31
+ dmulu.l yn,r1
+ not	DBL0H,r10
+ shld	r9,r8
+ tst	r2,r10
+ or	r8,r12	! a - 1; u0.32
+ bt	LOCAL(inf_nan_arg0)
+ sts	mach,r1	! d1+yn; u1.31
+ sett		! adjust y2 so that it can be interpreted as s1.31
+ not	DBL1H,r10
+ subc	r1,yn	! yn := y2 ; u1.31 ; can be 0x7fffffff
+ mov.l	LOCAL(x001fffff),r9
+ dmulu.l yn,r12
+ tst	r2,r10
+ or	DBL1H,r2
+ bt	LOCAL(inf_nan_arg1)
+ mov.l	r11,@-r15
+ sts	mach,r11	! y2*(a-1) ; u1.31
+ add	yn,r11		! z0       ; u1.31
+ dmulu.l r11,DBL1L
+ mov.l	LOCAL(x40000000),DBLRH	! bias + 1
+ and	r9,r2		! x ; u12.20
+ cmp/hi	DBL0L,DBL1L
+ sts	macl,r8
+ mov	#-24,r12
+ sts	mach,r9 	! r9:r8 := z0 * DBL1L; u-19.64
+ subc	DBL1H,DBLRH
+ mul.l	r11,r2  	! (r9+macl):r8 == z0*x; u-19.64
+ shll	r8
+ add	DBL0H,DBLRH	! result sign/exponent + 1
+ mov	r8,r10
+ sts	macl,DBLRL
+ add	DBLRL,r9
+ rotcl	r9		! r9:r8 := z*x; u-20.63
+ shld	r12,r10
+ mov.l	LOCAL(x7fe00000),DBLRL
+ sub	DBL0L,r9	! r9:r8 := -a ; u-20.63
+ mov.l	LOCAL(x00200000),r12
+FIXME: the following  shift might loose the sign.
+ shll8	r9
+ or	r10,r9	! -a1 ; s-28.32
+ mov.l	LOCAL(x00100000),r10
+ dmuls.l r9,yn	! r3 dead
+ mov	DBL1H,r3
+ mov.l LOCAL(xfff00000),DBL0L
+ xor	DBL0H,r3	! calculate expected sign & bit20
+ div0s	r3,DBLRH
+ xor	DBLRH,r3
+ bt	LOCAL(ret_denorm_inf)
+ tst	DBLRL,DBLRH
+ bt	LOCAL(ret_denorm)
+ sub	r12,DBLRH ! calculate sign / exponent minus implicit 1
+ tst	r10,r3	! set T if a >= x
+ sts	mach,r12! -z1 ; s-27.32
+ bt	0f
+ add	r11,r11	! z0 ; u1.31 / u0.31
+0: mov	#6,r3
+ negc	r3,r10 ! shift count := a >= x ? -7 : -6; T := 1
+ shll8	r8	! r9:r8 := -a1 ; s-28.64
+ shad	r10,r12	! -z1 ; truncate to s-20.32 / s-21.32
+ rotcl	r12	! -z1 ; s-21.32 / s-22.32 / round to odd 0.5 ulp ; T := sign
+ add	#20,r10
+ dmulu.l r12,DBL1L ! r12 signed, DBL1L unsigned
+ and	DBL0L,DBLRH	! isolate sign / exponent
+ shld	r10,r9
+ mov	r8,r3
+ shld	r10,r8
+ sts	macl,DBL0L
+ sts	mach,DBLRL
+ add	#-32,r10
+ shld	r10,r3
+ mul.l r12,r2
+ bf	0f	! adjustment for signed/unsigned multiply
+ sub	DBL1L,DBLRL	! DBL1L dead
+0: shar	r12	! -z1 ; truncate to s-20.32 / s-21.32
+ sts	macl,DBL1L
+ or	r3,r9	! r9:r8 := -a1 ;             s-41.64/s-42.64
+ !
+ cmp/hi	r8,DBL0L
+ add	DBLRL,DBL1L ! DBL1L:DBL0L := -z1*x ; s-41.64/s-42.64
+ subc	DBL1L,r9
+ not	r12,DBLRL ! z1, truncated to s-20.32 / s-21.32
+ shll	r9	! T :=  a2 > 0
+ mov	r11,r2
+ mov	#21,r7
+ shld	r7,r11
+ addc	r11,DBLRL
+ mov.l	@r15+,r11
+ mov.l	@r15+,r10
+ mov	#-11,r7
+ mov.l	@r15+,r9
+ shld	r7,r2
+ mov.l	@r15+,r8
+ addc	r2,DBLRH
+ rts
+ mov.l	@r15+,r12
+
+LOCAL(ret_denorm):
+	tst	r10,DBLRH
+	bra	LOCAL(denorm_have_count)
+	movt	DBLRH	! calculate shift count (off by 2)
+
+LOCAL(ret_denorm_inf):
+	mov	DBLRH,r12
+	add	r12,r12
+	cmp/pz	r12
+	mov	#-21,DBLRL
+	bt	LOCAL(ret_inf_late)
+	shld	DBLRL,DBLRH
+LOCAL(denorm_have_count):
+	add	#-2,DBLRH
+/* FIXME */
+	bra	LOCAL(return_0)
+	mov.l	@r15+,r11
+
+LOCAL(ret_inf_late):
+	mov.l	@r15+,r11
+	!
+	mov.l	@r15+,r10
+	!
+	mov.l	@r15+,r9
+	bra	LOCAL(return_inf)
+	mov.l	@r15+,r8
+
+	.balign	4
+LOCAL(clz):
+	mov.l	r8,@-r15
+	extu.w	r0,r8
+	mov.l	r9,@-r15
+	cmp/eq	r0,r8
+	bt/s	0f
+	mov	#8-11,r9
+	xtrct	r0,r8
+	add	#16,r9
+0:	tst	r12,r8	! 0xff00
+	mov.l	LOCAL(c_clz_tab),r0
+	bt	0f
+	shlr8	r8
+0:	bt	0f
+	add	#8,r9
+0:
+#ifdef	__PIC__
+	add	r0,r8
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r8),r8
+	mov	r9,r0
+	mov.l	@r15+,r9
+	!
+	!
+	!
+	sub	r8,r0
+	mov.l	@r15+,r8
+	rts
+	lds.l	@r15+,pr
+
+!	We encode even some words as pc-relative that would fit as immediate
+!	in the instruction in order to avoid some pipeline stalls on
+!	SH4-100 / SH4-200.
+LOCAL(d1):	.word 1
+LOCAL(d12):	.word 12
+LOCAL(d13):	.word 13
+
+	.balign 4
+LOCAL(x7ff00000): .long 0x7ff00000
+LOCAL(xfffe2006): .long 0xfffe2006
+LOCAL(x001fffff): .long 0x001fffff
+LOCAL(x40000000): .long 0x40000000
+LOCAL(x7fe00000): .long 0x7fe00000
+LOCAL(x00100000): .long 0x00100000
+LOCAL(x00200000): .long 0x00200000
+LOCAL(xfff00000): .long 0xfff00000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+LOCAL(ytab):
+        .byte   120, 105,  91,  78,  66,  54,  43,  33
+        .byte    24,  15,   8,   0,  -5, -12, -17, -22
+        .byte   -27, -31, -34, -37, -40, -42, -44, -45
+        .byte   -46, -46, -47, -46, -46, -45, -44, -42
+        .byte   -41, -39, -36, -34, -31, -28, -24, -20
+        .byte   -17, -12,  -8,  -4,   0,   5,  10,  16
+        .byte    21,  27,  33,  39,  45,  52,  58,  65
+        .byte    72,  79,  86,  93, 101, 109, 116, 124
+ENDFUNC(GLOBAL(divdf3))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/fixunsdfsi.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/fixunsdfsi.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/fixunsdfsi.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,81 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!! fixunsdfsi for Renesas SH / STMicroelectronics ST40 CPUs
+!! Contributed by J"orn Rennecke joern.rennecke@st.com
+
+	! What is a bit unusal about this implementation is that the
+	! sign bit influences the result for NANs: for cleared sign bit, you
+	! get INT_MAX, for set sign bit, you get INT_MIN.
+	! However, since the result for NANs is undefined, this should be no
+	! problem.
+	! N.B. This is scheduled both for SH4-200 and SH4-300
+	.balign 4
+	.global GLOBAL(fixunsdfsi)
+	FUNC(GLOBAL(fixunsdfsi))
+	.balign	4
+GLOBAL(fixunsdfsi):
+	mov.w	LOCAL(x413),r1	! bias + 20
+	mov	DBL0H,r0
+	shll	DBL0H
+	mov.l	LOCAL(mask),r3
+	mov	#-21,r2
+	shld	r2,DBL0H	! SH4-200 will start this insn in a new cycle
+	bt/s	LOCAL(ret0)
+	sub	r1,DBL0H
+	cmp/pl	DBL0H		! SH4-200 will start this insn in a new cycle
+	and	r3,r0
+	bf/s	LOCAL(ignore_low)
+	addc	r3,r0	! uses T == 1; sets implict 1
+	mov	#11,r2
+	shld	DBL0H,r0	! SH4-200 will start this insn in a new cycle
+	cmp/gt	r2,DBL0H
+	add	#-32,DBL0H
+	bt	LOCAL(retmax)
+	shld	DBL0H,DBL0L
+	rts
+	or	DBL0L,r0
+
+	.balign	8
+LOCAL(ignore_low):
+	mov	#-21,r2
+	cmp/gt	DBL0H,r2	! SH4-200 will start this insn in a new cycle
+	add	#1,r0
+	bf	0f
+LOCAL(ret0): mov #0,r0		! results in 0 return
+0:	rts
+	shld	DBL0H,r0
+
+LOCAL(retmax):
+	rts
+	mov	#-1,r0
+
+LOCAL(x413): .word 0x413
+
+	.balign 4
+LOCAL(mask): .long 0x000fffff
+	ENDFUNC(GLOBAL(fixunsdfsi))
+
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/addsf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/addsf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/addsf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,290 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! addsf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+
+	.balign 4
+	.global GLOBAL(subsf3)
+	FUNC(GLOBAL(subsf3))
+	.global GLOBAL(addsf3)
+	FUNC(GLOBAL(addsf3))
+GLOBAL(subsf3):
+	cmp/pz	r5
+	add	r5,r5
+	rotcr	r5
+	.balign 4
+GLOBAL(addsf3):
+	mov.l	LOCAL(x7f800000),r3
+	mov	r4,r6
+	add	r6,r6
+	mov	r5,r7
+	add	r7,r7
+	mov	r4,r0
+	or	r3,r0
+	cmp/hi	r6,r7
+	mov	r5,r1
+	bf/s	LOCAL(r4_hs)
+	 or	r3,r1
+	cmp/eq	r5,r1
+	bt	LOCAL(ret_r5) /* sole Inf or NaN, return unchanged.  */
+	shll8	r0	! r4 fraction
+	shll8	r1	! r5 fraction
+	mov	r6,r3
+	mov	#-24,r2
+	mov	r7,r6
+	shld	r2,r6	! r5 exp
+	mov	r0,r7
+	shld	r2,r3	! r4 exp
+	tst	r3,r3
+	sub	r6,r3	! exp difference (negative or 0)
+	bt	LOCAL(denorm_r4)
+LOCAL(denorm_r4_done): ! r1: u1.31
+	shld	r3,r0	! Get 31 upper bits, including 8 guard bits
+	mov.l	LOCAL(xff000000),r2
+	add	#31,r3
+	mov.l	r5,@-r15 ! push result sign.
+	cmp/pl	r3	! r0 has no more than one bit set -> return arg 1
+	shld	r3,r7	! copy of lowest guard bit in r0 and lower guard bits
+	bf	LOCAL(ret_stack)
+	div0s	r4,r5
+	bf/s	LOCAL(add)
+	 cmp/pl	r7	/* Is LSB in r0 clear, but any lower guards bit set?  */
+	subc	r0,r1
+	mov.l	LOCAL(c__clz_tab),r7
+	tst	r2,r1
+	mov	#-24,r3
+	bf/s LOCAL(norm_r0)
+	 mov	r1,r0
+	extu.w	r1,r1
+	bra	LOCAL(norm_check2)
+	 cmp/eq	r0,r1
+LOCAL(ret_r5):
+	rts
+	mov	r5,r0
+LOCAL(ret_stack):
+	rts
+	mov.l	@r15+,r0
+
+/* We leave the numbers denormalized, but we change the bit position to be
+   consistent with normalized numbers.  This also removes the spurious
+   leading one that was inserted before.  */
+LOCAL(denorm_r4):
+	tst	r6,r6
+	add	r0,r0
+	bf	LOCAL(denorm_r4_done)
+	bra	LOCAL(denorm_r4_done)
+	add	r1,r1
+LOCAL(denorm_r5):
+	tst	r6,r6
+	add	r1,r1
+	bf	LOCAL(denorm_r5_done)
+	clrt
+	bra	LOCAL(denorm_r5_done)
+	add	r0,r0
+
+/* If the exponent differs by two or more, normalization is minimal, and
+   few guard bits are needed for an exact final result, so sticky guard
+   bit compresion before subtraction (or add) works fine.
+   If the exponent differs by one, only one extra guard bit is generated,
+   and effectively no guard bit compression takes place.  */
+
+	.balign	4
+LOCAL(r4_hs):
+	cmp/eq	r4,r0
+	mov	#-24,r3
+	bt	LOCAL(inf_nan_arg0)
+	shld	r3,r7
+	shll8	r0
+	tst	r7,r7
+	shll8	r1
+	mov.l	LOCAL(xff000000),r2
+	bt/s	LOCAL(denorm_r5)
+	shld	r3,r6
+LOCAL(denorm_r5_done):
+	mov	r1,r3
+	subc	r6,r7
+	bf	LOCAL(same_exp)
+	shld	r7,r1	/* Get 31 upper bits.  */
+	add	#31,r7
+	mov.l	r4,@-r15 ! push result sign.
+	cmp/pl	r7
+	shld	r7,r3
+	bf	LOCAL(ret_stack)
+	div0s	r4,r5
+	bf/s	LOCAL(add)
+	 cmp/pl	r3	/* Is LSB in r1 clear, but any lower guard bit set?  */
+	subc	r1,r0
+	mov.l	LOCAL(c__clz_tab),r7
+LOCAL(norm_check):
+	tst	r2,r0
+	mov	#-24,r3
+	bf LOCAL(norm_r0)
+	extu.w	r0,r1
+	cmp/eq	r0,r1
+LOCAL(norm_check2):
+	mov	#-8,r3
+	bt LOCAL(norm_r0)
+	mov	#-16,r3
+LOCAL(norm_r0):
+	mov	r0,r1
+	shld	r3,r0
+#ifdef __pic__
+	add	r0,r7
+	mova  LOCAL(c__clz_tab),r0
+#endif
+	mov.b	@(r0,r7),r7
+	add	#25,r3
+	add	#-9+1,r6
+	mov	r1,r0
+	sub	r7,r3
+	mov.l	LOCAL(xbfffffff),r7
+	sub	r3,r6	/* generate exp-1  */
+	mov.w	LOCAL(d24),r2
+	cmp/pz	r6	/* check exp > 0  */
+	shld	r3,r0	/* Leading 1 becomes +1 exp adjustment.  */
+	bf	LOCAL(zero_denorm)
+LOCAL(denorm_done):
+	add	#30,r3
+	shld	r3,r1
+	mov.w   LOCAL(m1),r3
+	tst	r7,r1	! clear T if rounding up
+	shld	r2,r6
+	subc	r3,r0	! round - overflow will boost exp adjustment to 2.
+	mov.l	@r15+,r2
+	add	r6,r0	! overflow will generate inf
+	cmp/ge	r2,r3	! get sign into T
+	rts
+	rotcr	r0
+LOCAL(ret_r4):
+	rts
+	mov	r4,r0
+
+/* At worst, we are shifting the number back in place where an incoming
+   denormal was.  Thus, the shifts won't get out of range.  They still
+   might generate a zero fraction, but that's OK, that makes it 0.  */
+LOCAL(zero_denorm):
+	add	r6,r3
+	mov	r1,r0
+	mov	#0,r6	/* leading one will become free (except for rounding) */
+	bra	LOCAL(denorm_done)
+	shld	r3,r0
+
+/* Handle abs(r4) >= abs(r5), same exponents specially so we don't need
+   check for a zero fraction in the main path.  */
+LOCAL(same_exp):
+	div0s	r4,r5
+	mov.l	r4,@-r15
+	bf	LOCAL(add)
+	cmp/eq	r1,r0
+	mov.l	LOCAL(c__clz_tab),r7
+	bf/s	LOCAL(norm_check)
+	 sub	r1,r0
+	rts	! zero difference -> return +zero
+	mov.l	@r15+,r1
+
+/* r2: 0xff000000 */
+LOCAL(add):
+	addc	r1,r0
+	mov.w	LOCAL(x2ff),r7
+	shll8	r6
+	bf/s	LOCAL(no_carry)
+	shll16	r6
+	tst	r7,r0		
+	shlr8	r0
+	mov.l	@r15+,r3	! discard saved sign
+	subc	r2,r0
+	sett
+	addc	r6,r0
+	cmp/hs	r2,r0
+	bt/s	LOCAL(inf)
+	div0s	r7,r4 /* Copy sign.  */
+	rts
+	rotcr	r0
+LOCAL(inf):
+	mov	r2,r0
+	rts
+	rotcr	r0
+	
+LOCAL(no_carry):
+	mov.w	LOCAL(m1),r3
+	tst	r6,r6
+	bt	LOCAL(denorm_add)
+	add	r0,r0
+	tst	r7,r0		! check if lower guard bit set or round to even
+	shlr8	r0
+	mov.l	@r15+,r1	! discard saved sign
+	subc	r3,r0	! round ; overflow -> exp++
+	cmp/ge	r4,r3	/* Copy sign.  */
+	add	r6,r0	! overflow -> inf
+	rts
+	rotcr	r0
+
+LOCAL(denorm_add):
+	cmp/ge	r4,r3	/* Copy sign.  */
+	shlr8	r0
+	mov.l	@r15+,r1	! discard saved sign
+	rts
+	rotcr	r0
+
+LOCAL(inf_nan_arg0):
+	cmp/eq	r5,r1
+	bf	LOCAL(ret_r4)
+	div0s	r4,r5		/* Both are inf or NaN, check signs.  */
+	bt	LOCAL(ret_nan)	/* inf - inf, or NaN.  */
+	mov	r4,r0		! same sign; return NaN if either is NaN.
+	rts
+	or	r5,r0
+LOCAL(ret_nan):
+	rts
+	mov	#-1,r0
+
+LOCAL(d24):
+	.word	24
+LOCAL(x2ff):
+	.word	0x2ff
+LOCAL(m1):
+	.word	-1
+	.balign	4
+LOCAL(x7f800000):
+	.long	0x7f800000
+LOCAL(xbfffffff):
+	.long	0xbfffffff
+LOCAL(xff000000):
+	.long	0xff000000
+LOCAL(xfe000000):
+	.long	0xfe000000
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+
+	ENDFUNC(GLOBAL(addsf3))
+	ENDFUNC(GLOBAL(subsf3))
+
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/adddf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/adddf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/adddf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,614 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! adddf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4-200 without FPU, but can also be used for SH3.
+! Numbers with same sign are added in typically 37 cycles, worst case is
+! 43 cycles, unless there is an overflow, in which case the addition can
+! take up to takes 47 cycles.
+! Normal numbers with different sign are added in 56 (57 for PIC) cycles
+! or less on SH4.
+! If one of the inputs is a denormal, the worst case is 59 (60 for PIC)
+! cycles. (Two denormal inputs are faster than normal inputs, and
+! denormal outputs don't slow down computation).
+! Subtraction takes two cycles to negate the second input and then drops
+! through to addition.
+
+/* If the input exponents of a difference of two normalized numbers
+   differ by more than one, the output does not need to be adjusted
+   by more than one bit position.  Hence, it makes sense to ensure that
+   the shifts by 0 & 1 are handled quickly to reduce average and worst
+   case times.  */
+FUNC(GLOBAL(adddf3))
+FUNC(GLOBAL(subdf3))
+	.global	GLOBAL(adddf3)
+	.global	GLOBAL(subdf3)
+LOCAL(denorm_arg1):
+	bt LOCAL(inf_nan_arg0)
+	tst	r0,r2
+	bt/s	LOCAL(denorm_both)
+	shlr	r1
+	mov.l	LOCAL(x00100000),r3
+	bra	LOCAL(denorm_arg1_done)
+	 sub	r2,r3
+
+! Handle denorm addition here because otherwise the ordinary addition would
+! have to check for denormal results.
+! Denormal subtraction could also be done faster, but the denorm subtraction
+! path here is still one cycles faster than the one for normalized input
+! numbers, and 16 instructions shorter than the fastest version.
+! Here we also generate +0.0 + +0.0 -> +0.0 ; -0.0 + -0.0 -> -0.0
+LOCAL(denorm_both):
+	div0s	r8,DBL1H
+	mov.l	LOCAL(x800fffff),r9
+	bt/s	LOCAL(denorm_sub)
+	and	r1,DBL1H
+	and	r9,r8
+	mov.l	@r15+,r9
+	mov	DBL0L,DBLRL
+	mov	r8,DBLRH
+	addc	DBL1L,DBLRL
+	mov.l	@r15+,r8
+	rts
+	 addc	DBL1H,DBLRH
+
+! N.B., since subtraction also generates +0.0 for subtraction of numbers
+! with identical fractions, this also covers the +0.0 + -0.0 -> +0.0 /
+! -0.0 + +0.0 -> +0.0 cases.
+LOCAL(denorm_sub):
+	mov	r8,DBL0H	! tentative result sign
+	and	r1,DBL0H
+	bra	LOCAL(sub_same_exp)
+	 addc	r1,r2	! exponent++, clear T
+
+LOCAL(inf_nan_arg0):
+	cmp/hs 	r0,r3
+	bf		LOCAL(inf_nan_ret)
+	tst	DBL1L,DBL1L
+	bf		LOCAL(ret_nan)
+	shlr	r1
+	and 	DBL1H,r1
+	tst	r1,r1
+	bf		LOCAL(ret_nan)
+	div0s	r8,DBL1H
+	bf		LOCAL(inf_nan_ret)
+LOCAL(ret_nan):
+	mov 	#-1,DBLRH
+	bra	LOCAL(pop_r8_r9)
+		mov DBLRH,DBLRL
+  
+LOCAL(inf_nan_ret):
+	mov	DBL0L,DBLRL
+	bra	LOCAL(pop_r8_r9)
+		mov r8,DBLRH
+
+LOCAL(ret_arg0):
+	mov.l LOCAL(x800fffff),DBLRH
+	mov	DBL0L,DBLRL
+	mov	r2,r3
+LOCAL(ret_arg):
+	mov.l	@r15+,r9
+	and	r8,DBLRH
+	mov.l	@r15+,r8
+	rts
+	or r3,DBLRH
+
+LOCAL(no_carry):
+	shlr	r0
+	mov.l	LOCAL(x000fffff),DBLRH
+	addc	r3,r9
+	mov.w	LOCAL(d0),DBL1H
+	mov	DBL0L,DBLRL
+	and	DBL0H,DBLRH	! mask out implicit 1
+	mov.l	LOCAL(x7ff00000),r3
+	addc	DBL1H,DBLRL
+	addc	r2,DBLRH
+	mov.l	@r15+,r9
+	add	DBL1H,DBLRH	! fraction overflow -> exp increase
+	bra	LOCAL(add_done)
+	 cmp/hi	r3,DBLRH
+
+LOCAL(inf):
+	mov	#0,DBLRL
+	bra	LOCAL(or_sign)
+	mov	r3,DBLRH
+
+	.balign	4
+GLOBAL(subdf3):
+	cmp/pz DBL1H
+	add 	DBL1H,DBL1H
+	rotcr	DBL1H
+	nop
+
+GLOBAL(adddf3):
+	mov.l	LOCAL(x7ff00000),r0
+	mov	DBL0H,r2
+	mov.l	LOCAL(x001fffff),r1
+	mov	DBL1H,r3
+	mov.l	r8,@-r15
+	and	r0,r2		! r2 <- exp0
+	mov.l	r9,@-r15
+	and	r0,r3		! r3 <- exp1
+	cmp/hi r2,r3
+	or		r0,DBL0H
+	or		r0,DBL1H
+	bt		LOCAL(arg1_gt)
+	tst	r0,r3
+	mov	#-20,r9
+	mov	DBL0H,r8	! tentative result sign
+	and	r1,DBL0H	! arg0 fraction
+	bt/s	LOCAL(denorm_arg1)
+		cmp/hs r0,r2
+	bt		LOCAL(inf_nan_arg0)
+	sub	r2,r3
+LOCAL(denorm_arg1_done):	! r2 is tentative result exponent
+	shad	r9,r3
+	mov.w	LOCAL(m32),r9
+	mov	DBL1H,r0	! the 'other' sign
+	and	r1,DBL1H	! arg1 fraction
+	cmp/ge r9,r3
+	mov	DBL1H,r1
+	bf/s	LOCAL(large_shift_arg1)
+	 shld	r3,DBL1H
+LOCAL(small_shift_arg1):
+	mov	DBL1L,r9
+	shld	r3,DBL1L
+	tst	r3,r3
+	add	#32,r3
+	bt/s	LOCAL(same_exp)
+	 div0s r8,r0	! compare signs
+	shld	r3,r1
+
+	or		r1,DBL1L
+	bf/s	LOCAL(add)
+	shld	r3,r9
+	clrt
+	negc	r9,r9
+	mov.l	LOCAL(x001f0000),r3
+LOCAL(sub_high):
+	mov	DBL0L,DBLRL
+	subc	DBL1L,DBLRL
+	mov	DBL0H,DBLRH
+	bra	LOCAL(subtract_done)
+	 subc	DBL1H,DBLRH
+
+LOCAL(large_shift_arg1):
+	mov	DBL1L,r9
+	shld	r3,r9
+	add	#64,r3
+	cmp/pl r3
+	shld	r3,r1
+	shld	r3,DBL1L
+	bf		LOCAL(ret_arg0)
+	tst	DBL1L,DBL1L
+	bt		LOCAL(large_shift_arg1_end)
+	mov	#1,DBL1L
+	or 	DBL1L,r9
+LOCAL(large_shift_arg1_end):
+	mov	DBL1H,DBL1L
+	mov	#0,DBL1H
+	add	r1,r9
+	div0s	r8,r0	! compare signs
+	bf		LOCAL(add)
+	clrt
+	mov.l	LOCAL(x001f0000),r3
+	bra	LOCAL(sub_high)
+	 negc	r9,r9
+
+LOCAL(add_clr_r9):
+	mov	#0,r9
+LOCAL(add):
+	mov.l	LOCAL(x00200000),r3
+	addc	DBL1L,DBL0L
+	addc	DBL1H,DBL0H
+	mov.l	LOCAL(x80000000),r1
+	tst	r3,DBL0H
+	mov.l	LOCAL(x7fffffff),r3
+	mov	DBL0L,r0
+	bt/s	LOCAL(no_carry)
+	and	r1,r8
+	tst	r9,r9
+	bf		LOCAL(add_one)
+	tst	#2,r0
+LOCAL(add_one):
+	subc	r9,r9
+	sett
+	mov	r0,DBLRL 
+	addc	r9,DBLRL
+	mov	DBL0H,DBLRH
+	addc	r9,DBLRH
+	shlr	DBLRH
+	mov.l	LOCAL(x7ff00000),r3
+	add	r2,DBLRH
+	mov.l	@r15+,r9
+	rotcr	DBLRL
+	cmp/hs r3,DBLRH
+LOCAL(add_done):
+	bt		LOCAL(inf)
+LOCAL(or_sign):
+	or		r8,DBLRH
+	rts
+	 mov.l @r15+,r8
+
+LOCAL(same_exp):
+	bf	LOCAL(add_clr_r9)
+	clrt
+LOCAL(sub_same_exp):
+	subc	DBL1L,DBL0L
+	mov.l	LOCAL(x001f0000),r3
+	subc	DBL1H,DBL0H
+	mov.w	LOCAL(d0),r9
+	bf	LOCAL(pos_difference_0)
+	clrt
+	negc	DBL0L,DBLRL
+	mov.l	LOCAL(x80000000),DBL0L
+	negc	DBL0H,DBLRH
+	mov.l	LOCAL(x00100000),DBL0H
+	tst	r3,DBLRH
+	not	r8,r8
+	bt/s	LOCAL(long_norm)
+	and	DBL0L,r8
+	bra	LOCAL(norm_loop_2)
+	 not	DBL0L,r3
+
+LOCAL(large_shift_arg0):
+	mov	DBL0L,r9
+	shld	r2,r9
+	add	#64,r2
+	cmp/pl	r2
+	shld	r2,r1
+	shld	r2,DBL0L
+	bf	LOCAL(ret_arg1_exp_r3)
+	tst	DBL0L,DBL0L
+	bt LOCAL(large_shift_arg0_end)
+	mov 	#1,DBL0L
+	or		DBL0L,r9 
+LOCAL(large_shift_arg0_end):
+	mov	DBL0H,DBL0L
+	mov	#0,DBL0H
+	add	r1,r9
+	div0s	r8,r0	! compare signs
+	mov	r3,r2	! tentative result exponent
+	bf	LOCAL(add)
+	clrt
+	negc	r9,r9
+	bra	LOCAL(subtract_arg0_arg1_done)
+	 mov	DBL1L,DBLRL
+
+LOCAL(arg1_gt):
+	tst	r0,r2			! r0 = 0x7ff00000 r2 = exp0
+	mov	#-20,r9
+	mov	DBL1H,r8		! tentative result sign
+	and	r1,DBL1H
+	bt/s	LOCAL(denorm_arg0)
+	cmp/hs	r0,r3
+	bt	LOCAL(inf_nan_arg1)
+	sub	r3,r2
+LOCAL(denorm_arg0_done):
+	shad	r9,r2			! r2 <- shifting value
+	mov.w	LOCAL(m32),r9
+	mov	DBL0H,r0		! the 'other' sign
+	and	r1,DBL0H
+	cmp/ge	r9,r2
+	mov	DBL0H,r1
+	bf/s	LOCAL(large_shift_arg0)
+		shld	r2,DBL0H
+LOCAL(small_shift_arg0):
+	mov	DBL0L,r9
+	shld	r2,DBL0L
+	mov.l	r3,@-r15
+	mov 	#32,r3
+	add	r3,r2
+	cmp/ge	r3,r2
+	bf LOCAL(shifting)
+	mov	#0,r1
+	mov 	r1,r9
+LOCAL(shifting):
+	shld	r2,r1
+	mov	r2,r3
+	shld	r3,r9
+	div0s	r8,r0		! compare signs
+	mov.l	@r15+,r2	! tentative result exponent
+	bf/s	LOCAL(add)
+	or	r1,DBL0L
+	clrt
+	negc	r9,r9
+	mov	DBL1L,DBLRL
+LOCAL(subtract_arg0_arg1_done):
+	subc	DBL0L,DBLRL
+	mov	DBL1H,DBLRH
+	mov.l	LOCAL(x001f0000),r3
+	subc	DBL0H,DBLRH
+/* Since the exponents were different, the difference is positive.  */
+/* Fall through */
+LOCAL(subtract_done):
+/* First check if a shift by a few bits is sufficient.  This not only
+   speeds up this case, but also alleviates the need for considering
+   lower bits from r9 or rounding in the other code.
+   Moreover, by handling the upper 1+4 bits of the fraction here, long_norm
+   can assume that DBLRH fits into 20 (20 < 16) bit.  */
+	tst	r3,DBLRH
+	mov.l	LOCAL(x80000000),r3
+	mov.l	LOCAL(x00100000),DBL0H
+	bt/s	LOCAL(long_norm)
+	and	r3,r8
+	mov.l	LOCAL(x7fffffff),r3
+LOCAL(norm_loop_2):	! Well, this used to be a loop...
+	tst	DBL0H,DBLRH
+	sub	DBL0H,r2
+	bf	LOCAL(norm_round)
+	shll	r9
+	rotcl	DBLRL
+	
+	rotcl	DBLRH
+	
+	 subc	DBL0H,r2
+LOCAL(norm_loop_1):
+	bt	LOCAL(denorm0_n)
+	tst	DBL0H,DBLRH
+	bf	LOCAL(norm_round)
+	shll	DBLRL
+	rotcl	DBLRH	! clears T
+	bra	LOCAL(norm_loop_1)
+	 subc	DBL0H,r2
+	 
+LOCAL(denorm_arg0):
+	bt	LOCAL(inf_nan_arg1)
+	mov.l	LOCAL(x00100000),r2
+	shlr	r1				! r1 <- 0xfffff
+	bra	LOCAL(denorm_arg0_done)
+	 sub	r3,r2			! r2 <- 1 - exp1
+
+LOCAL(inf_nan_arg1):
+	mov	DBL1L,DBLRL
+	bra	LOCAL(pop_r8_r9)
+	 mov	r8,DBLRH
+
+LOCAL(ret_arg1_exp_r3):
+	mov.l	LOCAL(x800fffff),DBLRH
+	bra	LOCAL(ret_arg)
+	 mov	DBL1L,DBLRL
+
+LOCAL(pos_difference_0):
+	tst	r3,DBL0H
+	mov	DBL0L,DBLRL
+	mov.l	LOCAL(x80000000),DBL0L
+	mov	DBL0H,DBLRH
+	mov.l	LOCAL(x00100000),DBL0H
+	bt/s	LOCAL(long_norm)
+	and	DBL0L,r8
+	bra	LOCAL(norm_loop_2)
+	 not	DBL0L,r3
+
+#ifdef __pic__
+	.balign 8
+#endif
+LOCAL(m32):
+	.word	-32
+LOCAL(d0):
+	.word	0
+#ifndef __pic__
+	.balign 8
+#endif
+! Because we had several bits of cancellations, we know that r9 contains
+! only one bit.
+! We'll normalize by shifting words so that DBLRH:DBLRL contains
+! the fraction with 0 < DBLRH <= 0x1fffff, then we shift DBLRH:DBLRL
+! up by 21 minus the number of non-zero bits in DBLRH.
+LOCAL(long_norm):
+	tst	DBLRH,DBLRH
+	mov.w	LOCAL(xff),DBL0L
+	mov	#21,r3
+	bf	LOCAL(long_norm_highset)
+	mov.l	LOCAL(x02100000),DBL1L	! shift 32, implicit 1
+	tst	DBLRL,DBLRL
+	extu.w	DBLRL,DBL0H
+	bt	LOCAL(zero_or_ulp)
+	mov	DBLRL,DBLRH
+	cmp/hi	DBL0H,DBLRL
+	bf	0f
+	mov.l	LOCAL(x01100000),DBL1L	! shift 16, implicit 1
+	clrt
+	shlr16  DBLRH
+	xtrct	DBLRL,r9
+	mov     DBLRH,DBL0H
+LOCAL(long_norm_ulp_done):
+0:	mov	r9,DBLRL	! DBLRH:DBLRL == fraction; DBL0H == DBLRH
+	subc	DBL1L,r2
+	bt	LOCAL(denorm1_b)
+#ifdef __pic__
+	mov.l	LOCAL(c__clz_tab),DBL1H
+LOCAL(long_norm_lookup):
+	mov	r0,r9
+	mova	LOCAL(c__clz_tab),r0
+	add	DBL1H,r0
+#else
+	mov	r0,r9
+LOCAL(long_norm_lookup):
+	mov.l	LOCAL(c__clz_tab),r0
+#endif /* __pic__ */
+	cmp/hi	DBL0L,DBL0H
+	bf	0f
+	shlr8	DBL0H
+0:	mov.b	@(r0,DBL0H),r0
+	bf	0f
+	add	#-8,r3
+0:	mov.w	LOCAL(d20),DBL0L
+	mov	#-20,DBL0H
+	clrt
+	sub	r0,r3
+	mov	r9,r0
+	mov	r3,DBL1H
+	shld	DBL0L,DBL1H
+	subc	DBL1H,r2
+	!
+	bf	LOCAL(no_denorm)
+	shad	DBL0H,r2
+	bra	LOCAL(denorm1_done)
+	add	r2,r3
+	
+LOCAL(norm_round):
+	cmp/pz	r2
+	mov	#0,DBL1H
+	bf	LOCAL(denorm0_1)
+	or	r8,r2
+	mov	DBLRL,DBL1L
+	shlr	DBL1L
+	addc	r3,r9
+	mov.l	@r15+,r9
+	addc	DBL1H,DBLRL	! round to even
+	mov.l	@r15+,r8
+	rts
+	 addc	r2,DBLRH
+
+LOCAL(norm_pack):
+	add	r8,DBLRH
+	mov.l	@r15+,r8
+	rts
+	add	r2,DBLRH
+
+LOCAL(denorm0_1):
+	mov.l	@r15+,r9
+	mov	r8,DBL0L
+	mov.l	@r15+,r8
+LOCAL(denorm0_shift):
+	shlr	DBLRH
+	rotcr	DBLRL
+
+	rts
+	add	DBL0L,DBLRH
+
+LOCAL(denorm0_n):
+	mov.l	@r15+,r9
+	mov	r8,DBL0L
+	addc	DBL0H,r2
+	mov.l	@r15+,r8
+	bra LOCAL(denorm0_shift)
+		  nop
+
+LOCAL(no_denorm):
+	add	r2,r8		! add (exponent - 1) to sign
+
+LOCAL(denorm1_done):
+	shld	r3,DBLRH
+	mov	DBLRL,DBL0L
+	shld	r3,DBLRL
+
+	add	r8,DBLRH	! add in sign and (exponent - 1)
+	mov.l	@r15+,r9
+	add	#-32,r3
+	mov.l	@r15+,r8
+	shld	r3,DBL0L
+
+	rts
+	add	DBL0L,DBLRH
+
+LOCAL(long_norm_highset):
+	mov.l	LOCAL(x00200000),DBL1L	! shift 1, implicit 1
+	shll	r9
+	rotcl	DBLRL
+	mov	DBLRH,DBL0H
+	rotcl	DBLRH	! clears T
+#ifdef __pic__
+	mov.l	LOCAL(c__clz_tab),DBL1H
+#else
+	mov	r0,r9
+#endif /* __pic__ */
+	subc	DBL1L,r2
+	add	#-1,r3
+	bf	LOCAL(long_norm_lookup)
+LOCAL(denorm1_a):
+	shlr	DBLRH
+	rotcr	DBLRL
+	mov.l	@r15+,r9
+	or	r8,DBLRH
+
+	rts
+	mov.l	@r15+,r8
+
+	.balign	4
+LOCAL(denorm1_b):
+	mov	#-20,DBL0L
+	shad	DBL0L,r2
+	mov	DBLRH,DBL0L
+	shld	r2,DBLRH
+	shld	r2,DBLRL
+	or	r8,DBLRH
+	mov.l	@r15+,r9
+	add	#32,r2
+	mov.l	@r15+,r8
+	shld	r2,DBL0L
+	rts
+	or	DBL0L,DBLRL
+
+LOCAL(zero_or_ulp):
+	tst	r9,r9
+	bf	LOCAL(long_norm_ulp_done)
+	! return +0.0
+LOCAL(pop_r8_r9):
+	mov.l	@r15+,r9
+	rts
+	mov.l	@r15+,r8
+
+LOCAL(d20):
+	.word	20
+LOCAL(xff):
+	.word 0xff
+	.balign	4
+LOCAL(x7ff00000):
+	.long	0x7ff00000
+LOCAL(x001fffff):
+	.long	0x001fffff
+LOCAL(x80000000):
+	.long	0x80000000
+LOCAL(x000fffff):
+	.long	0x000fffff
+LOCAL(x800fffff):
+	.long	0x800fffff
+LOCAL(x001f0000):
+	.long	0x001f0000
+LOCAL(x00200000):
+	.long	0x00200000
+LOCAL(x7fffffff):
+	.long	0x7fffffff
+LOCAL(x00100000):
+	.long	0x00100000
+LOCAL(x02100000):
+	.long	0x02100000
+LOCAL(x01100000):
+	.long	0x01100000
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(adddf3))
+ENDFUNC(GLOBAL(subdf3))
+
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/mulsf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/mulsf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/mulsf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,269 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! mulsf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+
+	.balign 4
+	.global GLOBAL(mulsf3)
+	FUNC(GLOBAL(mulsf3))
+GLOBAL(mulsf3):
+   mov.l   LOCAL(x7f800000),r1
+   not     r4,r2
+	mov		r4,r3
+	not		r5,r0
+	tst		r1,r2
+	or			r1,r3
+	bt/s		LOCAL(inf_nan_arg0)
+	 tst		r1,r0
+	bt			LOCAL(inf_nan_arg1)
+	tst		r1,r5
+	mov		r1,r2
+	shll8		r3
+	or			r5,r1
+	bt/s		LOCAL(zero_denorm_arg1)
+	 shll8		r1
+	tst		r2,r4
+	bt			LOCAL(zero_denorm_arg0)
+	dmulu.l	r3,r1
+	mov		r4,r0
+	and		r2,r0
+LOCAL(arg_norm):
+	and		r5,r2
+	mov.l 	LOCAL(x3f800000),r3
+	sts		mach,r1
+	sub		r3,r0
+	sts		macl,r3
+	add		r2,r0
+	cmp/pz	r1
+	mov.w 	LOCAL(x100),r2
+	bf/s		LOCAL(norm_frac) 
+	 tst		r3,r3
+	shll2		r1	 ! Shift one up, replace leading 1 with 0.  
+	shlr		r1
+	tst		r3,r3
+LOCAL(norm_frac):
+	mov.w 	LOCAL(mx80),r3
+	bf			LOCAL(round_frac)
+	tst		r2,r1
+LOCAL(round_frac):
+	mov.l 	LOCAL(xff000000),r2
+	subc		r3,r1	! Even overflow gives right result: exp++, frac=0. 
+	shlr8 	r1
+	add		r1,r0
+	shll		r0
+	bt			LOCAL(ill_exp)
+	tst		r2,r0
+	bt			LOCAL(denorm)
+	cmp/hs	r2,r0
+	bt			LOCAL(inf)
+LOCAL(insert_sign):
+	div0s	r4,r5
+	rts
+	rotcr		r0
+LOCAL(denorm0):
+	tst	r1,r1
+	mov.w 	LOCAL(x100),r2
+	bf			LOCAL(round_den0)
+	tst		r2,r0
+LOCAL(round_den0):
+	mov 		#-7,r2
+	mov.w 	LOCAL(mx80),r3
+	subc 		r3,r0
+	bra		LOCAL(insert_sign)
+	 shld 		r2,r0
+LOCAL(zero_denorm_arg1):
+	mov.l 	LOCAL(x60000000),r2	/* Check exp0 >= -64	*/
+	add		r1,r1
+	tst		r1,r1	/* arg1 == 0 ? */
+	mov		#0,r0
+	bt			LOCAL(insert_sign) /* argument 1 is zero ==> return 0  */
+	tst		r4,r2
+	bt			LOCAL(insert_sign) /* exp0 < -64  ==> return 0 */
+	mov.l 	LOCAL(c__clz_tab),r0
+	mov		r3,r2
+	mov		r1,r3
+	bra		LOCAL(arg_normalize)
+	mov		r2,r1
+LOCAL(zero_denorm_arg0):
+	mov.l 	LOCAL(x60000000),r2	/* Check exp1 >= -64	*/
+	add		r3,r3
+	tst		r3,r3	/* arg0 == 0 ? */
+	mov		#0,r0
+	bt			LOCAL(insert_sign) /* argument 0 is zero ==> return 0  */
+	tst		r5,r2
+	bt			LOCAL(insert_sign) /* exp1 < -64  ==> return 0 */
+	mov.l 	LOCAL(c__clz_tab),r0
+LOCAL(arg_normalize):
+	mov.l	r7,@-r15
+	extu.w	r3,r7
+	cmp/eq	r3,r7
+	mov.l 	LOCAL(xff000000),r7
+	mov		#-8,r2
+	bt			0f
+	tst		r7,r3
+	mov		#-16,r2
+	bt			0f
+	mov		#-24,r2
+0:
+	mov		r3,r7
+	shld		r2,r7
+#ifdef __pic__
+	add		r0,r7
+	mova  	LOCAL(c__clz_tab),r0
+#endif
+	mov.b	@(r0,r7),r0
+	add		#32,r2
+	mov		r2,r7
+	mov		#23,r2
+	sub		r0,r7
+	mov.l	LOCAL(x7f800000),r0
+	shld		r7,r3
+	shld		r2,r7
+	mov		r0,r2
+	and		r4,r0
+	sub		r7,r0
+	mov.l	@r15+,r7
+	bra		LOCAL(arg_norm)
+	 dmulu.l	r3,r1
+#if 0 /* This is slightly slower, but could be used if table lookup causes
+         cache thrashing.  */
+	bt			LOCAL(insert_sign) /* exp1 < -64  ==> return 0 */
+	mov.l 	LOCAL(xff000000),r2
+	mov		r4,r0
+LOCAL(arg_normalize):
+	tst		r2,r3
+	bf			LOCAL(arg_bit_norm)
+LOCAL(arg_byte_loop):
+	tst		r2,r3
+	add		r2,r0
+	shll8		r3
+	bt			LOCAL(arg_byte_loop)
+	add		r4,r0
+LOCAL(arg_bit_norm):
+	mov.l 	LOCAL(x7f800000),r2
+	rotl		r3
+LOCAL(arg_bit_loop):
+	add		r2,r0
+	bf/s		LOCAL(arg_bit_loop)
+	 rotl		r3
+	rotr		r3
+	rotr		r3
+	sub		r2,r0
+	bra		LOCAL(arg_norm)
+	 dmulu.l	r3,r1
+#endif /* 0 */
+LOCAL(inf):
+	bra		LOCAL(insert_sign)
+	 mov		r2,r0
+LOCAL(inf_nan_arg0):
+	bt			LOCAL(inf_nan_both)
+	add		r0,r0
+!	cmp/eq	#-1,r0	Here : modif -1 replace by -2 
+	cmp/eq	#-2,r0	/* arg1 zero? -> NAN */
+	bt			LOCAL(insert_sign)
+	mov		r4,r0
+LOCAL(inf_insert_sign):
+	bra		LOCAL(insert_sign)
+	 add		r0,r0
+LOCAL(inf_nan_both):
+	mov		r4,r0
+	bra		LOCAL(inf_insert_sign)
+	 or		r5,r0
+LOCAL(inf_nan_arg1):
+	mov		r2,r0
+	add		r0,r0
+! cmp/eq	#-1,r0	Here : modif -1 replace by -2 
+	cmp/eq	#-2,r0	/* arg0 zero? */
+	bt			LOCAL(insert_sign)
+	bra		LOCAL(inf_insert_sign)
+	 mov		r5,r0
+LOCAL(ill_exp):
+	cmp/pz	r0
+	bt			LOCAL(inf)
+LOCAL(denorm):
+	mov		#-24,r3
+	add		r1,r1
+	mov		r0,r2
+	sub		r1,r2	! remove fraction to get back pre-rounding exponent.
+	tst 		r2,r2
+	sts		mach,r0
+	sts		macl,r1
+	bt			LOCAL(denorm0)
+	shad		r3,r2
+	mov		r0,r3
+	shld		r2,r0
+	add		#32,r2
+	cmp/pz	r2
+	shld		r2,r3
+	bf			LOCAL(zero)
+	or			r1,r3
+	mov		#-1,r1
+	tst		r3,r3
+	mov.w	LOCAL(x100),r3
+	bf/s		LOCAL(denorm_round_up)
+	mov		#-0x80,r1
+	tst		r3,r0
+LOCAL(denorm_round_up):
+	mov		#-7,r3
+	subc		r1,r0
+	bra		LOCAL(insert_sign)
+	 shld		r3,r0
+LOCAL(zero):
+	bra		LOCAL(insert_sign)
+	 mov 	#0,r0
+LOCAL(x100):
+	.word	0x100
+LOCAL(x200):
+	.word	0x200
+LOCAL(x17f):
+	.word	0x17f
+LOCAL(x80):
+	.word	0x80
+LOCAL(mx80):
+	.word	-0x80
+	.balign	4
+LOCAL(mx100):
+	.word	-0x100
+	.balign	4
+LOCAL(x7f800000):
+	.long 0x7f800000
+LOCAL(x3f800000):
+	.long 0x3f800000
+LOCAL(x1000000):
+	.long	0x1000000
+LOCAL(xff000000):
+	.long	0xff000000
+LOCAL(x60000000):
+	.long	0x60000000
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+	ENDFUNC(GLOBAL(mulsf3))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/floatsisf.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/floatsisf.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/floatsisf.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,106 @@
+/* Copyright (C) 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! floatsisf for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+
+FUNC(GLOBAL(floatsisf))
+	.global GLOBAL(floatsisf)
+	.balign	4
+GLOBAL(floatsisf):
+	cmp/pz	r4
+	mov	r4,r5
+	bt	0f
+	neg	r4,r5
+0:	mov.l	LOCAL(c_clz_tab),r0
+	extu.w	r5,r1
+	mov.w	LOCAL(xff00),r3
+	cmp/eq	r5,r1
+	mov	#24,r2
+	bt	0f
+	mov	r5,r1
+	shlr16	r1
+	add	#-16,r2
+0:	tst	r3,r1	! 0xff00
+	bt	0f
+	shlr8	r1
+0:	bt	0f
+	add	#-8,r2
+0:
+#ifdef	__PIC__
+	add	r0,r1
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r1),r1
+	cmp/pz	r4
+	mov.l	LOCAL(x4a800000),r3	! bias + 23 - implicit 1
+	bt	0f
+	mov.l	LOCAL(xca800000),r3	! sign + bias + 23 - implicit 1
+0:	mov	r5,r0
+	sub	r1,r2
+	mov.l	LOCAL(x80000000),r1
+	shld	r2,r0
+	cmp/pz	r2
+	add	r3,r0
+	bt	LOCAL(noround)
+	add	#31,r2
+	shld	r2,r5
+	add	#-31,r2
+	rotl	r5
+	cmp/hi	r1,r5
+	mov	#0,r3
+	addc	r3,r0
+	mov	#23,r1
+	shld	r1,r2
+	rts
+	sub	r2,r0
+	.balign	8
+LOCAL(noround):
+	mov	#23,r1
+	tst	r4,r4
+	shld	r1,r2
+	bt	LOCAL(ret0)
+	rts
+	sub	r2,r0
+LOCAL(ret0):
+	rts
+	mov	#0,r0
+
+LOCAL(xff00):	.word 0xff00
+	.balign	4
+LOCAL(x4a800000): .long 0x4a800000
+LOCAL(xca800000): .long 0xca800000
+LOCAL(x80000000): .long 0x80000000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(floatsisf))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/muldf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/muldf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/muldf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,502 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! muldf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+! Normal numbers are multiplied in 53 or 54 cycles on SH4-200.
+
+FUNC(GLOBAL(muldf3))
+	.global GLOBAL(muldf3)
+LOCAL(normalize_arg53):
+	tst	r2,DBL0H
+	mov	#1,r2
+	bt	LOCAL(normalize_arg48)
+	mov	DBL0H,r1
+	shlr16	r1
+	bra	LOCAL(normalize_DBL0H)
+	mov	#21-16,r3
+
+LOCAL(normalize_arg16):
+	mov.w	LOCAL(m31),r2 ! 1-32
+	mov	#0,DBL0L
+LOCAL(normalize_arg48):
+	mov	DBL0H,r1
+	mov	#21,r3
+LOCAL(normalize_DBL0H):
+	extu.b	r1,r8
+	mov.l	LOCAL(c__clz_tab),r0
+	cmp/eq	r8,r1
+	!
+	bt	0f
+	shlr8	r1
+0:
+#ifdef	__pic__
+	add	r0,r1
+
+	mova	LOCAL(c__clz_tab),r0
+
+#endif /* __pic__ */
+	mov.b	@(r0,r1),r8
+	mov	DBL0L,r1
+	mov.l	@r15+,r0
+	bt	0f
+	add	#-8,r3
+0:	clrt
+	sub	r8,r3
+	mov.w	LOCAL(d20),r8
+	shld	r3,DBL0H 	! Normalization
+	shld	r3,DBL0L
+	sub	r3,r2 	! r2 <- shifting number
+	add	#-32,r3
+	shld	r3,r1
+	or	r1,DBL0H
+	shld	r8,r2 	! positioning r2 for exp
+	mov.l	@r15+,r8
+
+	! Here :  test tinyness 
+	mov 	DBL1H, r1
+	neg 	r2,r3
+	shll 	r1
+	shll 	r3
+	cmp/hi r1,r3
+	bt LOCAL(zero)
+	
+	add	r2,DBL1H
+	mov.l	LOCAL(x001fffff),r2
+	mov.l LOCAL(x00100000),r3
+	dmulu.l	DBL0L,DBL1L
+	bra	LOCAL(arg_denorm_done)
+	or	r3,r0		! set implicit 1 bit
+
+LOCAL(inf_nan_denorm_or_zero_a):
+	mov.l r8,@-r15
+	sub 	r3,DBL0H 	! isolate high fraction (r3 = 0xfff00000)
+	mov.l @(4,r15),r8 ! original DBL0H (with sign & exp)
+	mov.l r0,@-r15
+	mov.l	r10,@-r15
+	mov 	r1,r10
+	sub 	r3,r1 	! r1 <- 0x7ff00000
+	mov.l LOCAL(x60000000),r3
+	shll16 	r2 	! r2 <- 0xffff0000
+	!			  no stall here for sh4-200
+	!
+	tst 	r1,r8 	! test DBL0 Inf or NaN ?
+	bf LOCAL(inf_nan_a)
+	tst r10,r0 	! test for DBL1 inf, nan or small
+	mov.l	@r15+,r10
+	bt LOCAL(ret_inf_nan_zero)
+LOCAL(normalize_arg):
+	tst 	DBL0H,DBL0H
+	bf LOCAL(normalize_arg53)
+	tst 	DBL0L,DBL0L 	! test for DBL0 is zero
+	bt LOCAL(a_zero)
+	tst 	r2,DBL0L 	! test DBL0L = 0x0000xxxx
+	mov 	DBL0L,DBL0H ! left shift 32
+	bt LOCAL(normalize_arg16)
+	shlr16 	DBL0H
+	mov.w LOCAL(m15),r2	! 1-16
+	bra 	LOCAL(normalize_arg48)
+	shll16 	DBL0L
+
+LOCAL(a_zero):
+	mov.l	@(4,r15),r8
+	add	#8,r15
+LOCAL(zero):
+	mov	#0,DBLRH
+	bra	LOCAL(pop_ret)
+	mov	#0,DBLRL
+
+! both inf / nan -> result is nan if at least one is none, else inf.
+! BBL0 inf/nan, DBL1 zero   -> result is nan
+! DBL0 inf/nan, DBL1 finite -> result is DBL0 with sign adjustemnt
+LOCAL(inf_nan_a):
+	mov.l	@r15+,r10
+	mov	r8,DBL0H
+	mov.l	@(4,r15),r8
+	tst	r1,r0	! arg1 inf/nan ?
+	mov	DBL0H,DBLRH
+	add	#8,r15
+	mov	DBL0L,DBLRL
+	bt	LOCAL(both_inf_nan)
+	tst	DBL1L,DBL1L
+	mov	DBL1H,r2
+	bf	LOCAL(pop_ret)
+	add	r2,r2
+	tst	r2,r2
+	!
+	bf	LOCAL(pop_ret)
+LOCAL(nan):
+	mov	#-1,DBLRL
+	bra	LOCAL(pop_ret)
+	mov	#-1,DBLRH
+
+LOCAL(both_inf_nan):
+	or	DBL1L,DBLRL
+	bra	LOCAL(pop_ret)
+	or	DBL1H,DBLRH
+
+LOCAL(ret_inf_nan_zero):
+	tst	r1,r0
+	mov.l	@(4,r15),r8
+	or	DBL0L,DBL0H
+	bf/s	LOCAL(zero)
+	add	#8,r15
+	tst	DBL0H,DBL0H
+	bt	LOCAL(nan)
+LOCAL(inf_nan_b):
+	mov	DBL1L,DBLRL
+	mov	DBL1H,DBLRH
+LOCAL(pop_ret):
+	mov.l	@r15+,DBL0H
+	add	DBLRH,DBLRH
+
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+
+	.balign	4
+/* Argument a has already been tested for being zero or denorm.
+   On the other side, we have to swap a and b so that we can share the
+   normalization code.
+   a: sign/exponent : @r15 fraction: DBL0H:DBL0L
+   b: sign/exponent: DBL1H fraction:    r0:DBL1L  */
+LOCAL(inf_nan_denorm_or_zero_b):
+	sub	r3,r1		! 0x7ff00000
+	mov.l	@r15,r2		! get original DBL0H
+	tst	r1,DBL1H
+	sub	r3,r0		! isolate high fraction
+	bf	LOCAL(inf_nan_b)
+	mov.l	DBL1H,@r15
+	mov	r0,DBL0H
+	mov.l	r8,@-r15
+	mov	r2,DBL1H
+	mov.l	LOCAL(0xffff0000),r2
+	mov.l	DBL1H,@-r15
+	mov	DBL1L,r1
+	mov	DBL0L,DBL1L
+	bra	LOCAL(normalize_arg)
+	mov	r1,DBL0L
+
+LOCAL(d20):
+	.word	20
+LOCAL(m15):
+	.word	-15
+LOCAL(m31):
+	.word	-31
+LOCAL(xff):
+	.word	0xff
+
+	.balign	4
+LOCAL(0xffff0000): .long 0xffff0000
+
+	! calculate a (DBL0H:DBL0L) * b (DBL1H:DBL1L)
+	.balign	4
+GLOBAL(muldf3):
+	mov.l	LOCAL(xfff00000),r3
+	mov	DBL1H,r0
+	dmulu.l	DBL0L,DBL1L
+	mov.l	LOCAL(x7fe00000),r1
+	sub	r3,r0
+	mov.l	DBL0H,@-r15
+	sub	r3,DBL0H
+	tst	r1,DBL0H
+	or	r3,DBL0H
+	mov.l	LOCAL(x001fffff),r2
+	bt	LOCAL(inf_nan_denorm_or_zero_a)
+	tst	r1,r0
+	or	r3,r0		! r0:DBL1L    := b fraction ; u12.52
+	bt	LOCAL(inf_nan_denorm_or_zero_b) ! T clear on fall-through
+LOCAL(arg_denorm_done):
+	and	r2,r0		! r0:DBL1L    := b fraction ; u12.52
+	sts	macl,r3
+	sts	mach,r1
+	dmulu.l	DBL0L,r0 ! r0 = DBL1H - exp
+	and	r2,DBL0H	! DBL0H:DBL0L := a fraction ; u12.52
+	mov.l	r8,@-r15
+	mov	#0,DBL0L
+	mov.l	r9,@-r15
+	sts	macl,r2
+	sts	mach,r8
+	dmulu.l	DBL0H,DBL1L
+	addc	r1,r2
+
+	addc	DBL0L,r8	! add T; clears T
+
+	sts	macl,r1
+	sts	mach,DBL1L
+	dmulu.l	DBL0H,r0
+	addc	r1,r2
+	mov.l	LOCAL(x7ff00000),DBL0H
+	addc	DBL1L,r8	! clears T
+	mov.l	@(8,r15),DBL1L	! a sign/exp w/fraction
+	sts	macl,DBLRL
+	sts	mach,DBLRH
+	and	DBL0H,DBL1L	! a exponent
+	mov.w	LOCAL(x200),r9
+	addc	r8,DBLRL
+	mov.l	LOCAL(x3ff00000),r8	! bias
+	addc	DBL0L,DBLRH	! add T
+	cmp/hi	DBL0L,r3	! 32 guard bits -> sticky: T := r3 != 0
+	movt	r3
+	tst	r9,DBLRH	! T := fraction < 2
+	or	r3,r2		! DBLRH:DBLRL:r2 := result fraction; u24.72
+	bt/s	LOCAL(shll12)
+	sub	r8,DBL1L
+	mov.l	LOCAL(x002fffff),r8
+	and	DBL1H,DBL0H	! b exponent
+	mov.l	LOCAL(x00100000),r9
+	add	DBL0H,DBL1L ! result exponent - 1
+	tst	r8,r2
+	mov.w	LOCAL(m20),r8
+	subc	DBL0L,r9
+	addc	r2,r9 ! r2 value is still needed for denormal rounding
+	mov.w	LOCAL(d11),DBL0L
+	rotcr	r9
+	clrt
+	shld	r8,r9
+	mov.w	LOCAL(m21),r8
+	mov	DBLRL,r3
+	shld	DBL0L,DBLRL
+	addc	r9,DBLRL
+	mov.l	@r15+,r9
+	shld	r8,r3
+	mov.l	@r15+,r8
+	shld	DBL0L,DBLRH
+	mov.l	@r15+,DBL0H
+	addc	r3,DBLRH
+	mov.l	LOCAL(x7ff00000),DBL0L
+	add	DBL1L,DBLRH	! implicit 1 adjusts exponent
+	mov.l	LOCAL(xffe00000),r3
+	cmp/hs	DBL0L,DBLRH
+	add	DBLRH,DBLRH
+	bt	LOCAL(ill_exp_11)
+	tst	r3,DBLRH
+	bt	LOCAL(denorm_exp0_11)
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+
+
+LOCAL(shll12):
+	mov.l	LOCAL(x0017ffff),r8
+	extu.b	DBLRH,DBLRH	! remove implicit 1.
+	mov.l	LOCAL(x00080000),r9
+	and	DBL1H,DBL0H	! b exponent
+	add	DBL0H,DBL1L	! result exponent
+	tst	r8,r2		! rounding adjust for lower guard ...
+	mov.w	LOCAL(m19),r8
+	subc	DBL0L,r9	! ... bits and round to even; clear T
+	addc	r2,r9 ! r2 value is still needed for denormal rounding
+	mov.w	LOCAL(d12),DBL0L
+	rotcr	r9
+	clrt
+	shld	r8,r9
+	mov.w	LOCAL(m20),r8
+	mov	DBLRL,r3
+	shld	DBL0L,DBLRL
+	addc	r9,DBLRL
+	mov.l	@r15+,r9
+	shld	r8,r3
+	mov.l	@r15+,r8
+	shld	DBL0L,DBLRH
+	mov.l	LOCAL(x7ff00000),DBL0L
+	addc	r3,DBLRH
+	mov.l	@r15+,DBL0H
+	add	DBL1L,DBLRH
+	mov.l	LOCAL(xffe00000),r3
+	cmp/hs	DBL0L,DBLRH
+	add	DBLRH,DBLRH
+	bt	LOCAL(ill_exp_12)
+	tst	r3,DBLRH
+	bt	LOCAL(denorm_exp0_12)
+LOCAL(insert_sign):
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+
+LOCAL(overflow):
+	mov	r3,DBLRH
+	mov	#0,DBLRL
+	bra	LOCAL(insert_sign)
+	mov.l	@r15+,r8
+
+LOCAL(denorm_exp0_11):
+	mov.l	r8,@-r15
+	mov	#-21,r8
+	mov.l	r9,@-r15
+	bra	LOCAL(denorm)
+	mov	#-2,DBL1L	! one for denormal, and one for sticky bit
+
+LOCAL(ill_exp_11):
+	mov	DBL1H,DBL1L
+	and	r3,DBL0L	! 0x7fe00000
+	add	DBL1L,DBL1L
+	mov.l	r8,@-r15
+	cmp/hi	DBL1L,DBL0L	! check if exp a was large
+	mov	#-20,DBL0L
+	bf	LOCAL(overflow)
+	mov	#-21,r8
+	mov	DBLRH,DBL1L
+	rotcr	DBL1L		! shift in negative sign
+	mov.l	r9,@-r15
+	shad	DBL0L,DBL1L	! exponent ; s32
+	bra	LOCAL(denorm)
+	add	#-2,DBL1L	! add one for denormal, and one for sticky bit
+
+LOCAL(denorm_exp0_12):
+	mov.l	r8,@-r15
+	mov	#-20,r8
+	mov.l	r9,@-r15
+	bra	LOCAL(denorm)
+	mov	#-2,DBL1L	! one for denormal, and one for sticky bit
+
+	.balign 4		! also aligns LOCAL(denorm)
+LOCAL(ill_exp_12):
+	and	r3,DBL0L	! 0x7fe00000
+	mov	DBL1H,DBL1L
+	add	DBL1L,DBL1L
+	mov.l	r8,@-r15
+	cmp/hi	DBL1L,DBL0L	! check if exp a was large
+	bf	LOCAL(overflow)
+	mov	DBLRH,DBL1L
+	rotcr	DBL1L		! shift in negative sign
+	mov	#-20,r8
+	shad	r8,DBL1L	! exponent ; s32
+	mov.l	r9,@-r15
+	add	#-2,DBL1L	! add one for denormal, and one for sticky bit
+LOCAL(denorm):
+	not	r3,r9		! 0x001fffff
+	mov.l	r10,@-r15
+	mov	r2,r10
+	shld	r8,r10	! 11 or 12 lower bit valid
+	and	r9,DBLRH ! Mask away vestiges of exponent.
+	add	#32,r8
+	sub	r3,DBLRH ! Make leading 1 explicit.
+	shld	r8,r2	! r10:r2 := unrounded result lowpart
+	shlr	DBLRH	! compensate for doubling at end of normal code
+	sub	DBLRL,r10	! reconstruct effect of previous rounding
+	exts.b	r10,r9
+	shad	r3,r10	! sign extension
+	mov	#0,r3
+	clrt
+	addc	r9,DBLRL	! Undo previous rounding.
+	bt LOCAL(unround_done)
+	addc	r9,DBLRH
+LOCAL(unround_done):
+	mov.w	LOCAL(m32),r9
+	cmp/hi	r3,r2
+	rotcl	DBLRL	! fit in the rest of r2 as a sticky bit.
+	mov.l	@r15+,r10
+	rotcl	DBLRH
+	cmp/ge	r9,DBL1L
+	bt	LOCAL(small_norm_shift)
+	cmp/hi	r3,DBLRL
+	add	#31,DBL1L
+	movt	DBLRL
+	shll 	DBLRH
+	cmp/ge	r9,DBL1L
+	or	DBLRH,DBLRL
+	bt/s	LOCAL(small_norm_shift)
+	mov	r3,DBLRH
+	mov	r3,DBLRL	! exponent too negative to shift - return zero
+	mov.l	@r15+,r9
+	mov.l	@r15+,r8
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+	.balign	4
+LOCAL(small_norm_shift):
+	mov	DBLRL,r2	! stash away guard bits
+	shld	DBL1L,DBLRL
+	mov	DBLRH,DBL0L
+	shld	DBL1L,DBLRH
+	mov.l	LOCAL(x7fffffff),r9
+	add	#32,DBL1L
+	shld	DBL1L,r2
+	shld	DBL1L,DBL0L
+	or	DBL0L,DBLRL
+	or	DBLRL,DBL0L
+	shlr	DBL0L
+	addc	r2,r9
+	mov.l	@r15+,r9
+	mov.l	@r15+,r8
+	addc	r3,DBLRL
+	addc	r3,DBLRH
+	div0s	DBL0H,DBL1H
+	add	DBLRH,DBLRH
+	rts
+	rotcr	DBLRH
+
+
+LOCAL(x200):
+	.word 0x200
+LOCAL(m19):
+	.word	-19
+LOCAL(m20):
+	.word	-20
+LOCAL(m21):
+	.word	-21
+LOCAL(m32):
+	.word	-32
+LOCAL(d11):
+	.word	11
+LOCAL(d12):
+	.word	12
+	.balign	4
+LOCAL(x60000000):
+	.long	0x60000000
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+LOCAL(xfff00000):
+	.long	0xfff00000
+LOCAL(x7fffffff):
+	.long	0x7fffffff
+LOCAL(x00100000):
+	.long	0x00100000
+LOCAL(x7fe00000):
+	.long	0x7fe00000
+LOCAL(x001fffff):
+	.long	0x001fffff
+LOCAL(x7ff00000):
+	.long	0x7ff00000
+LOCAL(x3ff00000):
+	.long	0x3ff00000
+LOCAL(x002fffff):
+	.long	0x002fffff
+LOCAL(xffe00000):
+	.long	0xffe00000
+LOCAL(x0017ffff):
+	.long	0x0017ffff
+LOCAL(x00080000):
+	.long	0x00080000
+ENDFUNC(GLOBAL(muldf3))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/floatsidf.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/floatsidf.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/floatsidf.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,103 @@
+/* Copyright (C) 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! floatsidf for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+
+FUNC(GLOBAL(floatsidf))
+	.global GLOBAL(floatsidf)
+	.balign	4
+GLOBAL(floatsidf):
+	tst	r4,r4
+	mov	r4,r1
+	bt	LOCAL(ret0)
+	cmp/pz	r4
+	bt	0f
+	neg	r4,r1
+0:	mov.l	LOCAL(c_clz_tab),r0
+	extu.w	r1,r5
+	mov.w	LOCAL(xff00),r3
+	cmp/eq	r1,r5
+	mov	#21,r2
+	bt	0f
+	mov	r1,r5
+	shlr16	r5
+	add	#-16,r2
+0:	tst	r3,r5	! 0xff00
+	bt	0f
+	shlr8	r5
+0:	bt	0f
+	add	#-8,r2
+0:
+#ifdef	__PIC__
+	add	r0,r5
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r5),r5
+	cmp/pz	r4
+	mov.l	LOCAL(x41200000),r3	! bias + 20 - implicit 1
+	bt	0f
+	mov.l	LOCAL(xc1200000),r3	! sign + bias + 20 - implicit 1
+0:	mov	r1,r0	! DBLRL & DBLRH
+	sub	r5,r2
+	mov	r2,r5
+	shld	r2,DBLRH
+	cmp/pz	r2
+	add	r3,DBLRH
+	add	#32,r2
+	shld	r2,DBLRL
+	bf	0f
+	mov.w	LOCAL(d0),DBLRL
+0:	mov	#20,r2
+	shld	r2,r5
+	rts
+	sub	r5,DBLRH
+LOCAL(ret0):
+	mov	#0,DBLRL
+	rts
+	mov	#0,DBLRH
+
+LOCAL(xff00):	.word 0xff00
+	.balign	4
+LOCAL(x41200000):
+#ifdef __LITTLE_ENDIAN__
+LOCAL(d0):	  .word 0
+		  .word 0x4120
+#else
+		  .word 0x4120
+LOCAL(d0):	  .word 0
+#endif
+LOCAL(xc1200000): .long 0xc1200000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(floatsidf))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/fixdfsi.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/m3/fixdfsi.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/m3/fixdfsi.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,113 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!! fixdfsi for Renesas SH / STMicroelectronics ST40 CPUs
+!! Contributed by J"orn Rennecke joern.rennecke@st.com
+
+	! What is a bit unusal about this implementation is that the
+	! sign bit influences the result for NANs: for cleared sign bit, you
+	! get UINT_MAX, for set sign bit, you get 0.
+	! However, since the result for NANs is undefined, this should be no
+	! problem.
+	! N.B. This is scheduled both for SH4-200 and SH4-300
+	.balign 4
+	.global GLOBAL(fixdfsi)
+	FUNC(GLOBAL(fixdfsi))
+	.balign	4
+GLOBAL(fixdfsi):
+	mov.w	LOCAL(x413),r1
+	mov	DBL0H,r0
+	shll	DBL0H
+	mov.l	LOCAL(mask),r3
+	mov	#-21,r2
+	shld	r2,DBL0H	! SH4-200 will start this insn in a new cycle
+	bt/s	LOCAL(neg)
+	sub	r1,DBL0H
+	cmp/pl	DBL0H		! SH4-200 will start this insn in a new cycle
+	and	r3,r0
+	bf/s	LOCAL(ignore_low)
+	addc	r3,r0	! uses T == 1; sets implict 1
+	mov	#10,r2
+	shld	DBL0H,r0	! SH4-200 will start this insn in a new cycle
+	cmp/gt	r2,DBL0H
+	add	#-32,DBL0H
+	bt	LOCAL(retmax)
+	shld	DBL0H,DBL0L
+	rts
+	or	DBL0L,r0
+
+	.balign	8
+LOCAL(ignore_low):
+	mov	#-21,r2
+	cmp/gt	DBL0H,r2	! SH4-200 will start this insn in a new cycle
+	bf	0f		! SH4-200 will start this insn in a new cycle
+	mov	#-31,DBL0H	! results in 0 return
+0:	add	#1,r0
+	rts
+	shld	DBL0H,r0
+
+	.balign 4
+LOCAL(neg):
+	cmp/pl	DBL0H
+	and	r3,r0
+	bf/s	LOCAL(ignore_low_neg)
+	addc	r3,r0	! uses T == 1; sets implict 1
+	mov	#10,r2
+	shld	DBL0H,r0	! SH4-200 will start this insn in a new cycle
+	cmp/gt	r2,DBL0H
+	add	#-32,DBL0H
+	bt	LOCAL(retmin)
+	shld	DBL0H,DBL0L
+	or	DBL0L,r0	! SH4-200 will start this insn in a new cycle
+	rts
+	neg	r0,r0
+
+	.balign 4
+LOCAL(ignore_low_neg):
+	mov	#-21,r2
+	cmp/gt	DBL0H,r2	! SH4-200 will start this insn in a new cycle
+	add	#1,r0
+	shld	DBL0H,r0
+	bf	0f
+	mov	#0,r0		! results in 0 return
+0:	rts
+	neg	r0,r0
+
+LOCAL(retmax):
+	mov	#-1,r0
+	rts
+	shlr	r0
+
+LOCAL(retmin):
+	mov	#1,r0
+	rts
+	rotr	r0
+
+LOCAL(x413): .word 0x413
+
+	.balign 4
+LOCAL(mask): .long 0x000fffff
+	ENDFUNC(GLOBAL(fixdfsi))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/divdf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/divdf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/divdf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,598 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!division of two double precision floating point numbers
+!Author:Aanchal Khanna
+!
+!Entry:
+!r4,r5:dividend
+!
+!r6,r7:divisor
+!
+!Exit:
+!r0,r1:quotient
+
+!Notes: dividend is passed in regs r4 and r5 and divisor is passed in regs 
+!r6 and r7, quotient is returned in regs r0 and r1. dividend is referred as op1
+!and divisor as op2.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align	5
+	.global	GLOBAL (divdf3)
+	FUNC (GLOBAL (divdf3))
+
+GLOBAL (divdf3):
+
+#ifdef  __LITTLE_ENDIAN__
+	mov	r4,r1
+	mov	r5,r4
+	mov	r1,r5
+
+        mov     r6,r1
+        mov     r7,r6
+        mov     r1,r7
+#endif
+	mov	r4,r2
+	mov.l	.L_inf,r1
+
+	and	r1,r2
+	mov.l   r8,@-r15
+
+	cmp/eq	r1,r2
+	mov     r6,r8
+
+	bt	.L_a_inv
+	and	r1,r8
+
+	cmp/eq	r1,r8
+	mov.l	.L_high_mant,r3
+
+	bf	.L_chk_zero
+	and	r6,r3
+
+	mov.l   .L_mask_sign,r8	
+	cmp/pl	r7
+
+	mov	r8,r0
+	bt	.L_ret_b	!op2=NaN,return op2
+
+	and	r4,r8
+	cmp/pl	r3
+
+	and	r6,r0
+	bt	.L_ret_b	!op2=NaN,return op2
+
+	xor     r8,r0           !op1=normal no,op2=Inf, return Zero
+	mov     #0,r1
+	
+#ifdef __LITTLE_ENDIAN__
+	mov	r0,r2
+	mov	r1,r0
+	mov	r2,r1
+#endif
+	rts
+	mov.l   @r15+,r8
+
+.L_ret_b:
+	mov	r7,r1
+	mov     r6,r0
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts
+	mov.l   @r15+,r8
+
+.L_a_inv:
+	!chk if op1 is Inf or NaN
+	mov.l   .L_high_mant,r2
+	cmp/pl  r5
+
+	and	r4,r2
+	bt	.L_ret_a
+
+	and	r1,r8		!r1 contains infinity
+	cmp/pl	r2
+
+	bt	.L_ret_a
+	cmp/eq	r1,r8
+
+	mov	r1,DBLRH
+	add	DBLRH,DBLRH
+	bf	0f
+	mov	#-1,DBLRH	! Inf/Inf, return NaN.
+0:	div0s	r4,r6
+	mov.l   @r15+,r8	
+	rts
+	rotcr	DBLRH
+
+.L_ret_a:
+	!return op1
+	mov	r5,r1
+	mov	r4,r0
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+        mov.l   @r15+,r8
+
+.L_chk_zero:
+	!chk if op1=0
+	mov.l   .L_mask_sign,r0
+        mov     r4,r3
+
+        and     r0,r3
+        shll    r4
+
+        and     r6,r0
+        shlr    r4
+
+        xor     r3,r0
+        shll    r6
+
+	shlr	r6
+	tst	r4,r4
+
+
+	bf      .L_op1_not_zero	
+	tst	r5,r5
+	
+        bf      .L_op1_not_zero
+	tst	r7,r7
+
+	mov.l   @r15+,r8
+	bf	.L_ret_zero
+
+	tst	r6,r6
+	bf	.L_ret_zero
+
+	rts
+	mov     #-1,DBLRH       !op1=op2=0, return NaN
+	
+.L_ret_zero:
+	!return zero
+	mov	r0,r1
+	rts
+#ifdef __LITTLE__ENDIAN
+	mov	#0,r0
+#else
+	mov	#0,r1		!op1=0,op2=normal no,return zero
+#endif
+
+.L_norm_b:
+	!normalize op2
+        shll    r7
+        mov.l   .L_imp_bit,r3
+
+        rotcl   r6
+        tst     r3,r6
+
+        add     #-1,r8
+        bt      .L_norm_b
+
+        bra     .L_divide
+        add     #1,r8
+
+.L_op1_not_zero:
+	!op1!=0, chk if op2=0
+	tst	r7,r7	
+	mov	r1,r3
+	
+	mov	#0,r1
+	bf	.L_normal_nos
+
+	tst	r6,r6
+	bf      .L_normal_nos
+
+	mov.l   @r15+,r8
+	or	r3,r0
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts
+	nop
+
+.L_normal_nos:
+	!op1 and op2 are normal nos
+	tst	r2,r2
+	mov	#-20,r1
+
+! The subsequent branch is for the upper compare
+! Shifting will not alter the result, for the
+! macro is declared with care.
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld    r1,r2
+#else
+	SHLR20 (r2)
+#endif
+	bt	.L_norm_a	!normalize dividend
+	
+.L_chk_b:
+	mov.l	r9,@-r15
+	tst	r8,r8
+
+        mov.l   .L_high_mant,r9
+
+! The subsequent branch is for the upper compare
+! Shifting will not alter the result, for the
+! macro is declared with care.
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r1,r8
+#else
+        SHLR20 (r8)
+#endif
+				! T set -> normalize divisor
+	SL(bt,	.L_norm_b,
+	 and	r9,r4)
+
+.L_divide:
+	mov.l   .L_2047,r1
+	sub	r8,r2
+
+	mov.l	.L_1023,r8
+	and	r9,r6
+
+	!resultant exponent
+	add	r8,r2
+	!chk the exponent for overflow
+	cmp/ge	r1,r2
+	
+	mov.l	.L_imp_bit,r1
+	bt	.L_overflow
+	
+	mov	#0,r8
+	or	r1,r4
+	
+	or      r1,r6	
+	mov	#-24,r3
+
+	!chk if the divisor is 1(mantissa only)
+	cmp/eq	r8,r7
+	bf	.L_div2
+
+	cmp/eq	 r6,r1
+	bt	.L_den_one
+
+.L_div2:
+	!divide the mantissas
+	shll8	r4
+	mov	r5,r9
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r3,r9
+#else
+        SHLR24 (r9)
+#endif
+	shll8	r6
+
+	or	r9,r4
+	shll8   r5
+
+	mov	r7,r9
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r3,r9
+#else
+        SHLR24 (r9)
+#endif
+	mov	r8,r3
+	shll8	r7
+
+	or	r9,r6	
+	cmp/gt	r4,r6
+
+	mov	r3,r9
+	bt	.L_shift
+
+	cmp/eq	r4,r6
+	bf	.L_loop
+
+	cmp/gt	r5,r7
+	bf	.L_loop
+
+.L_shift:
+	add	#-1,r2
+	shll	r5
+	rotcl	r4
+
+.L_loop:
+	!actual division loop
+	cmp/gt	r6,r4
+	bt	.L_subtract
+
+	cmp/eq	r6,r4
+	bf	.L_skip
+
+	cmp/ge	r7,r5
+	bf	.L_skip
+
+.L_subtract:
+	clrt
+	subc	r7,r5
+	
+	or	r1,r8
+	subc	r6,r4
+
+.L_skip:
+	shlr	r1
+	shll	r5
+
+	rotcl	r4
+	cmp/eq	r1,r3
+
+	bf	.L_loop
+	mov.l	.L_imp_bit,r1
+
+	!chk if the divison was for the higher word of the quotient
+	tst	r1,r9
+	bf	.L_chk_exp
+
+	mov	r8,r9
+	mov.l   .L_mask_sign,r1
+
+	!divide for the lower word of the quotient
+	bra	.L_loop
+	mov	r3,r8
+
+.L_chk_exp:
+	!chk if the result needs to be denormalized
+	cmp/gt	r2,r3
+	bf	.L_round
+	mov     #-53,r7
+
+.L_underflow:
+	!denormalize the result
+	add	#1,r2
+	cmp/gt	r2,r7
+
+	or      r4,r5           !remainder
+	add	#-2,r2
+
+	mov	#32,r4
+	bt      .L_return_zero
+
+	add	r2,r4
+	cmp/ge	r3,r4
+
+	mov	r2,r7
+	mov	r3,r1
+
+	mov     #-54,r2
+	bt	.L_denorm
+	mov	#-32,r7
+
+.L_denorm:
+	shlr	r8
+	rotcr	r1
+
+	shll	r8
+	add     #1,r7
+
+	shlr	r9
+	rotcr	r8
+
+	cmp/eq	r3,r7
+	bf	.L_denorm
+
+	mov	r4,r7
+	cmp/eq	r2,r4
+
+	bt	.L_break
+	mov     r3,r6
+
+	cmp/gt	r7,r3
+	bf	.L_break
+
+	mov	r2,r4
+	mov	r1,r6
+
+	mov	r3,r1
+	bt	.L_denorm
+
+.L_break:
+	mov     #0,r2
+
+	cmp/gt	r1,r2
+
+	addc	r2,r8
+	mov.l   .L_comp_1,r4
+
+	addc	r3,r9		
+	or	r9,r0
+
+	cmp/eq	r5,r3
+	bf	.L_return	
+
+	cmp/eq	r3,r6
+	mov.l	.L_mask_sign,r7
+
+	bf	.L_return
+	cmp/eq	r7,r1
+
+	bf	.L_return
+	and	r4,r8
+
+.L_return:
+	mov.l	@r15+,r9
+	mov     r8,r1
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l   @r15+,r8
+
+.L_norm_a:
+        !normalize op1
+        shll    r5
+        mov.l   .L_imp_bit,r3
+
+        rotcl   r4
+        tst     r3,r4
+
+        add     #-1,r2
+        bt      .L_norm_a
+
+        bra     .L_chk_b
+        add     #1,r2
+
+.L_overflow:
+	!overflow, return inf
+	mov.l   .L_inf,r2
+#ifdef __LITTLE_ENDIAN__
+	or	r2,r1	
+	mov	#0,r0
+#else
+	or	r2,r0
+	mov	#0,r1
+#endif
+        mov.l   @r15+,r9
+        rts
+        mov.l   @r15+,r8
+
+.L_den_one:
+	!denominator=1, result=numerator
+        mov     r4,r9
+        mov   	#-53,r7
+
+	cmp/ge	r2,r8
+	mov	r8,r4
+
+	mov	r5,r8
+	mov	r4,r3
+
+	!chk the exponent for underflow
+	SL(bt,	.L_underflow,
+	 mov     r4,r5)
+
+	mov.l	.L_high_mant,r7
+        bra     .L_pack
+	mov     #20,r6
+
+.L_return_zero:
+	!return zero
+	mov	r3,r1
+	mov.l	@r15+,r9
+
+	rts
+	mov.l   @r15+,r8
+
+.L_round:
+	!apply rounding
+	cmp/eq	r4,r6
+	bt	.L_lower
+
+	clrt
+	subc    r6,r4
+
+	bra     .L_rounding
+	mov	r4,r6
+	
+.L_lower:
+	clrt
+	subc	r7,r5
+	mov	r5,r6
+	
+.L_rounding:
+	!apply rounding
+	mov.l   .L_invert,r1
+	mov	r3,r4
+
+	movt	r3
+	clrt
+	
+	not	r3,r3
+	and	r1,r3	
+
+	addc	r3,r8
+	mov.l   .L_high_mant,r7
+
+	addc	r4,r9
+	cmp/eq	r4,r6
+
+	mov.l   .L_comp_1,r3
+	SL (bf,	.L_pack,
+	 mov     #20,r6)
+	and	r3,r8
+
+.L_pack:
+	!pack the result, r2=exponent,r0=sign,r8=lower mantissa, r9=higher mantissa
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld    r6,r2
+#else
+        SHLL20 (r2)
+#endif
+	and	r7,r9
+
+	or	r2,r0
+	mov	r8,r1
+
+	or      r9,r0
+	mov.l	@r15+,r9
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+	.align	2
+
+.L_mask_sign:
+	.long	0x80000000
+.L_high_mant:
+	.long	0x000fffff
+.L_inf:
+	.long	0x7ff00000
+.L_1023:
+	.long	1023
+.L_2047:
+	.long	2047
+.L_imp_bit:
+	.long	0x00100000	
+.L_comp_1:
+	.long	0xfffffffe
+.L_invert:
+	.long	0x00000001
+
+ENDFUNC (GLOBAL (divdf3))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/floatunssisf.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/floatunssisf.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/floatunssisf.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,137 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Conversion of unsigned integer to floating point
+
+! Author: Rakesh Kumar
+
+! Argument: r4
+! Result: r0
+
+! r4 is referred as op1
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+        .text
+        .align 5
+        .global GLOBAL (floatunsisf)
+	FUNC (GLOBAL (floatunsisf))
+
+GLOBAL (floatunsisf):
+	tst	r4,r4
+	mov	#23,r6
+
+	mov.l	.L_set_24_bits,r7
+	SL(bt,	.L_return,
+	 not	r7,r3)
+
+	! Decide the direction for shifting
+	mov.l	.L_set_24_bit,r5
+	cmp/hi	r7,r4
+
+	not	r5,r2
+	SL(bt,	.L_shift_right,
+	 mov	#0,r7)
+
+	tst	r5,r4
+	
+	mov	#0,r0
+	bf	.L_pack_sf
+
+! Shift the bits to the left. Adjust the exponent
+.L_shift_left:
+	shll	r4
+	tst	r5,r4
+
+	add	#-1,r6
+	bt	.L_shift_left
+
+! Pack the value in floating point format.
+! r6 has unbiased exponent, r4 has mantissa
+.L_pack_sf:
+	mov	#23,r3
+	add	#127,r6
+
+	! Align the exponent
+	and	r2,r4
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+        SHLL23 (r6)
+#else
+	shld	r3,r6
+#endif
+
+	or	r6,r0
+	rts
+	or	r4,r0
+
+! Shift right the number with rounding
+.L_shift_right:
+	shlr	r4
+	rotcr	r7
+
+	tst	r4,r3
+	add	#1,r6
+
+	bf	.L_shift_right
+	
+	tst	r7,r7
+	bt	.L_sh_rt_1
+
+	shll	r7
+	movt	r1
+
+	add	r1,r4
+
+	tst	r7,r7
+	bf	.L_sh_rt_1
+
+	! Halfway between two numbers.
+	! Round towards LSB = 0
+	shlr	r4
+	shll	r4
+
+.L_sh_rt_1:
+	mov	r4,r0
+
+	! Rounding may have misplaced MSB. Adjust.
+	and	r3,r0
+	cmp/eq	#0,r0
+
+	bf	.L_shift_right
+	bt	.L_pack_sf
+
+.L_return:
+	rts
+	mov	r4,r0
+
+	.align 2
+.L_set_24_bit:
+	.long 0x00800000
+
+.L_set_24_bits:
+	.long 0x00FFFFFF
+
+ENDFUNC (GLOBAL (floatunsisf))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/fixunssfsi.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/fixunssfsi.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/fixunssfsi.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,155 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Conversion from floating point to unsigned integer
+
+! Author: Rakesh Kumar
+
+! Argument: r4 (in floating point format)
+! Result: r0
+
+! For negative floating point numbers, it returns zero
+
+! The argument is referred as op1
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align 5
+	.global	GLOBAL (fixunssfsi)
+	FUNC (GLOBAL (fixunssfsi))
+
+GLOBAL (fixunssfsi):
+	mov.l	.L_sign,r0
+	mov	r4,r2
+
+	! Check for NaN
+	mov.l	.L_inf,r1
+	and	r4,r0
+
+	mov.l	.L_mask_sign,r7
+	mov	#127,r5
+
+	! Remove sign bit
+	cmp/eq	#0,r0
+	and	r7,r2
+
+	! If number is negative, return 0
+	! LIBGCC deviates from standard in this regard.
+	mov	r4,r3
+	SL(bf,	.L_epil,
+	 mov	#0,r0)
+
+	mov.l	.L_frac,r6
+	cmp/gt	r1,r2
+
+	shll	r2
+	SL1(bt,	.L_epil,
+	 shlr16	r2)
+
+	shlr8	r2	! r2 has exponent
+	mov.l	.L_24bit,r1
+
+	and	r6,r3	! r3 has fraction
+	cmp/gt	r2,r5
+
+	! If exponent is less than 127, return 0
+	or	r1,r3
+	bt	.L_epil
+
+	! Process only if exponent is less than 158
+	mov.l	.L_158,r1
+	shll8	r3
+
+	cmp/gt	r1,r2
+	sub	r2,r1
+
+	neg	r1,r1
+	bt	.L_ret_max
+
+! Shift the mantissa with exponent difference from 158
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r1,r3
+#else
+	cmp/gt	r0,r1
+	bt	.L_mov_left
+
+.L_mov_right:
+	cmp/eq	r1,r0
+	bt	.L_ret
+
+	add	#1,r1
+	bra	.L_mov_right
+	shlr	r3
+
+.L_mov_left:
+	add	#-1,r1
+	
+	shll	r3
+	cmp/eq	r1,r0
+
+	bf	.L_mov_left
+
+.L_ret:	
+#endif
+	rts
+	mov	r3,r0
+
+! r0 already has appropriate value
+.L_epil:
+	rts
+	nop
+
+! Return the maximum unsigned integer value
+.L_ret_max:
+	mov.l	.L_max,r3
+
+	rts
+	mov	r3,r0
+
+	.align 2
+.L_inf:
+	.long 0x7F800000
+
+.L_158:
+	.long 158
+
+.L_max:
+	.long 0xFFFFFFFF
+
+.L_frac:
+	.long 0x007FFFFF
+
+.L_sign:
+	.long 0x80000000
+
+.L_24bit:
+	.long 0x00800000
+
+.L_mask_sign:
+	.long 0x7FFFFFFF
+
+ENDFUNC (GLOBAL (fixunssfsi))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/floatunssidf.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/floatunssidf.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/floatunssidf.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,76 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!conversion of unsigned integer to double precision floating point number
+!Author:Rakesh Kumar
+!Rewritten for SH1 support: Joern Rennecke
+!
+!Entry:
+!r4:operand
+!
+!Exit:
+!r0,r1:result
+!
+!Note:argument is passed in reg r4 and the result is returned in
+!regs r0 and r1.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+        .text
+        .align 5
+        .global GLOBAL (floatunsidf)
+	FUNC (GLOBAL (floatunsidf))
+
+GLOBAL (floatunsidf):
+	mov.w	LOCAL(x41f0),DBLRH	! bias + 32
+	tst	r4,r4			! check for zero
+	bt	.L_ret_zero
+.L_loop:
+	shll	r4	
+	SL(bf,	.L_loop,
+	 add	#-16,DBLRH)
+
+	mov	r4,DBLRL
+
+        SHLL20 (DBLRL)
+
+        shll16	DBLRH ! put exponent in proper place
+
+        SHLR12 (r4)
+
+	rts
+	or	r4,DBLRH
+	
+.L_ret_zero:
+	mov	#0,r1
+	rts
+	mov	#0,r0
+
+LOCAL(x41f0):	.word	0x41f0
+	.align 2
+
+ENDFUNC (GLOBAL (floatunsidf))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/fixunsdfsi.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/fixunsdfsi.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/fixunsdfsi.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,181 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!conversion of double precision floating point number to unsigned integer
+!Author:Aanchal Khanna
+!
+!Entry:
+!r4,r5:operand
+!
+!Exit:
+!r0:result
+!
+!Note:argument is passed in regs r4 and r5, the result is returned in
+!reg r0.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align 5
+	.global GLOBAL (fixunsdfsi)
+	FUNC (GLOBAL (fixunsdfsi))
+
+GLOBAL (fixunsdfsi):
+
+#ifdef  __LITTLE_ENDIAN__
+        mov     r4,r1
+        mov     r5,r4
+        mov     r1,r5
+#endif
+	mov.l	.L_p_inf,r2
+	mov     #-20,r1
+	
+	mov	r2,r7
+	mov.l   .L_1023,r3
+
+	and	r4,r2
+	shll    r4
+
+        movt    r6		! r6 contains the sign bit
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r1,r2           ! r2 contains the exponent
+#else
+        SHLR20 (r2)
+#endif
+	shlr    r4
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r1,r7
+#else
+        SHLR20 (r7)
+#endif
+	tst	r6,r6	
+	SL(bf,	.L_epil,
+	 mov	#0,r0)
+
+	cmp/hi	r2,r3		! if exp < 1023,return 0
+	mov.l	.L_high_mant,r1
+
+	SL(bt,	.L_epil,
+	 and	r4,r1)		! r1 contains high mantissa
+
+	cmp/eq	r2,r7		! chk if exp is invalid
+	mov.l	.L_1054,r7
+
+	bt	.L_inv_exp
+	mov	#11,r0
+	
+	cmp/hi	r7,r2		! If exp > 1054,return maxint
+	sub     r2,r7		!r7 contains the number of shifts
+
+	mov.l	.L_21bit,r2
+	bt	.L_ret_max
+
+	or	r2,r1
+	mov	r7,r3
+
+	shll8   r1
+	neg     r7,r7
+
+	shll2	r1
+
+        shll	r1
+	cmp/hi	r3,r0
+
+	SL(bt,	.L_lower_mant,
+	 mov	#21,r0)
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r7,r1
+#else
+.L_sh_loop:
+        tst	r7,r7
+        bt      .L_break
+        add     #1,r7
+        bra     .L_sh_loop
+        shlr    r1
+
+.L_break:
+#endif
+	rts
+	mov     r1,r0
+
+.L_lower_mant:
+	neg	r0,r0
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r0,r5
+#else
+        SHLR21 (r5)
+#endif
+	or	r5,r1		!pack lower and higher mantissas
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r7,r1
+#else
+.L_loop:
+        tst	r7,r7
+        bt      .L_break1
+        add     #1,r7
+        bra     .L_loop
+        shlr    r1
+
+.L_break1:
+#endif
+	mov	r1,r0
+.L_epil:
+	rts
+	nop
+
+.L_inv_exp:
+	cmp/hi	r0,r5
+	bt	.L_epil
+
+	cmp/hi	r0,r1		!compare high mantissa,r1
+	bt	.L_epil
+
+.L_ret_max:
+	mov.l   .L_maxint,r0
+
+	rts
+	nop
+
+	.align	2
+
+.L_maxint:
+	.long	0xffffffff
+.L_p_inf:
+	.long	0x7ff00000
+.L_high_mant:
+	.long	0x000fffff
+.L_1023:
+	.long	0x000003ff
+.L_1054:
+	.long	1054
+.L_21bit:
+	.long	0x00100000
+
+ENDFUNC (GLOBAL (fixunsdfsi))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/addsf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/addsf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/addsf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,535 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Add floating point numbers in r4, r5.
+
+! Author: Rakesh Kumar
+
+! Arguments are in r4, r5 and result in r0
+
+! Entry points: ___subsf3, ___addsf3
+
+! r4 and r5 are referred as op1 and op2
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align 5
+        .global GLOBAL (subsf3)
+	.global	GLOBAL (addsf3)
+	FUNC (GLOBAL (subsf3))
+	FUNC (GLOBAL (addsf3))
+
+GLOBAL (subsf3):
+        mov.l   .L_sign_bit,r1
+        xor     r1,r5
+
+GLOBAL (addsf3):
+	mov.l	r8,@-r15
+	mov	r4,r3
+
+	mov.l	.L_pinf,r2
+	mov	#0,r8
+
+	and	r2,r3 ! op1's exponent.
+	mov	r5,r6
+
+	! Check NaN or Infinity
+	and	r2,r6 ! op2's exponent.
+	cmp/eq	r2,r3
+
+	! go if op1 is NaN or INF. 
+	mov.l	.L_sign_bit,r0
+	SL(bt,	.L_inv_op1,
+	 mov	#-23,r1)
+	
+	! Go if op2 is NaN/INF.
+	cmp/eq	r2,r6
+	mov	r0,r7
+	bt	.L_ret_op2
+
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLR23 (r3)
+#else
+	shld	r1,r3
+#endif
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLR23 (r6)
+#else
+	shld	r1,r6
+#endif
+
+	! Check for negative zero
+	cmp/eq	r0,r5
+
+	mov	r5,r1
+	SL(bt,	.L_ret_op1,
+	 and	r7,r1)
+
+	cmp/eq	r0,r4
+	bt	.L_ret_op2
+
+	! if op1 is zero return op2
+	tst	r4,r4
+	bt	.L_ret_op2
+
+	! Equal numbers with opposite sign
+	mov	r4,r2
+	xor	r5,r2
+
+	cmp/eq	r0,r2
+	bt	.L_ret_zero
+
+	! if op2 is zero return op1
+	mov.l	.L_mask_fra,r2
+	tst	r5,r5
+
+	! Extract the mantissa
+	mov	r4,r0
+	SL(bt,	.L_ret_op1,
+	 and	r2,r5)
+
+	and	r2,r4
+
+	mov.l	.L_imp_bit,r2
+	and	r7,r0	! sign bit of op1
+
+	! Check for denormals
+	tst	r3,r3
+	bt	.L_norm_op1
+
+	! Attach the implicit bit
+	or	r2,r4
+	tst	r6,r6
+
+	bt	.L_norm_op2
+
+	or	r2,r5
+	tst	r0,r0
+
+	! operands are +ve or -ve??
+	bt	.L_ptv_op1
+
+	neg	r4,r4
+
+.L_ptv_op1:
+	tst	r1,r1
+	bt	.L_ptv_op2
+
+	neg	r5,r5
+
+! Test exponents for equality
+.L_ptv_op2:
+	cmp/eq	r3,r6
+	bt	.L_exp_eq
+
+! Make exponents of two arguments equal
+.L_exp_ne:
+	! r0, r1 contain sign bits.
+	! r4, r5 contain mantissas.
+	! r3, r6 contain exponents.
+	! r2, r7 scratch.
+
+	! Calculate result exponent.
+	mov	r6,r2
+	sub	r3,r2	! e2 - e1
+
+	cmp/pl	r2
+	mov	#23,r7
+
+	! e2 - e1 is -ve
+	bf	.L_exp_ne_1
+
+	mov	r6,r3 ! Result exp.
+	cmp/gt	r7,r2 ! e2-e1 > 23
+
+	mov	#1,r7
+	bt	.L_pack_op2_0
+
+	! Align the mantissa
+.L_loop_ne:
+	shar	r4
+
+	rotcr	r8
+	cmp/eq	r7,r2
+
+	add	#-1,r2
+	bf	.L_loop_ne
+
+	bt	.L_exp_eq
+
+! Exponent difference is too high.
+! Return op2 after placing pieces in proper place
+.L_pack_op2_0:
+	! If op1 is -ve
+	tst	r1,r1
+	bt	.L_pack_op2
+
+	neg	r5,r5
+
+! r6 has exponent
+! r5 has mantissa, r1 has sign
+.L_pack_op2:
+	mov.l	.L_nimp_bit,r2
+	mov	#23,r3
+
+	mov	r1,r0
+	
+	and	r2,r5
+	mov.l	@r15+,r8
+
+	or	r5,r0
+
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLL23 (r6)
+#else
+	shld	r3,r6
+#endif
+        rts
+	or	r6,r0
+
+! return op1. It is NAN or INF or op2 is zero.
+.L_ret_op1:
+	mov	r4,r0
+
+	rts
+	mov.l	@r15+,r8
+
+! return zero
+.L_ret_zero:
+	mov	#0,r0
+
+	rts
+	mov.l	@r15+,r8
+
+! return op2. It is NaN or INF or op1 is zero.
+.L_ret_op2:
+	mov	r5,r0
+
+	rts
+	mov.l	@r15+,r8
+
+! op2 is denormal. Normalize it.
+.L_norm_op2:
+	shll	r5
+	add	#-1,r6
+
+	tst	r2,r5
+	bt	.L_norm_op2
+
+	! Check sign
+	tst	r1,r1
+	bt	.L_norm_op2_2
+
+	neg	r5,r5
+
+.L_norm_op2_2:
+	add	#1,r6
+	cmp/eq	r3,r6
+
+	bf	.L_exp_ne
+	bt	.L_exp_eq
+
+! Normalize op1
+.L_norm_op1:
+	shll	r4
+	add	#-1,r3
+
+	tst	r2,r4
+	bt	.L_norm_op1
+
+	! Check sign
+	tst	r0,r0
+	bt	.L_norm_op1_1
+
+	neg	r4,r4
+
+.L_norm_op1_1:
+	! Adjust biasing
+	add	#1,r3
+
+	! Check op2 for denormalized value
+	tst	r6,r6
+	bt	.L_norm_op2
+
+	mov.l	.L_imp_bit,r2
+
+	tst	r1,r1	! Check sign
+	or	r2,r5	! Attach 24th bit
+
+	bt	.L_norm_op1_2
+
+	neg	r5,r5
+
+.L_norm_op1_2:
+	cmp/eq	r3,r6
+
+	bt	.L_exp_eq
+	bf	.L_exp_ne
+
+! op1 is NaN or Inf
+.L_inv_op1:
+	! Return op1 if it is NAN. 
+	! r2 is infinity
+	cmp/gt	r2,r4
+	bt	.L_ret_op1
+
+	! op1 is +/- INF
+	! If op2 is same return now.
+	cmp/eq	r4,r5
+	bt	.L_ret_op1
+
+	! return op2 if it is NAN
+	cmp/gt	r2,r5
+	bt	.L_ret_op2
+
+	! Check if op2 is inf
+	cmp/eq	r2,r6
+	bf	.L_ret_op1
+	
+	! Both op1 and op2 are infinities 
+	!of opp signs, or there is -NAN. Return a NAN.
+	mov.l	@r15+,r8
+	rts
+	mov	#-1,r0
+
+! Make unequal exponents equal.
+.L_exp_ne_1:
+	mov	#-25,r7
+	cmp/gt	r2,r7 ! -23 > e2 - e1
+
+	add	#1,r2
+	bf	.L_exp_ne_2
+
+	tst	r0,r0
+	bt	.L_pack_op1
+
+.L_pack_op1_0:
+	bra	.L_pack_op1
+	neg	r4,r4
+
+! Accumulate the shifted bits in r8
+.L_exp_ne_2:
+	! Shift with rounding
+	shar	r5
+	rotcr	r8
+
+	tst	r2,r2
+
+	add	#1,r2
+	bf	.L_exp_ne_2
+
+! Exponents of op1 and op2 are equal (or made so)
+! The mantissas are in r4-r5 and remaining bits in r8
+.L_exp_eq:
+	add	r5,r4 ! Add fractions.
+	mov.l	.L_sign_bit,r2
+
+	! Check for negative result
+	mov	#0,r0
+	tst	r2,r4
+
+	mov.l	.L_255,r5
+	bt	.L_post_add
+
+	negc	r8,r8
+	negc	r4,r4
+	or	r2,r0
+
+.L_post_add:
+	! Check for extra MSB
+	mov.l	.L_chk_25,r2
+
+	tst	r2,r4
+	bt	.L_imp_check
+
+	shar 	r4
+	rotcr	r8
+
+	add	#1,r3
+	cmp/ge	r5,r3
+
+	! Return Inf if exp > 254
+	bt	.L_ret_inf
+
+! Check for implicit (24th) bit in result
+.L_imp_check:
+        mov.l	.L_imp_bit,r2
+	tst	r2,r4
+
+	bf	.L_pack_op1
+
+! Result needs left shift
+.L_lft_shft:
+	shll	r8
+	rotcl	r4
+
+	add	#-1,r3
+	tst	r2,r4
+
+	bt	.L_lft_shft
+	
+! Pack the result after rounding
+.L_pack_op1:
+	! See if denormalized result is possible 
+	mov.l	.L_chk_25,r5
+	cmp/pl	r3
+
+	bf	.L_denorm_res
+
+	! Are there any bits shifted previously?
+	tst	r8,r8
+	bt	.L_pack_1
+
+	! Round
+	shll	r8
+	movt	r6
+
+	add	r6,r4
+
+	! If we are halfway between two numbers,
+	! round towards LSB = 0
+	tst	r8,r8
+
+	bf	.L_pack_1
+
+	shlr	r4
+	shll	r4
+
+.L_pack_1:
+	! Adjust extra MSB generated after rounding
+	tst	r4,r5
+	mov.l	.L_255,r2
+
+	bt	.L_pack_2
+	shar	r4
+
+	add	#1,r3 
+	cmp/ge	r2,r3	! Check for exp overflow
+
+	bt	.L_ret_inf
+	
+! Pack it finally
+.L_pack_2:
+	! Do not store implicit bit
+	mov.l	.L_nimp_bit,r2
+	mov	#23,r1
+
+	and	r2,r4
+
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLL23 (r3)
+#else
+	shld	r1,r3
+#endif
+	mov.l	@r15+,r8
+
+	or	r4,r0
+        rts
+	or	r3,r0
+
+! Return infinity
+.L_ret_inf:
+	mov.l	.L_pinf,r2
+
+	mov.l	@r15+,r8
+	rts
+	or	r2,r0
+
+! Result must be denormalized
+.L_denorm_res:
+	mov	#0,r2
+	
+! Denormalizing loop with rounding
+.L_den_1:
+	shar	r4
+	movt	r6
+
+	tst	r3,r3
+	bt	.L_den_2
+
+	! Increment the exponent
+	add	#1,r3
+
+	tst	r6,r6
+	bt	.L_den_0
+
+	! Count number of ON bits shifted
+	add	#1,r2
+
+.L_den_0:
+	bra	.L_den_1
+	nop
+
+! Apply rounding
+.L_den_2:
+	cmp/eq	r6,r1
+	bf	.L_den_3
+
+	add	r6,r4
+	mov	#1,r1
+
+	! If halfway between two numbers,
+	! round towards LSB = 0
+	cmp/eq	r2,r1
+	bf	.L_den_3
+
+	shar	r4
+	shll	r4
+
+.L_den_3:
+
+	mov.l	@r15+,r8
+	rts
+	or	r4,r0
+	
+	.align 2
+.L_imp_bit:
+        .long   0x00800000
+
+.L_nimp_bit:
+	.long	0xFF7FFFFF
+
+.L_mask_fra:
+        .long   0x007FFFFF
+
+.L_pinf:
+        .long   0x7F800000
+
+.L_sign_bit:
+	.long	0x80000000
+
+.L_bit_25:
+	.long	0x01000000
+
+.L_chk_25:
+        .long   0x7F000000
+
+.L_255:
+	.long	0x000000FF
+
+ENDFUNC (GLOBAL (addsf3))
+ENDFUNC (GLOBAL (subsf3))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/adddf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/adddf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/adddf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,799 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Routine for adding two double numbers
+
+! Author: Rakesh Kumar
+! SH1 Support by Joern Rennecke
+! Sticky Bit handling : Joern Rennecke
+
+! Arguments: r4-r5, r6-r7
+! Result: r0-r1
+
+! The value in r4-r5 is referred to as op1
+! and that in r6-r7 is referred to as op2
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+        .align 5
+	.global	GLOBAL (subdf3)
+	FUNC (GLOBAL (subdf3))
+        .global GLOBAL (adddf3)
+	FUNC (GLOBAL (adddf3))
+
+GLOBAL (subdf3):
+#ifdef __LITTLE_ENDIAN__
+	mov	r4,r1
+	mov	r6,r2
+
+	mov	r5,r4
+	mov	r7,r6
+
+	mov	r1,r5
+	mov	r2,r7
+#endif
+	mov.l	.L_sign,r2
+	bra	.L_adddf3_1
+	xor	r2,r6
+
+GLOBAL (adddf3):
+#ifdef	__LITTLE_ENDIAN__
+	mov	r4,r1
+	mov	r6,r2
+
+	mov	r5,r4
+	mov	r7,r6
+
+	mov	r1,r5
+	mov	r2,r7
+#endif
+	
+.L_adddf3_1:
+	mov.l	r8,@-r15
+	mov	r4,r1
+
+	mov.l 	.L_inf,r2
+	mov	r6,r3
+
+	mov.l	r9,@-r15
+	and	r2,r1		!Exponent of op1 in r1
+
+	mov.l	r10,@-r15
+	and	r2,r3		!Exponent of op2 in r3
+
+	! Check for Nan or Infinity
+	mov.l	.L_sign,r9
+	cmp/eq	r2,r1
+
+	mov	r9,r10
+	bt	.L_thread_inv_exp_op1
+
+	mov	r9,r0
+	cmp/eq	r2,r3
+! op1 has a valid exponent. We need not check it again.
+! Return op2 straight away.
+	and	r4,r9		!r9 has sign bit for op1
+	bt	.L_ret_op2
+
+	! Check for -ve zero
+	cmp/eq	r4,r0
+	and	r6,r10		!r10 has sign bit for op2
+
+	bt	.L_op1_nzero
+
+	cmp/eq	r6,r0
+	bt	.L_op2_nzero
+
+! Check for zero
+.L_non_zero:
+	tst	r4,r4
+	bt	.L_op1_zero
+
+	! op1 is not zero, check op2 for zero
+	tst	r6,r6
+	bt	.L_op2_zero
+
+! r1 and r3 has masked out exponents, r9 and r10 has signs
+.L_add:
+	mov.l	.L_high_mant,r8
+	mov	#-20,r2
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r2,r1		! r1 now has exponent for op1 in its lower bits
+#else
+	SHLR20 (r1)
+#endif
+	and	r8,r6	! Higher bits of mantissa of op2
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r2,r3		! r3 has exponent for op2 in its lower bits
+#else
+	SHLR20 (r3)
+#endif
+	and	r8,r4	! Higher bits of mantissa of op1
+
+	mov.l	.L_21bit,r8
+
+	tst	r1,r1
+	bt	.L_norm_op1
+
+	! Set the 21st bit.
+	or	r8,r4
+	tst	r3,r3
+
+	bt	.L_norm_op2
+	or	r8,r6
+
+! Check for negative mantissas. Make them positive by negation
+! r9 and r10 have signs of op1 and op2 respectively
+.L_neg_mant:
+	tst	r9,r9
+	bf	.L_neg_op1
+
+	tst	r10,r10
+	bf	.L_neg_op2
+
+.L_add_1:
+	cmp/ge	r1,r3
+
+	mov	r1,r0
+	bt	.L_op2_exp_greater
+
+	sub	r3,r0
+	! If exponent difference is greater than 54, the resultant exponent
+	! won't be changed. Return op1 straight away.
+	mov	#54,r2
+	cmp/gt	r2,r0
+
+	bt	.L_pack_op1
+
+	mov	r1,r3
+	clrt
+
+	cmp/eq	#0,r0
+	bt	.L_add_mant
+
+	! Shift left the first operand and apply rest of shifts to second operand.
+	mov	#0,r2
+	shll	r5
+
+	rotcl	r4
+
+	add	#-1,r3
+	dt	r0
+
+	bt	.L_add_mant
+	dt	r0
+
+	bt	LOCAL(got_guard)
+	dt	r0
+
+	bt	LOCAL(got_sticky)
+
+! Shift the mantissa part of op2 so that both exponents are equal
+.L_shfrac_op2:
+	shar	r6
+	or	r7,r2	! sticky bit
+
+	rotcr	r7
+	dt	r0
+
+	bf	.L_shfrac_op2
+
+	shlr	r2
+
+	subc	r2,r2	! spread sticky bit across r2
+LOCAL(got_sticky):
+	shar	r6
+
+	rotcr	r7
+
+	rotcr	r2
+LOCAL(got_guard):
+	shar	r6
+
+	rotcr	r7
+
+	rotcr	r2
+
+
+! Add the psotive mantissas and check for overflow by checking the
+! MSB of the resultant. In case of overflow, negate the result.
+.L_add_mant:
+	clrt
+	addc	r7,r5
+
+	mov	#0,r10	! Assume resultant to be positive
+	addc	r6,r4
+
+	cmp/pz	r4
+
+	bt	.L_mant_ptv
+	negc	r2,r2
+
+	negc	r5,r5
+
+	mov.l	.L_sign,r10 ! The assumption was wrong, result is negative
+	negc	r4,r4
+
+! 23rd bit in the high part of mantissa could be set.
+! In this case, right shift the mantissa.
+.L_mant_ptv:
+	mov.l	.L_23bit,r0
+
+	tst	r4,r0
+	bt	.L_mant_ptv_0
+
+	shlr	r4
+	rotcr	r5
+
+	add	#1,r3
+	bra	.L_mant_ptv_1
+	rotcr	r2
+
+.L_mant_ptv_0:
+	mov.l	.L_22bit,r0
+	tst	r4,r0
+
+	bt	.L_norm_mant
+
+.L_mant_ptv_1:
+	! 22 bit of resultant mantissa is set. Shift right the mantissa
+	! and add 1 to exponent
+	add	#1,r3
+	shlr	r4
+	rotcr	r5
+	! The mantissa is already normalized. We don't need to
+	! spend any effort. Branch to epilogue. 
+	bra	.L_epil
+	rotcr	r2
+
+! Normalize operands
+.L_norm_op1:
+	shll	r5
+
+	rotcl	r4
+	add	#-1,r1
+
+	tst	r4,r8
+	bt	.L_norm_op1
+
+	tst	r3,r3
+	SL(bf,	.L_neg_mant,
+	 add	#1,r1)
+
+.L_norm_op2:
+	shll	r7
+
+	rotcl	r6
+	add	#-1,r3
+
+	tst	r6,r8
+	bt	.L_norm_op2
+
+	bra	.L_neg_mant
+	add	#1,r3
+
+! Negate the mantissa of op1
+.L_neg_op1:
+	clrt
+	negc	r5,r5
+
+	negc	r4,r4
+	tst	r10,r10
+
+	bt	.L_add_1
+
+! Negate the mantissa of op2
+.L_neg_op2:
+	clrt
+	negc	r7,r7
+
+	bra	.L_add_1
+	negc	r6,r6
+
+! Thread the jump to .L_inv_exp_op1
+.L_thread_inv_exp_op1:
+	bra	.L_inv_exp_op1
+	nop
+
+.L_ret_op2:
+	mov.l	@r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r6,r1
+#else
+	mov	r6,r0
+#endif
+
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r7,r0
+#else
+	mov	r7,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+
+.L_op1_nzero:
+	tst	r5,r5
+	bt	.L_ret_op2
+
+	! op1 is not zero. Check op2 for negative zero
+	cmp/eq	r6,r0
+	bf	.L_non_zero	! both op1 and op2 are not -0
+
+.L_op2_nzero:
+	tst	r7,r7
+	bf	.L_non_zero
+
+	mov.l	@r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r4,r1
+#else
+	mov	r4,r0	! op2 is -0, return op1
+#endif
+
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r5,r0
+#else
+	mov	r5,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+
+! High bit of op1 is known to be zero.
+! Check low bit. r2 contains 0x00000000
+.L_op1_zero:
+	tst	r5,r5
+	bt	.L_ret_op2
+
+	! op1 is not zero. Check high bit of op2
+	tst	r6,r6
+	bf	.L_add	! both op1 and op2 are not zero
+
+! op1 is not zero. High bit of op2 is known to be zero.
+! Check low bit of op2. r2 contains 0x00000000
+.L_op2_zero:
+	tst	r7,r7
+	bf	.L_add
+
+	mov.l	@r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r4,r1
+#else
+	mov	r4,r0	! op2 is zero, return op1
+#endif
+
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r5,r0
+#else
+	mov	r5,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+
+! exp (op1) is smaller or equal to exp (op2)
+! The logic of same operations is present in .L_add. Kindly refer it for
+! comments
+.L_op2_exp_greater:
+	mov	r3,r0
+	sub	r1,r0
+
+	mov	#54,r2
+	cmp/gt	r2,r0
+
+	bt	.L_pack_op2
+
+	cmp/eq	#0,r0
+	bt	.L_add_mant
+
+	mov	#0,r2
+	shll	r7
+	rotcl	r6
+	add	#-1,r0
+	add	#-1,r3
+
+	cmp/eq	#0,r0
+	bt	.L_add_mant
+.L_shfrac_op1:	
+        add     #-1,r0
+        shar    r4
+
+	rotcr	r5
+	rotcr	r2
+
+        cmp/eq  #0,r0
+        bf      .L_shfrac_op1
+
+	bra	.L_add_mant
+	nop
+
+! Return the value in op1
+.L_ret_op1:
+        mov.l   @r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r4,r1
+#else
+        mov     r4,r0
+#endif
+
+        mov.l   @r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r5,r0
+#else
+        mov     r5,r1
+#endif
+
+        rts
+        mov.l   @r15+,r8
+
+! r1 has exp, r9 has sign, r4 and r5 mantissa
+.L_pack_op1:
+	mov.l	.L_high_mant,r7
+	mov	r4,r0
+
+	tst	r9,r9
+	bt	.L_pack_op1_1
+
+	clrt
+	negc	r5,r5
+	negc	r0,r0
+
+.L_pack_op1_1:
+	and	r7,r0
+	mov	r1,r3
+
+	mov	#20,r2
+	mov	r5,r1
+
+	mov.l	@r15+,r10
+	or	r9,r0
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r2,r3
+#else
+	SHLL20 (r3)
+#endif
+	mov.l	@r15+,r9
+
+	or	r3,r0
+#ifdef	__LITTLE_ENDIAN__
+	mov	r0,r2
+	mov	r1,r0
+	mov	r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+!r2 has exp, r10 has sign, r6 and r7 mantissa
+.L_pack_op2:
+	mov.l	.L_high_mant,r9
+	mov	r6,r0
+
+	tst	r10,r10
+	bt	.L_pack_op2_1
+
+	clrt
+	negc	r7,r7
+	negc	r0,r0
+
+.L_pack_op2_1:
+	and	r9,r0
+	mov	r7,r1
+
+	mov	#20,r2
+	or	r10,r0
+
+	mov.l	@r15+,r10
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r2,r3
+#else
+	SHLL20 (r3)
+#endif
+
+	mov.l	@r15+,r9
+
+	or	r3,r0
+#ifdef	__LITTLE_ENDIAN__
+	mov	r0,r2
+	mov	r1,r0
+	mov	r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+! Normalize the mantissa by setting its 21 bit in high part
+.L_norm_mant:
+	mov.l	.L_21bit,r0
+
+	tst	r4,r0
+	bf	.L_epil
+
+	tst	r4,r4
+	bf	.L_shift_till_1
+
+	tst	r5,r5
+	bf	.L_shift_till_1
+
+	! Mantissa is zero, return 0
+	mov.l	@r15+,r10
+	mov	#0,r0
+
+	mov.l	@r15+,r9
+	mov.l	@r15+,r8
+
+	rts
+	mov	#0,r1
+
+! A loop for making the 21st bit 1 in high part of resultant mantissa
+! It is already ensured that 1 bit is present in the mantissa
+.L_shift_till_1:
+	clrt
+	shll	r5
+
+	rotcl	r4
+	add	#-1,r3
+
+	tst	r4,r0
+	bt	.L_shift_till_1
+
+! Return the result. Mantissa is in r4-r5. Exponent is in r3
+! Sign bit in r10
+.L_epil:
+	cmp/pl	r3
+
+	bf	.L_denorm
+	mov.l	LOCAL(x7fffffff),r0
+
+	mov	r5,r1
+	shlr	r1
+
+	mov	#0,r1
+	addc	r0,r2
+
+! Check extra MSB here
+	mov.l	.L_22bit,r9
+	addc	r1,r5	! round to even
+
+	addc	r1,r4
+	tst	r9,r4
+
+	bf	.L_epil_1
+
+.L_epil_0:
+	mov.l	.L_21bit,r1
+
+	not	r1,r1
+	and	r1,r4
+
+	mov	r4,r0
+	or	r10,r0
+
+	mov.l	@r15+,r10
+	mov	#20,r2
+
+	mov.l	@r15+,r9
+	mov	r5,r1
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r2,r3
+#else
+	SHLL20 (r3)
+#endif
+	or	r3,r0
+
+#ifdef	__LITTLE_ENDIAN__
+	mov	r0,r2
+	mov	r1,r0
+	mov	r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+.L_epil_1:
+	shlr	r4
+	add	#1,r3
+	bra	.L_epil_0
+	rotcr	r5
+
+.L_denorm:
+	add	#-1,r3
+.L_denorm_1:
+	tst	r3,r3
+	bt	.L_denorm_2
+
+	shlr	r4
+	rotcr	r5
+
+	movt	r1
+	bra	.L_denorm_1
+	add	#1,r3
+
+.L_denorm_2:
+	clrt
+	mov	#0,r2
+	addc	r1,r5
+
+	addc	r2,r4
+	mov	r4,r0
+
+	or	r10,r0
+	mov.l	@r15+,r10
+
+	mov	r5,r1
+
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r0,r2
+	mov	r1,r0
+	mov	r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+! op1 is known to be positive infinity, and op2 is Inf. The sign
+! of op2 is not known. Return the appropriate value
+.L_op1_pinf_op2_inf:
+	mov.l	.L_sign,r0
+	tst	r6,r0
+
+	bt	.L_ret_op2_1
+
+	! op2 is negative infinity. Inf - Inf is being performed
+	mov.l	.L_inf,r0
+	mov.l	@r15+,r10
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r0,r1
+#endif
+	mov.l	@r15+,r8
+
+	rts
+#ifdef	__LITTLE_ENDIAN__
+	mov	#1,r0
+#else
+	mov	#1,r1	! Any value here will return Nan
+#endif
+	
+.L_ret_op1_1:
+        mov.l   @r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r4,r1
+#else
+        mov     r4,r0
+#endif
+
+        mov.l   @r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r5,r0
+#else
+        mov     r5,r1
+#endif
+
+        rts
+        mov.l   @r15+,r8
+
+.L_ret_op2_1:
+	mov.l	@r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r6,r1
+#else
+	mov	r6,r0
+#endif
+
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r7,r0
+#else
+	mov	r7,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+
+! op1 is negative infinity. Check op2 for infinity or Nan
+.L_op1_ninf:
+	cmp/eq	r2,r3
+	bf	.L_ret_op1_1	! op2 is neither Nan nor Inf
+
+	mov.l	@r15+,r9
+	div0s	r4,r6		! different signs -> NaN
+	mov	r4,DBLRH
+	or	r6,DBLRH
+	mov.l	@r15+,r8
+	SL(bf, 0f,
+	 mov	r5,DBLRL)
+	mov	#-1,DBLRH	! return NaN.
+0:	rts
+	or	r7,DBLRL
+
+!r1 contains exponent for op1, r3 contains exponent for op2
+!r2 has .L_inf (+ve Inf)
+!op1 has invalid exponent. Either it contains Nan or Inf
+.L_inv_exp_op1:
+	! Check if a is Nan
+	cmp/pl	r5
+	bt	.L_ret_op1_1
+
+	mov.l	.L_high_mant,r0
+	and	r4,r0
+
+	cmp/pl	r0
+	bt	.L_ret_op1_1
+
+	! op1 is not Nan. It is infinity. Check the sign of it.
+	! If op2 is Nan, return op2
+	cmp/pz	r4
+
+	bf	.L_op1_ninf
+
+	! op2 is +ve infinity here
+	cmp/eq	r2,r3
+	bf	.L_ret_op1_1	! op2 is neither Nan nor Inf
+
+	! r2 is free now
+	mov.l	.L_high_mant,r0
+	tst	r6,r0		! op2 also has invalid exponent
+
+	bf	.L_ret_op2_1	! op2 is Infinity, and op1 is +Infinity
+
+	tst	r7,r7
+	bt	.L_op1_pinf_op2_inf	! op2 is Infinity, and op1 is +Infinity
+	!op2 is not infinity, It is Nan
+	bf	.L_ret_op2_1
+
+	.align 2	
+.L_high_mant:
+	.long 0x000FFFFF
+
+.L_21bits:
+	.long 0x001FFFFF
+
+.L_22bit:
+	.long 0x00200000
+
+.L_23bit:
+	.long 0x00400000
+
+.L_21bit:
+	.long 0x00100000
+
+.L_sign:
+	.long 0x80000000
+
+.L_inf:
+	.long 0x7ff00000
+
+LOCAL(x7fffffff): .long 0x7fffffff
+
+ENDFUNC (GLOBAL (subdf3))
+ENDFUNC (GLOBAL (adddf3))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/mulsf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/mulsf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/mulsf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,352 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Routine for multiplying two floating point numbers
+
+! Author: Rakesh Kumar
+
+! Arguments: r4 and r5
+! Result: r0
+
+! The arguments are referred as op1 and op2
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+        .text
+        .align 5
+        .global GLOBAL (mulsf3)
+        FUNC (GLOBAL (mulsf3))
+
+GLOBAL (mulsf3):
+	! Extract the sign bits
+	mov.l	.L_sign,r3
+	mov	r3,r0
+
+	and	r4,r3		! sign bit for op1
+	mov.l	.L_sign_mask,r6
+
+	! Mask out the sign bit from op1 and op2
+	and	r5,r0		! sign bit for op2
+	mov.l	.L_inf,r2
+
+	and	r6,r4
+	xor	r3,r0		! Final sign in r0
+
+	and	r6,r5
+	tst	r4,r4
+
+	! Check for zero
+	mov	r5,r7
+	! Check op1 for zero
+	SL(bt,	.L_op1_zero,
+	 mov	r4,r6)
+
+	tst	r5,r5
+	bt	.L_op2_zero	! op2 is zero
+
+	! Extract the exponents
+	and	r2,r6		! Exponent of op1
+	cmp/eq	r2,r6
+
+	and	r2,r7
+	bt	.L_inv_op1	! op1 is NaN or Inf
+
+	mov.l	.L_mant,r3
+	cmp/eq	r2,r7
+
+	and	r3,r4	! Mantissa of op1
+	bt	.L_ret_op2	! op2 is Nan or Inf
+
+	and	r3,r5	! Mantissa of op2
+
+	mov	#-23,r3
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLR23 (r6)
+	SHLR23 (r7)
+#else
+	shld	r3,r6
+	shld	r3,r7
+#endif
+	! Check for denormals
+	mov.l	.L_24bit,r3
+	tst	r6,r6
+
+	bt	.L_norm_op1	! op1 is denormal
+	add	#-127,r6	! Unbias op1's exp
+
+	tst	r7,r7
+	bt	.L_norm_op2	! op2 is denormal
+
+	add	#-127,r7	! Unbias op2's exp
+
+.L_multiply:
+	add	r6,r7	! Final exponent in r7
+	mov.l	.L_24bit,r1
+
+	! set 24th bit of mantissas
+	mov	#127,r3
+	or	r1,r4
+
+	DMULU_SAVE
+
+	! Multiply
+	or	r1,r5
+	DMULUL	(r4,r5,r4)
+
+	DMULUH	(r5)
+
+	DMULU_RESTORE
+
+	mov.l	.L_16bit,r6
+
+	! Check for extra MSB generated
+	tst	r5,r6
+
+	mov.l	.L_255,r1
+	bf	.L_shift_by_1	! Adjust the extra MSB
+	
+! Normalize the result with rounding
+.L_epil:
+	! Bias the exponent
+	add	#127,r7
+	cmp/ge	r1,r7
+	
+	! Check exponent overflow and underflow
+	bt	.L_ret_inf
+
+	cmp/pl	r7
+	bf	.L_denorm
+
+.L_epil_0:
+	mov	#-23,r3
+	shll	r5
+	mov	#0,r6
+
+! Fit resultant mantissa in 24 bits
+! Apply default rounding
+.L_loop_epil_0:
+        tst	r3,r3
+	bt	.L_loop_epil_out
+
+	add	#1,r3
+	shlr	r4
+
+	bra	.L_loop_epil_0
+	rotcr	r6
+
+! Round mantissa
+.L_loop_epil_out:
+	shll8	r5
+	or	r5,r4
+
+	mov.l	.L_mant,r2
+	mov	#23,r3
+
+	! Check last bit shifted out of result
+	tst	r6,r6
+	bt	.L_epil_2
+
+	! Round
+	shll	r6
+	movt	r5
+
+	add	r5,r4
+
+	! If this is the only ON bit shifted
+	! Round towards LSB = 0
+	tst	r6,r6
+	bf	.L_epil_2
+
+	shlr	r4
+	shll	r4
+
+.L_epil_2:
+	! Rounding may have produced extra MSB.
+	mov.l	.L_25bit,r5
+	tst	r4,r5
+
+	bt	.L_epil_1
+
+	add	#1,r7
+	shlr	r4
+
+.L_epil_1:
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLL23 (r7)
+#else
+	shld	r3,r7
+#endif
+
+	and	r2,r4
+
+	or	r7,r4
+	rts
+	or	r4,r0
+
+.L_denorm:
+	mov	#0,r3
+
+.L_den_1:
+	shlr	r5
+	rotcr	r4
+
+	cmp/eq	r3,r7
+	bt	.L_epil_0
+
+	bra	.L_den_1
+	add	#1,r7
+	
+
+! Normalize the first argument
+.L_norm_op1:
+	shll	r4
+	tst	r3,r4
+
+	add	#-1,r6
+	bt	.L_norm_op1
+
+	! The biasing is by 126
+	add	#-126,r6
+	tst	r7,r7
+
+	bt      .L_norm_op2
+
+	bra	.L_multiply
+	add	#-127,r7
+
+! Normalize the second argument
+.L_norm_op2:
+	shll	r5
+	tst	r3,r5
+
+	add	#-1,r7
+	bt	.L_norm_op2
+
+	bra	.L_multiply
+	add	#-126,r7
+
+! op2 is zero. Check op1 for exceptional cases
+.L_op2_zero:
+	mov.l	.L_inf,r2
+	and	r2,r6
+
+	! Check if op1 is deterministic
+	cmp/eq	r2,r6
+	SL(bf,	.L_ret_op2,
+	 mov	#1,r1)
+
+	! Return NaN
+	rts
+	mov	#-1,r0
+
+! Adjust the extra MSB
+.L_shift_by_1:
+	shlr	r5
+	rotcr	r4
+
+	add	#1,r7		! Show the shift in exponent
+
+	cmp/gt	r3,r7
+	bf	.L_epil
+
+	! The resultant exponent is invalid
+	mov.l	.L_inf,r1
+	rts
+	or	r1,r0
+
+.L_ret_op1:
+	rts
+	or	r4,r0
+
+! op1 is zero. Check op2 for exceptional cases
+.L_op1_zero:
+	mov.l	.L_inf,r2
+	and	r2,r7
+	
+	! Check if op2 is deterministic
+	cmp/eq	r2,r7
+	SL(bf,	.L_ret_op1,
+	 mov	#1,r1)
+
+	! Return NaN
+	rts
+	mov	#-1,r0
+
+.L_inv_op1:
+	mov.l	.L_mant,r3
+	mov	r4,r6
+
+	and	r3,r6
+	tst	r6,r6
+
+	bf	.L_ret_op1	! op1 is Nan
+	! op1 is not Nan. It is Inf
+
+	cmp/eq	r2,r7
+	bf	.L_ret_op1	! op2 has a valid exponent
+
+! op2 has a invalid exponent. It could be Inf, -Inf, Nan.
+! It doesn't make any difference.
+.L_ret_op2:
+	rts
+	or	r5,r0
+
+.L_ret_inf:
+	rts
+	or	r2,r0
+
+.L_ret_zero:
+	mov	#0,r2
+	rts
+	or	r2,r0
+
+	
+	.align 2
+.L_mant:
+	.long 0x007FFFFF
+
+.L_inf:
+	.long 0x7F800000
+
+.L_24bit:
+	.long 0x00800000
+
+.L_25bit:
+	.long 0x01000000
+
+.L_16bit:
+	.long 0x00008000
+
+.L_sign:
+	.long 0x80000000
+
+.L_sign_mask:
+	.long 0x7FFFFFFF
+
+.L_255:
+	.long 0x000000FF
+
+ENDFUNC (GLOBAL (mulsf3))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/floatsisf.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/floatsisf.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/floatsisf.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,200 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Conversion of integer to floating point
+
+! Author: Rakesh Kumar
+
+! Argument: r4
+! Result: r0
+
+! r4 is referred as op1
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+        .text
+        .align 5
+        .global GLOBAL (floatsisf)
+        FUNC (GLOBAL (floatsisf))
+
+GLOBAL (floatsisf):
+	mov.l	.L_sign,r2
+	mov	#23,r6
+
+	! Check for zero
+	tst	r4,r4
+	mov.l	.L_24_bits,r7
+
+	! Extract sign
+	and	r4,r2
+	bt	.L_ret
+
+	! Negative ???
+	mov.l	.L_imp_bit,r5
+	cmp/pl	r4
+
+	not	r7,r3
+	bf	.L_neg
+
+	! Decide the direction for shifting
+	cmp/gt	r7,r4
+	mov	r4,r0
+
+	and	r5,r0
+	bt	.L_shr_0
+
+	! Number may already be in normalized form
+	cmp/eq	#0,r0
+	bf	.L_pack
+
+! Shift the bits to the left. Adjust the exponent
+.L_shl:
+	shll	r4
+	mov	r4,r0
+
+	and	r5,r0
+	cmp/eq	#0,r0
+
+	SL(bt,	.L_shl,
+	 add	#-1,r6)
+
+! Pack the value in floating point format.
+! r6 has unbiased exponent, r4 has mantissa, r2 has sign
+.L_pack:
+	mov	#23,r3
+	not	r5,r5
+
+	mov	r2,r0
+	add	#127,r6
+
+	and	r5,r4
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLL23 (r6)
+#else
+	shld	r3,r6
+#endif
+
+	or	r6,r0
+	rts
+	or	r4,r0
+
+! Negate the number
+.L_neg:
+	! Take care for -2147483648.
+	mov	r4,r0
+	shll	r0
+	
+	cmp/eq	#0,r0
+	SL(bt,	.L_ret_min,
+	 neg	r4,r4)
+
+        cmp/gt  r7,r4
+        bt	.L_shr_0
+
+	mov	r4,r0
+	and	r5,r0
+
+	cmp/eq	#0,r0
+	bf	.L_pack
+	bt	.L_shl
+	
+.L_shr_0:
+	mov	#0,r1
+
+! Shift right the number with rounding
+.L_shr:
+	shlr	r4
+	movt	r7
+
+	tst	r7,r7
+
+	! Count number of ON bits shifted
+	bt	.L_shr_1
+	add	#1,r1
+
+.L_shr_1:
+	mov	r4,r0
+	add	#1,r6
+
+	and	r3,r0
+	cmp/eq	#0,r0
+
+	! Add MSB of shifted bits
+	bf	.L_shr
+	add	r7,r4
+
+	tst	r7,r7
+	bt	.L_pack
+
+.L_pack1:
+	mov	#1,r0
+	cmp/eq	r1,r0
+
+	bt	.L_rnd
+	mov	r4,r0
+
+	! Rounding may have misplaced MSB. Adjust.
+	and	r3,r0
+	cmp/eq	#0,r0
+
+	bf	.L_shr
+	bt	.L_pack
+
+! If only MSB of shifted bits is ON, we are halfway
+! between two numbers. Round towards even LSB of
+! resultant mantissa.
+.L_rnd:
+	shlr	r4
+	bra	.L_pack
+	shll	r4
+
+.L_ret:
+	rts
+	mov	r4,r0
+
+! Return value for -2147483648
+.L_ret_min:
+	mov.l	.L_min_val,r0
+	rts
+	nop
+
+	.align 2
+.L_sign:
+	.long 0x80000000
+
+.L_imp_bit:
+	.long 0x00800000
+
+.L_24_bits:
+	.long 0x00FFFFFF
+
+.L_nsign:
+	.long 0x7FFFFFFF
+
+.L_min_val:
+	.long 0xCF000000
+
+ENDFUNC (GLOBAL (floatsisf))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/muldf3.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/muldf3.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/muldf3.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,601 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!multiplication of two double precision floating point numbers
+!Author:Aanchal Khanna
+!SH1 Support / Simplifications: Joern Rennecke
+!
+!Entry:
+!r4,r5:operand 1
+!
+!r6,r7:operand 2
+!
+!Exit:
+!r0,r1:result
+!
+!Notes: argument 1 is passed in regs r4 and r5 and argument 2 is passed in regs
+!r6 and r7, result is returned in regs r0 and r1. operand 1 is referred as op1
+!and operand 2 as op2.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+	.text
+	.align	5	
+	.global	GLOBAL (muldf3)
+	FUNC (GLOBAL (muldf3))
+
+GLOBAL (muldf3):
+
+#ifdef  __LITTLE_ENDIAN__
+        mov     r4,r1
+        mov     r5,r4
+        mov     r1,r5
+
+        mov     r6,r1
+        mov     r7,r6
+        mov     r1,r7
+#endif
+	mov.l	.L_mask_sign,r0
+	mov	r4,r2
+
+	and	r0,r2		
+	mov	#0,r1
+
+	shll	r4
+	and	r6,r0		
+	
+	xor     r2,r0		!r0 contains the result's sign bit
+	shlr	r4
+
+	mov.l   .L_inf,r2
+	shll	r6
+
+	mov	r4,r3
+	shlr	r6
+	
+.L_chk_a_inv:
+	!chk if op1 is Inf/NaN
+	and	r2,r3
+	mov.l	r8,@-r15
+
+	cmp/eq	r3,r2
+	mov.l	.L_mask_high_mant,r8
+
+	mov	r2,r3
+	bf	.L_chk_b_inv
+
+	mov	r8,r3
+	and	r4,r8
+
+	cmp/hi  r1,r8		
+	bt	.L_return_a	!op1 NaN, return op1
+
+	cmp/hi  r1,r5	
+	mov	r2,r8
+
+	bt      .L_return_a	!op1 NaN, return op1
+	and	r6,r8
+
+	cmp/eq	r8,r2		
+	and	r6,r3
+
+	bt      .L_b_inv
+	cmp/eq	r1,r6		
+
+	bf	.L_return_a	!op1 Inf,op2= normal no return op1
+	cmp/eq	r1,r7
+
+	bf	.L_return_a	!op1 Inf,op2= normal no return op1
+	mov.l   @r15+,r8	
+
+	rts
+	mov	#-1,DBLRH	!op1=Inf, op2=0,return nan
+
+.L_b_inv:
+	!op2 is NaN/Inf
+	cmp/hi	r1,r7
+	mov	r1,r2
+
+	mov	r5,r1
+	bt	.L_return_b	!op2=NaN,return op2
+
+	cmp/hi	r2,r6
+	or	r4,r0
+
+	bt	.L_return_b	!op2=NaN,return op2
+	mov.l   @r15+,r8
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts			!op1=Inf,op2=Inf,return Inf with sign
+	nop
+
+.L_chk_b_inv:
+	!Chk if op2 is NaN/Inf
+	and	r6,r2
+	cmp/eq	r3,r2
+
+	bf	.L_chk_a_for_zero
+	and	r6,r8
+
+	cmp/hi	r1,r8
+	bt	.L_return_b	 !op2=NaN,return op2
+
+	cmp/hi	r1,r7
+	bt	.L_return_b	 !op2=NaN,return op2
+
+	cmp/eq	r5,r1
+	bf      .L_return_b	 !op1=normal number,op2=Inf,return Inf
+
+	mov	r7,r1
+	cmp/eq	r4,r1
+
+	bf	.L_return_b	/* op1=normal number, op2=Inf,return Inf */
+	mov.l   @r15+,r8
+
+	rts
+	mov	#-1,DBLRH	!op1=0,op2=Inf,return NaN
+
+.L_return_a:
+	mov	r5,r1
+	or	r4,r0
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts
+	mov.l   @r15+,r8
+
+.L_return_b:
+	mov	r7,r1
+	or	r6,r0	
+	
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+	
+.L_chk_a_for_zero:
+	!Chk if op1 is zero
+	cmp/eq	r1,r4
+	bf	.L_chk_b_for_zero
+	
+	cmp/eq	r1,r5
+	bf	.L_chk_b_for_zero
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+.L_chk_b_for_zero:
+	!op1=0,chk if op2 is zero
+        cmp/eq  r1,r6
+        mov	r1,r3
+	
+	mov.l   .L_inf,r1
+	bf      .L_normal_nos
+
+        cmp/eq  r3,r7
+        bf      .L_normal_nos
+
+	mov	r3,r1
+	mov.l   @r15+,r8
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	nop
+
+.L_normal_nos:
+	!op1 and op2 are normal nos
+	mov.l	r9,@-r15
+	mov	r4,r3
+
+	mov     #-20,r9	
+	and	r1,r3	
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r9,r2
+#else
+        SHLR20 (r2)
+#endif
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r9,r3
+#else
+        SHLR20 (r3)
+#endif
+	cmp/pl	r3
+
+	bf	.L_norm_a	!normalize op1
+.L_chk_b:	
+	cmp/pl	r2
+	bf	.L_norm_b	!normalize op2
+
+.L_mul1:
+	add	r3,r2
+	mov.l  .L_1023,r1
+	
+	!resultant exponent in r2
+	add     r1,r2
+	mov.l   .L_2047,r1	
+
+	!Chk the exponent for overflow
+	cmp/ge	r1,r2
+	and     r8,r4
+
+	bt	.L_return_inf
+	mov.l	.L_imp_bit,r1
+	
+	or	r1,r4		
+	and	r8,r6
+
+	or	r1,r6
+	clrt
+
+	!multiplying the mantissas
+	DMULU_SAVE
+	DMULUL	(r7,r5,r1) 	!bits 0-31 of product 	
+
+	DMULUH	(r3)
+	
+	DMULUL	(r4,r7,r8)
+
+	addc	r3,r8
+
+	DMULUH	(r3)
+
+	movt	r9
+	clrt
+
+	DMULUL	(r5,r6,r7)
+
+	addc	r7,r8		!bits 63-32 of product
+
+	movt	r7
+	add	r7,r9
+
+	DMULUH	(r7)
+
+	add	r7,r3
+
+	add	r9,r3
+	clrt
+
+	DMULUL	(r4,r6,r7)
+
+	addc	r7,r3		!bits 64-95 of product
+
+	DMULUH	(r7)
+	DMULU_RESTORE
+	
+	mov	#0,r5
+	addc	r5,r7		!bits 96-105 of product
+
+	cmp/eq	r5,r1
+	mov     #1,r4
+
+	bt	.L_skip
+	or	r4,r8
+.L_skip:
+	mov.l   .L_106_bit,r4
+	mov	r8,r9
+
+.L_chk_extra_msb:
+	!chk if exra MSB is generated
+	and     r7,r4
+	cmp/eq	r5,r4
+
+	mov     #12,r4
+	SL(bf,	.L_shift_rt_by_1,
+	 mov     #31,r5)
+	
+.L_pack_mantissa:
+	!scale the mantissa t0 53 bits
+	mov	#-19,r6
+	mov.l	.L_mask_high_mant,r5
+
+        SHLRN (19, r6, r8)
+
+	and	r3,r5
+
+	shlr	r8
+	movt	r1
+
+        SHLLN (12, r4, r5)
+
+	add	#-1,r6
+
+	or	r5,r8		!lower bits of resulting mantissa
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r6,r3
+#else
+        SHLR20 (r3)
+#endif
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r4,r7
+#else
+        SHLL12 (r7)
+#endif
+	clrt
+
+	or	r7,r3		!higher bits of resulting mantissa
+	mov     #0,r7
+
+	!chk the exponent for underflow
+	cmp/ge	r2,r7
+	bt	.L_underflow
+
+	addc    r1,r8           !rounding
+	mov	r8,r1
+
+	addc	r7,r3		!rounding
+	mov.l	.L_mask_22_bit,r5
+
+	and	r3,r5
+	!chk if extra msb is generated after rounding
+	cmp/eq	r7,r5
+
+	mov.l	.L_mask_high_mant,r8
+	bt	.L_pack_result
+
+	add	#1,r2
+	mov.l	.L_2047,r6
+
+	cmp/ge	r6,r2
+
+	bt	.L_return_inf
+	shlr	r3
+
+	rotcr	r1
+
+.L_pack_result:
+	!pack the result, r2=exponent, r3=higher mantissa, r1=lower mantissa
+	!r0=sign bit
+	mov	#20,r6
+	and	r8,r3
+	
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r6,r2
+#else
+        SHLL20 (r2)
+#endif
+	or	r3,r0
+	
+	or      r2,r0
+	mov.l   @r15+,r9
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l   @r15+,r8
+
+.L_norm_a:
+	!normalize op1
+	shll	r5
+	mov.l	.L_imp_bit,r1
+
+	rotcl	r4
+	add	#-1,r3
+
+	tst	r1,r4
+	bt	.L_norm_a
+
+	bra	.L_chk_b
+	add	#1,r3
+
+.L_norm_b:
+	!normalize op2
+        shll    r7
+        mov.l   .L_imp_bit,r1
+
+        rotcl   r6
+        add     #-1,r2
+
+        tst     r1,r6
+        bt      .L_norm_b
+
+        bra     .L_mul1
+        add     #1,r2
+
+.L_shift_rt_by_1:
+	!adjust the extra msb
+
+	add     #1,r2           !add 1 to exponent
+	mov.l	.L_2047,r6
+
+	cmp/ge	r6,r2
+	mov	#20,r6
+
+	bt	.L_return_inf
+	shlr	r7		!r7 contains bit 96-105 of product
+
+	rotcr	r3		!r3 contains bit 64-95 of product
+
+	rotcr	r8		!r8 contains bit 32-63 of product
+	bra	.L_pack_mantissa
+
+	rotcr	r1		!r1 contains bit 31-0 of product
+
+.L_return_inf:
+	!return Inf
+	mov.l	.L_inf,r2
+	mov     #0,r1
+
+	or	r2,r0
+	mov.l   @r15+,r9
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l   @r15+,r8
+	
+.L_underflow:
+	!check if the result needs to be denormalized
+	mov	#-53,r1
+	add	#1,r2
+
+	cmp/gt	r2,r1
+	mov	#32,r4
+
+	add	#-2,r2
+	bt	.L_return_zero
+
+	add	r2,r4
+	mov	r7,r1
+	
+	cmp/ge	r7,r4
+	mov	r2,r6
+
+	mov	#-54,r2
+	bt	.L_denorm
+
+	mov	#-32,r6
+	
+.L_denorm:
+	!denormalize the result
+	shlr	r8
+	rotcr	r1	
+
+	shll	r8
+	add	#1,r6
+
+	shlr	r3
+	rotcr	r8
+
+	cmp/eq	r7,r6
+	bf	.L_denorm
+
+	mov	r4,r6
+	cmp/eq	r2,r4
+
+	bt	.L_break
+	mov	r7,r5
+
+	cmp/gt	r6,r7
+	bf	.L_break
+
+	mov	r2,r4
+	mov	r1,r5
+
+	mov	r7,r1
+	bt	.L_denorm
+
+.L_break:
+	mov	#0,r2
+
+	cmp/gt	r1,r2
+
+	addc	r2,r8
+	mov.l	.L_comp_1,r4
+	
+	addc	r7,r3
+	or	r3,r0
+
+	cmp/eq	r9,r7
+	bf	.L_return
+
+	cmp/eq	r7,r5
+	mov.l	.L_mask_sign,r6
+
+	bf	.L_return
+	cmp/eq	r1,r6
+	
+	bf	.L_return
+	and	r4,r8
+
+.L_return:
+	mov.l	@r15+,r9
+	mov	r8,r1
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l   @r15+,r8
+
+.L_return_zero:
+	mov.l	@r15+,r9
+	mov	r7,r1
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+
+	.align	2
+
+.L_mask_high_mant:
+	.long	0x000fffff
+.L_inf:
+	.long	0x7ff00000	
+.L_mask_sign:
+	.long	0x80000000
+.L_1023:
+	.long	-1023
+.L_2047:
+	.long	2047
+.L_imp_bit:
+	.long	0x00100000
+.L_mask_22_bit:
+	.long	0x00200000
+.L_106_bit:
+	.long	0x00000200
+.L_comp_1:
+	.long	0xfffffffe
+
+ENDFUNC (GLOBAL (muldf3))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/fixsfsi.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/fixsfsi.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/fixsfsi.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,165 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Conversion routine for float to integer
+
+! Author: Rakesh Kumar
+
+! Arguments: r4 (in floating point format)
+! Return: r0
+
+! r4 is referred as op1
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align 5
+	.global	GLOBAL (fixsfsi)
+	FUNC (GLOBAL (fixsfsi))
+
+GLOBAL (fixsfsi):
+	mov.l	.L_mask_sign,r7
+	mov	r4,r2
+
+	! Check for NaN
+	mov.l	.L_inf,r1
+	and	r7,r2
+
+	cmp/gt	r1,r2
+	mov	#127,r5
+
+	mov	r4,r3
+	SL(bt,	.L_epil,
+	 mov	#0,r0)
+
+	shll	r2
+	mov.l	.L_frac,r6
+
+	shlr16	r2
+	and	r6,r3	! r3 has fraction
+
+	shlr8	r2	! r2 has exponent
+	mov.l	.L_24bit,r1
+
+	! If exponent is less than 127, return 0
+	cmp/gt	r2,r5
+	or	r1,r3	! Set the implicit bit
+
+	mov.l	.L_157,r1
+	SL1(bt,	.L_epil,
+	 shll8	r3)
+
+	! If exponent is greater than 157,
+	! return the maximum/minumum integer
+	! value deducing from sign
+	cmp/gt	r1,r2
+	sub	r2,r1
+
+	mov.l	.L_sign,r2
+	SL(bt,	.L_ret_max,
+	 add	#1,r1)
+
+	and	r4,r2	! Sign in r2
+	neg	r1,r1
+
+	! Shift mantissa by exponent difference from 157
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r1,r3
+#else
+        cmp/gt  r0,r1
+        bt      .L_mov_left
+
+.L_mov_right:
+        cmp/eq  r1,r0
+        bt      .L_ret
+
+        add     #1,r1
+        bra     .L_mov_right
+
+        shlr    r3
+
+.L_mov_left:
+        add     #-1,r1
+
+        shll    r3
+        cmp/eq  r1,r0
+
+        bf      .L_mov_left
+.L_ret:
+#endif
+	! If op1 is negative, negate the result
+	cmp/eq	r0,r2
+	SL(bf,	.L_negate,
+	 mov	r3,r0)
+
+! r0 has the appropriate value
+.L_epil:
+	rts
+	nop
+
+! Return the max/min integer value
+.L_ret_max:
+	and	r4,r2	! Sign in r2
+	mov.l	.L_max,r3
+
+	mov.l	.L_sign,r1
+	cmp/eq	r0,r2
+
+	mov	r3,r0
+	bt	.L_epil
+
+	! Negative number, return min int
+	rts
+	mov	r1,r0
+
+! Negate the result
+.L_negate:
+	rts
+	neg	r0,r0
+
+	.align 2
+.L_inf:
+	.long 0x7F800000
+
+.L_157:
+	.long 157
+
+.L_max:
+	.long 0x7FFFFFFF
+
+.L_frac:
+	.long 0x007FFFFF
+
+.L_sign:
+	.long 0x80000000
+
+.L_24bit:
+	.long 0x00800000
+
+.L_mask_sign:
+	.long 0x7FFFFFFF
+
+ENDFUNC (GLOBAL (fixsfsi))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/floatsidf.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/floatsidf.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/floatsidf.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,151 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!conversion of signed integer to double precision floating point number
+!Author:Rakesh Kumar
+!
+!Entry:
+!r4:operand 
+!
+!Exit:
+!r0,r1:result
+!
+!Note:argument is passed in reg r4 and the result is returned in 
+!regs r0 and r1.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+        .text
+        .align 5
+        .global GLOBAL (floatsidf)
+	FUNC (GLOBAL (floatsidf))
+
+GLOBAL (floatsidf):
+        mov.l   .L_sign,r0
+        mov     #0,r1
+
+	mov	r0,r2
+	tst	r4,r4 ! check r4 for zero
+
+	! Extract the sign
+	mov	r2,r3
+	SL(bt,	.L_ret_zero,
+	 and	r4,r0)
+
+	cmp/eq	r1,r0
+	not	r3,r3
+
+	mov	r1,r7
+	SL(bt,	.L_loop,
+	 and	r4,r3)
+
+	! Treat -2147483648 as special case
+	cmp/eq	r1,r3
+	neg	r4,r4
+
+	bt	.L_ret_min	
+
+.L_loop:
+	shll	r4	
+	mov	r4,r5
+
+	and	r2,r5
+	cmp/eq	r1,r5
+	
+	add	#1,r7
+	bt	.L_loop
+
+	mov.l	.L_initial_exp,r6
+	not	r2,r2
+	
+	and	r2,r4
+	mov	#21,r3
+
+	sub	r7,r6
+	mov	r4,r1
+
+	mov	#20,r7
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r3,r1
+#else
+        SHLL21 (r1)
+#endif
+	mov	#-11,r2
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r7,r6	! Exponent in proper place
+#else
+        SHLL20 (r6)
+#endif
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r2,r4
+#else
+        SHLR11 (r4)
+#endif
+	or	r6,r0
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+#ifdef __LITTLE_ENDIAN__
+	or	r4,r1
+#else
+	or	r4,r0
+#endif
+	
+.L_ret_zero:
+	rts
+	mov	#0,r0
+
+.L_ret_min:
+	mov.l	.L_min,r0
+	
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	nop
+
+	.align 2
+
+.L_initial_exp:
+	.long 0x0000041E
+
+.L_sign:
+	.long 0x80000000
+
+.L_min:
+	.long 0xC1E00000
+
+ENDFUNC (GLOBAL (floatsidf))
Index: gcc-4.5.2.orig/gcc/config/sh/IEEE-754/fixdfsi.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/IEEE-754/fixdfsi.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/IEEE-754/fixdfsi.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,200 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!conversion of double precision floating point number to signed integer
+!Author:Aanchal Khanna
+!
+!Entry:
+!r4,r5:operand
+!
+!Exit:
+!r0:result
+!
+!Note:argument is passed in regs r4 and r5, the result is returned in
+!reg r0.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align 	5
+	.global GLOBAL (fixdfsi)
+	FUNC (GLOBAL (fixdfsi))
+
+GLOBAL (fixdfsi):
+
+#ifdef  __LITTLE_ENDIAN__
+        mov     r4,r1
+        mov     r5,r4
+        mov     r1,r5
+
+#endif
+	mov.l	.L_p_inf,r2
+	mov     #-20,r1
+	
+	mov	r2,r7
+	mov.l   .L_1023,r3
+
+	and	r4,r2
+	shll    r4
+        
+	movt    r6		! r6 contains the sign bit
+	
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r1,r2		! r2 contains the exponent
+#else
+        SHLR20 (r2)
+#endif
+	 shlr    r4
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r1,r7
+#else
+        SHLR20 (r7)
+#endif
+	cmp/hi	r2,r3		! if exp < 1023,return 0
+	mov.l	.L_mask_high_mant,r1
+
+	SL(bt,	.L_epil,
+	 mov	#0,r0)
+	and	r4,r1		! r1 contains high mantissa
+
+	cmp/eq	r2,r7		! chk if exp is invalid
+	mov.l	.L_1053,r7
+
+	bt	.L_inv_exp
+	mov	#11,r0
+	
+	cmp/hi	r7,r2		! If exp > 1053,return maxint
+	sub     r2,r7
+
+	mov.l	.L_21bit,r2
+	SL(bt,	.L_ret_max,
+	 add	#1,r7)		! r7 contains the number of shifts
+
+	or	r2,r1
+	mov	r7,r3
+	shll8   r1
+
+	neg     r7,r7
+	shll2	r1
+
+        shll	r1
+	cmp/hi	r3,r0
+
+	!chk if the result can be made only from higher mantissa
+	SL(bt,	.L_lower_mantissa,
+	 mov	#21,r0)
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r7,r1
+#else
+.L_loop:
+        tst	r7,r7
+        bt      .L_break1
+        add     #1,r7
+        bra     .L_loop
+        shlr    r1
+
+.L_break1:
+#endif
+	tst	r6,r6
+	SL(bt,	.L_epil,
+	 mov	r1,r0)
+
+	rts
+	neg	r0,r0
+
+.L_lower_mantissa:
+	!result is made from lower mantissa also
+	neg	r0,r0
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r0,r5
+#else
+        SHLR21 (r5)
+#endif
+
+	or	r5,r1		!pack lower and higher mantissas
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r7,r1
+#else
+.L_sh_loop:
+	tst	r7,r7
+	bt	.L_break
+	add	#1,r7
+	bra	.L_sh_loop
+	shlr	r1
+
+.L_break:
+#endif
+	mov	r1,r0
+	bra	.L_chk_sign
+	nop
+
+.L_epil:
+	rts
+	nop
+
+.L_inv_exp:
+	cmp/hi	r0,r5
+	bt	.L_epil
+
+	cmp/hi	r0,r1		!compare high mantissa,r1
+	bt	.L_epil
+
+.L_ret_max:
+	mov.l   .L_maxint,r0
+	tst	r6,r6
+	bt	.L_epil
+
+	rts
+	add	#1,r0
+
+.L_chk_sign:
+	tst	r6,r6		!sign bit is set, number is -ve
+	bt	.L_epil
+	
+	rts
+	neg	r0,r0
+
+	.align	2
+
+.L_maxint:
+	.long	0x7fffffff
+.L_p_inf:
+	.long	0x7ff00000
+.L_mask_high_mant:
+	.long	0x000fffff
+.L_1023:
+	.long	0x000003ff
+.L_1053:
+	.long	1053
+.L_21bit:
+	.long	0x00100000
+
+ENDFUNC (GLOBAL (fixdfsi))
Index: gcc-4.5.2.orig/gcc/config/sh/lib1funcs-Os-4-200.asm
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/lib1funcs-Os-4-200.asm	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/lib1funcs-Os-4-200.asm	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,4 +1,5 @@
 /* Copyright (C) 2006, 2009 Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is free software; you can redistribute it and/or modify it
 under the terms of the GNU General Public License as published by the
@@ -25,7 +26,6 @@
 
 #include "lib1funcs.h"
 
-#if !__SHMEDIA__
 #ifdef L_udivsi3_i4i
 
 /* 88 bytes; sh4-200 cycle counts:
@@ -39,7 +39,7 @@
 	.global GLOBAL(udivsi3_i4i)
 	FUNC(GLOBAL(udivsi3_i4i))
 GLOBAL(udivsi3_i4i):
-	mova L1,r0
+	mova LOCAL(L1),r0
 	cmp/pz r5
 	sts fpscr,r1
 	lds.l @r0+,fpscr
@@ -106,7 +106,7 @@
 	movt r0
 
 	.p2align 2
-L1:
+LOCAL(L1):
 #ifndef FMOVD_WORKS
 	.long 0x80000
 #else
@@ -144,7 +144,7 @@
 	mov.l @r15+,r2
 #endif /* 0 */
 
-/* Size: 186 bytes jointly for udivsi3_i4i and sdivsi3_i4i
+/* Size: 188 bytes jointly for udivsi3_i4i and sdivsi3_i4i
    sh4-200 run times:
    udiv small divisor: 55 cycles
    udiv large divisor: 52 cycles
@@ -272,7 +272,7 @@
 GLOBAL(sdivsi3_i4i):
 	sts.l fpscr,@-r15
 	sts fpul,r1
-	mova L1,r0
+	mova LOCAL(L1),r0
 	lds.l @r0+,fpscr
 	lds r4,fpul
 #ifdef FMOVD_WORKS
@@ -309,7 +309,7 @@
 	lds r1,fpul
 
 	.p2align 2
-L1:
+LOCAL(L1):
 #ifndef FMOVD_WORKS
 	.long 0x80000
 #else
@@ -319,4 +319,3 @@
 	ENDFUNC(GLOBAL(sdivsi3_i4i))
 #endif /* __SH_FPU_DOUBLE__ */
 #endif /* L_sdivsi3_i4i */
-#endif /* !__SHMEDIA__ */
Index: gcc-4.5.2.orig/gcc/config/sh/crt1.asm
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/crt1.asm	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/crt1.asm	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2,6 +2,8 @@
    Free Software Foundation, Inc.
    This file was pretty much copied from newlib.
 
+   Copyright (c) 2006  STMicroelectronics.
+
 This file is part of GCC.
 
 GCC is free software; you can redistribute it and/or modify it
@@ -421,7 +423,7 @@
 #endif /* MMU_SUPPORT */
 
 	pt/l	.Lzero_bss_loop, tr0
-	pt/l	_init, tr5
+	pt/l	__init, tr5
 	pt/l	___setup_argv_and_call_main, tr6
 	pt/l	_exit, tr7
 
@@ -453,7 +455,7 @@
 
 	! arrange for exit to call fini
 	pt/l	_atexit, tr1
-	LOAD_ADDR (_fini, r2)
+	LOAD_ADDR (__fini, r2)
 	blink	tr1, r18
 
 	! call init
@@ -851,9 +853,9 @@
 atexit_k:
 	.long	_atexit
 init_k:
-	.long	_init
+	.long	__init
 fini_k:
-	.long	_fini
+	.long	__fini
 #ifdef VBR_SETUP
 old_vbr_k:
 	.long	old_vbr
@@ -1169,201 +1171,5 @@
 handler_exit_k:
 	.long _exit
 	.align 2
-! Simulated compile of trap handler.
-	.section	.debug_abbrev,"",@progbits
-.Ldebug_abbrev0:
-	.section	.debug_info,"",@progbits
-.Ldebug_info0:
-	.section	.debug_line,"",@progbits
-.Ldebug_line0:
-	.text
-.Ltext0:
-	.align 5
-	.type	__superh_trap_handler,@function
-__superh_trap_handler:
-.LFB1:
-	mov.l	r14,@-r15
-.LCFI0:
-	add	#-4,r15
-.LCFI1:
-	mov	r15,r14
-.LCFI2:
-	mov.l	r4,@r14
-	lds	r1, pr
-	add	#4,r14
-	mov	r14,r15
-	mov.l	@r15+,r14
-	rts	
-	nop
-.LFE1:
-.Lfe1:
-	.size	__superh_trap_handler,.Lfe1-__superh_trap_handler
-	.section	.debug_frame,"",@progbits
-.Lframe0:
-	.ualong	.LECIE0-.LSCIE0
-.LSCIE0:
-	.ualong	0xffffffff
-	.byte	0x1
-	.string	""
-	.uleb128 0x1
-	.sleb128 -4
-	.byte	0x11
-	.byte	0xc
-	.uleb128 0xf
-	.uleb128 0x0
-	.align 2
-.LECIE0:
-.LSFDE0:
-	.ualong	.LEFDE0-.LASFDE0
-.LASFDE0:
-	.ualong	.Lframe0
-	.ualong	.LFB1
-	.ualong	.LFE1-.LFB1
-	.byte	0x4
-	.ualong	.LCFI0-.LFB1
-	.byte	0xe
-	.uleb128 0x4
-	.byte	0x4
-	.ualong	.LCFI1-.LCFI0
-	.byte	0xe
-	.uleb128 0x8
-	.byte	0x8e
-	.uleb128 0x1
-	.byte	0x4
-	.ualong	.LCFI2-.LCFI1
-	.byte	0xd
-	.uleb128 0xe
-	.align 2
-.LEFDE0:
-	.text
-.Letext0:
-	.section	.debug_info
-	.ualong	0xb3
-	.uaword	0x2
-	.ualong	.Ldebug_abbrev0
-	.byte	0x4
-	.uleb128 0x1
-	.ualong	.Ldebug_line0
-	.ualong	.Letext0
-	.ualong	.Ltext0
-	.string	"trap_handler.c"
-	.string	"xxxxxxxxxxxxxxxxxxxxxxxxxxxx"
-	.string	"GNU C 3.2 20020529 (experimental)"
-	.byte	0x1
-	.uleb128 0x2
-	.ualong	0xa6
-	.byte	0x1
-	.string	"_superh_trap_handler"
-	.byte	0x1
-	.byte	0x2
-	.byte	0x1
-	.ualong	.LFB1
-	.ualong	.LFE1
-	.byte	0x1
-	.byte	0x5e
-	.uleb128 0x3
-	.string	"trap_reason"
-	.byte	0x1
-	.byte	0x1
-	.ualong	0xa6
-	.byte	0x2
-	.byte	0x91
-	.sleb128 0
-	.byte	0x0
-	.uleb128 0x4
-	.string	"unsigned int"
-	.byte	0x4
-	.byte	0x7
-	.byte	0x0
-	.section	.debug_abbrev
-	.uleb128 0x1
-	.uleb128 0x11
-	.byte	0x1
-	.uleb128 0x10
-	.uleb128 0x6
-	.uleb128 0x12
-	.uleb128 0x1
-	.uleb128 0x11
-	.uleb128 0x1
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0x1b
-	.uleb128 0x8
-	.uleb128 0x25
-	.uleb128 0x8
-	.uleb128 0x13
-	.uleb128 0xb
-	.byte	0x0
-	.byte	0x0
-	.uleb128 0x2
-	.uleb128 0x2e
-	.byte	0x1
-	.uleb128 0x1
-	.uleb128 0x13
-	.uleb128 0x3f
-	.uleb128 0xc
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0x3a
-	.uleb128 0xb
-	.uleb128 0x3b
-	.uleb128 0xb
-	.uleb128 0x27
-	.uleb128 0xc
-	.uleb128 0x11
-	.uleb128 0x1
-	.uleb128 0x12
-	.uleb128 0x1
-	.uleb128 0x40
-	.uleb128 0xa
-	.byte	0x0
-	.byte	0x0
-	.uleb128 0x3
-	.uleb128 0x5
-	.byte	0x0
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0x3a
-	.uleb128 0xb
-	.uleb128 0x3b
-	.uleb128 0xb
-	.uleb128 0x49
-	.uleb128 0x13
-	.uleb128 0x2
-	.uleb128 0xa
-	.byte	0x0
-	.byte	0x0
-	.uleb128 0x4
-	.uleb128 0x24
-	.byte	0x0
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0xb
-	.uleb128 0xb
-	.uleb128 0x3e
-	.uleb128 0xb
-	.byte	0x0
-	.byte	0x0
-	.byte	0x0
-	.section	.debug_pubnames,"",@progbits
-	.ualong	0x27
-	.uaword	0x2
-	.ualong	.Ldebug_info0
-	.ualong	0xb7
-	.ualong	0x67
-	.string	"_superh_trap_handler"
-	.ualong	0x0
-	.section	.debug_aranges,"",@progbits
-	.ualong	0x1c
-	.uaword	0x2
-	.ualong	.Ldebug_info0
-	.byte	0x4
-	.byte	0x0
-	.uaword	0x0
-	.uaword	0x0
-	.ualong	.Ltext0
-	.ualong	.Letext0-.Ltext0
-	.ualong	0x0
-	.ualong	0x0
 #endif /* VBR_SETUP */
 #endif /* ! __SH5__ */
Index: gcc-4.5.2.orig/gcc/config/sh/ieee-754-sf.S
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/ieee-754-sf.S	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/gcc/config/sh/ieee-754-sf.S	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,703 @@
+/* Copyright (C) 2006, 2008, 2009 Free Software Foundation, Inc.
+   Copyright (c) 2010 STMicroelectronics.
+	
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   Under Section 7 of GPL version 3, you are granted additional
+   permissions described in the GCC Runtime Library Exception, version
+   3.1, as published by the Free Software Foundation.
+
+   You should have received a copy of the GNU General Public License and
+   a copy of the GCC Runtime Library Exception along with this program;
+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+   <http://www.gnu.org/licenses/>.  */
+
+!! libgcc software floating-point routines for Renesas SH /
+!! STMicroelectronics ST40 CPUs
+!! Contributed by J"orn Rennecke joern.rennecke@st.com
+
+#ifndef __SH_FPU_ANY__
+
+#include "lib1funcs.h"
+#include "insn-constants.h"
+
+/* Single-precision floating-point emulation.
+   We handle NANs, +-infinity, and +-zero.
+   However, we assume that for NANs, the topmost bit of the fraction is set.  */
+#ifdef L_nesf2f
+/* -fno-finite-math-only inline version, T := r4:SF == r5:SF
+	cmp/eq	r4,r5
+	mov	r4,r0
+	bt	0f
+	or	r5,r0
+	add	r0,r0
+	tst	r0,r0	! test for +0.0 == -0.0 ; -0.0 == +0.0
+	0:			*/
+	.balign 4
+	.global GLOBAL(nesf2f)
+	HIDDEN_FUNC(GLOBAL(nesf2f))
+GLOBAL(nesf2f):
+        /* If the raw values are unequal, the result is unequal, unless
+	   both values are +-zero.
+	   If the raw values are equal, the result is equal, unless
+	   the values are NaN.  */
+	cmp/eq	r4,r5
+	mov.l   LOCAL(c_SF_NAN_MASK),r1
+	bt.s	LOCAL(check_nan)
+	not	r4,r0
+	mov	r4,r0
+	or	r5,r0
+	rts
+	add	r0,r0
+LOCAL(check_nan):
+	tst	r1,r0
+	bt.s 	LOCAL(nan)
+	mov	#96,r2
+	shll16  r2
+	xor 	r2,r1
+	tst	r1,r0	
+LOCAL(nan):		
+	rts
+	movt	r0
+	
+	.balign 4
+LOCAL(c_SF_NAN_MASK):
+	.long SF_NAN_MASK
+LOCAL(c_SF_SNAN_MASK):
+	ENDFUNC(GLOBAL(nesf2f))
+#endif /* L_nesf2f */
+
+#ifdef L_unord_sf
+	.balign 4
+	.global GLOBAL(unordsf2)
+	HIDDEN_FUNC(GLOBAL(unordsf2))
+GLOBAL(unordsf2):
+	mov.l	LOCAL(c_SF_NAN_MASK),r1
+	not	r4,r0
+	tst	r1,r0
+	not	r5,r0
+	bt	LOCAL(unord)
+	tst	r1,r0
+LOCAL(unord):
+	rts
+	movt	r0
+	.balign	4
+LOCAL(c_SF_NAN_MASK):
+	.long SF_NAN_MASK
+	ENDFUNC(GLOBAL(unordsf2))
+#endif /* L_unord_sf */
+
+#if defined(L_gtsf2t) || defined(L_gtsf2t_trap)
+/* -fno-finite-math-only inline version, T := r4:SF > r5:SF ? 0 : 1
+	cmp/pz	r4
+	mov	r4,r0
+	bf/s	0f
+	 cmp/hs	r5,r4
+	cmp/ge	r4,r5
+	or	r5,r0
+	bt	0f
+	add	r0,r0
+	tst	r0,r0
+	0:			*/
+#ifdef L_gtsf2t
+#define fun_label GLOBAL(gtsf2t)
+#else
+#define fun_label GLOBAL(gtsf2t_trap)
+#endif
+	.balign 4
+	.global fun_label
+	HIDDEN_FUNC(fun_label)
+fun_label:
+	/* If the raw values compare greater, the result true, unless
+	   any of them is a nan (but infinity is fine), or both values are
+	   +- zero.  Otherwise, the result false.  */
+	mov.l	LOCAL(c_SF_NAN_MASK),r1
+	cmp/pz	r4
+	not	r5,r0
+	SLC(bf,	LOCAL(neg),
+	 tst	r1,r0)
+	mov	r4,r0
+	bt	LOCAL(nan)
+	cmp/gt	r5,r4
+	SLC(bf,	LOCAL(check_nan),
+	 cmp/gt	r4,r1)
+	bf	LOCAL(nan)
+	or	r5,r0
+	rts
+	add	r0,r0
+LOCAL(neg):
+	SLI(tst	r1,r0)
+	bt	LOCAL(nan)
+	not	r4,r0
+	tst	r1,r0
+	bt	LOCAL(nan)
+	cmp/hi	r4,r5
+#if defined(L_gtsf2t) && defined(DELAYED_BRANCHES)
+LOCAL(check_nan):
+#endif /* DELAYED_BRANCHES */
+	rts
+	movt	r0
+#ifdef L_gtsf2t
+LOCAL(check_nan):
+LOCAL(nan):
+	rts
+	mov	#0,r0
+#else /* ! L_gtsf2t */
+LOCAL(check_nan):
+	SLI(cmp/gt	r4,r1)
+	bf	LOCAL(nan)
+	rts
+	movt	r0
+LOCAL(nan):
+	mov	#0,r0
+	trapa	#0
+#endif /* ! L_gtsf2t */
+	.balign	4
+LOCAL(c_SF_NAN_MASK):
+	.long SF_NAN_MASK
+	ENDFUNC(fun_label)
+#endif /* L_gtsf2t */
+
+#if defined(L_gesf2f) || defined(L_gesf2f_trap)
+/* -fno-finite-math-only inline version, T := r4:SF >= r5:SF */
+	cmp/pz	r5
+	mov	r4,r0
+	bf/s	0f
+	 cmp/hs	r4,r5
+	cmp/ge	r5,r4
+	or	r5,r0
+	bt	0f
+	add	r0,r0
+	tst	r0,r0
+	0:
+#ifdef L_gesf2f
+#define fun_label GLOBAL(gesf2f)
+#else
+#define fun_label GLOBAL(gesf2f_trap)
+#endif
+	.balign 4
+	.global fun_label
+	HIDDEN_FUNC(fun_label)
+fun_label:
+	/* If the raw values compare greater or equal, the result is
+	   true, unless any of them is a nan.  If both are -+zero, the
+	   result is true; otherwise, it is false.
+	   We use 0 as true and nonzero as false for this function.  */
+	mov.l	LOCAL(c_SF_NAN_MASK),r1
+	cmp/pz	r5
+	not	r4,r0
+	SLC(bf,	LOCAL(neg),
+	 tst	r1,r0)
+	mov	r4,r0
+	bt	LOCAL(nan)
+	cmp/gt	r4,r5
+	SLC(bf,	LOCAL(check_nan),
+	 cmp/ge	r1,r5)
+	bt	LOCAL(nan)
+	or	r5,r0
+	rts
+	add	r0,r0
+LOCAL(neg):
+	SLI(tst	r1,r0)
+	bt	LOCAL(nan)
+	not	r5,r0
+	tst	r1,r0
+	bt	LOCAL(nan)
+	cmp/hi	r5,r4
+#if defined(L_gesf2f) && defined(DELAYED_BRANCHES)
+LOCAL(nan): LOCAL(check_nan):
+#endif
+	rts
+	movt	r0
+#if defined(L_gesf2f) && ! defined(DELAYED_BRANCHES)
+LOCAL(check_nan):
+	cmp/ge	r1,r5
+LOCAL(nan):
+	rts
+	movt	r0
+#endif /* ! DELAYED_BRANCHES */
+#ifdef L_gesf2f_trap
+LOCAL(check_nan):
+	SLI(cmp/ge	r1,r5)
+	bt	LOCAL(nan)
+	rts
+LOCAL(nan):
+	movt	r0
+	trapa	#0
+#endif /* L_gesf2f_trap */
+	.balign	4
+LOCAL(c_SF_NAN_MASK):
+	.long SF_NAN_MASK
+	ENDFUNC(GLOBAL(gesf2f))
+#endif /* L_gesf2f */
+
+#ifndef DYN_SHIFT /* SH1 / SH2 code */
+#ifdef L_addsub_sf
+#include "IEEE-754/addsf3.S"
+#endif /* _addsub_sf */
+
+#ifdef L_mul_sf
+#include "IEEE-754/mulsf3.S"
+#endif /* L_mul_sf */
+
+#ifdef L__fixunssfsi
+#include "IEEE-754/fixunssfsi.S"
+#endif /* L_fixunssfsi */
+
+#ifdef L_sf_to_si
+#include "IEEE-754/fixsfsi.S"
+#endif /* L_sf_to_si */
+
+#ifdef L_usi_to_sf
+#include "IEEE-754/floatunssisf.S"
+#endif /* L_usi_to_sf */
+
+#ifdef L_si_to_sf
+#include "IEEE-754/floatsisf.S"
+#endif /* L_si_to_sf */
+
+#ifdef L_div_sf
+#include "IEEE-754/divsf3.S"
+#endif /* L_div_sf */
+#endif /* ! DYN_SHIFT */
+
+/* The actual arithmetic uses dynamic shift.  Supporting SH1 / SH2 here would
+   make this code too hard to maintain, so if you want to add SH1 / SH2
+   support, do it in a separate copy.  */
+#ifdef DYN_SHIFT
+#ifdef L_addsub_sf
+#include "IEEE-754/m3/addsf3.S"
+#endif /* L_addsub_sf */
+
+#ifdef L_mul_sf
+#include "IEEE-754/m3/mulsf3.S"
+#endif /* L_mul_sf */
+
+#ifdef L_fixunssfsi
+	! What is a bit unusal about this implementation is that the
+	! sign bit influences the result for NANs: for cleared sign bit, you
+	! get UINT_MAX, for set sign bit, you get 0.
+	! However, since the result for NANs is undefined, this should be no
+	! problem.
+	! N.B. This is scheduled both for SH4-200 and SH4-300
+	.balign 4
+	.global GLOBAL(fixunssfsi)
+	FUNC(GLOBAL(fixunssfsi))
+GLOBAL(fixunssfsi):
+	mov.l	LOCAL(max),r2
+	mov	#-23,r1
+	mov	r4,r0
+	shad	r1,r4
+	mov.l	LOCAL(mask),r1
+	add	#-127,r4
+	cmp/ge	r2,r0
+	or	r2,r0
+	bt	LOCAL(retmax)
+	cmp/pz	r4
+	and	r1,r0
+	bf	LOCAL(ret0)
+	add	#-23,r4
+	rts
+	shld	r4,r0
+LOCAL(ret0):
+LOCAL(retmax):
+	rts
+	subc	r0,r0
+	.balign 4
+LOCAL(mask):
+	.long	0x00ffffff
+LOCAL(max):
+	.long	0x4f800000
+	ENDFUNC(GLOBAL(fixunssfsi))
+#endif /* L_fixunssfsi */
+
+#ifdef L_sf_to_si
+	! What is a bit unusal about this implementation is that the
+	! sign bit influences the result for NANs: for cleared sign bit, you
+	! get INT_MAX, for set sign bit, you get INT_MIN.
+	! However, since the result for NANs is undefined, this should be no
+	! problem.
+	! N.B. This is scheduled both for SH4-200 and SH4-300
+	.balign 4
+	.global GLOBAL(fixsfsi)
+	FUNC(GLOBAL(fixsfsi))
+	.balign	4
+GLOBAL(fixsfsi):
+	mov	r4,r0
+	shll	r4
+	mov	#-24,r1
+	bt	LOCAL(neg)
+	mov.l	LOCAL(max),r2
+	shld	r1,r4
+	mov.l	LOCAL(mask),r1
+	add	#-127,r4
+	cmp/pz	r4
+	add	#-23,r4
+	bf	LOCAL(ret0)
+	cmp/gt	r0,r2
+	bf	LOCAL(retmax)
+	and	r1,r0
+	addc	r1,r0
+	rts
+	shld	r4,r0
+
+	.balign	4
+LOCAL(neg):
+	mov.l	LOCAL(min),r2
+	shld	r1,r4
+	mov.l	LOCAL(mask),r1
+	add	#-127,r4
+	cmp/pz	r4
+	add	#-23,r4
+	bf	LOCAL(ret0)
+	cmp/gt	r0,r2
+	bf	LOCAL(retmin)
+	and	r1,r0
+	addc	r1,r0
+	shld	r4,r0	! SH4-200 will start this insn on a new cycle
+	rts
+	neg	r0,r0
+
+	.balign	4
+LOCAL(ret0):
+	rts
+	mov	#0,r0
+
+LOCAL(retmax):
+	mov	#-1,r0
+	rts
+	shlr	r0
+
+LOCAL(retmin):
+	mov	#1,r0
+	rts
+	rotr	r0
+
+	.balign 4
+LOCAL(mask):
+	.long	0x007fffff
+LOCAL(max):
+	.long	0x4f000000
+LOCAL(min):
+	.long	0xcf000000
+	ENDFUNC(GLOBAL(fixsfsi))
+#endif /* L_sf_to_si */
+
+#ifdef L_usi_to_sf
+#include "IEEE-754/m3/floatunssisf.S"
+#endif /* L_usi_to_sf */
+
+#ifdef L_si_to_sf
+#include "IEEE-754/m3/floatsisf.S"
+#endif /* L_si_to_sf */
+
+#ifdef L_div_sf
+#include "IEEE-754/m3/divsf3.S"
+#endif /* L_div_sf */
+
+#ifdef L_hypotf
+	.balign 4
+	.global GLOBAL(hypotf)
+	FUNC(GLOBAL(hypotf))
+GLOBAL(hypotf):
+/* This integer implementation takes 71 to 72 cycles in the main path.
+   This is a bit slower than the SH4 can do this computation using double
+   precision hardware floating point - 57 cycles, or 69 with mode switches.  */
+ /* First, calculate x (r4) as the sum of the square of the fractions -
+    the exponent is calculated separately in r3.
+    Then, calculate sqrt(x) for the fraction by reciproot iteration.
+    We get an 7.5 bit inital value using linear approximation with two slopes
+    that are powers of two.
+    x (- [1. .. 2.)  y0 := 1.25 - x/4 - tab(x)   y (- (0.8 .. 1.0)
+    x (- [2. .. 4.)  y0 := 1.   - x/8 - tab(x)   y (- (0.5 .. 0.8)
+ x is represented with two bits before the point,
+ y with 0 bits before the binary point.
+ Thus, to calculate y0 := 1. - x/8 - tab(x), all you have to do is to shift x
+ right by 1, negate it, and subtract tab(x).  */
+
+ /* y1 := 1.5*y0 - 0.5 * (x * y0) * (y0 * y0)
+    z0 := x * y1
+    z1 := z0 + 0.5 * (y1 - (y1*y1) * z0) */
+
+	mov.l	LOCAL(xff000000),r1
+	add	r4,r4
+	mov	r4,r0
+	add	r5,r5
+	cmp/hs	r5,r4
+	sub	r5,r0
+	mov	#-24,r2
+	bf/s	LOCAL(r5_large)
+	shad	r2,r0
+	mov	r4,r3
+	shll8	r4
+	rotcr	r4
+	tst	#0xe0,r0
+	neg	r0,r0
+	bt	LOCAL(ret_abs_r3)
+	tst	r1,r5
+	shll8	r5
+	bt/s	LOCAL(denorm_r5)
+	cmp/hi	r3,r1
+	dmulu.l	r4,r4
+	bf	LOCAL(inf_nan)
+	rotcr	r5
+	shld	r0,r5
+LOCAL(denorm_r5_done):
+	sts	mach,r4
+	dmulu.l	r5,r5
+	mov.l	r6,@-r15
+	mov	#20,r6
+
+	sts	mach,r5
+LOCAL(add_frac):
+	mova	LOCAL(tab)-32,r0
+	mov.l	r7,@-r15
+	mov.w	LOCAL(x1380),r7
+	and	r1,r3
+	addc	r5,r4
+	mov.w	LOCAL(m25),r2	! -25
+	bf	LOCAL(frac_ok)
+	sub	r1,r3
+	rotcr	r4
+	cmp/eq	r1,r3	! did we generate infinity ?
+	bt	LOCAL(inf_nan)
+	shlr	r4
+	mov	r4,r1
+	shld	r2,r1
+	mov.b	@(r0,r1),r0
+	mov	r4,r1
+	shld	r6,r1
+	bra	LOCAL(frac_low2)
+	sub	r1,r7
+
+LOCAL(frac_ok):
+	mov	r4,r1
+	shld	r2,r1
+	mov.b	@(r0,r1),r1
+	cmp/pz	r4
+	mov	r4,r0
+	bt/s	LOCAL(frac_low)
+	shld	r6,r0
+	mov.w	LOCAL(xf80),r7
+	shlr	r0
+LOCAL(frac_low):
+	sub	r0,r7
+LOCAL(frac_low2):
+	mov.l	LOCAL(x40000080),r0 ! avoid denorm results near 1. << r3
+	sub	r1,r7	! {0.12}
+	mov.l	LOCAL(xfffe0000),r5 ! avoid rounding overflow near 4. << r3
+	swap.w	r7,r1	! {0.28}
+	dmulu.l	r1,r4 /* two issue cycles */
+	mulu.w	r7,r7  /* two issue cycles */
+	sts	mach,r2	! {0.26}
+	mov	r1,r7
+	shlr	r1
+	sts	macl,r6	! {0.24}
+	cmp/hi	r0,r4
+	shlr2	r2
+	bf	LOCAL(near_one)
+	shlr	r2	! {0.23} systemic error of linear approximation keeps y1 < 1
+	dmulu.l	r2,r6
+	cmp/hs	r5,r4
+	add	r7,r1	! {1.28}
+	bt	LOCAL(near_four)
+	shlr2	r1	! {1.26}
+	sts	mach,r0	! {0.15} x*y0^3 == {0.16} 0.5*x*y0^3
+	shlr2	r1	! {1.24}
+	shlr8	r1	! {1.16}
+	sett		! compensate for truncation of subtrahend, keep y1 < 1
+	subc	r0,r1   ! {0.16} y1;  max error about 3.5 ulp
+	swap.w	r1,r0
+	dmulu.l	r0,r4	! { 1.30 }
+	mulu.w	r1,r1
+	sts	mach,r2
+	shlr2	r0
+	sts	macl,r1
+	add	r2,r0
+	mov.l	LOCAL(xff000000),r6
+	add	r2,r0
+	dmulu.l	r1,r2
+	add	#127,r0
+	add	r6,r3	! precompensation for adding leading 1
+	sts	mach,r1
+	shlr	r3
+	mov.l	@r15+,r7
+	sub	r1,r0	! {0.31} max error about 50 ulp (+127)
+	mov.l	@r15+,r6
+	shlr8	r0	! {0.23} max error about 0.7 ulp
+	rts
+	add	r3,r0
+	
+LOCAL(r5_large):
+	mov	r5,r3
+	mov	#-31,r2
+	cmp/ge	r2,r0
+	shll8	r5
+	bf	LOCAL(ret_abs_r3)
+	rotcr	r5
+	tst	r1,r4
+	shll8	r4
+	bt/s	LOCAL(denorm_r4)
+	cmp/hi	r3,r1
+	dmulu.l	r5,r5
+	bf	LOCAL(inf_nan)
+	rotcr	r4
+LOCAL(denorm_r4_done):
+	shld	r0,r4
+	sts	mach,r5
+	dmulu.l	r4,r4
+	mov.l	r6,@-r15
+	mov	#20,r6
+	bra	LOCAL(add_frac)
+	sts	mach,r4
+
+LOCAL(near_one):
+	bra	LOCAL(assemble_sqrt)
+	mov	#0,r0
+LOCAL(near_four):
+	! exact round-to-nearest would add 255.  We add 256 for speed & compactness.
+	mov	r4,r0
+	shlr8	r0
+	add	#1,r0
+	tst	r0,r0
+	addc	r0,r3	! might generate infinity.
+LOCAL(assemble_sqrt):
+	mov.l	@r15+,r7
+	shlr	r3
+	mov.l	@r15+,r6
+	rts
+	add	r3,r0
+LOCAL(inf_nan):
+LOCAL(ret_abs_r3):
+	mov	r3,r0
+	rts
+	shlr	r0
+LOCAL(denorm_r5):
+	bf	LOCAL(inf_nan)
+	tst	r1,r4
+	bt	LOCAL(denorm_both)
+	dmulu.l	r4,r4
+	bra	LOCAL(denorm_r5_done)
+	shld	r0,r5
+LOCAL(denorm_r4):
+	bf	LOCAL(inf_nan)
+	tst	r1,r5
+	dmulu.l	r5,r5
+	bf	LOCAL(denorm_r4_done)
+LOCAL(denorm_both):	! normalize according to r3.
+	extu.w	r3,r2
+	mov.l	LOCAL(c__clz_tab),r0
+	cmp/eq	r3,r2
+	mov	#-8,r2
+	bt	0f
+	tst	r1,r3
+	mov	#-16,r2
+	bt	0f
+	mov	#-24,r2
+0:
+	shld	r2,r3
+	mov.l	r7,@-r15
+#ifdef __pic__
+	add	r0,r3
+	mova	 LOCAL(c__clz_tab),r0
+#endif
+	mov.b	@(r0,r3),r0
+	add	#32,r2
+	sub	r0,r2
+	shld	r2,r4
+	mov	r2,r7
+	dmulu.l	r4,r4
+	sts.l	pr,@-r15
+	mov	#1,r3
+	bsr	LOCAL(denorm_r5_done)
+	shld	r2,r5
+	mov.l	LOCAL(x01000000),r1
+	neg	r7,r2
+	lds.l	@r15+,pr
+	tst	r1,r0
+	mov.l	@r15+,r7
+	bt	0f
+	add	#1,r2
+	sub	r1,r0
+0:
+	rts
+	shld	r2,r0
+
+LOCAL(m25):
+	.word	-25
+LOCAL(x1380):
+	.word	0x1380
+LOCAL(xf80):
+	.word	0xf80
+	.balign	4
+LOCAL(xff000000):
+	.long	0xff000000
+LOCAL(x40000080):
+	.long	0x40000080
+LOCAL(xfffe0000):
+	.long	0xfffe0000
+LOCAL(x01000000):
+	.long	0x01000000
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+
+/*
+double err(double x)
+{
+  return (x < 2. ? 1.25 - x/4. : 1. - x/8.) - 1./sqrt(x);
+}
+
+int
+main ()
+{
+  int i = 0;
+  double x, s, v;
+  double lx, hx;
+
+  s = 1./32.;
+  for (x = 1.; x < 4; x += s, i++)
+    {
+      lx = x;
+      hx = x + s - 1. / (1 << 30);
+      v = 0.5 * (err (lx) + err (hx));
+      printf ("%s% 4d%c",
+              (i & 7) == 0 ? "\t.byte\t" : "",
+              (int)(v * 4096 + 0.5) - 128,
+              (i & 7) == 7 ? '\n' : ',');
+    }
+  return 0;
+} */
+
+	.balign	4
+LOCAL(tab):
+	.byte	-113, -84, -57, -33, -11,   8,  26,  41
+	.byte	  55,  67,  78,  87,  94, 101, 106, 110
+	.byte	 113, 115, 115, 115, 114, 112, 109, 106
+	.byte	 101,  96,  91,  84,  77,  69,  61,  52
+	.byte	  51,  57,  63,  68,  72,  77,  80,  84
+	.byte	  87,  89,  91,  93,  95,  96,  97,  97
+	.byte	  97,  97,  97,  96,  95,  94,  93,  91
+	.byte	  89,  87,  84,  82,  79,  76,  72,  69
+	.byte	  65,  61,  57,  53,  49,  44,  39,  34
+	.byte	  29,  24,  19,  13,   8,   2,  -4, -10
+	.byte	 -17, -23, -29, -36, -43, -50, -57, -64
+	.byte	 -71, -78, -85, -93,-101,-108,-116,-124
+	ENDFUNC(GLOBAL(hypotf))
+#endif /* L_hypotf */
+#endif /* DYN_SHIFT */
+
+#endif /* __SH_FPU_ANY__ */
Index: gcc-4.5.2.orig/gcc/config/sh/sh4-300.md
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/sh4-300.md	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/sh4-300.md	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,11 +1,13 @@
 ;; DFA scheduling description for ST40-300.
-;; Copyright (C) 2004, 2006, 2007 Free Software Foundation, Inc.
+;; Copyright (C) 2004 Free Software Foundation, Inc.
+;; Copyright (C) 2006 STMicroelectronics (Will be assigned to FSF when
+;; patch is contributed.)
 
 ;; This file is part of GCC.
 
 ;; GCC is free software; you can redistribute it and/or modify
 ;; it under the terms of the GNU General Public License as published by
-;; the Free Software Foundation; either version 3, or (at your option)
+;; the Free Software Foundation; either version 2, or (at your option)
 ;; any later version.
 
 ;; GCC is distributed in the hope that it will be useful,
@@ -14,8 +16,9 @@
 ;; GNU General Public License for more details.
 
 ;; You should have received a copy of the GNU General Public License
-;; along with GCC; see the file COPYING3.  If not see
-;; <http://www.gnu.org/licenses/>.
+;; along with GCC; see the file COPYING.  If not, write to
+;; the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+;; Boston, MA 02110-1301, USA.
 
 ;; Load and store instructions save a cycle if they are aligned on a
 ;; four byte boundary.  Using a function unit for stores encourages
@@ -186,9 +189,9 @@
 ;; Scheduling runs before reorg, so we approximate this by saying that we
 ;; want the call to be paired with a preceding insn.
 ;; In most cases, the insn that loads the address of the call should have
-;; a nonzero latency (mov rn,rm doesn't make sense since we could use rn
+;; a non-zero latency (mov rn,rm doesn't make sense since we could use rn
 ;; for the address then).  Thus, a preceding insn that can be paired with
-;; a call should be eligible for the delay slot.
+;; a call should be elegible for the delay slot.
 ;;
 ;; calls introduce a longisch delay that is likely to flush the pipelines
 ;; of the caller's instructions.  Ordinary functions tend to end with a
Index: gcc-4.5.2.orig/gcc/config/sh/t-linux
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/t-linux	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/t-linux	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,8 +1,9 @@
-LIB1ASMFUNCS_CACHE = _ic_invalidate _ic_invalidate_array
-
 LIB2FUNCS_EXTRA= $(srcdir)/config/sh/linux-atomic.asm
 
 MULTILIB_DIRNAMES= 
 MULTILIB_MATCHES = 
 
-EXTRA_MULTILIB_PARTS= crtbegin.o crtend.o crtbeginS.o crtendS.o crtbeginT.o
+EXTRA_MULTILIB_PARTS= crtbegin.o crtend.o crtbeginS.o crtendS.o crtbeginT.o \
+		      $(OPT_EXTRA_PARTS)
+
+LIB1ASMFUNCS_DIVTABLE= _div_table 
Index: gcc-4.5.2.orig/gcc/config/sh/t-elf
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/t-elf	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/t-elf	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,5 +1,6 @@
 EXTRA_MULTILIB_PARTS= crt1.o crti.o crtn.o \
-	crtbegin.o crtend.o crtbeginS.o crtendS.o $(IC_EXTRA_PARTS) $(OPT_EXTRA_PARTS)
+	crtbegin.o crtend.o crtbeginS.o crtendS.o $(IC_EXTRA_PARTS) \
+	$(OPT_EXTRA_PARTS) trap-handler.o
 
 # Compile crtbeginS.o and crtendS.o with pic.
 CRTSTUFF_T_CFLAGS_S = -fPIC
Index: gcc-4.5.2.orig/gcc/config/sh/sh.md
===================================================================
--- gcc-4.5.2.orig/gcc/config/sh/sh.md	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/gcc/config/sh/sh.md	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -3,6 +3,7 @@
 ;;  2003, 2004, 2005, 2006, 2007, 2008, 2009 Free Software Foundation, Inc.
 ;;  Contributed by Steve Chamberlain (sac@cygnus.com).
 ;;  Improved by Jim Wilson (wilson@cygnus.com).
+;;  Copyright (c) 2009  STMicroelectronics.
 
 ;; This file is part of GCC.
 
@@ -46,6 +47,8 @@
 ;;    l -- pr
 ;;    z -- r0
 ;;
+;;    R03 -- r0, r1, r2 or r3  - experimental constraint for SH4-300
+;;
 ;; Special formats used for outputting SH instructions:
 ;;
 ;;   %.  --  print a .s if insn needs delay slot
@@ -106,6 +109,7 @@
   (DR0_REG	64)
   (DR2_REG	66)
   (DR4_REG	68)
+  (FR4_REG	68)
   (FR23_REG	87)
 
   (TR0_REG	128)
@@ -164,6 +168,8 @@
   ;; (unspec [OFFSET ANCHOR] UNSPEC_PCREL_SYMOFF) == OFFSET - (ANCHOR - .).
   (UNSPEC_PCREL_SYMOFF	46)
 
+  (UNSPEC_BUILTIN_ROUND	47)
+
   ;; These are used with unspec_volatile.
   (UNSPECV_BLOCKAGE	0)
   (UNSPECV_ALIGN	1)
@@ -173,6 +179,17 @@
   (UNSPECV_WINDOW_END	10)
   (UNSPECV_CONST_END	11)
   (UNSPECV_EH_RETURN	12)
+  (UNSPECV_DB_INSN	13)
+
+  ;; NaN handling for software floating point:
+  ;; We require one bit specific for a precision to be set in all NaNs,
+  ;; so that we can test them with a not / tst sequence.
+  ;; ??? Ironically, this is the quiet bit for now, because that is the
+  ;; only bit set by __builtin_nan ("").
+  ;; ??? Should really use one bit lower and force it set by using
+  ;; a custom encoding function.
+  (SF_NAN_MASK		0x7fc00000)
+  (DF_NAN_MASK		0x7ff80000)
 ])
 
 ;; -------------------------------------------------------------------------
@@ -614,6 +631,14 @@
 	cmp/eq	%1,%0"
    [(set_attr "type" "mt_group")])
 
+(define_insn "fpcmp_i1"
+  [(set (reg:SI T_REG)
+	(match_operator:SI 1 "soft_fp_comparison_operator"
+	  [(match_operand 0 "soft_fp_comparison_operand" "r") (const_int 0)]))]
+  "TARGET_SH1_SOFTFP"
+  "tst	%0,%0"
+   [(set_attr "type" "mt_group")])
+
 (define_insn "cmpgtsi_t"
   [(set (reg:SI T_REG)
 	(gt:SI (match_operand:SI 0 "arith_reg_operand" "r,r")
@@ -735,18 +760,16 @@
     }
 }")
 
-(define_insn_and_split "cbranchdi4_i"
+(define_split
   [(set (pc)
 	(if_then_else (match_operator 0 "comparison_operator"
-			[(match_operand:DI 1 "arith_operand" "r,r")
-			 (match_operand:DI 2 "arith_operand" "rN,I08")])
+			[(match_operand:DI 1 "arith_operand" "")
+			 (match_operand:DI 2 "arith_operand" "")])
 		      (label_ref (match_operand 3 "" ""))
 		      (pc)))
-   (clobber (match_scratch:SI 4 "=X,&r"))
+   (clobber (match_scratch:SI 4 ""))
    (clobber (reg:SI T_REG))]
-  "TARGET_CBRANCHDI4"
-  "#"
-  "&& reload_completed"
+  "TARGET_CBRANCHDI4 && reload_completed"
   [(pc)]
   "
 {
@@ -1153,7 +1176,7 @@
 
 (define_insn "*movsicc_t_false"
   [(set (match_operand:SI 0 "arith_reg_dest" "=r,r")
-	(if_then_else (eq (reg:SI T_REG) (const_int 0))
+	(if_then_else:SI (eq (reg:SI T_REG) (const_int 0))
 		      (match_operand:SI 1 "general_movsrc_operand" "r,I08")
 		      (match_operand:SI 2 "arith_reg_operand" "0,0")))]
   "TARGET_PRETEND_CMOVE
@@ -1166,7 +1189,7 @@
 
 (define_insn "*movsicc_t_true"
   [(set (match_operand:SI 0 "arith_reg_dest" "=r,r")
-	(if_then_else (ne (reg:SI T_REG) (const_int 0))
+	(if_then_else:SI (ne (reg:SI T_REG) (const_int 0))
 		      (match_operand:SI 1 "general_movsrc_operand" "r,I08")
 		      (match_operand:SI 2 "arith_reg_operand" "0,0")))]
   "TARGET_PRETEND_CMOVE
@@ -1994,6 +2017,7 @@
   "
 {
   rtx last;
+  rtx lab2 = NULL_RTX;
 
   operands[3] = gen_reg_rtx (Pmode);
   /* Emit the move of the address to a pseudo outside of the libcall.  */
@@ -2132,9 +2156,42 @@
       function_symbol (operands[3], sh_divsi3_libfunc, SFUNC_GOT);
       last = gen_divsi3_i1 (operands[0], operands[3]);
     }
+
+   if (TARGET_DIVIDE_CALL_PRE1) 
+   {
+      rtx tmp = gen_reg_rtx (SImode);
+      rtx lab = gen_label_rtx ();
+
+      lab2 = gen_label_rtx ();
+
+      operands[1] = force_reg (SImode, operands[1]);
+      operands[2] = force_reg (SImode, operands[2]);
+
+      emit_move_insn (tmp, operands[1]);
+      emit_insn (gen_iorsi3 (tmp, tmp, operands[2]));
+      emit_insn (gen_ashlsi3_k (tmp, tmp, GEN_INT (1)));
+      emit_jump_insn (gen_branch_true (lab));
+      emit_move_insn (tmp, operands[1]); 
+      emit_insn (gen_subc (tmp, tmp, operands[2]));
+
+      emit_jump_insn (gen_branch_true (lab));
+
+      emit_insn (gen_subc (tmp, tmp, operands[2]));
+      emit_jump_insn (gen_branch_false (lab));
+
+      emit_move_insn (operands[0], GEN_INT (1));
+      emit_jump_insn (gen_jump_compact (lab2));
+
+      emit_label (lab);
+    }
+
   emit_move_insn (gen_rtx_REG (SImode, 4), operands[1]);
   emit_move_insn (gen_rtx_REG (SImode, 5), operands[2]);
   emit_insn (last);
+
+  if (TARGET_DIVIDE_CALL_PRE1)
+    emit_label (lab2);
+
   DONE;
 }")
 
@@ -2149,8 +2206,7 @@
 				    (match_operand:DI 2 "register_operand" "r")]
 			 UNSPEC_DIV_INV_TABLE)))]
   "TARGET_SHMEDIA"
-  "@
-	ldx.ub	%1, %2, %0"
+  "ldx.ub	%1, %2, %0"
   [(set_attr "type" "load_media")
    (set_attr "highpart" "user")])
 
@@ -2161,8 +2217,7 @@
 				    (match_operand:DI 2 "register_operand" "r")]
 			 UNSPEC_DIV_INV_TABLE)))]
   "TARGET_SHMEDIA"
-  "@
-	ldx.w	%1, %2, %0"
+  "ldx.w	%1, %2, %0"
   [(set_attr "type" "load_media")
    (set_attr "highpart" "user")])
 
@@ -2708,6 +2763,16 @@
   "mul.l	%1,%0"
   [(set_attr "type" "dmpy")])
 
+(define_insn "mulr03"
+  [(set (match_operand:SI 0 "arith_reg_operand" "=r")
+	(mult:SI (match_operand:SI 1 "arith_reg_operand" "%0")
+		 (match_operand:SI 2 "arith_reg_operand" "R03")))]
+  "TARGET_R0R3_TO_REG_MUL - !reload_completed >= 1"
+  "mulr	%2,%0"
+  [(set_attr "type" "dmpy")])
+
+;; ??? should we also use mulr if we'd need two reg-reg copies?
+
 (define_expand "mulsi3"
   [(set (reg:SI MACL_REG)
 	(mult:SI  (match_operand:SI 1 "arith_reg_operand" "")
@@ -2717,7 +2782,12 @@
   "TARGET_SH1"
   "
 {
-  if (!TARGET_SH2)
+    if (TARGET_R0R3_TO_REG_MUL == 2)
+    {
+       emit_insn (gen_mulr03 (operands[0], operands[1], operands[2]));
+       DONE;
+    }
+   else if (!TARGET_SH2)
     {
       /* The address must be set outside the libcall,
 	 since it goes into a pseudo.  */
@@ -3431,6 +3501,17 @@
   [(set_attr "type" "arith")
    (set_attr "length" "4")])
 
+(define_insn "ashlsi3_k"
+  [(set (match_operand:SI 0 "arith_reg_dest" "=r")
+	(ashift:SI (match_operand:SI 1 "arith_reg_operand" "0")
+		   (match_operand:SI 2 "const_int_operand" "M")))
+   (set (reg:SI T_REG)
+	(lt:SI (match_dup 1) (const_int 0)))]
+  "TARGET_SH1"
+  "shal	%0"
+  [(set_attr "type" "arith")])
+
+
 ;; This pattern is used by init_expmed for computing the costs of shift
 ;; insns.
 
@@ -3605,44 +3686,28 @@
 ;; code, so just let the machine independent code widen the mode.
 ;; That's why we don't have ashrhi3_k / lshrhi3_k / lshrhi3_m / lshrhi3 .
 
-
-;; ??? This should be a define expand.
-
-(define_insn "ashrsi2_16"
-  [(set (match_operand:SI 0 "arith_reg_dest" "=r")
-        (ashiftrt:SI (match_operand:SI 1 "arith_reg_operand" "r")
-                     (const_int 16)))]
-  "TARGET_SH1"
-  "#"
-  [(set_attr "length" "4")])
-
-(define_split
-  [(set (match_operand:SI 0 "arith_reg_dest" "")
+(define_expand "ashrsi2_16"
+  [(parallel [(set (match_operand:SI 0 "arith_reg_dest" "")
         (ashiftrt:SI (match_operand:SI 1 "arith_reg_operand" "")
-		     (const_int 16)))]
+				(const_int 16)))
+	      (clobber (reg:SI T_REG))])]
   "TARGET_SH1"
-  [(set (match_dup 0) (rotate:SI (match_dup 1) (const_int 16)))
-   (set (match_dup 0) (sign_extend:SI (match_dup 2)))]
-  "operands[2] = gen_lowpart (HImode, operands[0]);")
+  "
+{
+  rtx low0 = gen_lowpart (HImode, operands[0]);
 
-;; ??? This should be a define expand.
+  emit_insn (gen_rotlsi3_16 (operands[0], operands[1]));
+  emit_insn (gen_extendhisi2 (operands[0], low0));
+  DONE;
+}
+")
 
-(define_insn "ashrsi2_31"
-  [(set (match_operand:SI 0 "arith_reg_dest" "=r")
+(define_expand "ashrsi2_31"
+  [(parallel [(set (match_operand:SI 0 "arith_reg_dest" "=r")
 	(ashiftrt:SI (match_operand:SI 1 "arith_reg_operand" "0")
 		     (const_int 31)))
-   (clobber (reg:SI T_REG))]
-  "TARGET_SH1"
-  "#"
-  [(set_attr "length" "4")])
-
-(define_split
-  [(set (match_operand:SI 0 "arith_reg_dest" "")
-	(ashiftrt:SI (match_operand:SI 1 "arith_reg_operand" "")
-		     (const_int 31)))
-   (clobber (reg:SI T_REG))]
+	      (clobber (reg:SI T_REG))])]
   "TARGET_SH1"
-  [(const_int 0)]
   "
 {
   emit_insn (gen_ashlsi_c (operands[0], operands[1]));
@@ -4782,12 +4847,22 @@
   "")
 
 (define_insn "pop_fpul"
-  [(set (reg:SF FPUL_REG) (mem:SF (post_inc:SI (reg:SI SP_REG))))]
-  "TARGET_SH2E && ! TARGET_SH5"
+  [(parallel [(set (reg:SF FPUL_REG) (mem:SF (post_inc:SI (reg:SI SP_REG))))
+	      (clobber (scratch:SI))])]
+  "TARGET_SH1 && ! TARGET_SH5"
   "lds.l	@r15+,fpul"
   [(set_attr "type" "load")
    (set_attr "hit_stack" "yes")])
 
+(define_insn "pop_fpul2"
+  [(parallel [(set (reg:SF FPUL_REG)
+	(mem:SF (post_inc:SI (match_operand:SI 0 "register_operand" "r"))))
+	      (clobber (scratch:SI))])]
+  ""
+  "lds.l      @%0+,fpul"
+  [(set_attr "type" "load")
+   (set_attr "hit_stack" "no")])
+
 (define_expand "pop_4"
   [(parallel [(set (match_operand:DF 0 "" "")
 		   (mem:DF (post_inc:SI (reg:SI SP_REG))))
@@ -5779,7 +5854,7 @@
 ;; instructions.  And when not optimizing, no splits are done before fixing
 ;; up pcloads, so we need usable length information for that.
 (define_insn "movdf_i4"
-  [(set (match_operand:DF 0 "general_movdst_operand" "=d,r,d,d,m,r,r,m,!??r,!???d")
+  [(set (match_operand:DF 0 "general_movdst_operand" "=d,r,d,d,m,r,*r,*m,!??r,!???d")
 	(match_operand:DF 1 "general_movsrc_operand"  "d,r,F,m,d,FQ,m,r,d,r"))
    (use (match_operand:PSI 2 "fpscr_operand"          "c,c,c,c,c,c,c,c,c,c"))
    (clobber (match_scratch:SI 3                      "=X,X,&z,X,X,X,X,X,X,X"))]
@@ -5807,7 +5882,7 @@
      [(if_then_else (eq_attr "fmovd" "yes") (const_int 4) (const_int 8))
       (const_int 4)
       (if_then_else (eq_attr "fmovd" "yes") (const_int 4) (const_int 6))
-      (if_then_else (eq_attr "fmovd" "yes") (const_int 4) (const_int 6))
+      (const_int 4)
       (if_then_else (eq_attr "fmovd" "yes") (const_int 4) (const_int 6))
       (const_int 4)
       (const_int 8) (const_int 8) ;; these need only 8 bytes for @(r0,rn)
@@ -6565,7 +6640,7 @@
 	(match_operand:SF 1 "general_movsrc_operand"
 	  "f,r,G,H,FQ,mf,f,FQ,mr,r,y,f,>,fr,y,r,y,>,y"))
    (use (match_operand:PSI 2 "fpscr_operand" "c,c,c,c,c,c,c,c,c,c,c,c,c,c,c,c,c,c,c"))
-   (clobber (match_scratch:SI 3 "=X,X,Bsc,Bsc,&z,X,X,X,X,X,X,X,X,y,X,X,X,X,X"))]
+   (clobber (match_scratch:SI 3 "=X,X,Bsc,Bsc,&z,X,X,&z,X,X,X,X,X,y,X,X,X,X,X"))]
 
   "TARGET_SH2E
    && (arith_reg_operand (operands[0], SFmode)
@@ -6627,9 +6702,26 @@
       (const_int 2)
       (const_int 2)
       (const_int 0)])
-   (set (attr "fp_mode") (if_then_else (eq_attr "fmovd" "yes")
+  (set_attr_alternative "fp_mode"
+     [(if_then_else (eq_attr "fmovd" "yes") (const_string "single") (const_string "none"))
+      (const_string "none")
+      (const_string "single")
 					   (const_string "single")
-					   (const_string "single")))])
+      (const_string "none")
+      (if_then_else (eq_attr "fmovd" "yes") (const_string "single") (const_string "none"))
+      (if_then_else (eq_attr "fmovd" "yes") (const_string "single") (const_string "none"))
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")])])
 
 (define_split
   [(set (match_operand:SF 0 "register_operand" "")
@@ -6750,7 +6842,17 @@
 
 (define_insn "*movsi_y"
   [(set (match_operand:SI 0 "register_operand" "=y,y")
-	(match_operand:SI 1 "immediate_operand" "Qi,I08"))
+	(match_operand 1 "immediate_operand" "Qi,I08"))
+   (clobber (match_scratch:SI 2 "=&z,r"))]
+  "TARGET_SH2E
+   && (reload_in_progress || reload_completed)"
+  "#"
+  [(set_attr "length" "4")
+   (set_attr "type" "pcload,move")])
+
+(define_insn "*movsf_y"
+  [(set (match_operand:SF 0 "register_operand" "=y,y")
+	(match_operand 1 "immediate_operand" "Qi,I08"))
    (clobber (match_scratch:SI 2 "=&z,r"))]
   "TARGET_SH2E
    && (reload_in_progress || reload_completed)"
@@ -6980,6 +7082,50 @@
   "b%o3%'	%N2, %N1, %0%>"
   [(set_attr "type" "cbranch_media")])
 
+(define_expand "cmpun_sdf"
+  [(unordered (match_operand 0 "" "") (match_operand 1 "" ""))]
+  ""
+  "
+{
+  HOST_WIDE_INT mask;
+  switch (GET_MODE (operands[0]))
+    {
+    case SFmode:
+      mask = SF_NAN_MASK;
+      break;
+    case DFmode:
+      mask = DF_NAN_MASK;
+      break;
+    default:
+      FAIL;
+    }
+  emit_insn (gen_cmpunsf_i1 (operands[0], operands[1],
+			     force_reg (SImode, GEN_INT (mask))));
+  DONE;
+}")
+
+(define_expand "cmpuneq_sdf"
+  [(uneq (match_operand 0 "" "") (match_operand 1 "" ""))]
+  ""
+  "
+{
+  HOST_WIDE_INT mask;
+  switch (GET_MODE (operands[0]))
+    {
+    case SFmode:
+      mask = SF_NAN_MASK;
+      break;
+    case DFmode:
+      mask = DF_NAN_MASK;
+      break;
+    default:
+      FAIL;
+    }
+  emit_insn (gen_cmpuneqsf_i1 (operands[0], operands[1],
+			       force_reg (SImode, GEN_INT (mask))));
+  DONE;
+}")
+
 ;; combiner splitter for test-and-branch on single bit in register.  This
 ;; is endian dependent because the non-paradoxical subreg looks different
 ;; on big endian.
@@ -7024,7 +7170,7 @@
 	      (set (match_dup 0)
 		   (plus:SI (match_dup 0) (const_int -1)))
 	      (clobber (reg:SI T_REG))])]
-  "TARGET_SH2"
+  "TARGET_SH2 && !optimize_size"
   "
 {
   if (GET_MODE (operands[0]) != SImode)
@@ -8286,6 +8432,14 @@
   DONE;
 }")
 
+(define_insn "dup_db_insn"
+  [(unspec_volatile [(const_int 0)] UNSPECV_DB_INSN)]
+  "TARGET_DEAD_DELAY"
+  ""
+  [(set_attr "length" "0")
+   (set_attr "in_delay_slot" "yes")])
+
+
 ;; ------------------------------------------------------------------------
 ;; Misc insns
 ;; ------------------------------------------------------------------------
@@ -8828,8 +8982,8 @@
 
 (define_insn "casesi_worker_0"
   [(set (match_operand:SI 0 "register_operand" "=r,r")
-	(unspec:SI [(match_operand:SI 1 "register_operand" "0,r")
-		 (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI))
+	(mem:SI (unspec:SI [(match_operand:SI 1 "register_operand" "0,r")
+		 (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI)))
    (clobber (match_scratch:SI 3 "=X,1"))
    (clobber (match_scratch:SI 4 "=&z,z"))]
   "TARGET_SH1"
@@ -8837,38 +8991,38 @@
 
 (define_split
   [(set (match_operand:SI 0 "register_operand" "")
-	(unspec:SI [(match_operand:SI 1 "register_operand" "")
-		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI))
+	(mem:SI (unspec:SI [(match_operand:SI 1 "register_operand" "")
+		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI)))
    (clobber (match_scratch:SI 3 ""))
    (clobber (match_scratch:SI 4 ""))]
   "TARGET_SH1 && ! TARGET_SH2 && reload_completed"
   [(set (reg:SI R0_REG) (unspec:SI [(label_ref (match_dup 2))] UNSPEC_MOVA))
    (parallel [(set (match_dup 0)
-	      (unspec:SI [(reg:SI R0_REG) (match_dup 1)
-			  (label_ref (match_dup 2))] UNSPEC_CASESI))
+	      (mem:SI (unspec:SI [(reg:SI R0_REG) (match_dup 1)
+			  (label_ref (match_dup 2))] UNSPEC_CASESI)))
 	      (clobber (match_dup 3))])
    (set (match_dup 0) (plus:SI (match_dup 0) (reg:SI R0_REG)))]
   "if (GET_CODE (operands[2]) == CODE_LABEL) LABEL_NUSES (operands[2])++;")
 
 (define_split
   [(set (match_operand:SI 0 "register_operand" "")
-	(unspec:SI [(match_operand:SI 1 "register_operand" "")
-		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI))
+	(mem:SI (unspec:SI [(match_operand:SI 1 "register_operand" "")
+		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI)))
    (clobber (match_scratch:SI 3 ""))
    (clobber (match_scratch:SI 4 ""))]
   "TARGET_SH2 && reload_completed"
   [(set (reg:SI R0_REG) (unspec:SI [(label_ref (match_dup 2))] UNSPEC_MOVA))
    (parallel [(set (match_dup 0)
-	      (unspec:SI [(reg:SI R0_REG) (match_dup 1)
-			  (label_ref (match_dup 2))] UNSPEC_CASESI))
+	      (mem:SI (unspec:SI [(reg:SI R0_REG) (match_dup 1)
+			  (label_ref (match_dup 2))] UNSPEC_CASESI)))
 	      (clobber (match_dup 3))])]
   "if (GET_CODE (operands[2]) == CODE_LABEL) LABEL_NUSES (operands[2])++;")
 
 (define_insn "casesi_worker_1"
   [(set (match_operand:SI 0 "register_operand" "=r,r")
-	(unspec:SI [(reg:SI R0_REG)
+	(mem:SI (unspec:SI [(reg:SI R0_REG)
 		    (match_operand:SI 1 "register_operand" "0,r")
-		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI))
+		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI)))
    (clobber (match_scratch:SI 3 "=X,1"))]
   "TARGET_SH1"
   "*
@@ -8895,10 +9049,10 @@
 
 (define_insn "casesi_worker_2"
   [(set (match_operand:SI 0 "register_operand" "=r,r")
-	(unspec:SI [(reg:SI R0_REG)
+	(mem:SI (unspec:SI [(reg:SI R0_REG)
 		    (match_operand:SI 1 "register_operand" "0,r")
 		    (label_ref (match_operand 2 "" ""))
-		    (label_ref (match_operand 3 "" ""))] UNSPEC_CASESI))
+		    (label_ref (match_operand 3 "" ""))] UNSPEC_CASESI)))
    (clobber (match_operand:SI 4 "" "=X,1"))]
   "TARGET_SH2 && reload_completed && flag_pic"
   "*
@@ -9340,6 +9494,19 @@
 
 
 
+(define_expand "sunle"
+  [(set (match_operand:SI 0 "arith_reg_operand" "")
+	(match_dup 1))]
+  "TARGET_SH1_SOFTFP"
+  "
+{
+  if (! currently_expanding_to_rtl)
+    FAIL;
+    sh_emit_compare_and_branch (operands, DFmode);
+  emit_insn (gen_movt (operands[0]));
+  DONE;
+}")
+
 ;; sne moves the complement of the T reg to DEST like this:
 ;;      cmp/eq ...
 ;;      mov    #-1,temp
@@ -9550,7 +9717,8 @@
   [(unspec_volatile [(const_int 0)] UNSPECV_CONST_END)]
   ""
   "* return output_jump_label_table ();"
-  [(set_attr "in_delay_slot" "no")])
+  [(set_attr "length" "0")
+   (set_attr "in_delay_slot" "no")])
 
 ; emitted at the end of the window in the literal table.
 
@@ -9734,15 +9902,10 @@
   "fschg"
   [(set_attr "type" "fpscr_toggle") (set_attr "fp_set" "unknown")])
 
-;; There's no way we can use it today, since optimize mode switching
-;; doesn't enable us to know from which mode we're switching to the
-;; mode it requests, to tell whether we can use a relative mode switch
-;; (like toggle_pr) or an absolute switch (like loading fpscr from
-;; memory).
 (define_insn "toggle_pr"
   [(set (reg:PSI FPSCR_REG)
 	(xor:PSI (reg:PSI FPSCR_REG) (const_int 524288)))]
-  "TARGET_SH4A_FP && ! TARGET_FPU_SINGLE"
+  "(TARGET_SH4A_FP || TARGET_SH4_300)" 
   "fpchg"
   [(set_attr "type" "fpscr_toggle")])
 
@@ -9750,7 +9913,7 @@
   [(set (match_operand:SF 0 "arith_reg_operand" "")
 	(plus:SF (match_operand:SF 1 "arith_reg_operand" "")
 		 (match_operand:SF 2 "arith_reg_operand" "")))]
-  "TARGET_SH2E || TARGET_SHMEDIA_FPU"
+  "TARGET_SH2E || (TARGET_SH3 && TARGET_OSFP) || TARGET_SHMEDIA_FPU"
   "
 {
   if (TARGET_SH2E)
@@ -9758,6 +9921,12 @@
       expand_sf_binop (&gen_addsf3_i, operands);
       DONE;
     }
+  else if (TARGET_OSFP)
+    {
+      expand_sfunc_binop (SFmode, &gen_addsf3_i3, \"__addsf3\", PLUS,
+			  operands);
+      DONE;
+    }
 }")
 
 (define_insn "*addsf3_media"
@@ -9856,6 +10025,22 @@
 }"
   [(set_attr "type" "fparith_media")])
 
+(define_insn "addsf3_i3"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=z")
+	(plus:SF (reg:SF R4_REG) (reg:SF R5_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (clobber (reg:SI R6_REG))
+   (clobber (reg:SI R7_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_OSFP && ! TARGET_SH2E"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 (define_insn "addsf3_i"
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "=f")
 	(plus:SF (match_operand:SF 1 "fp_arith_reg_operand" "%0")
@@ -9870,7 +10055,7 @@
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "")
 	(minus:SF (match_operand:SF 1 "fp_arith_reg_operand" "")
 		  (match_operand:SF 2 "fp_arith_reg_operand" "")))]
-  "TARGET_SH2E || TARGET_SHMEDIA_FPU"
+  "TARGET_SH2E || (TARGET_SH3 && TARGET_OSFP) || TARGET_SHMEDIA_FPU"
   "
 {
   if (TARGET_SH2E)
@@ -9878,6 +10063,12 @@
       expand_sf_binop (&gen_subsf3_i, operands);
       DONE;
     }
+  else if (TARGET_OSFP)
+    {
+      expand_sfunc_binop (SFmode, &gen_subsf3_i3, \"__subsf3\", MINUS,
+			  operands);
+      DONE;
+    }
 }")
 
 (define_insn "*subsf3_media"
@@ -9888,6 +10079,23 @@
   "fsub.s	%1, %2, %0"
   [(set_attr "type" "fparith_media")])
 
+(define_insn "subsf3_i3"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=z")
+	(minus:SF (reg:SF R4_REG) (reg:SF R5_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (clobber (reg:SI R5_REG))
+   (clobber (reg:SI R6_REG))
+   (clobber (reg:SI R7_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_OSFP && ! TARGET_SH2E"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 (define_insn "subsf3_i"
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "=f")
 	(minus:SF (match_operand:SF 1 "fp_arith_reg_operand" "0")
@@ -9902,8 +10110,16 @@
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "")
 	(mult:SF (match_operand:SF 1 "fp_arith_reg_operand" "")
 		 (match_operand:SF 2 "fp_arith_reg_operand" "")))]
-  "TARGET_SH2E || TARGET_SHMEDIA_FPU"
-  "")
+  "TARGET_SH2E || (TARGET_SH3 && TARGET_OSFP) || TARGET_SHMEDIA_FPU"
+  "
+{
+  if (!TARGET_SH2E && TARGET_OSFP)
+    {
+      expand_sfunc_binop (SFmode, &gen_mulsf3_i3, \"__mulsf3\", MULT,
+                         operands);
+      DONE;
+    }
+}")
 
 (define_insn "*mulsf3_media"
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "=f")
@@ -9944,6 +10160,22 @@
   [(set_attr "type" "fp")
    (set_attr "fp_mode" "single")])
 
+(define_insn "mulsf3_i3"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=z")
+	(mult:SF (reg:SF R4_REG) (reg:SF R5_REG)))
+   (clobber (reg:SI MACH_REG))
+   (clobber (reg:SI MACL_REG))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_OSFP && ! TARGET_SH2E"
+   "jsr	@%1%#"
+   [(set_attr "type" "sfunc")
+    (set_attr "needs_delay_slot" "yes")])
+
 (define_insn "mac_media"
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "=f")
 	(plus:SF (mult:SF (match_operand:SF 1 "fp_arith_reg_operand" "%f")
@@ -10113,6 +10345,155 @@
   [(set_attr "type" "fp_cmp")
    (set_attr "fp_mode" "single")])
 
+ (define_insn "cmpnesf_i1"
+   [(set (match_operand:CC_FP_NE 0 "register_operand" "=z")
+ 	(compare:CC_FP_NE (reg:SF R4_REG) (reg:SF R5_REG)))
+    (clobber (reg:SI T_REG))
+    (clobber (reg:SI PR_REG))
+    (clobber (reg:SI R1_REG))
+    (clobber (reg:SI R2_REG))
+    (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+   "TARGET_SH1 && ! TARGET_SH2E"
+   "jsr	@%1%#"
+   [(set_attr "type" "sfunc")
+    (set_attr "needs_delay_slot" "yes")])
+
+ (define_insn "cmpgtsf_i1"
+   [(set (match_operand:CC_FP_GT 0 "register_operand" "=z")
+ 	(compare:CC_FP_GT (reg:SF R4_REG) (reg:SF R5_REG)))
+    (clobber (reg:SI T_REG))
+    (clobber (reg:SI PR_REG))
+    (clobber (reg:SI R1_REG))
+    (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+   "TARGET_SH1 && ! TARGET_SH2E"
+   "jsr	@%1%#"
+   [(set_attr "type" "sfunc")
+    (set_attr "needs_delay_slot" "yes")])
+
+ (define_insn "cmpunltsf_i1"
+   [(set (match_operand:CC_FP_UNLT 0 "register_operand" "=z")
+ 	(compare:CC_FP_UNLT (reg:SF R4_REG) (reg:SF R5_REG)))
+    (clobber (reg:SI T_REG))
+    (clobber (reg:SI PR_REG))
+    (clobber (reg:SI R1_REG))
+    (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+   "TARGET_SH1 && ! TARGET_SH2E"
+   "jsr	@%1%#"
+   [(set_attr "type" "sfunc")
+    (set_attr "needs_delay_slot" "yes")])
+
+ (define_insn "cmpeqsf_i1_finite"
+   [(set (reg:SI T_REG)
+ 	(eq:SI (match_operand:SF 0 "arith_reg_operand" "r,r,r")
+ 	       (match_operand:SF 1 "arith_reg_operand" "r,r,r")))
+    (clobber (match_scratch:SI 2 "=0,1,?r"))]
+   "TARGET_SH1 && ! TARGET_SH2E && flag_finite_math_only"
+   "*
+ {
+   if (which_alternative == 0)
+      output_asm_insn (\"cmp/eq\t%0,%1\;or\t%1,%2\;bt\t0f\", operands);
+   else if (which_alternative == 1)
+      output_asm_insn (\"cmp/eq\t%0,%1\;or\t%0,%2\;bt\t0f\", operands);
+   else
+     output_asm_insn (\"cmp/eq\t%0,%1\;mov\t%0,%2\;bt\t0f\;or\t%1,%2\",
+ 		     operands);
+   return \"add\t%2,%2\;tst\t%2,%2\\n0:\";
+ }"
+   [(set_attr "length" "10,10,12")])
+
+ (define_insn "cmplesf_i1_finite"
+   [(set (reg:SI T_REG)
+ 	(le:SI (match_operand:SF 0 "arith_reg_operand" "r,r,r")
+ 	       (match_operand:SF 1 "arith_reg_operand" "r,r,r")))
+    (clobber (match_scratch:SI 2 "=0,1,r"))]
+   "TARGET_SH1 && ! TARGET_SH2E && flag_finite_math_only"
+   "*
+ {
+   output_asm_insn (\"cmp/pz\t%0\", operands);
+   if (which_alternative == 2)
+     output_asm_insn (\"mov\t%0,%2\", operands);
+   if (TARGET_SH2)
+     output_asm_insn (\"bf/s\t0f\;cmp/hs\t%1,%0\;cmp/ge\t%0,%1\", operands);
+   else
+     output_asm_insn (\"bt\t1f\;bra\t0f\;cmp/hs\t%1,%0\\n1:\tcmp/ge\t%0,%1\",
+ 		     operands);
+   if (which_alternative == 1)
+     output_asm_insn (\"or\t%0,%2\", operands);
+   else
+     output_asm_insn (\"or\t%1,%2\", operands);
+   return \"bt\t0f\;add\t%2,%2\;tst\t%2,%2\\n0:\";
+ }"
+   [(set_attr "length" "18,18,20")])
+
+ (define_insn "cmpunsf_i1"
+   [(set (reg:SI T_REG)
+ 	(unordered:SI (match_operand:SF 0 "arith_reg_operand" "r")
+ 		      (match_operand:SF 1 "arith_reg_operand" "r")))
+    (use (match_operand:SI 2 "arith_reg_operand" "r"))
+    (clobber (match_scratch:SI 3 "=&r"))]
+   "TARGET_SH1 && ! TARGET_SH2E"
+   "not\t%0,%3\;tst\t%2,%3\;bt.s\t0f
+\tnot\t%1,%3\;tst\t%2,%3\;bt.s\t0f
+\tmov\t#96,%3\;shll16\t%3\;xor\t%3,%2
+\tnot\t%0,%3\;tst\t%2,%3\;bt.s\t0f
+\tnot\t%1,%3\;tst\t%2,%3
+0:"
+   [(set_attr "length" "28")])
+
+ ;; ??? This is a lot of code with a lot of branches; a library function
+ ;; might be better.
+ (define_insn "cmpuneqsf_i1"
+   [(set (reg:SI T_REG)
+ 	(uneq:SI (match_operand:SF 0 "arith_reg_operand" "r")
+ 		 (match_operand:SF 1 "arith_reg_operand" "r")))
+    (use (match_operand:SI 2 "arith_reg_operand" "r"))
+    (clobber (match_scratch:SI 3 "=&r"))]
+   "TARGET_SH1 && ! TARGET_SH2E"
+   "*
+ {
+   output_asm_insn (\"not\t%0,%3\;tst\t%2,%3\;not\t%1,%3\", operands);
+   output_asm_insn (\"bt\t0f\;tst\t%2,%3\;bt\t0f\;cmp/eq\t%0,%1\", operands);
+   output_asm_insn (\"mov\t%0,%3\;bt\t0f\;or\t%1,%3\", operands);
+   return \"add\t%3,%3\;tst\t%3,%3\\n0:\";
+ }"
+   [(set_attr "length" "24")])
+
+ (define_insn "movcc_fp_ne"
+   [(set (match_operand:CC_FP_NE 0 "general_movdst_operand"
+ 	    "=r,r,m")
+ 	(match_operand:CC_FP_NE 1 "general_movsrc_operand"
+ 	 "rI08,mr,r"))]
+   "TARGET_SH1"
+   "@
+ 	mov	%1,%0
+ 	mov.l	%1,%0
+ 	mov.l	%1,%0"
+   [(set_attr "type" "move,load,store")])
+
+ (define_insn "movcc_fp_gt"
+   [(set (match_operand:CC_FP_GT 0 "general_movdst_operand"
+ 	    "=r,r,m")
+ 	(match_operand:CC_FP_GT 1 "general_movsrc_operand"
+ 	 "rI08,mr,r"))]
+   "TARGET_SH1"
+   "@
+ 	mov	%1,%0
+ 	mov.l	%1,%0
+ 	mov.l	%1,%0"
+   [(set_attr "type" "move,load,store")])
+
+ (define_insn "movcc_fp_unlt"
+   [(set (match_operand:CC_FP_UNLT 0 "general_movdst_operand"
+ 	    "=r,r,m")
+ 	(match_operand:CC_FP_UNLT 1 "general_movsrc_operand"
+ 	 "rI08,mr,r"))]
+   "TARGET_SH1"
+   "@
+ 	mov	%1,%0
+ 	mov.l	%1,%0
+ 	mov.l	%1,%0"
+   [(set_attr "type" "move,load,store")])
+
 (define_insn "cmpeqsf_t"
   [(set (reg:SI T_REG)
 	(eq:SI (match_operand:SF 0 "fp_arith_reg_operand" "f")
@@ -10131,6 +10512,21 @@
   "* return output_ieee_ccmpeq (insn, operands);"
   [(set_attr "length" "4")])
 
+(define_insn "*cmpltgtsf_t"
+  [(set (reg:SI T_REG)
+	(ltgt:SI (match_operand:SF 0 "fp_arith_reg_operand" "f")
+		 (match_operand:SF 1 "fp_arith_reg_operand" "f")))]
+  "TARGET_SH2E && ! (TARGET_SH4 || TARGET_SH2A_SINGLE)"
+  "fcmp/gt\t%1,%0\;bt\t0f\;fcmp/gt\t%0,%1\\n0:"
+  [(set_attr "length" "6")])
+
+(define_insn "*cmporderedsf_t"
+  [(set (reg:SI T_REG)
+	(ordered:SI (match_operand:SF 0 "fp_arith_reg_operand" "f")
+		    (match_operand:SF 1 "fp_arith_reg_operand" "f")))]
+  "TARGET_SH2E && ! (TARGET_SH4 || TARGET_SH2A_SINGLE)"
+  "fcmp/eq\t%0,%0\;bf\t0f\;fcmp/eq\t%1,%1\\n0:"
+  [(set_attr "length" "6")])
 
 (define_insn "cmpgtsf_t_i4"
   [(set (reg:SI T_REG)
@@ -10163,6 +10559,26 @@
   [(set_attr "length" "4")
    (set_attr "fp_mode" "single")])
 
+(define_insn "*cmpltgtsf_t_4"
+  [(set (reg:SI T_REG)
+	(ltgt:SI (match_operand:SF 0 "fp_arith_reg_operand" "f")
+		 (match_operand:SF 1 "fp_arith_reg_operand" "f")))
+   (use (match_operand:PSI 2 "fpscr_operand" "c"))]
+  "TARGET_SH4 || TARGET_SH2A_SINGLE"
+  "fcmp/gt\t%1,%0\;bt\t0f\;fcmp/gt\t%0,%1\\n0:"
+  [(set_attr "length" "6")
+   (set_attr "fp_mode" "single")])
+
+(define_insn "*cmporderedsf_t_4"
+  [(set (reg:SI T_REG)
+	(ordered:SI (match_operand:SF 0 "fp_arith_reg_operand" "f")
+		    (match_operand:SF 1 "fp_arith_reg_operand" "f")))
+   (use (match_operand:PSI 2 "fpscr_operand" "c"))]
+  "TARGET_SH4 || TARGET_SH2A_SINGLE"
+  "fcmp/eq\t%0,%0\;bf\t0f\;fcmp/eq\t%1,%1\\n0:"
+  [(set_attr "length" "6")
+   (set_attr "fp_mode" "single")])
+
 (define_insn "cmpeqsf_media"
   [(set (match_operand:SI 0 "register_operand" "=r")
 	(eq:SI (match_operand:SF 1 "fp_arith_reg_operand" "f")
@@ -10411,11 +10827,39 @@
   [(set_attr "type" "fmove")
    (set_attr "fp_mode" "single")])
 
+(define_expand "abssc2"
+  [(set (match_operand:SF 0 "fp_arith_reg_operand" "")
+	(abs:SF (match_operand:SC 1 "fp_arith_reg_operand" "")))]
+  "TARGET_OSFP && ! TARGET_SH2E"
+  "
+{
+  expand_sfunc_unop (SCmode, &gen_abssc2_i3, \"__hypotf\", ABS, operands);
+  DONE;
+}")
+
+(define_insn "abssc2_i3"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=z")
+	(abs:SF (reg:SC R4_REG)))
+   (clobber (reg:SI MACH_REG))
+   (clobber (reg:SI MACL_REG))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (clobber (reg:SI R4_REG))
+   (clobber (reg:SI R5_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_OSFP && ! TARGET_SH2E"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 (define_expand "adddf3"
   [(set (match_operand:DF 0 "fp_arith_reg_operand" "")
 	(plus:DF (match_operand:DF 1 "fp_arith_reg_operand" "")
 		 (match_operand:DF 2 "fp_arith_reg_operand" "")))]
-  "(TARGET_SH4 || TARGET_SH2A_DOUBLE) || TARGET_SHMEDIA_FPU"
+  "TARGET_FPU_DOUBLE || (TARGET_SH3 && TARGET_OSFP)"
   "
 {
   if (TARGET_SH4 || TARGET_SH2A_DOUBLE)
@@ -10423,6 +10867,12 @@
       expand_df_binop (&gen_adddf3_i, operands);
       DONE;
     }
+  else if (TARGET_SH3 && TARGET_OSFP)
+    {
+      expand_sfunc_binop (DFmode, &gen_adddf3_i3_wrap, \"__adddf3\", PLUS,
+			  operands);
+      DONE;
+    }
 }")
 
 (define_insn "*adddf3_media"
@@ -10443,6 +10893,30 @@
   [(set_attr "type" "dfp_arith")
    (set_attr "fp_mode" "double")])
 
+(define_expand "adddf3_i3_wrap"
+  [(match_operand:DF 0 "" "") (match_operand:SI 1 "" "")]
+  "TARGET_SH3"
+  "
+{
+  emit_insn (gen_adddf3_i3 (operands[1]));
+  emit_move_insn (operands[0], gen_rtx_REG (DFmode, R0_REG));
+  DONE;
+}")
+
+(define_insn "adddf3_i3"
+  [(set (reg:DF R0_REG)
+	(plus:DF (reg:DF R4_REG) (reg:DF R6_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:DI R2_REG))
+   (clobber (reg:DF R4_REG))
+   (clobber (reg:DF R6_REG))
+   (use (match_operand:SI 0 "arith_reg_operand" "r"))]
+  "TARGET_SH3"
+  "jsr	@%0%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 (define_expand "subdf3"
   [(set (match_operand:DF 0 "fp_arith_reg_operand" "")
 	(minus:DF (match_operand:DF 1 "fp_arith_reg_operand" "")
@@ -10479,7 +10953,7 @@
   [(set (match_operand:DF 0 "fp_arith_reg_operand" "")
 	(mult:DF (match_operand:DF 1 "fp_arith_reg_operand" "")
 		 (match_operand:DF 2 "fp_arith_reg_operand" "")))]
-  "(TARGET_SH4 || TARGET_SH2A_DOUBLE) || TARGET_SHMEDIA_FPU"
+  "TARGET_FPU_DOUBLE || (TARGET_SH3 && TARGET_OSFP)"
   "
 {
   if (TARGET_SH4 || TARGET_SH2A_DOUBLE)
@@ -10487,6 +10961,12 @@
       expand_df_binop (&gen_muldf3_i, operands);
       DONE;
     }
+  else if (TARGET_SH3 && TARGET_OSFP)
+    {
+      expand_sfunc_binop (DFmode, &gen_muldf3_i3_wrap, \"__muldf3\", MULT,
+			  operands);
+      DONE;
+    }
 }")
 
 (define_insn "*muldf3_media"
@@ -10507,6 +10987,32 @@
   [(set_attr "type" "dfp_mul")
    (set_attr "fp_mode" "double")])
 
+(define_expand "muldf3_i3_wrap"
+  [(match_operand:DF 0 "" "") (match_operand:SI 1 "" "")]
+  "TARGET_SH3"
+   "
+ {
+   emit_insn (gen_muldf3_i3 (operands[1]));
+   emit_move_insn (operands[0], gen_rtx_REG (DFmode, R0_REG));
+   DONE;
+ }")
+
+ (define_insn "muldf3_i3"
+   [(set (reg:DF R0_REG)
+ 	(mult:DF (reg:DF R4_REG) (reg:DF R6_REG)))
+    (clobber (reg:SI MACH_REG))
+    (clobber (reg:SI MACL_REG))
+    (clobber (reg:SI T_REG))
+    (clobber (reg:SI PR_REG))
+    (clobber (reg:DI R2_REG))
+    (clobber (reg:DF R4_REG))
+    (clobber (reg:DF R6_REG))
+    (use (match_operand:SI 0 "arith_reg_operand" "r"))]
+   "TARGET_SH3"
+   "jsr	@%0%#"
+   [(set_attr "type" "sfunc")
+    (set_attr "needs_delay_slot" "yes")])
+
 (define_expand "divdf3"
   [(set (match_operand:DF 0 "fp_arith_reg_operand" "")
 	(div:DF (match_operand:DF 1 "fp_arith_reg_operand" "")
@@ -10636,6 +11142,79 @@
 ;; 	      (use (match_dup 2))])
 ;;    (set (match_dup 0) (reg:SI FPUL_REG))])
 
+(define_insn "cmpnedf_i1"
+  [(set (match_operand:CC_FP_NE 0 "register_operand" "=z")
+	(compare:CC_FP_NE (reg:DF R4_REG) (reg:DF R6_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
+(define_insn "cmpgtdf_i1"
+  [(set (match_operand:CC_FP_GT 0 "register_operand" "=z")
+	(compare:CC_FP_GT (reg:DF R4_REG) (reg:DF R6_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
+(define_insn "cmpunltdf_i1"
+  [(set (match_operand:CC_FP_UNLT 0 "register_operand" "=z")
+	(compare:CC_FP_UNLT (reg:DF R4_REG) (reg:DF R6_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
+(define_insn "cmpeqdf_i1_finite"
+  [(set (reg:SI T_REG)
+	(eq:SI (match_operand:DF 0 "arith_reg_operand" "r")
+	       (match_operand:DF 1 "arith_reg_operand" "r")))
+   (clobber (match_scratch:SI 2 "=&r"))]
+  "TARGET_SH1_SOFTFP && flag_finite_math_only"
+  "cmp/eq\t%R0,%R1\;mov\t%S0,%2\;bf\t0f\;cmp/eq\t%S0,%S1\;bt\t0f\;or\t%S1,%2\;add\t%2,%2\;or\t%R0,%2\;tst\t%2,%2\\n0:"
+  [(set_attr "length" "18")])
+
+(define_insn "cmpundf_i1"
+  [(set (reg:SI T_REG)
+	(unordered:SI (match_operand:DF 0 "arith_reg_operand" "r")
+		      (match_operand:DF 1 "arith_reg_operand" "r")))
+   (use (match_operand:SI 2 "arith_reg_operand" "r"))
+   (clobber (match_scratch:SI 3 "=&r"))]
+  "TARGET_SH1 && ! TARGET_SH2E"
+   "not\t%S0,%3\;tst\t%2,%3\;bt.s\t0f
+  \tnot\t%S1,%3\;tst\t%2,%3\;bt.s\t0f
+  \tmov\t#12,%3\;shll16\t%3\;xor\t%3,%2
+  \tnot\t%S0,%3\;tst\t%2,%3\;bt.s\t0f
+  \tnot\t%S1,%3\;tst\t%2,%3
+0:"
+  [(set_attr "length" "28")])
+
+;; ??? This is a lot of code with a lot of branches; a library function
+;; might be better.
+(define_insn "cmpuneqdf_i1"
+  [(set (reg:SI T_REG)
+	(uneq:SI (match_operand:DF 0 "arith_reg_operand" "r")
+		 (match_operand:DF 1 "arith_reg_operand" "r")))
+   (use (match_operand:SI 2 "arith_reg_operand" "r"))
+   (clobber (match_scratch:SI 3 "=&r"))]
+  "TARGET_SH1_SOFTFP"
+  "not\t%S0,%3\;tst\t%2,%3\;not\t%S1,%3\;bt\t0f\;tst\t%2,%3\;bt\t0f\;cmp/eq\t%R0,%R1\; bf\t0f\;cmp/eq\t%S0,%S1\;bt\t0f\;mov\t%S0,%3\;or\t%S1,%3\;add\t%3,%3\;or\t%R0,%3\;tst\t%3,%3\\n0:"
+  [(set_attr "length" "30")])
+
 (define_insn "cmpgtdf_t"
   [(set (reg:SI T_REG)
 	(gt:SI (match_operand:DF 0 "arith_reg_operand" "f")
@@ -10667,6 +11246,26 @@
   [(set_attr "length" "4")
    (set_attr "fp_mode" "double")])
 
+(define_insn "*cmpltgtdf_t"
+  [(set (reg:SI T_REG)
+	(ltgt:SI (match_operand:DF 0 "fp_arith_reg_operand" "f")
+		 (match_operand:DF 1 "fp_arith_reg_operand" "f")))
+   (use (match_operand:PSI 2 "fpscr_operand" "c"))]
+  "TARGET_SH4 || TARGET_SH2A_DOUBLE"
+  "fcmp/gt\t%1,%0\;bt\t0f\;fcmp/gt\t%0,%1\\n0:"
+  [(set_attr "length" "6")
+   (set_attr "fp_mode" "double")])
+
+(define_insn "*cmpordereddf_t_4"
+  [(set (reg:SI T_REG)
+	(ordered:SI (match_operand:DF 0 "fp_arith_reg_operand" "f")
+		    (match_operand:DF 1 "fp_arith_reg_operand" "f")))
+   (use (match_operand:PSI 2 "fpscr_operand" "c"))]
+  "TARGET_SH4 || TARGET_SH2A_SINGLE"
+  "fcmp/eq\t%0,%0\;bf\t0f\;fcmp/eq\t%1,%1\\n0:"
+  [(set_attr "length" "6")
+   (set_attr "fp_mode" "double")])
+
 (define_insn "cmpeqdf_media"
   [(set (match_operand:SI 0 "register_operand" "=r")
 	(eq:SI (match_operand:DF 1 "fp_arith_reg_operand" "f")
@@ -10808,7 +11407,7 @@
 (define_expand "extendsfdf2"
   [(set (match_operand:DF 0 "fp_arith_reg_operand" "")
 	(float_extend:DF (match_operand:SF 1 "fpul_operand" "")))]
-  "(TARGET_SH4 || TARGET_SH2A_DOUBLE) || TARGET_SHMEDIA_FPU"
+  "TARGET_FPU_DOUBLE || (TARGET_SH3 && TARGET_OSFP) || TARGET_SHMEDIA_FPU"
   "
 {
   if (TARGET_SH4 || TARGET_SH2A_DOUBLE)
@@ -10817,6 +11416,18 @@
 					get_fpscr_rtx ()));
       DONE;
     }
+  if (TARGET_SH2E && TARGET_OSFP)
+    {
+      expand_sfunc_unop (SFmode, &gen_extendsfdf2_i2e, \"__extendsfdf2\",
+ 		 FLOAT_EXTEND, operands);
+      DONE;
+    }
+  else if (TARGET_SH1 && TARGET_OSFP)
+    {
+      expand_sfunc_unop (SFmode, &gen_extendsfdf2_i1, \"__extendsfdf2\",
+			 FLOAT_EXTEND, operands);
+      DONE;
+    }
 }")
 
 (define_insn "*extendsfdf2_media"
@@ -10835,10 +11446,76 @@
   [(set_attr "type" "fp")
    (set_attr "fp_mode" "double")])
 
+;; ??? In order to use this efficiently, we'd have to have an extra
+;; register class for r0 and r1 - and that would cause repercussions in
+;; register allocation elsewhere.  So just say we clobber r0 / r1, and
+;; that we can use an arbitrary target.  */
+(define_insn_and_split "extendsfdf2_i1"
+  [(set (match_operand:DF 0 "arith_reg_dest" "=r")
+	(float_extend:DF (reg:SF R4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R0_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && !TARGET_SH2E"
+  "#"
+  "&& reload_completed"
+  [(set (match_dup 0) (reg:DF R0_REG))]
+  "emit_insn (gen_extendsfdf2_i1_r0 (operands[1]));"
+  [(set_attr "type" "sfunc")])
+
+(define_insn "extendsfdf2_i1_r0"
+  [(set (reg:DF R0_REG) (float_extend:DF (reg:SF R4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (use (match_operand:SI 0 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && !TARGET_SH2E"
+  "jsr	@%0%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
+(define_insn_and_split "extendsfdf2_i2e"
+  [(set (match_operand:DF 0 "arith_reg_dest" "=r")
+	(float_extend:DF (reg:SF FR4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R0_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (clobber (reg:SI R4_REG))
+   (clobber (reg:SI FPUL_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && TARGET_SH2E"
+  "#"
+  "&& reload_completed"
+  [(set (match_dup 0) (reg:DF R0_REG))]
+  "emit_insn (gen_extendsfdf2_i2e_r0 (operands[1]));"
+  [(set_attr "type" "sfunc")])
+
+(define_insn "extendsfdf2_i2e_r0"
+  [(set (reg:DF R0_REG) (float_extend:DF (reg:SF FR4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (clobber (reg:SI R4_REG))
+   (clobber (reg:SI FPUL_REG))
+   (use (match_operand:SI 0 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && TARGET_SH2E"
+  "jsr	@%0%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 (define_expand "truncdfsf2"
   [(set (match_operand:SF 0 "fpul_operand" "")
 	(float_truncate:SF (match_operand:DF 1 "fp_arith_reg_operand" "")))]
-  "(TARGET_SH4 || TARGET_SH2A_DOUBLE) || TARGET_SHMEDIA_FPU"
+  "TARGET_FPU_DOUBLE || (TARGET_SH3 && TARGET_OSFP) || TARGET_SHMEDIA_FPU"
   "
 {
   if (TARGET_SH4 || TARGET_SH2A_DOUBLE)
@@ -10847,6 +11524,18 @@
 				       get_fpscr_rtx ()));
       DONE;
     }
+  else if (TARGET_SH2E && TARGET_OSFP)
+    {
+      expand_sfunc_unop (DFmode, &gen_truncdfsf2_i2e, \"__truncdfsf2\",
+			 FLOAT_TRUNCATE, operands);
+      DONE;
+    }
+  else if (TARGET_SH1 && TARGET_OSFP)
+    {
+      expand_sfunc_unop (DFmode, &gen_truncdfsf2_i1, \"__truncdfsf2\",
+			 FLOAT_TRUNCATE, operands);
+      DONE;
+    }
 }")
 
 (define_insn "*truncdfsf2_media"
@@ -10865,6 +11554,36 @@
   [(set_attr "type" "fp")
    (set_attr "fp_mode" "double")])
 
+(define_insn "truncdfsf2_i1"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=z")
+	(float_truncate:SF (reg:DF R4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && !TARGET_SH2E"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
+(define_insn "truncdfsf2_i2e"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=w")
+	(float_truncate:SF (reg:DF R4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI FPUL_REG))
+   (clobber (reg:SI R0_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && TARGET_SH2E"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 ;; Bit field extract patterns.  These give better code for packed bitfields,
 ;; because they allow auto-increment addresses to be generated.
 
@@ -11238,6 +11957,28 @@
 	bxor.b\\t%2,@(0,%t1)\;movt\\t%0"
   [(set_attr "length" "6,6")])
 
+(define_expand "lrintsfsi2"
+  [(set (match_operand:SI 0 "general_operand" "")
+	(unspec:SI [(match_operand:SF 1 "fp_arith_reg_operand" "")]
+		   UNSPEC_BUILTIN_ROUND))]
+  "(TARGET_SH4 || TARGET_SH2A_SINGLE) && !optimize_size"
+  "
+{
+  sh_expand_lround (operand0, operand1, 1);
+  DONE;
+}")
+
+(define_expand "lroundsfsi2"
+  [(set (match_operand:SI 0 "general_operand" "")
+	(unspec:SI [(match_operand:SF 1 "fp_arith_reg_operand" "")]
+		   UNSPEC_BUILTIN_ROUND))]
+  "(TARGET_SH4 || TARGET_SH2A_SINGLE) && !optimize_size"
+  "
+{
+  sh_expand_lround (operand0, operand1, 0);
+  DONE;
+}")
+
 
 ;; -------------------------------------------------------------------------
 ;; Peepholes
Index: gcc-4.5.2.orig/libstdc++-v3/src/bitmap_allocator.cc
===================================================================
--- gcc-4.5.2.orig/libstdc++-v3/src/bitmap_allocator.cc	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/libstdc++-v3/src/bitmap_allocator.cc	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -3,6 +3,8 @@
 // Copyright (C) 2004, 2005, 2006, 2007, 2008, 2009
 // Free Software Foundation, Inc.
 //
+// Copyright (C) 2009 STMicroelectronics
+//
 // This file is part of the GNU ISO C++ Library.  This library is free
 // software; you can redistribute it and/or modify it under the
 // terms of the GNU General Public License as published by the
@@ -49,6 +51,7 @@
   {
 #if defined __GTHREADS
     __mutex_type& __bfl_mutex = _M_get_mutex();
+    __bfl_mutex.lock(); 
 #endif
     const vector_type& __free_list = _M_get_free_list();
     using __gnu_cxx::__detail::__lower_bound;
Index: gcc-4.5.2.orig/libstdc++-v3/ChangeLog.STM
===================================================================
--- gcc-4.5.2.orig/libstdc++-v3/ChangeLog.STM	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/libstdc++-v3/ChangeLog.STM	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,28 @@
+2009-10-06  Antony King  <antony.king@st.com>
+
+	INSbl30052:
+	* configure.host: Enable atomic builtins for sh*-superh-elf.
+	* acinclude.m4 [GLIBCXX_ENABLE_ATOMIC_BUILTINS]: Add check for
+	enable_atomic_builtins.
+	* configure: Regenerate.
+
+2009-02-24  Antony King  <antony.king@st.com>
+	    Christian Bruel  <christian.bruel@st.com>
+
+	INSbl30245:
+	* src/bitmap_allocator.cc (_M_get): lock mutex.
+
+2009-02-24  Antony King  <antony.king@st.com>
+	    Christian Bruel  <christian.bruel@st.com>
+
+	INSbl28513:
+	* include/ext/concurrence.h (__scoped_gmutex_lock): Defined.
+	(__mutex:_M_init): Declare and initialize.
+	(__recursive_mutex:_M_init): Idem.
+	(__mutex:lock): Initialize mutex if needed.
+	(__recursive_mutex:lock): Idem.
+	* libsupc++/eh_globals.cc (__cxa_get_globals): Initialize eh_globals.
+	(__eh_globals_init:_M_create): New function
+	(__eh_globals_init): Initialize _M_once.
+	(__cxa_get_globals): Call init_create once.
+	
Index: gcc-4.5.2.orig/libstdc++-v3/configure.host
===================================================================
--- gcc-4.5.2.orig/libstdc++-v3/configure.host	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/libstdc++-v3/configure.host	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -330,6 +330,9 @@
 	;;
     esac
     ;;
+  sh*-superh-elf)
+    enable_atomic_builtins=yes
+    ;;
   powerpc*-*-darwin*)
     port_specific_symbol_files="\$(srcdir)/../config/os/bsd/darwin/ppc-extra.ver"
     ;;
Index: gcc-4.5.2.orig/libstdc++-v3/include/ext/concurrence.h
===================================================================
--- gcc-4.5.2.orig/libstdc++-v3/include/ext/concurrence.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/libstdc++-v3/include/ext/concurrence.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -3,6 +3,8 @@
 // Copyright (C) 2003, 2004, 2005, 2006, 2007, 2009
 // Free Software Foundation, Inc.
 //
+// Copyright (C) 2009 STMicroelectronics
+//
 // This file is part of the GNU ISO C++ Library.  This library is free
 // software; you can redistribute it and/or modify it under the
 // terms of the GNU General Public License as published by the
@@ -31,6 +33,7 @@
 #ifndef _CONCURRENCE_H
 #define _CONCURRENCE_H 1
 
+#include <cstdlib>
 #include <exception>
 #include <bits/gthr.h> 
 #include <bits/functexcept.h>
@@ -99,7 +102,7 @@
 #if __EXCEPTIONS
     throw __concurrence_lock_error();
 #else
-    __builtin_abort();
+    std::abort();
 #endif
   }
 
@@ -109,7 +112,7 @@
 #if __EXCEPTIONS
     throw __concurrence_unlock_error();
 #else
-    __builtin_abort();
+    std::abort();
 #endif
   }
 
@@ -135,16 +138,74 @@
   }
 #endif
  
+#if __GTHREADS
+  class __scoped_gmutex_lock
+  {
+  private:
+    __scoped_gmutex_lock(const __scoped_gmutex_lock&);
+    __scoped_gmutex_lock& operator=(const __scoped_gmutex_lock&);
+
+    class __mutex_type
+    {
+    public:
+      __gthread_mutex_t _M_mutex;
+      __gthread_once_t  _M_once;
+
+      __mutex_type() : _M_once(__GTHREAD_ONCE_INIT) { }
+
+      ~__mutex_type() { }
+
+      void
+      _M_create()
+      {
+#if defined __GTHREAD_MUTEX_INIT
+	__gthread_mutex_t __tmp = __GTHREAD_MUTEX_INIT;
+	_M_mutex = __tmp;
+#else
+	__GTHREAD_MUTEX_INIT_FUNCTION(&_M_mutex);
+#endif
+      }
+    };
+
+    static __mutex_type _M_device;
+
+    static void
+    __M_device_create()
+    { _M_device._M_create(); }
+
+  public:
+    explicit __scoped_gmutex_lock()
+    {
+      // Do not need to check __gthread_active_p() as assume already
+      // checked before a sentry is created.
+      __gthread_once(&_M_device._M_once, __M_device_create);
+
+      if (__gthread_mutex_lock(&_M_device._M_mutex) != 0)
+	__throw_concurrence_lock_error();
+    }
+
+    ~__scoped_gmutex_lock() throw()
+    {
+      if (__gthread_mutex_unlock(&_M_device._M_mutex) != 0)
+	__throw_concurrence_unlock_error();
+    }
+  };
+
+  __scoped_gmutex_lock::__mutex_type __attribute__((weak))
+    __scoped_gmutex_lock::_M_device;
+#endif
+
   class __mutex 
   {
   private:
     __gthread_mutex_t _M_mutex;
+    bool	      _M_init;
 
     __mutex(const __mutex&);
     __mutex& operator=(const __mutex&);
 
   public:
-    __mutex() 
+    __mutex() : _M_init(false)
     { 
 #if __GTHREADS
       if (__gthread_active_p())
@@ -155,6 +216,7 @@
 #else
 	  __GTHREAD_MUTEX_INIT_FUNCTION(&_M_mutex); 
 #endif
+          _M_init = true;
 	}
 #endif 
     }
@@ -164,6 +226,21 @@
 #if __GTHREADS
       if (__gthread_active_p())
 	{
+	  if (__builtin_expect(_M_init == false, false))
+	    {
+	      __scoped_gmutex_lock sentry;
+	      if (_M_init == false)
+		{
+#if defined __GTHREAD_MUTEX_INIT
+		  __gthread_mutex_t __tmp = __GTHREAD_MUTEX_INIT;
+		  _M_mutex = __tmp;
+#else
+		  __GTHREAD_MUTEX_INIT_FUNCTION(&_M_mutex);
+#endif
+		  _M_init = true;
+		}
+	    }
+
 	  if (__gthread_mutex_lock(&_M_mutex) != 0)
 	    __throw_concurrence_lock_error();
 	}
@@ -189,12 +266,13 @@
   {
   private:
     __gthread_recursive_mutex_t _M_mutex;
+    bool			_M_init;
 
     __recursive_mutex(const __recursive_mutex&);
     __recursive_mutex& operator=(const __recursive_mutex&);
 
   public:
-    __recursive_mutex() 
+    __recursive_mutex()  : _M_init(false)
     { 
 #if __GTHREADS
       if (__gthread_active_p())
@@ -205,6 +283,7 @@
 #else
 	  __GTHREAD_RECURSIVE_MUTEX_INIT_FUNCTION(&_M_mutex); 
 #endif
+          _M_init = true;
 	}
 #endif 
     }
@@ -214,6 +293,22 @@
 #if __GTHREADS
       if (__gthread_active_p())
 	{
+	  if (__builtin_expect(_M_init == false, false))
+	    {
+	      __scoped_gmutex_lock sentry;
+	      if (_M_init == false)
+		{
+#if defined __GTHREAD_RECURSIVE_MUTEX_INIT
+		  __gthread_recursive_mutex_t __tmp =
+		    __GTHREAD_RECURSIVE_MUTEX_INIT;
+		  _M_mutex = __tmp;
+#else
+		  __GTHREAD_RECURSIVE_MUTEX_INIT_FUNCTION(&_M_mutex);
+#endif
+		  _M_init = true;
+		}
+	    }
+
 	  if (__gthread_recursive_mutex_lock(&_M_mutex) != 0)
 	    __throw_concurrence_lock_error();
 	}
Index: gcc-4.5.2.orig/libstdc++-v3/libsupc++/eh_globals.cc
===================================================================
--- gcc-4.5.2.orig/libstdc++-v3/libsupc++/eh_globals.cc	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/libstdc++-v3/libsupc++/eh_globals.cc	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2,6 +2,8 @@
 // Copyright (C) 2001, 2002, 2003, 2004, 2005, 2006, 2009
 // Free Software Foundation, Inc.
 //
+// Copyright (c) 2009  STMicroelectronics.
+//
 // This file is part of GCC.
 //
 // GCC is free software; you can redistribute it and/or modify
@@ -29,6 +31,7 @@
 #include "cxxabi.h"
 #include "unwind-cxx.h"
 #include "bits/gthr.h"
+#include <ext/concurrence.h>
 
 #if _GLIBCXX_HOSTED
 using std::free;
@@ -62,7 +65,6 @@
 __cxxabiv1::__cxa_get_globals() throw()
 { return get_global(); }
 
-
 #else
 
 // Single-threaded fallback buffer.
@@ -92,12 +94,10 @@
 {
   __gthread_key_t  	_M_key;
   bool 			_M_init;
+  __gthread_once_t	_M_once;
 
-  __eh_globals_init() : _M_init(false)
-  { 
-    if (__gthread_active_p())
-      _M_init = __gthread_key_create(&_M_key, eh_globals_dtor) == 0; 
-  }
+  __eh_globals_init() : _M_init(false), _M_once(__GTHREAD_ONCE_INIT)
+  { }
 
   ~__eh_globals_init()
   {
@@ -105,14 +105,23 @@
       __gthread_key_delete(_M_key);
     _M_init = false;
   }
+
+  inline void
+  _M_create()
+  { _M_init = __gthread_key_create(&_M_key, eh_globals_dtor) == 0; }
 };
 
 static __eh_globals_init init;
 
+static void
+init_create()
+{ init._M_create(); }
+
 extern "C" __cxa_eh_globals*
 __cxxabiv1::__cxa_get_globals_fast() throw()
 {
   __cxa_eh_globals* g;
+
   if (init._M_init)
     g = static_cast<__cxa_eh_globals*>(__gthread_getspecific(init._M_key));
   else
@@ -124,6 +133,11 @@
 __cxxabiv1::__cxa_get_globals() throw()
 {
   __cxa_eh_globals* g;
+
+  if (__builtin_expect(init._M_init == false, false)
+      && __gthread_active_p())
+    __gthread_once(&init._M_once, init_create);
+
   if (init._M_init)
     {
       g = static_cast<__cxa_eh_globals*>(__gthread_getspecific(init._M_key));
Index: gcc-4.5.2.orig/libstdc++-v3/acinclude.m4
===================================================================
--- gcc-4.5.2.orig/libstdc++-v3/acinclude.m4	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/libstdc++-v3/acinclude.m4	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -2587,7 +2587,8 @@
 
     AC_MSG_CHECKING([for atomic builtins for bool])
     if AC_TRY_EVAL(ac_compile); then
-      if grep __sync_ conftest.s >/dev/null 2>&1 ; then
+      if test x$enable_atomic_builtins != xyes && \
+      grep __sync_ conftest.s >/dev/null 2>&1 ; then
         glibcxx_cv_atomic_bool=no
       else
       AC_DEFINE(_GLIBCXX_ATOMIC_BUILTINS_1, 1,
@@ -2617,7 +2618,8 @@
 
     AC_MSG_CHECKING([for atomic builtins for short])
     if AC_TRY_EVAL(ac_compile); then
-      if grep __sync_ conftest.s >/dev/null 2>&1 ; then
+      if test x$enable_atomic_builtins != xyes && \
+      grep __sync_ conftest.s >/dev/null 2>&1 ; then
         glibcxx_cv_atomic_short=no
       else
       AC_DEFINE(_GLIBCXX_ATOMIC_BUILTINS_2, 1,
@@ -2648,7 +2650,8 @@
 
     AC_MSG_CHECKING([for atomic builtins for int])
     if AC_TRY_EVAL(ac_compile); then
-      if grep __sync_ conftest.s >/dev/null 2>&1 ; then
+      if test x$enable_atomic_builtins != xyes && \
+      grep __sync_ conftest.s >/dev/null 2>&1 ; then
         glibcxx_cv_atomic_int=no
       else
       AC_DEFINE(_GLIBCXX_ATOMIC_BUILTINS_4, 1,
@@ -2678,7 +2681,8 @@
 
     AC_MSG_CHECKING([for atomic builtins for long long])
     if AC_TRY_EVAL(ac_compile); then
-      if grep __sync_ conftest.s >/dev/null 2>&1 ; then
+      if test x$enable_atomic_builtins != xyes && \
+      grep __sync_ conftest.s >/dev/null 2>&1 ; then
         glibcxx_cv_atomic_long_long=no
       else
       AC_DEFINE(_GLIBCXX_ATOMIC_BUILTINS_8, 1,
Index: gcc-4.5.2.orig/configure.ac
===================================================================
--- gcc-4.5.2.orig/configure.ac	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/configure.ac	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1512,7 +1512,7 @@
 # Check for PPL
 ppl_major_version=0
 ppl_minor_version=10
-ppllibs=" -lppl_c -lppl -lgmpxx"
+ppllibs=" -lppl_c -lppl -lgmpxx $with_host_libstdcxx"
 pplinc=
 
 AC_ARG_WITH(ppl, [  --with-ppl=PATH         Specify prefix directory for the installed PPL package
@@ -2451,12 +2451,19 @@
     ;;
 esac
 
-alphaieee_frag=/dev/null
+ieee_frag=/dev/null
 case $target in
-  alpha*-*-*)
+  alpha*-*-* | sh*-*-*)
     # This just makes sure to use the -mieee option to build target libs.
     # This should probably be set individually by each library.
-    alphaieee_frag="config/mt-alphaieee"
+    ieee_frag="config/mt-ieee"
+    ;;
+esac
+
+relax_frag=/dev/null
+case $target in
+  sh-superh-elf)
+    relax_frag="config/mt-relax"
     ;;
 esac
 
@@ -3030,7 +3037,7 @@
        # to it.  This is right: we don't want to search that directory
        # for binaries, but we want the header files in there, so add
        # them explicitly.
-       FLAGS_FOR_TARGET=$FLAGS_FOR_TARGET' -isystem $$r/$(HOST_SUBDIR)/gcc/include'
+       FLAGS_FOR_TARGET=$FLAGS_FOR_TARGET' -isystem $$r/$(HOST_SUBDIR)/gcc/include -isystem $$r/$(HOST_SUBDIR)/gcc/include-fixed'
 
        # Someone might think of using the pre-installed headers on
        # Canadian crosses, in case the installed compiler is not fully
@@ -3117,7 +3124,7 @@
 esac
 
 # Makefile fragments.
-for frag in host_makefile_frag target_makefile_frag alphaieee_frag ospace_frag;
+for frag in host_makefile_frag target_makefile_frag ieee_frag ospace_frag relax_frag;
 do
   eval fragval=\$$frag
   if test $fragval != /dev/null; then
@@ -3126,8 +3133,9 @@
 done
 AC_SUBST_FILE(host_makefile_frag)
 AC_SUBST_FILE(target_makefile_frag)
-AC_SUBST_FILE(alphaieee_frag)
+AC_SUBST_FILE(ieee_frag)
 AC_SUBST_FILE(ospace_frag)
+AC_SUBST_FILE(relax_frag)
 
 # Miscellanea: directories, flags, etc.
 AC_SUBST(RPATH_ENVVAR)
Index: gcc-4.5.2.orig/Makefile.tpl
===================================================================
--- gcc-4.5.2.orig/Makefile.tpl	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/Makefile.tpl	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -506,8 +506,9 @@
 
 #### host and target specific makefile fragments come in here.
 @target_makefile_frag@
-@alphaieee_frag@
 @ospace_frag@
+@ieee_frag@
+@relax_frag@
 @host_makefile_frag@
 ###
 
Index: gcc-4.5.2.orig/include/ChangeLog.STM
===================================================================
--- gcc-4.5.2.orig/include/ChangeLog.STM	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/include/ChangeLog.STM	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,3 @@
+2006-03-27  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* libiberty.h: Add support for cygpath.c.
Index: gcc-4.5.2.orig/include/libiberty.h
===================================================================
--- gcc-4.5.2.orig/include/libiberty.h	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/include/libiberty.h	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -3,6 +3,8 @@
    Copyright 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005,
    2006, 2007, 2008, 2009 Free Software Foundation, Inc.
    
+   Copyright (C) 2006 STMicroelectronics
+   
    Note - certain prototypes declared in this header file are for
    functions whoes implementation copyright does not belong to the
    FSF.  Those prototypes are present in this file for reference
@@ -657,9 +659,21 @@
    (char *) memcpy (libiberty_nptr, libiberty_optr, libiberty_len))
 #endif
 
+#ifdef __MINGW32__
+/* Reassign the pointer PATH without freeing anything.  */
+extern char *cygpath (const char *path);
+#define CYGPATH(path) do {path = cygpath (path);} while(0)
+
+/* Reassign the pointer PATH and free the previous content.  */
+extern void cygpath_replace (char **path);
+#else
+/* If these were properly empty statements then there might be warnings
+   which would kill a -Werror build.  */
+#define CYGPATH(path) do {} while (0)
+#endif
+
 #ifdef __cplusplus
 }
 #endif
 
-
 #endif /* ! defined (LIBIBERTY_H) */
Index: gcc-4.5.2.orig/libiberty/configure.ac
===================================================================
--- gcc-4.5.2.orig/libiberty/configure.ac	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/libiberty/configure.ac	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -185,6 +185,7 @@
   *-*-freebsd2.2.[[012]])	frag=mh-fbsd21 ;;
   i370-*-opened*)       frag=mh-openedition ;;
   i[[34567]]86-*-windows*)	frag=mh-windows ;;
+  *-*-mingw*)		frag=mh-mingw ;;
 esac
 
 if [[ -n "${frag}" ]]; then
Index: gcc-4.5.2.orig/libiberty/wrap_file.c
===================================================================
--- gcc-4.5.2.orig/libiberty/wrap_file.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/libiberty/wrap_file.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,138 @@
+/*
+  THIS FILE HAS BEEN MODIFIED OR ADDED BY STMicroelectronics, Inc. 1999-2009
+*/
+/*
+ * wrap_fopen.c
+ *
+ * This file redefines the standard library functions 
+ * open, create, fopen, fdopen, freopen, remove, rename, unlink, stat for native WIN32 build.
+ * Its purpose is to preprocess argument strings in order to
+ * convert CYGWIN like paths specifiers into native WIN32 paths
+ * It uses the GNU ld -wrap functionality to replace
+ * at link time calls to fopen into calls to __wrap_fopen.
+ *
+ * This file must be linked with any DLL or EXE object
+ * and the linker command line must have the following  option:
+ * -Wl,-wrap,open,-wrap,creat,-wrap,fopen,-wrap,freopen,-wrap,remove,-wrap,rename,-wrap,unlink,-wrap,stat
+ *
+ */
+
+#ifdef __MINGW32__
+#include <stdio.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <dirent.h>
+#include <unistd.h>
+
+#include "libiberty.h"
+
+/*
+ * Declare real versions of functions.
+ */
+extern int __real_open (const char *pathname, int flags, mode_t mode);
+extern int __real_creat (const char *pathname, mode_t mode);
+extern FILE *__real_fopen (const char *path, const char *mode);
+extern FILE *__real_freopen (const char *path, const char *mode, FILE *stream);
+extern int __real_unlink (const char *pathname);
+extern int __real_remove (const char *pathname);
+extern int __real_stat (const char *file_name, struct stat *buf);
+extern int __real_chdir (const char *path);
+extern int __real_rmdir (const char *pathname); 
+extern DIR *__real_opendir (const char *name);
+extern int __real_access (const char *pathname, int mode);
+
+/*
+ * Following is the implementation of replacement functions.
+ */
+int 
+__wrap_open (const char *pathname, int flags, mode_t mode)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_open (path, flags, mode);
+  return r;
+}
+
+int 
+__wrap_creat (const char *pathname, mode_t mode)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_creat (path, mode);
+  return r;
+}
+
+FILE *
+__wrap_fopen (const char *pathname, const char *mode)
+{
+  FILE *f;
+  char *path = cygpath (pathname);
+  f = __real_fopen (path, mode);
+  return f;
+}
+
+FILE *__wrap_freopen (const char *pathname, const char *mode, FILE *stream)
+{
+  FILE *f;
+  char *path = cygpath (pathname);
+  f = __real_freopen (path, mode, stream);
+  return f;
+}
+
+int __wrap_unlink (const char *pathname) 
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_unlink (path);
+  return r;
+}
+
+int __wrap_remove (const char *pathname)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_remove (path);
+  return r;
+}
+
+int __wrap_stat(const char *pathname, struct stat *buf)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_stat (path, buf);
+  return r;
+}
+
+int __wrap_chdir(const char *pathname)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_chdir (path);
+  return r;
+}
+
+int __wrap_rmdir(const char *pathname)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_rmdir (path);
+  return r;
+}
+
+DIR *__wrap_opendir(const char *pathname)
+{
+  DIR *d;
+  char *path = cygpath (pathname);
+  d = __real_opendir (path);
+  return d;
+}
+
+int __wrap_access(const char *pathname, int mode)
+{
+  int r; 
+  char *path = cygpath (pathname);
+  r = __real_access (path, mode);
+  return r;
+}
+
+#endif /* __MINGW32__ */
Index: gcc-4.5.2.orig/libiberty/cygpath.c
===================================================================
--- gcc-4.5.2.orig/libiberty/cygpath.c	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/libiberty/cygpath.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,358 @@
+/* Basic Cygwin pathname support for MinGW.
+
+   Copyright (C) 2006 STMicroelectronics
+
+   This file is part of the libiberty library.
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 2 of the License, or
+   (at your option) any later version.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 51 Franklin Street - Fifth Floor,
+   Boston, MA 02110-1301, USA.
+
+
+   This file implements a limited amount of support for Cygwin paths.
+   It is intended for use by MinGW programs that must interact with Cygwin.
+
+   It is limited to absolute paths only.  I.e. Those beginning with Cygwin
+   mounts, such as /cygdrive/...  See the comment on cygpath() below.  */
+
+#include "libiberty.h"
+#include <string.h>
+#include <ctype.h>
+#include <windows.h>
+
+
+/* These are all the possible settings for the ST_CYGPATH_MODE
+   environment variable.  */
+static enum
+{
+  mode_unset,
+  mode_off,
+  mode_normal,
+  mode_full
+} mode = mode_unset;
+
+
+/* These are the values extracted from the registry.
+   They are extracted the first time cygpath is called.  */
+static const char *cygdrive = NULL;
+static struct mount
+{
+  /* The name of the Cygwin mount point.  E.g. "/usr/bin"  */
+  char *mount;
+
+  /* The actual Windows path that the mount translates to.  */
+  char *actual;
+
+  struct mount *next;
+} *mounts = NULL;
+
+
+/* Read a string from the Windows Registry.
+   KEY should be a valid handle from RegOpenKeyEx().
+   NAME should be the name of the value within the key.
+   The value should be of type REG_SZ.
+   If the value does not exist, is of the wrong typei, or another error
+   occurs, then NULL is returned.
+   Otherwise a malloced string is returned.  */
+static char *
+read_string_from_registry (HKEY key, const char *name)
+{
+  DWORD valuetype = REG_NONE;
+  DWORD valuesize = 0;
+  char *value = NULL;
+
+  if (RegQueryValueEx (key, name, NULL, &valuetype,
+		       NULL, &valuesize) == ERROR_SUCCESS
+      && valuetype == REG_SZ)
+    {
+      value = (char *)xmalloc (valuesize);
+      if (RegQueryValueEx (key, name, NULL, &valuetype, (unsigned char *)value,
+			   &valuesize) != ERROR_SUCCESS)
+	{
+	  free (value);
+	  value = NULL;
+	}
+    }
+
+  return value;
+}
+
+
+/* Fill in the mounts list (mounts is defined statically above).
+   All subkeys (not values) of KEY that contain a REG_SZ value named 'native'
+   are added to the start of the mounts list.  */
+static void
+read_mounts (HKEY key)
+{
+  int mountsize = 15;
+  char *mount = (char *)xmalloc (mountsize);
+  DWORD size = mountsize;
+  int index = 0;
+  int retval = 0;
+
+  /* For each subkey ...  */
+  while ((retval = RegEnumKeyEx (key, index, mount, &size, 0, NULL, 0, NULL))
+	 != ERROR_NO_MORE_ITEMS)
+    {
+      struct mount *newmount;
+      HKEY subkey;
+      char *actual;
+
+      switch (retval) {
+      case ERROR_MORE_DATA:
+	/* The buffer wasn't large enough for this key name.
+	   Unlike RegQueryValueEx, RegEnumKeyEx won't tell us how big it
+	   should be, so just make it bigger and try again.
+	   Note that this code path does NOT increment index.
+       	   Most of the time we will only be dealing with short strings.  */
+	mountsize += 10;
+	mount = (char *)xrealloc (mount, mountsize);
+	break;
+
+      case ERROR_SUCCESS:
+	/* Find the actual windows path.  */
+  	if (RegOpenKeyEx (key, mount, 0, KEY_READ, &subkey) != ERROR_SUCCESS)
+	  {
+	    index++;
+	    break;
+	  }
+	actual = read_string_from_registry (subkey, "native");	
+	RegCloseKey (subkey);
+	if (actual == NULL)
+	  {
+	    index++;
+	    break;
+	  }
+
+	/* Create the new entry in the mount table.  */
+	newmount = (struct mount *)xmalloc (sizeof (struct mount));
+	newmount->mount = xstrdup (mount);
+	newmount->actual = actual;
+	newmount->next = mounts;
+	mounts = newmount;
+	index++;
+	break;
+
+      default:
+	/* Don't infinite loop should any other return value occur.  */
+        index++;
+      }
+
+      /* The last call to RegEnumKeyEx may have clobbered size.
+         Fix it before the next call.  */
+      size = mountsize;
+    }
+
+  free (mount);
+}
+
+
+/* The top level registry reading function.
+   Open the keys, call the above functions to get the right values,
+   and clean up.  */
+static void
+read_registry (void)
+{
+  HKEY hcu_key, hlm_key;
+
+  /* Get key handles for the two places cygwin keeps its registry data.  */
+  if (RegOpenKeyEx (HKEY_CURRENT_USER,
+		    "Software\\Cygnus Solutions\\Cygwin\\mounts v2",
+		    0, KEY_READ, &hcu_key) != ERROR_SUCCESS)
+    hcu_key = NULL;
+
+  if (RegOpenKeyEx (HKEY_LOCAL_MACHINE,
+		    "SOFTWARE\\Cygnus Solutions\\Cygwin\\mounts v2",
+		    0, KEY_READ, &hlm_key) != ERROR_SUCCESS)
+    hlm_key = NULL;
+
+  /* Get the virtual mount point used for windows drives.  */
+  if (hcu_key)
+    cygdrive = read_string_from_registry (hcu_key, "cygdrive prefix");
+  if (hlm_key && cygdrive == NULL)
+    cygdrive = read_string_from_registry (hlm_key, "cygdrive prefix");
+
+  /* Read the other mount points.
+     Read hlm before hcu to ensure hcu settings get used by preference
+     by being closer on the mounts stack.  */
+  if (hlm_key)
+    read_mounts (hlm_key);
+  if (hcu_key)
+    read_mounts (hcu_key);
+
+  if (hlm_key)
+    RegCloseKey (hlm_key);
+  if (hcu_key)
+    RegCloseKey (hcu_key);
+}
+
+
+/* Given a path of unknown variety, return the same path with any
+   Cygwin mount points substituted.
+   This function always returns a malloced string which should be
+   freed when the the caller is finished with it.
+
+   The mapping is affected by the ST_CYGPATH_MODE environment variable.
+   See the fprintf messages below for full information.
+
+   It can replace /cygdrive/<letter>/..... style pathnames, even if the
+   user has used 'mount -c' to an alternative string.
+
+   It can replace (if enabled) other Cygwin mount points, such as
+   the usual '/', '/usr/bin', '/usr/lib', as well as any other user defined
+   mount points.
+
+   It does NOT attempt to convert any pathnames that look like native Windows
+   names - such as those starting with '<letter>:' or double slash (UNC).
+
+   It does NOT handle relative pathnames passing through cygwin mounts
+   (e.g. '../cygdrive/c'), or absolute paths with repeated directory
+   separators or relative elements within the mount name
+   (e.g. '/usr/./bin').
+   
+   It does NOT allow backslash \ directory separators within the actual mount
+   path (e.g. '/usr\bin').  Cygwin does not always allow them there either.  */
+char *
+cygpath (const char *path)
+{
+  char *result = NULL;
+
+  if (path == NULL)
+    return NULL;
+
+  /* If this is the first time this function has been called then read the
+     environment and registry.  */
+  if (mode == mode_unset)
+    {
+      char *env = getenv ("ST_CYGPATH_MODE");
+
+      if (env == NULL || strcmp (env, "normal") == 0)
+    	mode = mode_normal;
+      else if (strcmp (env, "full") == 0)
+	mode = mode_full;
+      else if (strcmp (env, "off") == 0)
+	mode = mode_off;
+
+      if (mode != mode_off)
+	read_registry();
+
+      if (mode == mode_unset)
+	{
+	  /* The variable was set, but not to any known value.
+	     Set up a default and print an informational message
+	     for the user.  */
+	  mode = mode_normal;
+	  fprintf (stderr, "ST_CYGPATH_MODE should be one of:\n");
+	  fprintf (stderr, " off    - Disable all path translation.\n");
+	  fprintf (stderr, " normal - Translate %s only.\n", cygdrive);
+	  fprintf (stderr, " full   - Translate all Cygwin mounts.\n");
+	}
+    }
+
+  /* First, test if this can only be a windows (non-cygwin) path.
+     This includes paths that start with a drive letter or UNC double slash.  */
+  if ((isalpha (path[0]) && path[1] == ':')
+      || ((path[0] == '\\' || path[0] == '/')
+	  && (path[1] == '\\' || path[1] == '/')))
+    result = xstrdup (path);
+
+  /* Second, handle /cygdrive/<letter>/ (or whatever) paths.  */
+  if (!result && cygdrive != NULL && (mode == mode_normal || mode == mode_full))
+    {
+      int length = strlen (cygdrive);
+      /* Note that cygwin does not allow '\\' instead of '/' in cygdrive.  */
+      if (strncmp (cygdrive, path, length) == 0
+	  && (path[length] == '/' || path[length] == '\\'
+	      || path[length] == '\0')
+	  && isalpha (path[length+1]))
+        {
+	  result = (char *)xmalloc (strlen (path) - length+1 + 1);
+	  result[0] = path[length+1];
+	  result[1] = ':';
+	  strcpy (result + 2, path + length + 2);
+	}
+    }
+
+  /* Third, handle other types of cygwin path.  */
+  if (!result && mounts != NULL && mode == mode_full)
+    {
+      int matched = 0;
+      struct mount *foundat = NULL;
+      struct mount *mount = mounts;
+      /* Find the longest matching mount point.
+	 This is important. If we just used the first matching mount point
+	 it would probably always match '/' when '/usr/bin' is right.
+	 Use the first of equal length matches - this allows current-user
+	 mounts to override 'local machine' mounts (can this happen?).
+         It is a match only if the matching part is followed by a directory
+         separator or the end of the path, except for the root mount point.  */
+      while (mount != NULL)
+	{
+	  int length = strlen (mount->mount);
+	  if (strncmp (mount->mount, path, length) == 0
+	      && matched < length
+	      && (length == 1 /* Special case for root mount point '/'.  */
+		  || path[length] == '/' || path[length] == '\\'
+		  || path[length] == '\0'))
+	    {
+	      matched = length;
+	      foundat = mount;
+	    }
+	  mount = mount->next;
+	}
+      if (matched)
+	{
+	  /* There was a match so do the substitution.
+	     If matched is 1 then it can only be the root mount point, in
+	     which case we do not want to remove the matched part as it is the 
+	     directory separator.  */
+	  if (matched == 1)
+	    matched = 0;
+	  result = (char *)xmalloc (strlen (foundat->actual) + strlen (path) + 1
+			    - matched);
+	  strcpy (result, foundat->actual);
+	  strcat (result, path + matched);
+	}
+    }
+
+  if (result)
+    {
+      /* Ensure that the return is never just a drive letter.
+	 This is not a valid directory on Windows, but code often
+	 trims trailing slashes.  */
+      int length = strlen(result);
+      if (result[length-1] == ':')
+	{
+	  result = (char *)xrealloc (result, length+2);
+	  result[length] = '/';
+	  result[length+1] = '\0';
+	}
+      return result;
+    }
+
+  /* If we get here then it must have been some other kind of path.  */
+  return xstrdup (path);
+}
+
+
+/* This is just to make inserting the conversion more convenient.
+   The CYGPATH_REPLACE is conditionally compiled so it is harder to
+   add clean up code to go with it without this.  */
+void
+cygpath_replace (char **path)
+{
+  char *result = cygpath (*path);
+  free (*path);
+  *path = result;
+}
Index: gcc-4.5.2.orig/libiberty/aclocal.m4
===================================================================
--- gcc-4.5.2.orig/libiberty/aclocal.m4	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/libiberty/aclocal.m4	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,223 +1,19 @@
-sinclude(../config/acx.m4)
-sinclude(../config/no-executables.m4)
-sinclude(../config/override.m4)
-sinclude(../config/warnings.m4)
-
-dnl See whether strncmp reads past the end of its string parameters.
-dnl On some versions of SunOS4 at least, strncmp reads a word at a time
-dnl but erroneously reads past the end of strings.  This can cause
-dnl a SEGV in some cases.
-AC_DEFUN(libiberty_AC_FUNC_STRNCMP,
-[AC_REQUIRE([AC_FUNC_MMAP])
-AC_CACHE_CHECK([for working strncmp], ac_cv_func_strncmp_works,
-[AC_TRY_RUN([
-/* Test by Jim Wilson and Kaveh Ghazi.
-   Check whether strncmp reads past the end of its string parameters. */
-#include <sys/types.h>
-
-#ifdef HAVE_FCNTL_H
-#include <fcntl.h>
-#endif
-
-#ifdef HAVE_SYS_MMAN_H
-#include <sys/mman.h>
-#endif
-
-#ifndef MAP_ANON
-#ifdef MAP_ANONYMOUS
-#define MAP_ANON MAP_ANONYMOUS
-#else
-#define MAP_ANON MAP_FILE
-#endif
-#endif
-
-#ifndef MAP_FILE
-#define MAP_FILE 0
-#endif
-#ifndef O_RDONLY
-#define O_RDONLY 0
-#endif
-
-#define MAP_LEN 0x10000
-
-main ()
-{
-#if defined(HAVE_MMAP) || defined(HAVE_MMAP_ANYWHERE)
-  char *p;
-  int dev_zero;
-
-  dev_zero = open ("/dev/zero", O_RDONLY);
-  if (dev_zero < 0)
-    exit (1);
-  
-  p = (char *) mmap (0, MAP_LEN, PROT_READ|PROT_WRITE,
-		     MAP_ANON|MAP_PRIVATE, dev_zero, 0);
-  if (p == (char *)-1)
-    p = (char *) mmap (0, MAP_LEN, PROT_READ|PROT_WRITE,
-		       MAP_ANON|MAP_PRIVATE, -1, 0);
-  if (p == (char *)-1)
-    exit (2);
-  else
-    {
-      char *string = "__si_type_info";
-      char *q = (char *) p + MAP_LEN - strlen (string) - 2;
-      char *r = (char *) p + 0xe;
-
-      strcpy (q, string);
-      strcpy (r, string);
-      strncmp (r, q, 14);
-    }
-#endif /* HAVE_MMAP || HAVE_MMAP_ANYWHERE */
-  exit (0);
-}
-], ac_cv_func_strncmp_works=yes, ac_cv_func_strncmp_works=no,
-  ac_cv_func_strncmp_works=no)
-rm -f core core.* *.core])
-if test $ac_cv_func_strncmp_works = no ; then
-  AC_LIBOBJ([strncmp])
-fi
-])
-
-dnl See if errno must be declared even when <errno.h> is included.
-AC_DEFUN(libiberty_AC_DECLARE_ERRNO,
-[AC_CACHE_CHECK(whether errno must be declared, libiberty_cv_declare_errno,
-[AC_TRY_COMPILE(
-[#include <errno.h>],
-[int x = errno;],
-libiberty_cv_declare_errno=no,
-libiberty_cv_declare_errno=yes)])
-if test $libiberty_cv_declare_errno = yes
-then AC_DEFINE(NEED_DECLARATION_ERRNO, 1,
-  [Define if errno must be declared even when <errno.h> is included.])
-fi
-])
-
-dnl See whether we need a declaration for a function.
-AC_DEFUN(libiberty_NEED_DECLARATION,
-[AC_MSG_CHECKING([whether $1 must be declared])
-AC_CACHE_VAL(libiberty_cv_decl_needed_$1,
-[AC_TRY_COMPILE([
-#include "confdefs.h"
-#include <stdio.h>
-#ifdef HAVE_STRING_H
-#include <string.h>
-#else
-#ifdef HAVE_STRINGS_H
-#include <strings.h>
-#endif
-#endif
-#ifdef HAVE_STDLIB_H
-#include <stdlib.h>
-#endif
-#ifdef HAVE_UNISTD_H
-#include <unistd.h>
-#endif],
-[char *(*pfn) = (char *(*)) $1],
-libiberty_cv_decl_needed_$1=no, libiberty_cv_decl_needed_$1=yes)])
-AC_MSG_RESULT($libiberty_cv_decl_needed_$1)
-if test $libiberty_cv_decl_needed_$1 = yes; then
-  AC_DEFINE([NEED_DECLARATION_]translit($1, [a-z], [A-Z]), 1,
-            [Define if $1 is not declared in system header files.])
-fi
-])dnl
-
-# We always want a C version of alloca() compiled into libiberty,
-# because native-compiler support for the real alloca is so !@#$%
-# unreliable that GCC has decided to use it only when being compiled
-# by GCC.  This is the part of AC_FUNC_ALLOCA that calculates the
-# information alloca.c needs.
-AC_DEFUN(libiberty_AC_FUNC_C_ALLOCA,
-[AC_CACHE_CHECK(whether alloca needs Cray hooks, ac_cv_os_cray,
-[AC_EGREP_CPP(webecray,
-[#if defined(CRAY) && ! defined(CRAY2)
-webecray
-#else
-wenotbecray
-#endif
-], ac_cv_os_cray=yes, ac_cv_os_cray=no)])
-if test $ac_cv_os_cray = yes; then
-  for ac_func in _getb67 GETB67 getb67; do
-    AC_CHECK_FUNC($ac_func, 
-      [AC_DEFINE_UNQUOTED(CRAY_STACKSEG_END, $ac_func, 
-  [Define to one of _getb67, GETB67, getb67 for Cray-2 and Cray-YMP
-   systems. This function is required for alloca.c support on those
-   systems.])  break])
-  done
-fi
-
-AC_CACHE_CHECK(stack direction for C alloca, ac_cv_c_stack_direction,
-[AC_TRY_RUN([find_stack_direction ()
-{
-  static char *addr = 0;
-  auto char dummy;
-  if (addr == 0)
-    {
-      addr = &dummy;
-      return find_stack_direction ();
-    }
-  else
-    return (&dummy > addr) ? 1 : -1;
-}
-main ()
-{
-  exit (find_stack_direction() < 0);
-}], 
-  ac_cv_c_stack_direction=1,
-  ac_cv_c_stack_direction=-1,
-  ac_cv_c_stack_direction=0)])
-AC_DEFINE_UNQUOTED(STACK_DIRECTION, $ac_cv_c_stack_direction,
-  [Define if you know the direction of stack growth for your system;
-   otherwise it will be automatically deduced at run-time.
-        STACK_DIRECTION > 0 => grows toward higher addresses
-        STACK_DIRECTION < 0 => grows toward lower addresses
-        STACK_DIRECTION = 0 => direction of growth unknown])
-])
-
-# AC_LANG_FUNC_LINK_TRY(C)(FUNCTION)
-# ----------------------------------
-# Don't include <ctype.h> because on OSF/1 3.0 it includes
-# <sys/types.h> which includes <sys/select.h> which contains a
-# prototype for select.  Similarly for bzero.
-#
-# This test used to merely assign f=$1 in main(), but that was
-# optimized away by HP unbundled cc A.05.36 for ia64 under +O3,
-# presumably on the basis that there's no need to do that store if the
-# program is about to exit.  Conversely, the AIX linker optimizes an
-# unused external declaration that initializes f=$1.  So this test
-# program has both an external initialization of f, and a use of f in
-# main that affects the exit status.
-#
-m4_define([AC_LANG_FUNC_LINK_TRY(C)],
-[AC_LANG_PROGRAM(
-[/* System header to define __stub macros and hopefully few prototypes,
-    which can conflict with char $1 (); below.
-    Prefer <limits.h> to <assert.h> if __STDC__ is defined, since
-    <limits.h> exists even on freestanding compilers.  Under hpux,
-    including <limits.h> includes <sys/time.h> and causes problems
-    checking for functions defined therein.  */
-#if defined (__STDC__) && !defined (_HPUX_SOURCE)
-# include <limits.h>
-#else
-# include <assert.h>
-#endif
-/* Override any gcc2 internal prototype to avoid an error.  */
-#ifdef __cplusplus
-extern "C"
-{
-#endif
-/* We use char because int might match the return type of a gcc2
-   builtin and then its argument prototype would still apply.  */
-char $1 ();
-/* The GNU C library defines this for functions which it implements
-    to always fail with ENOSYS.  Some functions are actually named
-    something starting with __ and the normal name is an alias.  */
-#if defined (__stub_$1) || defined (__stub___$1)
-choke me
-#else
-char (*f) () = $1;
-#endif
-#ifdef __cplusplus
-}
-#endif
-], [return f != $1;])])
+# generated automatically by aclocal 1.9.6 -*- Autoconf -*-
 
+# Copyright (C) 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004,
+# 2005  Free Software Foundation, Inc.
+# This file is free software; the Free Software Foundation
+# gives unlimited permission to copy and/or distribute it,
+# with or without modifications, as long as this notice is preserved.
+
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY, to the extent permitted by law; without
+# even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+# PARTICULAR PURPOSE.
+
+m4_include([../config/acx.m4])
+m4_include([../config/no-executables.m4])
+m4_include([../config/override.m4])
+m4_include([../config/proginstall.m4])
+m4_include([../config/warnings.m4])
+m4_include([acinclude.m4])
Index: gcc-4.5.2.orig/libiberty/Makefile.in
===================================================================
--- gcc-4.5.2.orig/libiberty/Makefile.in	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/libiberty/Makefile.in	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -124,7 +124,7 @@
 CFILES = alloca.c argv.c asprintf.c atexit.c				\
 	basename.c bcmp.c bcopy.c bsearch.c bzero.c			\
 	calloc.c choose-temp.c clock.c concat.c cp-demangle.c		\
-	 cp-demint.c cplus-dem.c crc32.c				\
+	cp-demint.c cplus-dem.c crc32.c cygpath.c			\
 	dyn-string.c							\
 	fdmatch.c ffs.c fibheap.c filename_cmp.c floatformat.c		\
 	fnmatch.c fopen_unlocked.c					\
@@ -151,7 +151,7 @@
 	tmpnam.c							\
 	unlink-if-ordinary.c						\
 	vasprintf.c vfork.c vfprintf.c vprintf.c vsnprintf.c vsprintf.c	\
-	waitpid.c							\
+	waitpid.c wrap_file.c						\
 	xatexit.c xexit.c xmalloc.c xmemdup.c xstrdup.c xstrerror.c	\
 	 xstrndup.c
 
@@ -182,7 +182,7 @@
 # maint-missing" and "make check".
 CONFIGURED_OFILES = ./asprintf.o ./atexit.o				\
 	./basename.o ./bcmp.o ./bcopy.o ./bsearch.o ./bzero.o		\
-	./calloc.o ./clock.o ./copysign.o				\
+	./calloc.o ./clock.o ./copysign.o cygpath.o			\
 	./_doprnt.o							\
 	./ffs.o								\
 	./getcwd.o ./getpagesize.o ./gettimeofday.o			\
@@ -200,7 +200,7 @@
 	./tmpnam.o							\
 	./vasprintf.o ./vfork.o ./vfprintf.o ./vprintf.o ./vsnprintf.o	\
 	 ./vsprintf.o							\
-	./waitpid.o
+	./waitpid.o ./wrap_file.o
 
 # These files are installed if the library has been configured to do so.
 INSTALLED_HEADERS =                                                     \
@@ -603,6 +603,12 @@
 	else true; fi
 	$(COMPILE.c) $(srcdir)/dyn-string.c $(OUTPUT_OPTION)
 
+ ./cygpath.o: $(srcdir)/cygpath.c $(INCDIR)/ansidecl.h $(INCDIR)/libiberty.h
+	if [ x"$(PICFLAG)" != x ]; then \
+	  $(COMPILE.c) $(PICFLAG) $(srcdir)/cygpath.c -o pic/$@; \
+	else true; fi
+	$(COMPILE.c) $(srcdir)/cygpath.c $(OUTPUT_OPTION)
+
 ./fdmatch.o: $(srcdir)/fdmatch.c config.h $(INCDIR)/ansidecl.h \
 	$(INCDIR)/libiberty.h
 	if [ x"$(PICFLAG)" != x ]; then \
@@ -1128,6 +1134,13 @@
 	else true; fi
 	$(COMPILE.c) $(srcdir)/waitpid.c $(OUTPUT_OPTION)
 
+./wrap_file.o: $(srcdir)/wrap_file.c config.h $(INCDIR)/ansidecl.h \
+	$(INCDIR)/libiberty.h
+	if [ x"$(PICFLAG)" != x ]; then \
+	  $(COMPILE.c) $(PICFLAG) $(srcdir)/wrap_file.c -o pic/$@; \
+	else true; fi
+	$(COMPILE.c) $(srcdir)/wrap_file.c $(OUTPUT_OPTION)
+
 ./xatexit.o: $(srcdir)/xatexit.c config.h $(INCDIR)/ansidecl.h \
 	$(INCDIR)/libiberty.h
 	if [ x"$(PICFLAG)" != x ]; then \
Index: gcc-4.5.2.orig/libiberty/config/mh-mingw
===================================================================
--- gcc-4.5.2.orig/libiberty/config/mh-mingw	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/libiberty/config/mh-mingw	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1 @@
+EXTRA_OFILES=cygpath.o wrap_file.o
Index: gcc-4.5.2.orig/libiberty/configure
===================================================================
--- gcc-4.5.2.orig/libiberty/configure	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/libiberty/configure	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -4828,6 +4828,7 @@
   *-*-freebsd2.2.[012])	frag=mh-fbsd21 ;;
   i370-*-opened*)       frag=mh-openedition ;;
   i[34567]86-*-windows*)	frag=mh-windows ;;
+  *-*-mingw*)		frag=mh-mingw ;;
 esac
 
 if [ -n "${frag}" ]; then
Index: gcc-4.5.2.orig/libiberty/ChangeLog.STM
===================================================================
--- gcc-4.5.2.orig/libiberty/ChangeLog.STM	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/libiberty/ChangeLog.STM	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,34 @@
+2010-04-12  Christian Bruel  <christian.bruel@st.com>
+
+	* wrap_file.c: Fix prototypes.
+	Remove rename wrapper.
+	* cygpath.c: Shut-up warnings.
+
+2010-01-20  Christian Bruel  <christian.bruel@st.com>
+
+	Backport from trunk:
+	2010-01-04  Nobuhiro Iwamatsu <iwamatsu@nigauri.org>
+
+	PR target/42316
+	* configure.ac (PICFLAG): Use -fPIC on SH hosts.
+	* configure: Regenerate.
+
+2009-12-07  Yvan Roux  <yvan.roux@st.com>
+
+	* wrap_file.c: New file.
+	* Makefile.in: Add wrap_file.[co].
+	* config/mh-mingw: Add wrap_file.o.
+
+2006-05-15  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* cygpath.c (cygpath): Convert pathnames consisting only of a
+	drive specifier to a valid directory (e.g 'c:' -> 'c:/').
+
+2006-03-27  Andrew Stubbs  <andrew.stubbs@st.com>
+
+libiberty/
+	* cygpath.c: New file.
+	* config/mh-mingw: New file.
+	* configure.ac: Add mh-mingw makefile fragment when host is MinGW.
+	* configure: Regenerate.
+	* Makefile.in: Add cygpath.[co] .
Index: gcc-4.5.2.orig/config/mt-alphaieee
===================================================================
--- gcc-4.5.2.orig/config/mt-alphaieee	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/config/mt-alphaieee	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,2 +0,0 @@
-CFLAGS_FOR_TARGET += -mieee
-CXXFLAGS_FOR_TARGET += -mieee
Index: gcc-4.5.2.orig/config/mt-ieee
===================================================================
--- gcc-4.5.2.orig/config/mt-ieee	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/config/mt-ieee	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,2 @@
+CFLAGS_FOR_TARGET += -mieee
+CXXFLAGS_FOR_TARGET += -mieee
Index: gcc-4.5.2.orig/config/mt-relax
===================================================================
--- gcc-4.5.2.orig/config/mt-relax	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/config/mt-relax	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,2 @@
+CFLAGS_FOR_TARGET += -mrelax
+# CXXFLAGS_FOR_TARGET += -mrelax
Index: gcc-4.5.2.orig/config/mt-ospace
===================================================================
--- gcc-4.5.2.orig/config/mt-ospace	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/config/mt-ospace	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -1,3 +1,3 @@
 # Build libraries optimizing for space, not speed.
- CFLAGS_FOR_TARGET = -g -Os
- CXXFLAGS_FOR_TARGET = -g -Os
+CFLAGS_FOR_TARGET += -g -Os 
+CXXFLAGS_FOR_TARGET += -g -Os 
Index: gcc-4.5.2.orig/config/mh-mingw
===================================================================
--- gcc-4.5.2.orig/config/mh-mingw	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/config/mh-mingw	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -4,3 +4,7 @@
 CFLAGS += -D__USE_MINGW_ACCESS
 # Increase stack limit to same as Linux default.
 LDFLAGS += -Wl,--stack,8388608
+
+# Activation of CYGPATH feature: Support for cygwin pathes in mingwin32 shell
+#   through syscall wrapping at linker level
+LDFLAGS += -Wl,--wrap,open,--wrap,creat,--wrap,fopen,--wrap,freopen,--wrap,remove,--wrap,unlink,--wrap,stat,--wrap,chdir,--wrap,rmdir,--wrap,opendir,--wrap,access
Index: gcc-4.5.2.orig/libcpp/ChangeLog.STM
===================================================================
--- gcc-4.5.2.orig/libcpp/ChangeLog.STM	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/libcpp/ChangeLog.STM	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,12 @@
+2009-06-10  Antony King  <antony.king@st.com>
+
+	* mkdeps.c (deps_write): Use ISALPHA instead of isalpha.
+	(deps_phony_targets): Likewise.
+
+2007-08-14  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* mkdeps.c (deps_write): Convert paths to Cygwin format on MinGW,
+	if GCC_CYGWIN_DEPS environment variable is set.
+	(deps_phony_targets): Likewise.
+
+
Index: gcc-4.5.2.orig/libcpp/mkdeps.c
===================================================================
--- gcc-4.5.2.orig/libcpp/mkdeps.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/libcpp/mkdeps.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -321,6 +321,17 @@
 	      column++;
 	    }
 	}
+#ifdef __MINGW32__
+      if (getenv ("GCC_CYGWIN_DEPS") != NULL
+	  && ISALPHA (d->targetv[i][0])
+	  && d->targetv[i][1] == ':')
+	{
+	  fputs ("/cygdrive/", fp);
+	  fputc (d->targetv[i][0], fp);
+	  fputs (d->targetv[i]+2, fp);
+	}
+      else
+#endif
       fputs (d->targetv[i], fp);
     }
 
@@ -341,6 +352,17 @@
 	  putc (' ', fp);
 	  column++;
 	}
+#ifdef __MINGW32__
+      if (getenv ("GCC_CYGWIN_DEPS") != NULL
+	  && ISALPHA (d->depv[i][0])
+	  && d->depv[i][1] == ':')
+	{
+	  fputs ("/cygdrive/", fp);
+	  fputc (d->depv[i][0], fp);
+	  fputs (d->depv[i]+2, fp);
+	}
+      else
+#endif
       fputs (d->depv[i], fp);
     }
   putc ('\n', fp);
@@ -354,6 +376,17 @@
   for (i = 1; i < d->ndeps; i++)
     {
       putc ('\n', fp);
+#ifdef __MINGW32__
+      if (getenv ("GCC_CYGWIN_DEPS") != NULL
+	  && ISALPHA (d->depv[i][0])
+	  && d->depv[i][1] == ':')
+	{
+	  fputs ("/cygdrive/", fp);
+	  fputc (d->depv[i][0], fp);
+	  fputs (d->depv[i]+2, fp);
+	}
+      else
+#endif
       fputs (d->depv[i], fp);
       putc (':', fp);
       putc ('\n', fp);
Index: gcc-4.5.2.orig/fixincludes/ChangeLog.STM
===================================================================
--- gcc-4.5.2.orig/fixincludes/ChangeLog.STM	(.../vendor/tags/4.5.2)	(revision 0)
+++ gcc-4.5.2/fixincludes/ChangeLog.STM	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -0,0 +1,20 @@
+2008-28-08  Antony King  <antony.king@st.com>
+
+	* check.tpl: Avoid premature termination of script on fgrep -v
+	failure.
+
+2008-27-08  Christian Bruel  <christian.bruel@st.com>
+
+	* fixincl.c (test_test). Dont quote test.
+
+2007-10-02  Antony King  <antony.king@st.com>
+
+	* fixincl.c (cygpath_open): New function.
+	(load_file): Replace open() with cygpath_open().
+	(create_file): Likewise.
+	(process): Likewise.
+	(initialize): Add calls to CYGPATH() and CYGPATH_FREE().
+	(test_test): Add missing quotes.
+	(fix_with_system): Likewise.
+	(fix_with_system): Force use of Unix shell.
+	(main): Redirect stdin to nul: on Windows.
Index: gcc-4.5.2.orig/fixincludes/check.tpl
===================================================================
--- gcc-4.5.2.orig/fixincludes/check.tpl	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/fixincludes/check.tpl	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -143,9 +143,9 @@
 
 cd $TESTBASE
 
-find * -type f -print | \
+( find * -type f -print | \
 fgrep -v 'CVS/' | \
-fgrep -v '.svn/' > ${TESTDIR}/LIST
+fgrep -v '.svn/' > ${TESTDIR}/LIST ; true )
 
 exitok=`
 exec < ${TESTDIR}/LIST
Index: gcc-4.5.2.orig/fixincludes/fixincl.c
===================================================================
--- gcc-4.5.2.orig/fixincludes/fixincl.c	(.../vendor/tags/4.5.2)	(revision 1626)
+++ gcc-4.5.2/fixincludes/fixincl.c	(.../tags/gcc-st40-4.5.2.110124)	(revision 1626)
@@ -101,6 +101,20 @@
 
 #include "fixincl.x"
 
+static int
+cygpath_open (const char *file, int oflag, mode_t mode)
+{
+  int fd;
+
+#ifdef _O_BINARY
+  oflag |= _O_BINARY;
+#endif
+
+  fd = open (file, oflag, mode);
+
+  return fd;
+}
+
 /* * * * * * * * * * * * * * * * * * *
  *
  *  MAIN ROUTINE
@@ -122,7 +136,11 @@
       and err open so that the proper input file does not get closed
       by accident  */
 
+#if defined(__MSDOS__) || defined(_WIN32)
+  freopen ("nul:", "r", stdin);
+#else
   freopen ("/dev/null", "r", stdin);
+#endif
 
   if (file_name_buf == (char *) NULL)
     {
@@ -211,6 +229,8 @@
 void
 initialize ( int argc, char** argv )
 {
+  char *arg;
+
   xmalloc_set_program_name (argv[0]);
 
   switch (argc)
@@ -221,7 +241,8 @@
     case 2:
       if (strcmp (argv[1], "-v") == 0)
         do_version ();
-      if (freopen (argv[1], "r", stdin) == (FILE*)NULL)
+      arg = argv[1];
+      if (freopen (arg, "r", stdin) == (FILE*)NULL)
         {
           fprintf (stderr, "Error %d (%s) reopening %s as stdin\n",
                    errno, xstrerror (errno), argv[1] );
@@ -325,7 +346,7 @@
       the file size is not a multiple of the page size.  If it is a multiple,
       then this adjustment sometimes fails anyway.  */
   data_map_size = stbf.st_size+1;
-  data_map_fd   = open (fname, O_RDONLY);
+  data_map_fd   = cygpath_open (fname, O_RDONLY, 0);
   ttl_data_size += data_map_size-1;
 
   if (data_map_fd < 0)
@@ -476,7 +497,7 @@
 
   sprintf (fname, "%s/%s", pz_dest_dir, pz_curr_file + find_base_len);
 
-  fd = open (fname, O_WRONLY | O_CREAT | O_TRUNC, S_IRALL);
+  fd = cygpath_open (fname, O_WRONLY | O_CREAT | O_TRUNC, S_IRALL);
 
   /*  We may need to create the directories needed... */
   if ((fd < 0) && (errno == ENOENT))
@@ -501,7 +522,7 @@
         }
 
       /*  Now, lets try the open again... */
-      fd = open (fname, O_WRONLY | O_CREAT | O_TRUNC, S_IRALL);
+      fd = cygpath_open (fname, O_WRONLY | O_CREAT | O_TRUNC, S_IRALL);
     }
   if (fd < 0)
     {
@@ -539,7 +560,7 @@
 test_test (tTestDesc* p_test, char* pz_test_file)
 {
   tSCC cmd_fmt[] =
-"file=%s\n\
+"file='%s'\n\
 if ( test %s ) > /dev/null 2>&1\n\
 then echo TRUE\n\
 else echo FALSE\n\
@@ -852,7 +873,7 @@
 #else
       /* Don't use positional formatting arguments because some lame-o
          implementations cannot cope  :-(.  */
-      tSCC   z_cmd_fmt[] = " %s > %sX ; rm -f %s; mv -f %sX %s";
+      tSCC   z_cmd_fmt[] = " '%s' > '%sX'; rm -f '%s'; mv -f '%sX' '%s'";
 #endif
       tCC**  ppArgs = p_fixd->patch_args;
 
@@ -935,7 +956,34 @@
                pz_temp_file, pz_temp_file, pz_temp_file);
 #endif
     }
+#if 1
+  {
+    char *cmd;
+    char *fname = make_temp_file( 0 );
+    FILE *pf = fopen( fname, "w" );
+    if (pf == NULL)
+      {
+	fprintf (stderr, "Error %d (%s) creating %s\n",
+		 errno, xstrerror (errno), fname);
+	exit (EXIT_FAILURE);
+      }
+    fwrite( pz_cmd, 1, strlen( pz_cmd ), pf );
+    fclose( pf );
+    asprintf( &cmd, "sh %s", fname );
+    if (cmd == NULL)
+      {
+	fprintf (stderr, "Error %d (%s)\n",
+		 errno, xstrerror (errno));
+	exit (EXIT_FAILURE);
+      }
+    system( cmd );
+    free( (void*)cmd );
+    unlink( fname );
+    free( (void*)fname );
+  }
+#else
   system( pz_cmd );
+#endif
   free( (void*)pz_cmd );
 }
 
@@ -1283,7 +1331,7 @@
 
       if (read_fd == -1)
         {
-          read_fd = open (pz_curr_file, O_RDONLY);
+          read_fd = cygpath_open (pz_curr_file, O_RDONLY, 0);
           if (read_fd < 0)
             {
               fprintf (stderr, "Error %d (%s) opening %s\n", errno,
@@ -1337,7 +1385,7 @@
       pz_file_source = pz_temp_file;
     }
 
-  read_fd = open (pz_temp_file, O_RDONLY);
+  read_fd = cygpath_open (pz_temp_file, O_RDONLY, 0);
   if (read_fd < 0)
     {
       if (errno != ENOENT)

Property changes on: .
___________________________________________________________________
Added: svn:mergeinfo
   Merged /vendor/tags/4.4.2:r1174
   Merged /vendor/tags/4.5.2:r1597-1598
   Merged /vendor/branches/4.5:r1356-1596
   Merged /branches/4.3_devs:r554-1184
   Merged /branches/4.4_devs:r1175-1433
Added: svn:externals
   + libada/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/libada/
libjava/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/libjava/
libgfortran/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/libgfortran/
libobjc/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/libobjc/
gcc/java/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/gcc/java/
gcc/ada/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/gcc/ada
gcc/gnattools/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/gcc/gnattools/
gcc/objc/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/gcc/objc
gcc/objcp/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/gcc/objcp
gcc/fortran/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/gcc/fortran
gcc/testsuite/ada/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/gcc/testsuite/ada
gcc/testsuite/objc/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/gcc/testsuite/objc
gcc/testsuite/objc.dg/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/gcc/testsuite/objc.dg
gcc/testsuite/gfortran.dg/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/gcc/testsuite/gfortran.dg
gcc/testsuite/gfortran.fortran-torture/ https://codex.cro.st.com/svnroot/sh4gcc/vendor/tags/4.5.2/gcc/testsuite/gfortran.fortran-torture


